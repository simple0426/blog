<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[证书生成工具cfssl]]></title>
    <url>%2F2020%2F07%2F15%2F%E9%80%9A%E7%94%A8%E6%8A%80%E8%83%BD%2F%E8%AF%81%E4%B9%A6%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7cfssl%2F</url>
    <content type="text"><![CDATA[下载cfssl工具1234567wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64chmod +x cfssl*mv cfssl_linux-amd64 /usr/bin/cfsslmv cfssljson_linux-amd64 /usr/bin/cfssljsonmv cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfo 创建CA初始化配置1234# configcfssl print-defaults config &gt; ca-config.json# csrcfssl print-defaults csr &gt; ca-csr.json CA配置文件-范例1234567891011121314151617181920cat &gt; ca-config.json &lt;&lt;EOF&#123; &quot;signing&quot;: &#123; &quot;default&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot; &#125;, &quot;profiles&quot;: &#123; &quot;kubernetes&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot;, &quot;usages&quot;: [ &quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot; ] &#125; &#125; &#125;&#125;EOF ca-config.json：可以定义多个profiles，分别指定不同的过期时间、使用场景等参数；后续在签名证书时需要使用某个profile signing：表示该证书可用于签名其他证书 server auth：表示client可以用该CA对server提供的证书进行验证 client auth：表示server可以用该CA对client提供的证书进行验证 CA证书签名请求-范例123456789101112131415161718cat &gt; ca-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;kubernetes&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;L&quot;: &quot;Beijing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF CN-Common Name：kube-apiserver从证书中提取该字段作为请求的用户名(User Name)；浏览器使用该字段验证网站是否合法 C-countryName：国家名 ST-stateOrProvinceName：省份 L-localityName：城市名 O-Organization：组织机构名，kube-apiserver从证书中提取该字段作为请求用户所属的组(Group) OU-OrganizationUnitName：组织下的部门名称 hosts：如果hosts字段不为空，则需要指定使用该证书的IP或域名列表 生成CA证书和私钥1234cfssl gencert -initca ca-csr.json | cfssljson -bare ca -ls ca*.pem# 证书信息查看cfssl-certinfo -cert ca.pem CA签发普通证书1234567891011121314151617181920cat &gt; nginx.myapp.com-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;nginx.myapp.com&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot; &#125; ]&#125;EOFcfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes nginx.myapp.com-csr.json | cfssljson -bare nginx.myapp.com]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>cfssl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-二进制方式部署]]></title>
    <url>%2F2020%2F07%2F12%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%B9%E5%BC%8F%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[重度参考 部署一套完整的Kubernetes高可用集群（上） ​部署一套完整的Kubernetes高可用集群（下） 前置条件系统设置 主机数：4台以上 操作系统： CentOS7.x-86_x64 软件版本： docker：19.03 kubernetes：1.18 硬件要求：2核2G以上 网络：主机间互联、且可以连接公网（下载容器镜像） 主机名、MAC地址唯一，在hosts中做手动解析 个别端口放开 关闭swap 12swapoff -ased -i &apos;/swap/s/^/#/&apos; /etc/fstab 时间同步 所有主机时间和互联网时间都需要同步，否则使用证书进行连接认证时会出错 1234yum install -y ntpntpdate times.aliyun.comsystemctl start ntpdsystemctl enable ntpd 关闭防火墙、selinux 123456systemctl stop firewalldsystemctl disable firewalldsystemctl stop iptablessystemctl disable iptablessetenforce 0sed -i &apos;s/=enforcing/=disabled/g&apos; /etc/selinux/config iptables设置：可以查看网桥流量 12345cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsudo sysctl --system 安装docker 使用阿里云镜像源，采用yum方式安装 配置docker-engine 1234567891011121314cat &gt; /etc/docker/daemon.json &lt;&lt;EOF&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;registry-mirrors&quot; : [&quot;https://2x97hcl1.mirror.aliyuncs.com&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;100m&quot; &#125;, &quot;storage-driver&quot;: &quot;overlay2&quot;, &quot;storage-opts&quot;: [ &quot;overlay2.override_kernel_check=true&quot; ]&#125;EOF docker启动并设置开机自启动 123systemctl daemon-reloadsystemctl enable dockersystemctl start docker 架构规划 角色 ip 服务组件 master1(node/LB-master) 192.168.31.211/192.168.31.216(vip) apiserver、scheduler、controller-manager、kubelet、kube-proxy、etcd、nginx、keepalived node1 192.168.31.212 kubelet、kube-proxy、etcd node2 192.168.31.213 kubelet、kube-proxy、etcd master2(node/LB-backup) 192.168.31.214 apiserver、scheduler、controller-manager、kubelet、kube-proxy、nginx、keepalived master节点部署master组件（apiserver、scheduler、controller-manager）和node（kubelet、kube-proxy）组件，所以工作负载也可以在master上运行 etcd部署在3个节点上（211/212/213） k8s集群和etcd使用两台证书(即2个CA) 先实现单master架构，后扩容为多master架构 高可用架构采用nginx+keepalived实现，nginx和keepalived也部署在master节点 部署etcd集群生成etcd证书下载cfssl工具cfssl是一个开源的证书管理工具，使用json生成证书文件，以下使用master作为操作主机 1234567wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64chmod +x cfssl_linux-amd64 cfssljson_linux-amd64 cfssl-certinfo_linux-amd64mv cfssl_linux-amd64 /usr/local/bin/cfsslmv cfssljson_linux-amd64 /usr/local/bin/cfssljsonmv cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfo 制作ca根证书 创建工作目录 12mkdir ~/tls/&#123;etcd,k8s&#125; -pcd ~/tls/etcd/ 创建ca配置文件 12345678910111213141516171819202122232425262728293031323334353637cat &gt; ca-config.json &lt;&lt; EOF&#123; &quot;signing&quot;: &#123; &quot;default&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot; &#125;, &quot;profiles&quot;: &#123; &quot;www&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot;, &quot;usages&quot;: [ &quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot; ] &#125; &#125; &#125;&#125;EOFcat &gt; ca-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;etcd CA&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;Beijing&quot;, &quot;ST&quot;: &quot;Beijing&quot; &#125; ]&#125;EOF 使用cfssl工具生成ca证书 12cfssl gencert -initca ca-csr.json | cfssljson -bare cals ca*.pem 使用ca证书签发etcd证书 创建etcd证书请求文件【hosts字段包含集群的所有节点，可以预留几个ip用于后期集群扩容】 123456789101112131415161718192021222324cat &gt; server-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;etcd&quot;, &quot;hosts&quot;: [ &quot;192.168.31.211&quot;, &quot;192.168.31.212&quot;, &quot;192.168.31.213&quot;, &quot;192.168.31.214&quot;, &quot;192.168.31.215&quot;, &quot;192.168.31.216&quot; ], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot; &#125; ]&#125;EOF 制作证书 12cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=www server-csr.json | cfssljson -bare serverls server*.pem 部署etcd集群 下载二进制文件：https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gz 创建工作目录并解压二进制文件 123mkdir /opt/etcd/&#123;bin,cfg,ssl&#125; -ptar zxvf etcd-v3.4.9-linux-amd64.tar.gzmv etcd-v3.4.9-linux-amd64/&#123;etcd,etcdctl&#125; /opt/etcd/bin/ 创建etcd配置文件 123456789101112cat &gt; /opt/etcd/cfg/etcd.conf &lt;&lt; EOFETCD_NAME=&quot;etcd-1&quot;ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;ETCD_LISTEN_PEER_URLS=&quot;https://192.168.31.211:2380&quot;ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.31.211:2379&quot;#[Clustering]ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.31.211:2380&quot;ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.31.211:2379&quot;ETCD_INITIAL_CLUSTER=&quot;etcd-1=https://192.168.31.211:2380,etcd-2=https://192.168.31.212:2380,etcd-3=https://192.168.31.213:2380&quot;ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;EOF ETCD_NAME：节点名称，集群中唯一 ETCD_DATA_DIR：集群数据目录 ETCD_LISTEN_PEER_URLS：集群通信时的本机地址 ETCD_LISTEN_CLIENT_URLS：本节点提供的客户端服务地址 ETCD_INITIAL_ADVERTISE_PEER_URLS：集群初始化时，通告其他节点本机的通信地址 ETCD_ADVERTISE_CLIENT_URLS：集群初始化时，通告其他节点本机服务地址 ETCD_INITIAL_CLUSTER：集群节点 ETCD_INITIAL_CLUSTER_TOKEN：集群初始化时的认证token ETCD_INITIAL_CLUSTER_STATE：节点加入的集群的状态；NEW为新集群；EXISTING表示加入已有集群 systemd管理etcd 12345678910111213141516171819202122cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF[Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyEnvironmentFile=/opt/etcd/cfg/etcd.confExecStart=/opt/etcd/bin/etcd \--cert-file=/opt/etcd/ssl/server.pem \--key-file=/opt/etcd/ssl/server-key.pem \--peer-cert-file=/opt/etcd/ssl/server.pem \--peer-key-file=/opt/etcd/ssl/server-key.pem \--trusted-ca-file=/opt/etcd/ssl/ca.pem \--peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \--logger=zapRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF 复制证书到配置文件中的路径 1cp ~/tls/etcd/ca*.pem ~/tls/etcd/server*.pem /opt/etcd/ssl/ 启动并设置开机启动【第一台etcd启动时会挂起，只需查看日志和进程是否存在即可】 123systemctl daemon-reloadsystemctl enable etcdsystemctl start etcd 复制文件到其他节点 1234scp -r /opt/etcd/ root@192.168.31.212:/optscp -r /opt/etcd/ root@192.168.31.213:/optscp /usr/lib/systemd/system/etcd.service root@192.168.31.212:/usr/lib/systemd/systemscp /usr/lib/systemd/system/etcd.service root@192.168.31.213:/usr/lib/systemd/system 修改节点2和节点3的配置文件【etcd.conf】，启动服务并设置开机启动 查看集群状态12ETCDCTL_API=3/opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem --endpoints=&quot;https://192.168.31.211:2379,https://192.168.31.212:2379,https://192.168.31.213:2379&quot; endpoint health master节点部署生成kube-apiserver证书 创建ca证书配置文件 1234567891011121314151617181920212223242526272829303132333435363738cat &gt; ca-config.json &lt;&lt; EOF&#123; &quot;signing&quot;: &#123; &quot;default&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot; &#125;, &quot;profiles&quot;: &#123; &quot;kubernetes&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot;, &quot;usages&quot;: [ &quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot; ] &#125; &#125; &#125;&#125;EOFcat &gt; ca-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;kubernetes&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;Beijing&quot;, &quot;ST&quot;: &quot;Beijing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF 生成ca证书 12cfssl gencert -initca ca-csr.json | cfssljson -bare cals ca*.pem 创建kube-apiserver证书请求【hosts中的ip为所有master/LB/VIP ip,为了后期扩容可以预留几个ip】 12345678910111213141516171819202122232425262728293031323334cd TLS/k8scat &gt; server-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;kubernetes&quot;, &quot;hosts&quot;: [ &quot;10.0.0.1&quot;, &quot;127.0.0.1&quot;, &quot;192.168.31.211&quot;, &quot;192.168.31.212&quot;, &quot;192.168.31.213&quot;, &quot;192.168.31.214&quot;, &quot;192.168.31.215&quot;, &quot;192.168.31.216&quot;, &quot;kubernetes&quot;, &quot;kubernetes.default&quot;, &quot;kubernetes.default.svc&quot;, &quot;kubernetes.default.svc.cluster&quot;, &quot;kubernetes.default.svc.cluster.local&quot; ], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF 生成kube-apiserver证书 12cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare serverls server*.pem 下载并解压二进制文件 下载服务端二进制文件：kubernetes-server-linux-amd64.tar.gz 解压二进制文件 12345mkdir -p /opt/kubernetes/&#123;bin,cfg,ssl,logs&#125;tar xzf kubernetes-server-linux-amd64.tar.gzcd kubernetes/server/bin/cp kube-apiserver kube-controller-manager kube-scheduler /opt/kubernetes/bin/cp kubectl /usr/bin apiserver部署 创建apiserver配置文件 1234567891011121314151617181920212223242526272829cat &gt; /opt/kubernetes/cfg/kube-apiserver.conf &lt;&lt; EOFKUBE_APISERVER_OPTS=&quot;--logtostderr=false \\--v=2 \\--log-dir=/opt/kubernetes/logs \\--etcd-servers=https://192.168.31.211:2379,https://192.168.31.212:2379,https://192.168.31.213:2379 \\--bind-address=192.168.31.211 \\--secure-port=6443 \\--advertise-address=192.168.31.211 \\--allow-privileged=true \\--service-cluster-ip-range=10.0.0.0/24 \\--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,NodeRestriction \\--authorization-mode=RBAC,Node \\--enable-bootstrap-token-auth=true \\--token-auth-file=/opt/kubernetes/cfg/token.csv \\--service-node-port-range=30000-32767 \\--kubelet-client-certificate=/opt/kubernetes/ssl/server.pem \\--kubelet-client-key=/opt/kubernetes/ssl/server-key.pem \\--tls-cert-file=/opt/kubernetes/ssl/server.pem \\--tls-private-key-file=/opt/kubernetes/ssl/server-key.pem \\--client-ca-file=/opt/kubernetes/ssl/ca.pem \\--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\--etcd-cafile=/opt/etcd/ssl/ca.pem \\--etcd-certfile=/opt/etcd/ssl/server.pem \\--etcd-keyfile=/opt/etcd/ssl/server-key.pem \\--audit-log-maxage=30 \\--audit-log-maxbackup=3 \\--audit-log-maxsize=100 \\--audit-log-path=/opt/kubernetes/logs/k8s-audit.log&quot;EOF –logtostderr=false：启用日志 –v=2：日志级别 –log-dir：日志目录 –etcd-servers：etcd集群地址 –bind-address：服务监听地址 –secure-port：https端口 –advertise-address：集群通告地址 –allow-privileged：允许开启特权容器 –service-cluster-ip-range：service虚拟ip地址段 –enable-admission-plugins：开启准入控制插件 –authorization-mode：授权模式，开启RBAC授权和Node自管理 –enable-bootstrap-token-auth：开启kubelet的bootstrap机制 –token-auth-file： bootstrap token文件 –service-node-port-range：service的Nodeport端口设置范围 –kubelet-client-*： apiserver访问kubelet客户端的证书 –tls-cert-*：apiserver的https证书 –client-ca-file：客户端证书的ca证书 –service-account-key-file：ca证书的key，用于验证ServiceAccount的tokens –etcd-*：etcd集群证书配置 –audit-log：审计日志配置 复制api-server证书到配置文件中的路径 1cp ~/tls/k8s/ca*.pem ~/tls/k8s/server*.pem /opt/kubernetes/ssl/ bootstrap token文件制作 123cat &gt; /opt/kubernetes/cfg/token.csv &lt;&lt; EOFc47ffb939f5ca36231d9e3121a252940,kubelet-bootstrap,10001,&quot;system:node-bootstrapper&quot;EOF 文件格式：token，用户名，uid，用户组 token生成方式：22972cc804fc8612da9f3c1fc597ac67 systemd管理kube-apiserver 1234567891011cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF[Unit]Description=Kubernetes API ServerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-apiserver.confExecStart=/opt/kubernetes/bin/kube-apiserver \$KUBE_APISERVER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF 服务启动并设置开机启动 123systemctl daemon-reloadsystemctl start kube-apiserversystemctl enable kube-apiserver 授权kubelet-bootstrap用户允许请求证书 123kubectl create clusterrolebinding kubelet-bootstrap \--clusterrole=system:node-bootstrapper \--user=kubelet-bootstrap controller-manager部署 创建配置文件 12345678910111213141516cat &gt; /opt/kubernetes/cfg/kube-controller-manager.conf &lt;&lt; EOFKUBE_CONTROLLER_MANAGER_OPTS=&quot;--logtostderr=false \\--v=2 \\--log-dir=/opt/kubernetes/logs \\--leader-elect=true \\--master=127.0.0.1:8080 \\--bind-address=127.0.0.1 \\--allocate-node-cidrs=true \\--cluster-cidr=10.244.0.0/16 \\--service-cluster-ip-range=10.0.0.0/24 \\--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\--root-ca-file=/opt/kubernetes/ssl/ca.pem \\--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\--experimental-cluster-signing-duration=87600h0m0s&quot;EOF –leader-elect：启动多个controller时自动举行选举形成高可用 –master：通过本地非安全端口连接apiserver –bind-address：绑定地址 –allocate-node-cidrs：允许云厂商设置pod地址 –cluster-cidr：pod地址段 –service-cluster-ip-range：service地址段 –cluster-signing-*：可以为集群范围组件签发证书的ca证书【如kubelet】 –root-ca-file：用于验证ServiceAccount token的ca证书 –service-account-private-key-file：用于验证ServiceAccount token的ca证书的key –experimental-cluster-signing-duration：集群范围签发证书的有效期 systemd管理controller-manager 1234567891011cat &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF[Unit]Description=Kubernetes Controller ManagerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-controller-manager.confExecStart=/opt/kubernetes/bin/kube-controller-manager \$KUBE_CONTROLLER_MANAGER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF 启动服务并设置开机启动 123systemctl daemon-reloadsystemctl start kube-controller-managersystemctl enable kube-controller-manager scheduler部署 创建配置文件 12345678cat &gt; /opt/kubernetes/cfg/kube-scheduler.conf &lt;&lt; EOFKUBE_SCHEDULER_OPTS=&quot;--logtostderr=false \--v=2 \--log-dir=/opt/kubernetes/logs \--leader-elect \--master=127.0.0.1:8080 \--bind-address=127.0.0.1&quot;EOF systemd管理scheduler 1234567891011cat &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF[Unit]Description=Kubernetes SchedulerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-scheduler.confExecStart=/opt/kubernetes/bin/kube-scheduler \$KUBE_SCHEDULER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF 服务启动并设置开机启动 123systemctl daemon-reloadsystemctl start kube-schedulersystemctl enable kube-scheduler 查看组件状态kubectl get cs node节点部署创建目录并复制二进制文件123mkdir -p /opt/kubernetes/&#123;bin,cfg,ssl,logs&#125; cd kubernetes/server/bincp kubelet kube-proxy /opt/kubernetes/bin # 本地拷贝 部署kubelet 创建配置文件 123456789101112cat &gt; /opt/kubernetes/cfg/kubelet.conf &lt;&lt; EOFKUBELET_OPTS=&quot;--logtostderr=false \\--v=2 \\--log-dir=/opt/kubernetes/logs \\--hostname-override=node1 \\--network-plugin=cni \\--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\--config=/opt/kubernetes/cfg/kubelet-config.yml \\--cert-dir=/opt/kubernetes/ssl \\--pod-infra-container-image=registry.aliyuncs.com/google_containers/pause-amd64:3.0&quot;EOF –hostname-override：在集群中的名称，集群中唯一 –network-plugin：启用cni网络插件 –kubeconfig：bootstrap认证后由集群生产的连接apiserver配置文件 –bootstrap-kubeconfig：首次启动(bootstrap)连接apiserver的配置文件 –config：配置参数文件 –cert-dir：kubelet证书生成目录 –pod-infra-container-image：管理pod网络的容器镜像地址 配置参数文件 1234567891011121314151617181920212223242526272829303132cat &gt; /opt/kubernetes/cfg/kubelet-config.yml &lt;&lt; EOFkind: KubeletConfigurationapiVersion: kubelet.config.k8s.io/v1beta1address: 0.0.0.0port: 10250readOnlyPort: 10255cgroupDriver: systemdclusterDNS:- 10.0.0.2clusterDomain: cluster.local failSwapOn: falseauthentication: anonymous: enabled: false webhook: cacheTTL: 2m0s enabled: true x509: clientCAFile: /opt/kubernetes/ssl/ca.pem authorization: mode: Webhook webhook: cacheAuthorizedTTL: 5m0s cacheUnauthorizedTTL: 30sevictionHard: imagefs.available: 15% memory.available: 100Mi nodefs.available: 10% nodefs.inodesFree: 5%maxOpenFiles: 1000000maxPods: 110EOF cgroupDriver：docker的cgroups驱动，默认cgroupfs，需要和docker-engin的配置一致 clusterDNS：集群dns地址，后续安装的dns插件使用 生成bootstrap.kubeconfig 123456789101112131415KUBE_APISERVER=&quot;https://192.168.31.211:6443&quot;TOKEN=&quot;22972cc804fc8612da9f3c1fc597ac67&quot; #与/opt/kubernetes/cfg/token.csv中一样kubectl config set-cluster kubernetes \ --certificate-authority=/opt/kubernetes/ssl/ca.pem \ --embed-certs=true \ --server=$&#123;KUBE_APISERVER&#125; \ --kubeconfig=bootstrap.kubeconfigkubectl config set-credentials &quot;kubelet-bootstrap&quot; \ --token=$&#123;TOKEN&#125; \ --kubeconfig=bootstrap.kubeconfigkubectl config set-context default \ --cluster=kubernetes \ --user=&quot;kubelet-bootstrap&quot; \ --kubeconfig=bootstrap.kubeconfigkubectl config use-context default --kubeconfig=bootstrap.kubeconfig 复制证书到配置文件中的路径 1cp bootstrap.kubeconfig /opt/kubernetes/cfg systemd管理kubelet 123456789101112cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF[Unit]Description=Kubernetes KubeletAfter=docker.service[Service]EnvironmentFile=/opt/kubernetes/cfg/kubelet.confExecStart=/opt/kubernetes/bin/kubelet \$KUBELET_OPTSRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF 服务启动并设置开机启动 123systemctl daemon-reloadsystemctl start kubeletsystemctl enable kubelet 批准kubelet申请加入集群 12kubectl get csrkubectl certificate approve node-csr-MQkj9DZylo2JcofJKBAcM_Aye5jL2oWJfpBdptpW03o 部署kube-proxy 创建配置文件 123456cat &gt; /opt/kubernetes/cfg/kube-proxy.conf &lt;&lt; EOFKUBE_PROXY_OPTS=&quot;--logtostderr=false \\--v=2 \\--log-dir=/opt/kubernetes/logs \\--config=/opt/kubernetes/cfg/kube-proxy-config.yml&quot;EOF 配置参数文件 12345678910cat &gt; /opt/kubernetes/cfg/kube-proxy-config.yml &lt;&lt; EOFkind: KubeProxyConfigurationapiVersion: kubeproxy.config.k8s.io/v1alpha1bindAddress: 0.0.0.0metricsBindAddress: 0.0.0.0:10249clientConnection: kubeconfig: /opt/kubernetes/cfg/kube-proxy.kubeconfighostnameOverride: node1clusterCIDR: 10.0.0.0/24EOF 生成kube-proxy.kubeconfig 创建证书请求 12345678910111213141516171819cat &gt; kube-proxy-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;system:kube-proxy&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF 生成证书 12cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxyls kube-proxy*.pem 基于证书生成kubeconfig 123456789101112131415kubectl config set-cluster kubernetes \ --certificate-authority=/opt/kubernetes/ssl/ca.pem \ --embed-certs=true \ --server=$&#123;KUBE_APISERVER&#125; \ --kubeconfig=kube-proxy.kubeconfigkubectl config set-credentials kube-proxy \ --client-certificate=./kube-proxy.pem \ --client-key=./kube-proxy-key.pem \ --embed-certs=true \ --kubeconfig=kube-proxy.kubeconfigkubectl config set-context default \ --cluster=kubernetes \ --user=kube-proxy \ --kubeconfig=kube-proxy.kubeconfigkubectl config use-context default --kubeconfig=kube-proxy.kubeconfig 将证书复制到配置文件路径 1cp kube-proxy.kubeconfig /opt/kubernetes/cfg/ systemd管理kube-proxy 123456789101112cat &gt; /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF[Unit]Description=Kubernetes ProxyAfter=network.target[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-proxy.confExecStart=/opt/kubernetes/bin/kube-proxy \$KUBE_PROXY_OPTSRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF 服务启动并设置开机启动 123systemctl daemon-reloadsystemctl start kube-proxysystemctl enable kube-proxy 部署cni网络 下载cni插件，并将二进制执行文件移动到默认工作目录 12mkdir /opt/cni/bin -ptar zxvf cni-plugins-linux-amd64-v0.8.6.tgz -C /opt/cni/bin 部署cni网络插件，比如flannel，资源文件修改如下 pod网络修改(net-conf.json) 镜像地址修改 主机间通信节点设置：–iface=eth1 网络插件部署好后node即为Ready状态 授权apiserver访问kubelet1234567891011121314151617181920212223242526272829303132333435363738cat &gt; apiserver-to-kubelet-rbac.yaml &lt;&lt; EOFapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: annotations: rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot; labels: kubernetes.io/bootstrapping: rbac-defaults name: system:kube-apiserver-to-kubeletrules: - apiGroups: - &quot;&quot; resources: - nodes/proxy - nodes/stats - nodes/log - nodes/spec - nodes/metrics - pods/log verbs: - &quot;*&quot;---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: system:kube-apiserver namespace: &quot;&quot;roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-apiserver-to-kubeletsubjects: - apiGroup: rbac.authorization.k8s.io kind: User name: kubernetesEOFkubectl apply -f apiserver-to-kubelet-rbac.yaml 新增node节点 将master上的worker配置文件复制到新增节点上 1234scp -r /opt/&#123;kubernetes,cni&#125; root@192.168.31.212:/optscp -r /opt/&#123;kubernetes,cni&#125; root@192.168.31.213:/optscp /usr/lib/systemd/system/&#123;kubelet,kube-proxy&#125;.service root@192.168.31.212:/usr/lib/systemd/systemscp /usr/lib/systemd/system/&#123;kubelet,kube-proxy&#125;.service root@192.168.31.213:/usr/lib/systemd/system 删除kubelet证书和kubelet.kubeconfig 12rm -f /opt/kubernetes/cfg/kubelet.kubeconfig rm -f /opt/kubernetes/ssl/kubelet* 修改主机名 12/opt/kubernetes/cfg/kubelet.conf /opt/kubernetes/cfg/kube-proxy-config.yml 启动服务并设置开机启动 12345systemctl daemon-reloadsystemctl start kubeletsystemctl enable kubeletsystemctl start kube-proxysystemctl enable kube-proxy 在master节点批准新node申请的证书 12kubectl get csrkubectl certificate approve node-csr-JjEj_4TxUHtHYpwZcEIYhcdZd-ykNafmUlrGFxHxN2E 查看节点状态：kubectl get node 插件部署dashboard部署 下载dashboard资源并修改 将dashboard的访问端口暴露在宿主机上：containers–》ports–》hostPort: 8443 dashboard部署在node02上：nodeName: node2 建立dashboard用户 123456789101112131415161718apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kubernetes-dashboard---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard 登录token获取：kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk &#39;{print $1}&#39;) web访问： https://192.168.31.212:8443/ CoreDNS部署 下载资源文件: 文件1：https://github.com/coredns/deployment/blob/master/kubernetes/coredns.yaml.sed 文件2：https://github.com/coredns/deployment/blob/master/kubernetes/deploy.sh 执行：bash deploy.sh -r 10.0.0.0/24 -i 10.0.0.2 |kubectl apply -f - -r：指定service地址段 -i：指定dns pod的ip 测试：kubectl run -it --rm dns-test --image=busybox:1.28.4 sh nslookup kubernetes metrics-server部署 创建metrics-server证书 1234567891011121314151617181920cat &gt; metrics-server-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;aggregator&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;Hangzhou&quot;, &quot;L&quot;: &quot;Hangzhou&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;4Paradigm&quot; &#125; ]&#125;EOFcfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes metrics-server-csr.json|cfssljson -bare metrics-server 将证书复制到配置文件路径：cp metrics-server*.pem /opt/kubernetes/ssl/ apiserver设置并重启： 12345678--enable-aggregator-routing=true \--requestheader-client-ca-file=/opt/kubernetes/ssl/ca.pem \--requestheader-allowed-names=aggregator \--requestheader-extra-headers-prefix=X-Remote-Extra- \--requestheader-group-headers=X-Remote-Group \--requestheader-username-headers=X-Remote-User \--proxy-client-cert-file=/opt/kubernetes/ssl/metrics-server.pem \--proxy-client-key-file=/opt/kubernetes/ssl/metrics-server-key.pem \ 资源文件下载并修改 修改镜像地址 修改容器启动参数 --kubelet-insecure-tls --kubelet-preferred-address-types=InternalIP 测试：kubectl top node/pod 高可用架构 数据存储etcd：采用3节点组建etcd集群 控制节点 controller-manager、scheduler组件通过自身的选举机制实现高可用【同一时间只有一个组件在工作】 apiserver：通过使用nginx+keepalived实现2个以上的apiserver组件的高可用和负载均衡 公有云一般不支持keepalived，可以使用它们的负载均衡产品（内网免费） 部署新增master节点的组件 将master1上的文件复制到master2 123scp -r /opt/&#123;etcd,cni,kubernetes&#125; root@192.168.31.214:/optscp /usr/lib/systemd/system/kube* root@192.168.31.214:/usr/lib/systemd/systemscp /usr/bin/kubectl root@192.168.31.214:/usr/bin 删除kubelet证书文件 12rm -f /opt/kubernetes/cfg/kubelet.kubeconfigrm -f /opt/kubernetes/ssl/kubelet* 修改配置文件中的主机名和ip 123/opt/kubernetes/cfg/kube-apiserver.conf/opt/kubernetes/cfg/kubelet.conf/opt/kubernetes/cfg/kube-proxy-config.yml 服务启动并设置开机启动 1234567891011systemctl daemon-reloadsystemctl start kube-apiserversystemctl start kube-controller-managersystemctl start kube-schedulersystemctl start kubeletsystemctl start kube-proxysystemctl enable kube-apiserversystemctl enable kube-controller-managersystemctl enable kube-schedulersystemctl enable kubeletsystemctl enable kube-proxy 查看组件状态：kubectl get cs 批准新增节点kubelet证书请求 12kubectl get csrkubectl certificate approve node-csr-vHlBaG92ISuIJqPlyisvVsVE12hA8DTCvuuBTFhSkH0 部署nginx+keepalived 安装软件（主/备） 12yum install epel-release -yyum install nginx keepalived -y nginx配置文件(主/备) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455cat &gt; /etc/nginx/nginx.conf &lt;&lt; &quot;EOF&quot;user nginx;worker_processes auto;error_log /var/log/nginx/error.log;pid /run/nginx.pid;include /usr/share/nginx/modules/*.conf;events &#123; worker_connections 1024;&#125;# 四层负载均衡，为两台Master apiserver组件提供负载均衡stream &#123; log_format main &apos;$remote_addr $upstream_addr - [$time_local] $status $upstream_bytes_sent&apos;; access_log /var/log/nginx/k8s-access.log main; upstream k8s-apiserver &#123; server 192.168.31.211:6443; # Master1 APISERVER IP:PORT server 192.168.31.214:6443; # Master2 APISERVER IP:PORT &#125; server &#123; listen 16443; proxy_pass k8s-apiserver; &#125;&#125;http &#123; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; server &#123; listen 80 default_server; server_name _; location / &#123; &#125; &#125;&#125;EOF keepalived配置文件(主/备) 主备router_id、state、priority不同 1234567891011121314151617181920212223242526272829303132333435cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOFglobal_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id NGINX_MASTER&#125;vrrp_script check_nginx &#123; script &quot;/etc/keepalived/check_nginx.sh&quot;&#125;vrrp_instance VI_1 &#123; state MASTER interface eth1 #虚拟ip绑定及心跳检测通信接口 virtual_router_id 51 # VRRP 路由 ID实例，每个实例是唯一的 priority 100 # 优先级，备服务器设置 90 advert_int 1 # 指定VRRP 心跳包通告间隔时间，默认1秒 authentication &#123; auth_type PASS auth_pass 1111 &#125; # 虚拟IP（VIP） virtual_ipaddress &#123; 192.168.31.216/24 &#125; # 根据脚本执行结果判断是否执行故障转移【0为正常，非0为不正常】 track_script &#123; check_nginx &#125;&#125;EOF 检查nginx状态脚本 1234567891011cat &gt; /etc/keepalived/check_nginx.sh &lt;&lt; &quot;EOF&quot;#!/bin/bashcount=$(ps -ef |grep nginx |egrep -cv &quot;grep|$$&quot;)if [ &quot;$count&quot; -eq 0 ];then exit 1else exit 0fiEOFchmod +x /etc/keepalived/check_nginx.sh 服务启动并设置开机启动 12345systemctl daemon-reloadsystemctl start nginxsystemctl start keepalivedsystemctl enable nginxsystemctl enable keepalived 检测keepalived工作状态（接口是否绑定vip）：ip a nginx+keepalived高可用测试：pkill nginx执行后查看vip是否绑定到了备机上 使用vip进行负载均衡功能测试：curl -k https://192.168.31.211:16443/version 修改node组件连接地址123sed -i &apos;s/192.168.31.211:6443/192.168.31.216:16443/g&apos; /opt/kubernetes/cfg/&#123;kubelet.kubeconfig,kube-proxy.kubeconfig&#125;systemctl restart kubeletsystemctl restart kube-proxy 制作kubectl使用的kubeconfig文件 基于kube-dashboard的admin-user 12345kubectl config set-cluster kubernetes --embed-certs=true --server=&quot;https://192.168.31.216:16443&quot; --certificate-authority=/opt/kubernetes/ssl/ca.pem --kubeconfig=./kubeconfigADMIN_TOKEN=$(kubectl get secret $(kubectl get secret -n kubernetes-dashboard|awk &apos;/admin-user/&#123;print $1&#125;&apos;) -n kubernetes-dashboard -o jsonpath=&#123;.data.token&#125;|base64 -d)kubectl config set-credentials kubernetes-dashboard:admin-user --token=$&#123;ADMIN_TOKEN&#125; --kubeconfig=./kubeconfigkubectl config set-context admin-user@kubernetes --cluster=kubernetes --user=kubernetes-dashboard:admin-user --kubeconfig=./kubeconfigkubectl config use-context admin-user@kubernetes --kubeconfig=./kubeconfig]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python-编码]]></title>
    <url>%2F2020%2F07%2F10%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython-%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[通用编码 ASCII[1个字节] 只支持英文字母和一些常用的符号 Unicode[2个字节] UTF-8 把一个Unicode字符根据不同的数字大小编码成1-6个字节 常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节 ASCII编码实际上可以被看成是UTF-8编码的一部分 中文编码 gb2312 GB2312(1980年)一共收录了7445个字符，在windows中的代码页是CP936 原来的CP936和GB 2312-80一模一样 gbk GBK最初是由微软对GB2312的扩展，也就是CP936字码表 (Code Page 936)的扩展 gbk并非国家正式标准 GB18030 GB18030取代了GBK1.0的正式国家标准。该标准收录了27484个汉字，同时还收录了藏文、蒙文、维吾尔文等主要的少数民族文字。 现在的PC平台必须支持GB18030，GB18030在windows中的代码页是CP54936。 python文件设置python3默认使用utf-8编码读取文件，支持读取中文python2默认使用ASCII编码读取文件，不支持读取中文；在文件中设置#-*- coding:utf8 -*-可以使python2使用UTF-8编码方式读取文件，从而支持读取中文 python2与python3 python3 str即为unicode bytes即为str.encode()的结果 python2 str是bytes u’str’为unicode str与bytes转换 python3下 在内存中，统一使用unicode编码，数据为str类型 如果数据需要在网络上传输或保存到硬盘上，就需要把str变成bytes，使用encode方法 反之，如果我们从网络或磁盘读取了字节流，需要使用decode方法将数据由bytes类型转换为str类型 单字符的编码 ord(ordinals)：获取单字符的unicode编码(整数) print(ord(‘中’)) chr(character)：把Unicode编码(整数)转换为对应的字符 print(chr(20013))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[源代码管理-gitlab]]></title>
    <url>%2F2020%2F07%2F06%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%8E%E9%83%A8%E7%BD%B2%2Fgitlab%2F%E6%BA%90%E4%BB%A3%E7%A0%81%E7%AE%A1%E7%90%86-gitlab%2F</url>
    <content type="text"><![CDATA[gitlab服务软件安装docker方式 由于gitlab的访问端口由external_url中决定，如下配置中容器中的gitlab服务暴露在80端口，宿主机以外通过http://172.17.8.53:9999/访问gitlab的web服务 123456789101112docker run -d \ --name gitlab \ -p 8443:443 \ -p 9999:80 \ -p 9998:22 \ -v $PWD/config:/etc/gitlab \ -v $PWD/logs:/var/log/gitlab \ -v $PWD/data:/var/opt/gitlab \ -v /etc/localtime:/etc/localtime \ --restart=always \ -e GITLAB_OMNIBUS_CONFIG=&quot;external_url &apos;http://172.17.8.53/&apos;&quot; \ gitlab/gitlab-ce:latest ubuntu16.04 软件源 12sudo curl https://packages.gitlab.com/gpg.key 2&gt; /dev/null | sudo apt-key add - &amp;&gt;/dev/nullecho &quot;deb https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu xenial main&quot; &gt; /etc/apt/sources.list.d/gitlab-ce.list 安装 12sudo apt-get updatesudo apt-get install gitlab-ce Centos7 软件源 12345[gitlab-ce]name=Gitlab CE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/gpgcheck=0enabled=1 安装 12sudo yum makecachesudo yum install gitlab-ce 软件配置 /etc/gitlab/gitlab.rb 服务器地址配置【在邮件通知中会使用此地址】external_url &#39;http://10.10.10.164&#39; 备份保留时间配置[以s为单位]gitlab_rails[&#39;backup_keep_time&#39;] = 86400 邮箱配置 12345678910gitlab_rails[&apos;smtp_enable&apos;] = truegitlab_rails[&apos;smtp_address&apos;] = &quot;smtp.exmail.qq.com&quot;gitlab_rails[&apos;smtp_port&apos;] = 465gitlab_rails[&apos;smtp_user_name&apos;] = &quot;gitlab@abc.com&quot;gitlab_rails[&apos;smtp_password&apos;] = &quot;Git@abc123&quot;gitlab_rails[&apos;smtp_domain&apos;] = &quot;exmail.qq.com&quot;gitlab_rails[&apos;smtp_authentication&apos;] = &quot;login&quot;gitlab_rails[&apos;smtp_enable_starttls_auto&apos;] = truegitlab_rails[&apos;smtp_tls&apos;] = truegitlab_rails[&apos;gitlab_email_from&apos;] = &quot;gitlab@abc.com&quot; 邮箱功能测试 进入控制台：gitlab-rails console 测试：Notify.test_email(&#39;destination_email@address.com‘, ‘Message Subject’, ‘Message Body’).deliver_now 常用命令 查看gitlab版本：cat /opt/gitlab/version-manifest.json 变更配置：sudo gitlab-ctl reconfigure 创建备份：gitlab-rake gitlab:backup:create 恢复备份(BACKUP后为在备份目录【默认/var/opt/gitlab/backups/】产生文件名中数字)：gitlab-rake gitlab:backup:restore BACKUP=1507879010_2017_10_13 服务状态操作(查/起/停)：gitlab-ctl status|start|stop git客户端配置 web界面注册账号 本地配置账号 12git config --global user.name=simple0426git config --global user.email=perfect_0426@qq.com 生产秘钥并上传至gitlabssh-keygen -t rsa -C &quot;perfect_0426@qq.com 测试连通性ssh -T git@github.com 根据gitlab范例创建项目 123456789mkdir blog-commentscd blog-commentsgit initecho &quot;# blog-comments&quot; &gt;&gt; README.mdgit add README.mdgit commit -m &quot;first commit&quot;# 本地库关联远程库git remote add origin git@github.com:simple0426/blog-comments.gitgit push -u origin master 多仓库设置产生密钥对 ssh-keygen.exe -t rsa -P “” -f “C:\Users\simple\.ssh\gitee” ssh-keygen.exe -t rsa -P “” -f “C:\Users\simple\.ssh\github” 在两个平台添加公钥配置ssh的config文件 windows下：C:\Users\simple\.ssh\config 123456789101112Host gitee.com ProxyCommand none IdentityFile C:\Users\simple\\.ssh\gitee ServerAliveInterval 60 StrictHostKeyChecking no TCPKeepAlive yesHost github.com ProxyCommand none IdentityFile C:\Users\simple\\.ssh\github ServerAliveInterval 60 StrictHostKeyChecking no TCPKeepAlive yes ssh登录测试 ssh -T git@github.com ssh -T git@gitee.com 配置项目config文件 .git\config 123456[remote &quot;github&quot;] url = git@github.com:simple0426/blog.git fetch = +refs/heads/*:refs/remotes/origin/*[remote &quot;gitee&quot;] url = git@gitee.com:simple0426/simple0426.git fetch = +refs/heads/*:refs/remotes/origin/* 客户端命令 git pull github master git push github master]]></content>
      <categories>
        <category>CICD</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-安全-认证]]></title>
    <url>%2F2020%2F03%2F30%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-%E5%AE%89%E5%85%A8-%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[访问控制对kubernetes安全的保护主要通过如下方式实现： 认证（authentication）：验证访问者的身份 授权（authorization）：确定认证用户的权限和可以执行的操作，如增删改查指定的对象 准入控制（admission control）：验证操作是否符合规范 用默认值补足要创建的目标资源中未定义的各字段 检查目标namespace是否存在 检查是否违反系统资源限制 客户端访问访问方式 kubectl 客户端库 REST接口 访问者 用户账号(user account)：kubernetes中不存在此类对象，也不会存储此类账号，它们仅仅用于校验用户是否有权限执行相应的操作；作用于系统全局 服务账号（service account）：kubernetes管理的账号，用于为pod中的进程访问api server提供身份标识；隶属于名称空间级别 用户组（group）：用户账号的逻辑集合，附加于组上的权限可由其内部的所有用户继承；以下为一些内置的组 system：unauthorized：未通过认证的用户；未被任何验证机制明确拒绝的用户即为匿名用户，自动被标识为system:anonymous，并隶属于system:unauthorized组 system：authenticated：通过认证的用户 system：serviceaccounts：当前系统上所有的service account对象 system：serviceaccount：namespace：特定名称空间的serviceaccount对象 认证方式api server支持同时启用多种认证机制，但至少应该分别为serviceaccount和useraccount各自启用一个认证插件各种认证方式串行进行，直到一种方式认证成功；若认证失败，则返回401状态码kubernetes认证插件尝试将下列属性关联到请求中： Username：用户名，如kubernetes-admin UID：确定用户唯一性ID Groups：用户所属的组，用于权限指派和继承 Extra：键值类型字符串，用于提供认证所需额外信息 APIserver支持的认证方式，如下： X509数字证书(–client-ca-file=SOMEFILE)：证书主体(subject)中包含用户(CN)和组(O)信息; 静态token文件(–token-auth-file=SOMEFILE)：token文件定义后不可变，除非apiserver重启；token标识也可以在http的头部进行设置； 引导令牌(–enable-bootstrap-token-auth):常用于新建集群中节点认证过程；在master节点使用引导令牌完成节点的认证后自动为其签署数字证书用于后续通信 静态密码文件(–basic-auth-file=SOMEFILE):用户名和密码以CSV明文格式存储 service account token：由apiserver自动启用；通过加载【–service-account-key-file】来验证由其签名的令牌；如果没有指定，则使用apiserver自己的私钥文件验证令牌合法性 openID连接令牌：OAuth2认证风格，它属于json web（JWT）类型 webhook令牌：HTTP身份验证允许将服务器的URL注册为webhook，并接受带有承载令牌的POST请求进行身份验证 认证代理：通过从请求头的值中识别用户，如X-Remote-User 授权方式 Node：基于pod资源的目标调度节点来实现对kubelet的访问控制 ABAC：attribute-based access control，基于属性的访问控制 RBAC：role-based access control，基于角色的访问控制 webhook：基于http回调机制通过外部REST服务检查确认用户授权的访问控制 AlwaysAllow(总是允许)：用于期望不希望进行授权检查 AlwaysDeny(总是拒绝)：仅用于测试 准入控制器 AlwaysPullImages：总是下载镜像，常用于多租户环境下确保私有镜像仅能被有权限的用户使用 DefaultStorageClass：为创建PVC设置一个默认的storageclass DefaultTolerationSeconds：如果pod对象没有设置污点容忍期限，则在此设置默认宽容期 LimitRanger：pod可用资源限制 MutatingAdmissionWebhook：串行调用任何可能更改对象的webhook NamespaceLifecycle：拒绝在不存在的名称空间创建对象，删除名称空间也会删除空间下的所有对象 ResourceQuota：定义名称空间内可使用的资源配额 serviceaccount：用于实现service account管控机制的自动化，实现创建pod对象时自动为其附加相关的service account对象（当前名称空间的default） ValidatingAdmissionWebhook：并行调用匹配当前请求的所有验证类webhook，任何一个验证失败，请求即失败 ServiceAccountkubernetes系统通过三个独立的组件间的相互协作完成服务账户的自动化 serviceaccount控制器(controller-manager)负责管理名称空间的资源，确保每个名称空间都存在一个“default”的serviceaccount对象 secret控制器(controller-manager)负责监控serviceaccount对象，联动创建或删除相关的secret对象 serviceaccount准入控制器：在pod没有定义serviceaccount对象时将其设置为“default”，并将相关的secret对象以volume形式挂载到容器中；pod和api servcer交互时即可使用此secret进行认证 服务账号自动化需要进行的设置： api-server：–service-account-key-file controller-manager：–service-account-private-key-file 实践 创建serviceaccount对象(相应的secret对象也会创建)：kubectl create serviceaccount sa-demo 调用imagePullSecret（需要事先创建用户私有仓库认证的secret对象）123456apiVersion: v1kind: ServiceAccountmetadata: name: sa-demoimagePullSecrets:- name: aliyun-simple X509数字证书使用方式 服务端认证：只为服务器端配置证书，由客户端验证服务端的身份，常见场景如：为web服务配置https证书 双向认证：客户端和服务端需要验证对方身份 k8s中应用场景 APIserver与controller-manager、scheduler、kube-proxy APIserver与kubelet初次通信，kubelet自动生成私钥和证书前面请求，master为其自动进行证书签名和颁发(即所谓的tls bootstraping),kubelet后续使用私钥和证书通信 APIServer与kubelet及其他形式客户端，如pod对象 APIserver(pod)与外部通信【服务端】 kubelet和kube-proxy间通信 etcd存储 etcd集群内各节点间 etcd服务器与客户端 kubeconfig各类APIserver的客户端都可以使用kubeconfig形式和APIserver通信： controller-manager scheduler kube-proxy kubelet kubelet的bootstrap kubectl 配置命令 kubectl config view:查看文件内容 kubectl config set-cluster：设置clusters字段【访问APIserver的URL和集群名称】 kubectl config set-credentials：设置users字段【访问APIServer的用户名和认证信息】 kubectl config set-context：设置context字段【context由用户名和集群名称组合而成】 kubectl config use-context：设置要使用的context，即current-context 配置范例以创建kube-user1为例 创建私钥和证书 创建私钥文件：openssl genrsa -out kube-user1.key 2048 创建证书签名请求：openssl req -new -key kube-user1.key -out kube-user1.csr -subj &quot;/CN=kube-user1/O=kubernetes&quot;【CN用户名，O用户组】 基于ca根证书签署证书：openssl x509 -req -in kube-user1.csr -CA ../ssl/ca.pem -CAkey ../ssl/ca-key.pem -CAcreateserial -out kube-user1.crt -days 3650 查看证书信息【可选】：openssl x509 -in kube-user1.crt -text -noout 配置kubeconfig 配置集群信息：kubectl config set-cluster kubernetes --embed-certs=true --server=&quot;https://172.17.8.101:6443&quot; --certificate-authority=/etc/kubernetes/ssl/ca.pem 配置用户信息：kubectl config set-credentials kube-user1 --embed-certs=true --client-certificate=/etc/kubernetes/pki/kube-user1.crt --client-key=/etc/kubernetes/pki/kube-user1.key 配置上下文：kubectl config set-context kube-user1@kubernetes --cluster=kubernetes --user=kube-user1 切换当前上下文：kubectl config use-context kube-user1@kubernetes 测试【可选】：在启用RBAC的集群上，由于kube-user1所属组kubernetes无任何管理权限，所以执行命令会出错 TLS-Bootstrapping新的工作节点加入集群时需要配置相关的私钥和证书，可以由管理员手动配置，也可以让kubelet自行生成相关的私钥和证书但是集群规模扩大后，手动配置会增加管理员工作量，kubelet自动配置则会降低PKI本身的优势结合这两种方式，kubernetes提出了新方案(TLS Bootstrapping)：由kubelet自行生成私钥和证书签名请求然后向集群的证书签署进程(CA)发起请求，获取的证书和已有的私钥文件共同存储于kubelet客户端以用于后续的通信但是，这样一来就认证和非认证的kubelet客户端都会发起证书签名请求，为了控制仅那些认证的客户端可以发起请求，就需要使用令牌机制(bootstrap token)来确认认证的客户端APIserver使用基于认证令牌对“system:bootstrappers”组内用户完成认证controller-manager会用到这个组的默认审批控制器来决定是否颁发证书，它依赖于由管理员将此token绑定于合适的RBAC策略，以限制其仅用于签证操作 apiserver 配置项 –enable-bootstrap-token-auth：开启bootstrap认证 –token-auth-file：bootstrap token文件 –client-ca-file=FILENAME：开启客户端证书认证，指定客户端证书的根证书机构（ca证书） –tls-cert-file –tls-private-key-file：如果apiserver开启https服务，则需要指定私钥和证书【由ca颁发的证书】 token文件范例：02b50b05283e98dd0fd71db496ef01e8,kubelet-bootstrap,10001,&quot;system:bootstrappers&quot; 授权kubelet可以创建证书签名请求12345678910111213# enable bootstrapping nodes to create CSRapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: create-csrs-for-bootstrappingsubjects:- kind: Group name: system:bootstrappers apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: system:node-bootstrapper apiGroup: rbac.authorization.k8s.io controller-manager 配置项 –cluster-signing-cert-file –cluster-signing-key-file：用于颁发集群范围内证书的ca证书 –root-ca-file：根ca证书，此根证书颁发机构将包含在服务帐户的令牌密钥中 批准kubelet证书请求12345678910111213# Approve all CSRs for the group &quot;system:bootstrappers&quot;apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: auto-approve-csrs-for-groupsubjects:- kind: Group name: system:bootstrappers apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: system:certificates.k8s.io:certificatesigningrequests:nodeclient apiGroup: rbac.authorization.k8s.io kubelet 配置项 –bootstrap-kubeconfig：bootstrap的kubeconfig配置，主要包含bootstrap token –kubeconfig：kubelet和apiserver通信的kubeconfig配置 –cert-dir：bootstrap获取的证书和原有的私钥文件的存储位置 配置bootstrap-kubeconfig1234kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-cluster bootstrap --server=&apos;https://my.server.example.com:6443&apos; --certificate-authority=/var/lib/kubernetes/ca.pemkubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-credentials kubelet-bootstrap --token=07401b.f395accd246ae52dkubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-context bootstrap --user=kubelet-bootstrap --cluster=bootstrapkubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig use-context bootstrap]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubeconfig</tag>
        <tag>认证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-安全-授权和准入控制]]></title>
    <url>%2F2020%2F03%2F30%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-%E5%AE%89%E5%85%A8-%E6%8E%88%E6%9D%83%E5%92%8C%E5%87%86%E5%85%A5%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[RBAC基于角色的访问控制(role-based access control),将权限授予角色而非直接授予使用者RBAC主要定义谁(subject)可以操作(verb)什么对象(object)，具体如下： 主体(subject):动作的发出者，通常以“账号”为载体，包含用户账号(UserAccount)和服务账号(ServiceAccount) 操作(verbs)：要执行的具体操作，如创建、删除、修改、查看等；对应于kubectl命令来说，则为create、delete、apply、update、patch、edit、get等子命令 客体(object)：动作施加于的目标实体，包含各类资源对象和非资源型的URL RBAC包含两种类型的角色(权限集合)：Role和ClusterRole Role：表示对哪些资源(object)可以执行的权限集合(verbs)，作用于名称空间级别 ClusterRole：作用于集群级别,控制Role无法生效的资源类型，如 集群级别的资源：Nodes、persistvolume 非资源类端点(URL)：/healthz 作用于所有名称空间的资源 对角色授权需要用到：RoleBinding和ClusterRoleBinding RoleBinding：将同一名称空间的Role或ClusterRole绑定到一个或一组用户上，作用域仅为同一名称空间 ClusterRoleBinding：将ClusterRole绑定到一个或一组用户,使用户有全部名称空间(即集群级别)的的操作权限 Role 资源文件 123456789kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: namespace: testing name: pods-readerrules: # 定义规则- apiGroups: [&quot;&quot;] resources: [&quot;pods&quot;, &quot;pods/log&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;] 资源文件语法： apiGroups：资源的API群组，空串标识核心群组core resources：规则应用的资源类型 resourceNames：规则应用的资源名称，缺省则表示指定资源类型下的所有资源 verbs：对资源可以执行的操作：get、list、create、update、patch、watch、proxy、redirect、delete、deletecollection nonResourceURLs：非资源型URL地址，仅适用于ClusterRole和ClusterRoleBinding kubectl命令方式：kubectl create role service-admin --verb=&quot;*&quot; --resource=&quot;services,services/*&quot; -n testing RoleBinding 资源文件 12345678910111213kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: resources-reader namespace: testingsubjects:- kind: User name: kube-user1 apiGroup: rbac.authorization.k8s.ioroleRef: kind: Role name: pods-reader apiGroup: rbac.authorization.k8s.io kubectl命令方式：kubectl create rolebinding admin-service --role=service-admin --user=kube-user1 -n testing 资源文件语法 subjects:要绑定的主体 kind：主体资源类型，包括：User、Group、ServiceAccount apiGroup：主体所属的API群组，ServiceAccount默认为空串””，User和Group默认为“rbac.authorization.k8s.io” name：主体名称 namespace：主体(ServiceAccount类型)所属名称空间 RoleRef：引用的角色 apiGroup：引用的Role或ClusterRole所属的API群组 kind：引用的资源类型，Role或ClusterRole name：引用的资源名称 ClusterRole集群资源12345678kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: nodes-readerrules:- apiGroups: [&quot;&quot;] resources: [&quot;nodes&quot;] verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;] 非资源型URL12345678910apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: url-adminrules:- nonResourceURLs: - /healthz verbs: - get - create 聚合类型 父级资源:通过标签匹配资源 123456789kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: monitoringaggregationRule: clusterRoleSelectors: - matchLabels: rbac.example.com/aggregate-to-monitoring: &quot;true&quot;rules: [] 子级资源：定义标签 12345678910kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: monitoring-endpoints labels: rbac.example.com/aggregate-to-monitoring: &quot;true&quot;rules:- apiGroups: [&quot;&quot;] resources: [&quot;services&quot;, &quot;endpoints&quot;, &quot;pods&quot;] verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;] 内置ClusterRole ClusterRole ClusterRoleBinding 说明 cluster-admin system:masters 授予超级管理员在任何对象上执行任何操作的权限 admin None 以RoleBinding机制访问指定名称空间的所有资源，包括Role和RoleBinding，但不包含资源配置和名称空间本身 edit None 允许读写访问一个名称空间内的绝大多数资源，但不允许查看或修改Role或RoleBinding view None 允许读取一个名称空间的绝大多数资源，但不允许查看Role或RoleBinding，以及secret资源 超级管理员(cluster-admin)：基于同名的ClusterRoleBinding绑定到“system:masters”组，任何属于该组的用户都有超级管理员权限 自定义超级管理员的方式： 创建用户证书，其中O的值为“system:masters”【用户所属组】 将创建的用户使用ClusterRoleBinding绑定到cluster-admin 自定义管理员(admin)：kubectl create rolebinding dev-admin --clusterrole=admin --user=kube-user1 -n dev kube-dashboard部署部署https访问证书 创建私钥和证书 123openssl genrsa -out certs/dashboard.key 2048openssl req -new -key certs/dashboard.key -out certs/dashboard.csr -subj &quot;/CN=kube-user1/O=kubernetes&quot;openssl x509 -req -in certs/dashboard.csr -CA /etc/kubernetes/pki/ca.pem -CAkey /etc/kubernetes/pki/ca-key.pem -CAcreateserial -out certs/dashboard.crt -days 3650 创建secret对象【kubernetes-dashboard-certs】：kubectl create secret generic kubernetes-dashboard-certs --from-file=certs -n kube-system 资源文件部署 使用hostPort或NodePort将访问端口暴露在宿主机 资源文件中也包含创建secret对象的内容【部署https证书】，可能会发出警告信息 访问认证dashboard是部署于集群中的pod对象，访问集群中的资源需要使用ServiceAccount账户类型同时这种ServiceAccount账户需要绑定集群角色(cluster-admin)，以获得对集群的相应操作权限dashboard页面提供了kubeconfig和token两种访问认证方式 创建服务账号 12345apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kubernetes-dashboard 给服务账号绑定权限 123456789101112apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard 获取ServiceAccount的token信息，访问dashboard：kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk &#39;{print $1}&#39;) 基于token信息制作kubeconfig，访问dashboard12345kubectl config set-cluster kubernetes --embed-certs=true --server=&quot;https://172.17.8.101:6443&quot; --certificate-authority=/etc/kubernetes/ssl/ca.pem --kubeconfig=./kubeconfigADMIN_TOKEN=$(kubectl get secret admin-token-l7gjt -n kube-system -o jsonpath=&#123;.data.token&#125;|base64 -d)kubectl config set-credentials kube-system:admin --token=$&#123;ADMIN_TOKEN&#125; --kubeconfig=./kubeconfigkubectl config set-context admin --cluster=kubernetes --user=kube-system:admin --kubeconfig=./kubeconfigkubectl config use-context kube-system:admin --kubeconfig=./kubeconfig 准入控制器LimitRanger 支持在名称空间级别为每个资源对象指定最大、最小、默认的计算或存储资源请求和资源限制 支持限制容器(cpu/内存)、pod(cpu/内存)、persistvolumeclaim(存储)三种资源的用量 范例1234567891011121314151617apiVersion: v1kind: LimitRangemetadata: name: cpu-limit-rangespec: limits: - default: #默认限制 cpu: 1000m defaultRequest: #默认需求 cpu: 1000m min: #最小可申请资源 cpu: 500m max: #最大可申请资源 cpu: 2000m maxLimitRequestRatio: #最大可申请资源（最小用量的倍数） cpu: 4 type: Container #限制的资源类型 ResourceQuota 定义名称空间的对象数量，以及所有对象消耗的系统资源总量(计算及存储资源) 在名称空间启用cpu和内存等系统资源配额后，用户创建pod对象时必须指定资源需求或资源限制【也可以通过LimitRange控制器设置默认值】 资源配额仅对创建ResourceQuota对象之后创建的对象有效，对已经存在的对象不会产生任何影响 开启资源配额(apiserver)：【–enable-admission-plugins=ResourceQuota】 资源配额类型 计算资源配额 limits.cpu limits.memory requests.cpu requests.memory 存储资源配额 requests.storage：所有pvc存储总量 persistentvolumeclaims：可以申请的pvc数量 storage-class-name.storageclass.storage.k8s.io/requests.storage：指定类别下的pvc存储总量 storage-class-name.storageclass.storage.k8s.io/persistentvolumeclaims：指定类别下的pvc数量 requests.ephemeral-storage：所有pod可用的本地临时存储需求总量 limits.ephemeral-storage：所有pod可用的本地临时存储限制总量 资源对象数量配额【1.9版本开始支持所有标准名称空间类型资源，形如count/resource.group】 count/persistentvolumeclaims count/services count/secrets count/configmaps count/replicationcontrollers count/deployments.apps count/replicasets.apps count/statefulsets.apps count/jobs.batch count/cronjobs.batch count/deployments.extensions 资源对象数量配额【1.9版本之前语法】 configmaps persistentvolumeclaims pods replicationcontrollers resourcequotas services services.loadbalancers services.nodeports services.nodeports 自定义资源对象数量配额【1.15版本支持自定义资源，形如count/widgets.example.com】 资源配额适用范围 Terminating NotTerminating BestEffort NotBestEffort 范例123456789101112131415apiVersion: v1kind: ResourceQuotametadata: name: quota-example namespace: testspec: hard: pods: &quot;5&quot; requests.cpu: &quot;1&quot; requests.memory: 1Gi limits.cpu: &quot;2&quot; limits.memory: 2Gi count/deployments.apps: &quot;1&quot; count/deployments.extensions: &quot;1&quot; persistentvolumeclaims: &quot;2&quot; PodSecuritypolicy 定义：用于控制用户在配置pod资源时可以设定的特权类属性，比如 是否可以使用特权容器、根名称空间、主机文件系统 可使用的主机网络和端口、卷类型、linux capabilities 使用步骤： 创建PSP对象 对相关的使用主体(用户、组、服务账号)进行RBAC授权 将use权限授予特定的Role或ClusterRole 将UserAccount或ServiceAccount完成角色绑定 apiserver启用PodSecuritypolicy准入控制器(–enable-admission-plugins=PodSecurityPolicy) PSP对象 特权PSP 非特权PSP ClusterRole和ClusterRoleBinding ClusterRole 12345678910apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: &lt;role name&gt;rules:- apiGroups: [&apos;policy&apos;] resources: [&apos;podsecuritypolicies&apos;] verbs: [&apos;use&apos;] resourceNames: - &lt;list of policies to authorize&gt; ClusterRoleBinding 12345678910111213141516171819202122232425apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: &lt;binding name&gt;roleRef: kind: ClusterRole name: &lt;role name&gt; apiGroup: rbac.authorization.k8s.iosubjects:# Authorize specific service accounts:- kind: ServiceAccount name: &lt;authorized service account name&gt; namespace: &lt;authorized pod namespace&gt;# Authorize specific users (not recommended):- kind: User apiGroup: rbac.authorization.k8s.io name: &lt;authorized user name&gt;# Authorize all service accounts in a namespace:- kind: Group apiGroup: rbac.authorization.k8s.io name: system:serviceaccounts# Or equivalently, all authenticated users in a namespace:- kind: Group apiGroup: rbac.authorization.k8s.io name: system:authenticated]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>RBAC</tag>
        <tag>资源限制</tag>
        <tag>资源配额</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-pod资源调度]]></title>
    <url>%2F2020%2F03%2F24%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-pod%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[创建pod流程 用户通过UI或CLI提交一个pod给API Server进行部署 API Server将信息写入etcd存储 Scheduler通过API Server的watch或notification机制获取这个信息 Scheduler通过资源使用情况进行调度决策(pod在哪个节点部署)，并把决策信息返回给API server API server将决策结果写入etcd API server通知相应的节点进行pod部署 相应节点的kubelet得到通知后，调用container runtime启动容器、调度存储插件配置存储、调度网络插件配置网络 pod调度器 apiserver接收用户创建pod对象请求后，调度器会从集群中选择一个可用的最佳节点来运行它 kube-scheduler是默认的调度器 用户也可以自定义调度器插件，并在定义pod对象时通过spec.schedulerName指定 调度过程 预选：基于过滤条件，过滤可行的节点 优选：基于不同的度量因子对可行的节点进行优先级排序 选择：选择优先级最高的节点来运行pod对象 影响调度因素 单个pod或所有pod的资源要求：cpu、内存等资源要求 硬件、软件、策略约束：pod只能运行在特定节点；pod对特定硬件的要求（SSD、GPU） 亲和性、反亲和性要求 数据存储位置：某些存储卷只能某些区域加载使用 工作负载间的相互干扰 节点过滤规则 PodFitsHostPorts：检查节点端口是否满足pod需求 PodFitsHost：检查节点主机名（hostname）是佛满足pod需求 PodFitsResources：检查节点是否有可用资源（cpu、内存）满足pod需求 PodMatchNodeSelector：检查pod的节点选择器是否匹配节点标签 NoVolumeZoneConflict：在给定区域(zone)上，检查pod要求的存储卷在节点上是否可用 NoDiskConflict：在给定的节点上，检查pod要求的存储卷是否可用；如果这个节点已经挂载了卷，其他使用这个卷的pod不能调度到这个节点上 MaxCSIVolumeCount:单个节点最多可以挂载多少个CSI存储卷 CheckNodeMemoryPressure：检测节点内存压力 CheckNodePIDPressure：检测节点PID压力 CheckNodeDiskPressure：检测节点磁盘压力（文件系统满或接近满） CheckNodeCondition：检测节点在下列情况是否可用 文件系统满 网络不可达 kubelet还没准备好调度pod PodToleratesNodeTaints:检测pod的容忍度是否可以容忍节点的污点 CheckVolumeBinding：检查节点上已绑定或未绑定的PVC是否满足pod对存储的需求 优先级排序规则 SelectorSpreadPriority：是否可以将service、statefulset、replicaset所属的pod对象扩展到尽可能多的节点 InterPodAffinityPriority：遍历pod对象的亲和性条目，并将那些能够匹配到给定节点的条目的权重相加，结果值越大的节点得分越高 LeastRequestedPriority：request越少得分越高，比较倾向于让pod分配到空闲的机器上 MostRequestedPriority：request越多得分越高，比较倾向于尽量压慢一台机器，避免过多碎片化 RequestedToCapacityRatioPriority：按照请求和容量的比例记分 BalancedResourceAllocation：cpu、内存使用更均衡的节点得分更高 NodePreferAvoidPodsPriority：根据节点是否设置了注解【scheduler.alpha.kubernetes.io/preferAvoidPods】；使用这个选项，可以标识哪些pod不能运行在同一个节点上 NodeAffinityPriority：使用基于【PreferredDuringSchedulingIgnoredDuringExecution】的节点亲和性偏好进行优先级排序；匹配的条目越多，权重越高，得分也越高 TaintTolerationPriority：根据节点上无法容忍的污点数量对节点进行排序 ImageLocalityPriority：节点上存在pod对象要求的镜像时，得分高 ServiceSpreadingPriority：service的pod可以尽可能多的部署在不同节点 CalculateAntiAffinityPriorityMap：计算pod的反亲和性优先级 EqualPriorityMap：给所有的节点相同的权重 节点选择-nodeName 位置：spec.nodeName 功能：以下两者功能相同123nodeName: minikubenodeSelector: - kubernetes.io/hostname=minikube 节点选择器-nodeSelector将pod调度至特定节点运行 节点标签定义 定义：kubectl label nodes minikube minikube=yes 查看：kubectl get node –show-labels 内置节点标签 kubernetes.io/os=linux：操作系统类型 kubernetes.io/hostname=minikube：节点主机名 pod定义nodeSelector123456spec: containers: - name: myapp image: ikubernetes/myapp:v1 nodeSelector: hostname: node2 节点亲和调度通过在节点定义标签，在pod对象上指定标签选择器来确定pod的运行位置 分类 硬亲和性（required）：pod对象调度时必须满足的规则，不满足时pod处于pending状态 软亲和性（preferred）：pod对象调度时应当遵守的规则 注意事项：IgnoredDuringExecution，在基于节点亲和性完成pod调度后，节点标签变更也不会将pod对象从节点移出，它只对新建的pod对象生效。 硬亲和性将pod调度到拥有zone标签且其值为foo的节点上123456789spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: zone operator: In values: [&quot;foo&quot;] 软亲和性12345678910111213141516spec: affinity: nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 60 preference: matchExpressions: - key: zone operator: In values: [&quot;foo&quot;] - weight: 30 preference: matchExpressions: - key: ssd operator: Exists values: [] pod资源亲和调度 亲和性：基于某些需求，需要把某些pod资源部署在相近的位置，此时这些pod资源间具有亲和性(affinity) 反亲和性：相反，需要把一些pod隔离开分散部署，此时这些资源具有反亲和性(anti-affinity) 先使用标签选择器选出与之关联的pod对象，然后基于某种关系(topologyKey)将部署的pod和已存在的pod进行相近部署或分散部署 硬亲和性12345678910spec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: [&quot;cirros&quot;] topologyKey: kubernetes.io/hostname 软亲和性1234567891011121314151617181920spec: affinity: podAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 80 podAffinityTerm: labelSelector: matchExpressions: - key: app operator: In values: [&quot;cache&quot;] topologyKey: zone - weight: 20 podAffinityTerm: labelSelector: matchExpressions: - key: app operator: In values: [&quot;db&quot;] topologyKey: zone 反亲和性12345678910spec: affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: [&quot;myapp&quot;] topologyKey: kubernetes.io/hostname 污点和容忍度 污点（taint）：是定义在节点上的键值对，用于让节点拒绝将pod部署于其上，除非该pod对象具有接纳该污点的容忍度 容忍度（toleration）：是定义在pod对象之上的键值对，用于配置其可以容忍的节点污点，而且调度器仅能将pod对象调度至能容忍该污点的节点上 污点和容忍度语法 污点定义在节点node.spec，容忍度定义在pod的pod.spec 他们都是键值对型数据，语法：key=value:effect effect定义对pod对象的排斥等级 NoSchedule：不能容忍此污点的pod对象不能调度到此节点 PreferNoSchedule：不能容忍此污点的pod对象可以调度到此节点 NoExecute：不能容忍此污点的pod对象不能调度到此节点，pod对象的容忍度或节点的污点变动时，pod对象将被驱逐 pod定义容忍度，支持两种操作符（operator） Equal：容忍度和污点在key、value、effect完全相同 Exists：容忍度和污点在key、effect完全匹配，容忍度中的value字段要使用空值 一个节点可以有多个污点，一个pod对象也可以有多个容忍度 管理节点的污点 添加污点：kubectl taint node node1 node-type=prod:NoSchedule 查看污点：kubectl describe node node01|grep -i taint 删除key的不同effect：kubectl taint node node1 node-type:PreferNoSchedule- 删除key：kubectl taint node node1 node-type- pod对象容忍度12345678910spec: tolerations: - key: &quot;key1&quot; operator: &quot;Equal&quot; value: &quot;value1&quot; effect: &quot;NoSchedule&quot; - key: &quot;key1&quot; operator: &quot;Exists&quot; effect: &quot;NoExecute&quot; tolerationSeconds: 3600 问题节点标识当节点出现问题时，节点控制器自动为节点添加污点信息，使用NoExecute标识 node.kubernetes.io/not-ready：节点进入“NotReady”状态时被自动添加 node.kubernetes.io/unreachable：节点进入“NotReachable”状态时被自动添加 node.kubernetes.io/out-of-disk：节点进入“OutOfDisk”状态时被自动添加 node.kubernetes.io/memory-pressure：节点内存压力 node.kubernetes.io/disk-pressure：节点磁盘压力 node.kubernetes.io/network-unavailable：节点网络不可达 node.kubernetes.io/unschedulable：节点不可调度 node.cloudprovider.kubernetes.io/uninitialized：kubelet由外部云环境启动时，它将自动为节点添加此污点；待到云控制器管理器中的控制器初始化此节点时再将其删除 pod优先级和抢占待续]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>污点</tag>
        <tag>容忍度</tag>
        <tag>亲和性</tag>
        <tag>反亲和性</tag>
        <tag>nodeSelector</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-资源管理]]></title>
    <url>%2F2020%2F03%2F21%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[管理实现方式-APIkubernetes API是管理各种资源的唯一入口，它提供了一个RESTful风格的CRUD接口，用于查询和修改集群的状态，并将结果存储于etcd中。 API设计模式 声明式 天然记录了状态 幂等操作，可在任意时刻反复操作 正常操作即巡检 可合并多个变更 命令式 如果命令没有响应，需要反复重试、记录当前的操作 如果多次重试、操作有可能出问题 需要单独的巡检操作，巡检本身也可能会有问题或带来额外影响 多并发操作，需要加锁处理；不仅复杂，也降低了系统执行效率 实现原理 API-&gt;Controller 由声明式的API驱动(k8s资源对象) 由控制器异步地控制系统向终态趋近 使系统自动化和无人值守成为可能 便于扩展(自定义资源和控制器) 查看api资源 支持的api接口版本：kubectl api-versions 支持的api资源信息：kubectl api-resources 自定义api资源 修改kubernetes源码自定义类型 创建自定义API server，并将其聚合至集群中 使用自定义资源CRD API使用 客户端命令(kubectl)：默认使用https访问接口，并且需要进行认证检查(kubeconfig) http方式：为了使用通用的HTTP方式访问API接口，可以使用kubectl proxy在本地启动一个网关代理 启动代理网关：kubectl proxy –port 8080 访问接口：curl localhost:8080/api/v1/namespaces/ web界面：kubernetes dashboard 自动化配置管理(kube-applier)：用户将配置推送到git仓库中，配置工具自动将配置同步到集群中 资源对象资源对象分类 工作负载（workload）：replicaset、job、deployment、statefulset、daemonset 发现和负载均衡（Discovery&amp;LB）：service、endpoint、ingress 配置和存储（config&amp;storage）：ConfigMap、secret、volume 集群级别资源（cluster）： namespace Node Role：名称空间级别的权限集合，可被RoleBinding引用 ClusterRole：cluster级别的权限集合，可被RoleBinding、ClusterRoleBinding医用 RoleBinding：将Role或ClusterRole许可的权限绑定在一个或一组用户之上，隶属于且仅能作用于一个名称空间 ClusterRoleBinding：将ClusterRole许可的权限绑定在一个或一组用户之上 元数据（metadata）：HPA(自动弹性伸缩)、pod模板、LimitRange(限制pod的资源使用) 资源对象格式123456789101112apiVersion: v1kind: Podmetadata: name: nginx lables: name: nginxspec: containers: - name: nginx image: nginx ports: - containerPort: 80 kind：资源类型 apiVersion：API群组及相关的版本 metadata：为资源提供元数据，如名称、隶属的名称空间、标签 spec：用户期望的状态；资源配置详情 status(集群维护，用户只读)：活动对象的当前状态 资源对象文档 查看资源对象语法：kubectl explain resources_name.field_name metadata必选字段 namespace：所属名称空间【默认default】 name：对象名称 uid(集群自动生成)：当前对象的唯一标识符 可选字段 labels:设定用于标识当前对象的键值对，常用作筛选条件 annotations：非标识性键值对，用于labels的补充 标签和标签选择器标识型的key:value元数据；可以在创建时指定，也可以通过命令随时添加到活动对象上 标签定义 键由键前缀和健名组成 健名最多63个字符，只能以字母和数字开头及结尾，包含字母、数字、连词符、下划线、点 键前缀是dns子域名格式，且不能超过253字符；省略前缀，键将被视为用户私有数据；由kubernetes系统组件或第三方组件为用户添加的键必须使用键前缀；“kubernetes.io”是系统核心组件使用的 键值：和健名规则相同 常用标签 版本标签：release：stable，release：canary，release：beta 环境标签：environment：dev，environment：qa，environment：prod 应用标签：app：ui，app：as，app：pc，app：sc 服务分层标签：tier：frontend，tier：backend，backend：cache 分区标签：partition：customerA，partition：customerB 品控级别标签：track：daily，track：weekly 创建时添加标签1234567891011kind: PodapiVersion: v1metadata: name: pod-label labels: env: qa tier: frontendspec: containers: - name: myapp image: ikubernetes/myapp:v1 动态修改标签 修改已存在标签：kubectl label pods/pod-label env=prod –overwrite 添加新标签：kubectl label pods/pod-label release=alpha 删除标签：kubectl label pods/pod-label release- 标签显示 显示所有标签：kubectl get pod –show-labels 显示特定键标签：kubectl get pod -L env,tier 标签选择器 标签选择器逻辑 多个选择器之间为逻辑“与”关系 空值的标签选择器意味着所有对象都被选中 空标签选择器意味着没有对象被选中 选择器种类 等值关系，操作符：“=”，“==”，“！=” 集合关系，操作符：in，notin，exists(key-存在，!key-不存在) 命令行使用： 相等型：kubectl get deployment –show-labels -l env=test,env!=prod 集合型：kubectl get deployment –show-labels -l “Env in (test,gray)，Tie notin (front,back)，release，!release” selector使用【deployment、service、replicaset等使用】： matchLabels：相等型关系匹配 matchExpressions：集合型关系匹配 key：key_name operator：In、NotIn、Exists、DoesNotExist values：[values1,values2…]12345678910selector: matchLables: component: redis matchExpressions: - key: tier operator: In values: [cache] - key: environment operator: Exists values: 注解-annotations定义它也是标识型的键值对信息，但不能用于标签及对象选择，仅用于为资源提供元数据注解中的数据不受字符数量、特殊字符限制，可以是结构化(如json)也可以是非结构化数据 使用场景 在为某资源引入新字段时，先以注解的方式提供；确定支持使用后，在资源中添加新字段，同时删除相关注解 资源的相关描述信息 查看注解 describe：kubectl describe pod storage-provisioner -n kube-system get -o yaml：kubectl get pod storage-provisioner -n kube-system -o yaml 手动添加注解kubectl annotate pods pod-label ilinux.io/created-by=”cluster admin” kubectl命令语法格式kubectl sub_command resource_type resource_name cmd_option 子命令 基础命令-初级 create：从文件或标准输入创建资源 expose： 基于RC、service、deployment或pod创建service run：通过创建Deployment在集群运行指定的镜像 set：设置指定资源的属性 基础命令-中级 explain：资源文档 get：显示一个或多个资源 edit：编辑集群上的资源，相当于先get后apply delete：基于标准输入、文件名、资源名，或者资源标签删除资源 部署命令 rollout：管理资源的滚动更新 scale：设置资源Deployment、Replicaset、ReplicationController、Job的副本数 autoscale：自动设置Deployment、Replicaset、ReplicationController的副本数 集群管理命令 certificate：配置数字证书资源 cluster-info：显示集群信息 top：显示资源(CPU/内存/存储)使用率 cordon：标记节点为“不可调度”状态 uncordon：标记节点为“可调度”状态 drain：驱逐节点上的工作负载进入“维护”模式 taint：更新节点的污点 排错和调试命令 describe：显示资源或资源组详情 logs：显示pod内容器的日志 attach：挂载终端到一个运行中的容器 exec：在容器中执行命令 port-forward：转发一个或多个本地端口流量到pod proxy：创建一个可以访问APIServer的代理 cp：在容器间复制文件和目录 auth：显示授权信息 高级命令 diff：对比活动的资源信息和将要应用的资源信息 apply：基于文件名或标准输入应用资源配置信息 patch：使用策略合并补丁更新资源的字段信息 replace：基于文件名或标准输入替换一个资源 wait：实验性功能，等待一个或多个资源的特定条件 convert：为不同api版本转换配置文件 设置命令 label：更新资源标签 annotate：更新资源注解 completion：输出指定shell的命令补全代码 其他命令： api-resources：显示k8s支持的api资源 api-versions：显示k8s支持的api资源，以“group/version”形式 config：配置kubeconfig文件 plugin：提供和插件交互的工具 version：显示客户端和服务端的版本信息 命令选项 -f：指定资源文件 可以读取json、yaml格式资源清单 指定清单文件路径、URL、目录 可以多次使用 -R递归获取多级目录清单文件 -o：指定输出格式 wide：宽格式显示 yaml、json：yaml、json格式显示资源对象 go-template：以自定义的go模板格式显示资源对象 custom-columns：自定义输出字段：kubectl get pod -o custom-columns=NAME:metadata.name,IMAGE:spec.containers[0].image -l：通过标签过滤资源 -n：指定名称空间 -s：指定apiserver地址 –kubeconfig：指定kubeconfig文件【默认~/.kube/config】 插件-kubectl-debug 简介:通过启动一个安装了各种排障工具的容器，来诊断目标容器 安装 命令使用：kubectl debug pod_name --agentless 命令参数： –fork：诊断一个处于CrashLookBackoff的pod –agentless：启动无代理模式【命令使用时自动创建一个agent】 –image：指定使用的工具镜像【默认的镜像：nicolaka/netshoot】 -c container-name：指定要进入的容器内 常见对象操作创建资源对象 直接通过各种子命令管理资源对象：kubectl run 根据资源文件创建资源对象：kubectl create 根据声明式资源文件让kubernetes集群自动调整资源状态：kubectl apply 查看资源对象 get命令：kubectl get resource_type resource_name describe命令：kubectl describe resource_type resource_name 参数： -o wide/yaml/json/custom-columns:显示格式 -n namespace 名称空间 -l key=value 指定过滤标签 修改资源对象 edit: 编辑运行中的资源 apply：应用修改的资源文件 删除资源对象 delete命令:：kubectl delete resource_type resource_name 查看pod日志 logs命令:kubectl logs pod_id 参数： -c 指定容器名称 容器中执行命令 exec命令: kubectl exec -it pod_name -c container_name /bin/bash pod弹性伸缩 scale命令: kubectl scale rc nginx –replicas=4 镜像升级和回滚 查看当前版本：kubectl get deploy -o wide 更新镜像：kubectl set image deploy/nginx-deployment nginx=nginx:1.13 回滚到上个版本：kubectl rollout undo deploy nginx-deployment]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubectl</tag>
        <tag>标签</tag>
        <tag>选择器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式存储glusterfs与heketi]]></title>
    <url>%2F2020%2F03%2F18%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8glusterfs%E4%B8%8Eheketi%2F</url>
    <content type="text"><![CDATA[简介在实践kubernetes的statefulset及各种需要持久存储的功能时，通常需要用到PV的动态供给功能，而glusterfs就是这样一种可以提供动态供给功能的存储系统 部署架构 主机名 ip地址 角色 node1 172.17.8.101 glusterfs node2 172.17.8.102 glusterfs node3 172.17.8.103 glusterfs,heketi 部署glusterfs 安装软件【三个节点都进行】 123yum install centos-release-gluster -yyum --enablerepo=centos-gluster*-test install glusterfs-server -ysystemctl start glusterd.service 在任意节点使用命令“发现”其他节点【例如node1】 12gluster peer probe node2gluster peer probe node3 查看集群状态:gluster peer status 部署heketiheketi为管理glusterfs存储卷的生命周期提供了一个RESTful管理接口，借助于heketi，kubernetes可以动态调配glusterfs存储卷；在heketi中注册的设备(device)可以是裸分区或裸磁盘 安装heketi 添加仓库：wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 安装程序：yum install heketi heketi-client 配置heketi到glusterfs的ssh123456ssh-keygen -t rsa -q -f /etc/heketi/heketi_key -N &apos;&apos;chmod 0600 /etc/heketi/heketi_key.pub chown heketi.heketi /etc/heketi/heketi_key*ssh-copy-id -i /etc/heketi/heketi_key.pub root@172.17.8.103ssh-copy-id -i /etc/heketi/heketi_key.pub root@172.17.8.102ssh-copy-id -i /etc/heketi/heketi_key.pub root@172.17.8.101 heketi配置文件 /etc/heketi/heketi.json 1234567891011121314151617181920212223&#123; &quot;port&quot;: &quot;8080&quot;, # 服务端口 &quot;use_auth&quot;: true, # 开启认证 &quot;jwt&quot;: &#123; &quot;admin&quot;: &#123; #管理员及密码 &quot;key&quot;: &quot;admin secret&quot; &#125;, &quot;user&quot;: &#123; &quot;key&quot;: &quot;My Secret&quot; &#125; &#125;, &quot;glusterfs&quot;: &#123; #heketi管理glusterfs的方式 &quot;executor&quot;: &quot;ssh&quot;, &quot;sshexec&quot;: &#123; &quot;keyfile&quot;: &quot;/etc/heketi/heketi_key&quot;, &quot;user&quot;: &quot;root&quot;, &quot;port&quot;: &quot;22&quot;, &quot;fstab&quot;: &quot;/etc/fstab&quot; &#125;, &quot;db&quot;: &quot;/var/lib/heketi/heketi.db&quot;, #heketi数据库 &quot;loglevel&quot; : &quot;debug&quot; #日志 &#125;&#125; 启动heketi服务 systemctl enable heketi systemctl start heketi 测试： curl方式：curl http://node3:8080/hello 内置命令：heketi-cli --server http://node3:8080 --user admin --secret &quot;admin secret&quot; cluster list heketi添加glusterfs 拓扑配置【/etc/heketi/heketi-topology.json】 1234567891011121314151617181920212223242526272829303132333435363738&#123; &quot;clusters&quot;: [ &#123; &quot;nodes&quot;: [ &#123; &quot;node&quot;: &#123; &quot;hostnames&quot;: &#123; &quot;manage&quot;: [&quot;172.17.8.101&quot;], &quot;storage&quot;: [&quot;172.17.8.101&quot;] &#125;, &quot;zone&quot;: 1 &#125;, &quot;devices&quot;: [&quot;/dev/sdb&quot;, &quot;/dev/sdc&quot;] &#125;, &#123; &quot;node&quot;: &#123; &quot;hostnames&quot;: &#123; &quot;manage&quot;: [&quot;172.17.8.102&quot;], &quot;storage&quot;: [&quot;172.17.8.102&quot;] &#125;, &quot;zone&quot;: 1 &#125;, &quot;devices&quot;: [&quot;/dev/sdb&quot;, &quot;/dev/sdc&quot;] &#125;, &#123; &quot;node&quot;: &#123; &quot;hostnames&quot;: &#123; &quot;manage&quot;: [&quot;172.17.8.103&quot;], &quot;storage&quot;: [&quot;172.17.8.103&quot;] &#125;, &quot;zone&quot;: 1 &#125;, &quot;devices&quot;: [&quot;/dev/sdb&quot;, &quot;/dev/sdc&quot;] &#125; ] &#125; ]&#125; heketi添加glusterfs拓扑配置：heketi-cli -s http://node3:8080 --user admin --secret &quot;admin secret&quot; topology load --json=/etc/heketi/heketi-topology.json 信息查看： 查看集群信息：cluster list|cluster info ced9fc3405909cda59dd36101afea898 查看节点信息：node list|node info 96a281a85ce8cc8a97a74c88c9173442 存储卷信息：volume list 测试 创建存储卷：volume create –size=5 删除存储卷：volume delete volume_id kubernetes中使用glusterfs创建storageclass1234567891011121314apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: glusterfsprovisioner: kubernetes.io/glusterfsparameters: resturl: &quot;http://172.17.8.103:8080&quot; clusterid: &quot;ced9fc3405909cda59dd36101afea898&quot; restauthenabled: &quot;true&quot; restuser: &quot;admin&quot; restuserkey: &quot;admin secret&quot; # secretNamespace: &quot;default&quot; # secretName: &quot;heketi-secret&quot; volumetype: &quot;replicate:2&quot; 创建pvc123456789101112apiVersion: v1kind: PersistentVolumeClaimmetadata: name: myclaimspec: storageClassName: &quot;glusterfs&quot; accessModes: - ReadWriteOnce volumeMode: Filesystem resources: requests: storage: 5Gi]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>glusterfs</tag>
        <tag>heketi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-statefulset控制器]]></title>
    <url>%2F2020%2F03%2F18%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-statefulset%E6%8E%A7%E5%88%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[有无状态 分类标准：应用程序在和其他用户、设备、程序通信时，根据是否需要记录相关状态信息以用于下次通信，可以将程序分类如下： 有状态应用(stateful)：需要记录信息 无状态应用(stateless)：无需记录 控制器 无状态控制器：replicaset，多个pod使用共享的存储卷(ReadWriteMany，ReadMany) 有状态控制器：statefulset，每个pod使用专用的存储卷(ReadWriteOnce) 状态和存储交叉组合 需要读写磁盘的有状态应用：支持事务功能的RDBMS；各种分布式存储系统（redis cluster、mongodb、zookeeper） 需要读写磁盘的无状态应用：具有幂等性的文件上传服务；从外部存储加载静态资源以响应用户请求的web服务 无磁盘访问的无状态应用：地理坐标转换器 无磁盘访问的有状态应用：电子商城中的购物车系统 statefulset介绍特点 稳定且唯一的网络标识符：pod名称 稳定且持久的存储：基于动态或静态的pvc 有序的部署和终止：基于索引号从前往后部署，基于索引号从后往前终止 有序的自动滚动更新：基于索引号从后往前更新 一般组成 Headless Service：为pod资源生成DNS记录 Statefulset：管控pod资源 volumeClaimTemplate：为pod资源提供专用且固定的存储 statefulset范例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051apiVersion: v1kind: Servicemetadata: name: myapp-svc labels: app: myapp-svcspec: ports: - port: 80 name: web clusterIP: None selector: app: myapp-pod---apiVersion: apps/v1kind: StatefulSetmetadata: name: myappspec: updateStrategy: rollingUpdate: partition: 2 serviceName: myapp-svc replicas: 3 selector: matchLabels: app: myapp-pod template: metadata: labels: app: myapp-pod spec: containers: - name: myapp image: ikubernetes/myapp:v5 ports: - containerPort: 80 name: web volumeMounts: - name: myappdata mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: myappdata spec: accessModes: [&quot;ReadWriteOnce&quot;] # storageClassName: &quot;standard&quot; storageClassName: &quot;glusterfs&quot; resources: requests: storage: 2Gi statefulset管理扩容缩容 支持扩容缩容，但具体的实现机制依赖于应用本身 scale方法：kubectl scale statefulset myapp --replicas=4 patch方法：kubectl patch statefulset myapp -p &#39;{&quot;spec&quot;:{&quot;replicas&quot;:3}}&#39; 更新 支持自动更新 更新策略： OnDelete：删除pod才会触发重建更新 RollingUpdate：自动更新，默认的更新策略 分区更新： RollingUpdate也支持分区机制(partition),只有大于索引号(partition)的pod资源才会被滚动更新 若给定的分区号大于副本数量，则意味着不会有pod资源索引号大于此分区号，所有的pod资源均不会被更新 命令： 查看镜像信息：kubectl get pod -o custom-columns=NAME:metadata.name,IMAGE:spec.containers[0].image 更新镜像：kubectl set image statefulset myapp myapp=ikubernetes/myapp:v6 更新状态查询：kubectl rollout status statefulset myapp 实践 暂存更新操作：将分区号(partition)设置为和副本数(replicas)一样大，此后所有的更新操作都将暂停 金丝雀部署：调整分区号至小于副本数，不断“放出金丝雀”，触发更新操作 实践不同的有状态应用的运维操作过程差别巨大，statefulset本身无法提供通用管理机制现实中的各种有状态应用通常是使用专门的自定义控制器专门封装特定的运维操作流程这些自定义控制器有时被统一称为operator 范例-etcd集群service1234567891011121314151617apiVersion: v1kind: Servicemetadata: name: etcd labels: app: etcd annotations: service.alpha.kubernetes.io/tolerate-unready-endpoints: &quot;true&quot;spec: ports: - port: 2379 name: client - port: 2380 name: peer clusterIP: None selector: app: etcd-member statefulset1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162apiVersion: apps/v1kind: StatefulSetmetadata: name: etcd labels: app: etcdspec: serviceName: etcd replicas: 3 selector: matchLabels: app: etcd-member template: metadata: name: etcd labels: app: etcd-member spec: containers: - name: etcd image: &quot;quay.mirrors.ustc.edu.cn/coreos/etcd:v3.3.18&quot; ports: - containerPort: 2379 name: client - containerPort: 2380 name: peer env: - name: CLUSTER_SIZE value: &quot;3&quot; - name: SET_NAME value: &quot;etcd&quot; volumeMounts: - name: data mountPath: /var/run/etcd command: - &quot;/bin/sh&quot; - &quot;-ecx&quot; - | IP=$(hostname -i) PEERS=&quot;&quot; for i in $(seq 0 $(($&#123;CLUSTER_SIZE&#125; - 1)));do PEERS=&quot;$&#123;PEERS&#125;$&#123;PEERS:+,&#125;$&#123;SET_NAME&#125;-$&#123;i&#125;=http://$&#123;SET_NAME&#125;-$&#123;i&#125;.$&#123;SET_NAME&#125;:2380&quot; done exec etcd --name $&#123;HOSTNAME&#125; \ --listen-peer-urls http://$&#123;IP&#125;:2380 \ --listen-client-urls http://$&#123;IP&#125;:2379,http://127.0.0.1:2379 \ --advertise-client-urls http://$&#123;HOSTNAME&#125;.$&#123;SET_NAME&#125;:2379 \ --initial-advertise-peer-urls http://$&#123;HOSTNAME&#125;.$&#123;SET_NAME&#125;:2380 \ --initial-cluster-token etcd-cluster-1 \ --initial-cluster $&#123;PEERS&#125; \ --initial-cluster-state new \ --data-dir /var/run/etcd/default.etcd volumeClaimTemplates: - metadata: name: data spec: storageClassName: &quot;glusterfs&quot; accessModes: - &quot;ReadWriteOnce&quot; resources: requests: storage: 2Gi 验证 查看service与pod绑定关系：kubectl get endpoints -l app=etcd 查看pod：kubectl get pod -l app=etcd-member -o wide 查看etcd集群状态：kubectl exec etcd-0 -- etcdctl cluster-health 注意 扩缩容： 扩容：先提升副本数量再手动添加节点 缩容：先移除节点再手动缩减副本数量 镜像升级：使用scale或patch即可完成应用镜像升级]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>StatefulSet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-kubeadm方式部署]]></title>
    <url>%2F2020%2F03%2F11%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-kubeadm%E6%96%B9%E5%BC%8F%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[kubeadm介绍kubeadm是kubernetes集群的全生命周期管理工具，可实现：集群部署、升级、降级、拆除kubeadm仅关心集群的初始化并启动集群，只安装必需的组件(dns)，其他的组件（dashboard、ingress、flannel）则需要管理员自行部署 kubeadm init：集群初始化，核心功能是部署master节点的各个组件(kube-api-server/kube-controller-manager/kube-scheduler) kubeadm join：将节点加入集群 kubeadm token：集群构建后管理加入集群的token kubeadm reset：删除集群构建过程中产生的文件，恢复到未创建集群的状态 部署要求 部署实践：https://gitee.com/simple0426/kubeadm-k8s.git 主机数：3个及以上 os：Ubuntu 16.04+、CentOS 7 内存：2G以上 cpu：2核以上 网络：主机互联、且可以连接公网（下载镜像） 主机名、MAC地址唯一，在hosts中做手动解析 个别端口放开 关闭swap 12swapoff -ased -i &apos;/swap/s/^/#/&apos; /etc/fstab 时间同步 1234yum install -y ntpntpdate times.aliyun.comsystemctl start ntpdsystemctl enable ntpd 关闭防火墙、selinux 123456systemctl stop firewalldsystemctl disable firewalldsystemctl stop iptablessystemctl disable iptablessetenforce 0sed -i &apos;s/=enforcing/=disabled/g&apos; /etc/selinux/config 启用ipvs模块 1234567ipvs_mods_dir=&quot;/usr/lib/modules/$(uname -r)/kernel/net/netfilter/ipvs&quot;for i in $(ls $ipvs_mods_dir|grep -o &quot;^[^.]*&quot;);do/sbin/modinfo -F filename $i &amp;&gt; /dev/nullif [ $? -eq 0 ];then/sbin/modprobe $ifidone iptables设置：可以查看网桥流量 12345cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsudo sysctl --system 部署步骤安装docker master、node都操作 根据kubeadm要求配置启动参数 配置镜像加速地址1234567891011121314151617cat &gt; /etc/docker/daemon.json &lt;&lt;EOF&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;registry-mirrors&quot; : [&quot;https://2x97hcl1.mirror.aliyuncs.com&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;100m&quot; &#125;, &quot;storage-driver&quot;: &quot;overlay2&quot;, &quot;storage-opts&quot;: [ &quot;overlay2.override_kernel_check=true&quot; ]&#125;EOFsystemctl daemon-reloadsystemctl enable dockersystemctl restart docker 安装kubelet、kubeadm、kubectl master、node都操作 注意事项：此处的kubelet、kubeadm、kubectl需要与下文中kubernetes版本保持一致，由于阿里镜像源滞后，所以不能安装最新版本k8s 指定版本安装：yum install kubelet-1.17.3 kubeadm-1.17.3 kubectl-1.17.3 -y kubelet开启启动：systemctl enable kubelet 集群初始化 master操作 123456kubeadm init --kubernetes-version=v1.17.3 \--pod-network-cidr=10.244.0.0/16 \--service-cidr=10.96.0.0/12 \--apiserver-advertise-address=172.17.8.201 \--image-repository=registry.aliyuncs.com/google_containers \--ignore-preflight-errors=NumCPU --dry-run 根据init结果提示操作 配置kubectl【master】 安装网络插件【master】 允许master部署负载【master/可选】:kubectl taint nodes --all node-role.kubernetes.io/master- 使用kubeadm join命令将node加入集群【node】 网络插件插件分类 flannel，包含模式如下 vxlan：隧道模式 host-gw：路由模式，性能最好 calico，包含模式如下 ipip bgp 插件选择 网络规模大小 网络规模小，使用flannel的host-gw模式 网络规模小，但是有路由等网络限制，使用flannel的vxlan 网络规模大，使用calico 多租户使用，且有ACL访问限制，使用calico 维护成本，flannel小，calico大 flannel安装 下载资源文件 kube-flannel.yml文件修改 pod网络设置(net-conf.json) 镜像地址修改 主机间通信接口设置(假设eth1为主机间通信接口：--iface=eth1) 应用资源文件：kubectl apply -f kube-flannel.yml kubeadm管理移除节点 master节点执行： kubectl drain &lt;node name&gt; --delete-local-data --force --ignore-daemonsets kubectl delete node &lt;node name&gt; 被移除节点执行：kubeadm reset 被移除节点删除iptables：iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X 被移除节点删除ipvs：ipvsadm -C join认证信息 token：默认24小时过期 查看：kubeadm token list 产生新的：kubeadm token create --print-join-command cert-hash查看12openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | \ openssl dgst -sha256 -hex | sed &apos;s/^.* //&apos; 证书管理 查看证书过期时间(默认1年)：kubeadm alpha certs check-expiration 证书续签(默认1年)：kubeadm alpha certs renew all 续签后使用证书的组件重启：kubelet/kube-proxy/apiserver/scheduler/control-manager 附加组件部署dashboard 下载资源文件 资源文件修改 将dashboard的访问端口暴露在宿主机上：containers–》ports–》hostPort: 8443 dashboard部署在node02上：nodeSelector–》kubernetes.io/hostname: “node02” 建立管理员 登录token获取：kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk &#39;{print $1}&#39;) web访问：https://172.17.8.202:8443/ ingress-nginx 下载资源文件 pod及service修改配置 ingress部署在node02上：nodeSelector–》kubernetes.io/hostname: “node02” 修改nginx-ingress-controller镜像地址 将ingress的访问端口暴露在宿主机上：nodePort：30080/30443 metric-server 设置api-server： 文件位置：/etc/kubernetes/manifests/kube-apiserver.yaml 配置：--enable-aggregator-routing=true 重载配置：删除api-server的pod使其自动重建 下载资源文件 修改配置(deployment) 修改镜像地址(image) 容器启动参数(args) --kubelet-insecure-tls --kubelet-preferred-address-types=InternalIP 验证资源指标API可用性 kubectl get --raw &quot;/apis/metrics.k8s.io/v1beta1/pods&quot; kubectl get --raw &quot;/apis/metrics.k8s.io/v1beta1/nodes&quot; 获取node或pod对象的资源使用情况：kubectl top node/pod prometheus 设置api-server： 文件位置：/etc/kubernetes/manifests/kube-apiserver.yaml 配置：–enable-aggregator-routing=true 重载配置：删除api-server的pod使其自动重建 设置kubelet【/etc/sysconfig/kubelet】 --authentication-token-webhook=true --authorization-mode=Webhook 下载资源文件 kubectl create -f manifests/setup kubectl create -f manifests/ hosts设置【由于nginx-ingress部署在172.17.8.202】 123172.17.8.202 alertmanager.myapp.com172.17.8.202 grafana.myapp.com172.17.8.202 prometheus.myapp.com 访问入口设置-ingress 12345678910111213141516171819202122232425262728apiVersion: extensions/v1beta1kind: Ingressmetadata: name: prometheus-ingress namespace: monitoringspec: rules: - host: prometheus.myapp.com http: paths: - path: / backend: serviceName: prometheus-k8s servicePort: 9090 - host: grafana.myapp.com http: paths: - path: / backend: serviceName: grafana servicePort: 3000 - host: alertmanager.myapp.com http: paths: - path: / backend: serviceName: alertmanager-main servicePort: 9093 访问： grafana：http://grafana.myapp.com:30080/ alert：http://alertmanager.myapp.com:30080/ prometheus：http://prometheus.myapp.com:30080/]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubeadm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-监控和日志]]></title>
    <url>%2F2020%2F03%2F11%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-%E7%9B%91%E6%8E%A7%E5%92%8C%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[监控类型 资源监控(cpu、内存、磁盘、带宽) 性能监控-APM(jvm) 安全监控 k8s事件监控 监控方案-heapster架构 数据采集：kubelet/cadvisor 数据接口：kubelet、summary、prometheus 数据消费：dashboard、horizontal pod autoscaler(HPA/pod弹性伸缩)、kubectl top 整合方案 inflexDB：存储 grafana：可视化 heapster：数据采集 heapter缺点 包含了太多的存储后端接口代码，某些代码已不再维护 接口格式混乱，不支持prometheus 仅支持以CPU为基础的弹性伸缩 新一代监控方案 资源指标API和自定义指标API被创建为API定义而非具体实现，他们作为聚合的API安装到kubernetes集群中，从而允许API在保持不变的情况下切换其具体的实现方案 通过APIServer Aggregated API注册了三种不同的metrics接口，将监控的消费能力进行标准化和解耦，从而实现了与社区的融合 - API 注释 Resources metrics metrics.k8s.io 主要的实现为metrics-server，提供资源监控 Custom metrics custom.metrics.k8s.io 主要的实现为prometheus，提供资源监控和自定义监控 External metrics external.metrics.k8s.io 主要的实现为云厂商的provider，提供云资源的监控指标 metric-server部署安装参考：https://github.com/kubernetes-sigs/metrics-server错误处理：以下解决方式适用于手动安装的kubernetes集群（非kubeadm方式） 安装metric-server证书 错误：metric-server x509: certificate signed by unknown authority 需要先安装cfssl工具 cd /etc/kubernetes/pki/ 创建签名请求 12345678910111213141516171819cat &gt; metrics-server-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;aggregator&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;Hangzhou&quot;, &quot;L&quot;: &quot;Hangzhou&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;4Paradigm&quot; &#125; ]&#125;EOF 使用CA签发证书和私钥：cfssl gencert -ca=/etc/kubernetes/pki/ca.pem -ca-key=/etc/kubernetes/pki/ca-key.pem -config=/etc/kubernetes/pki/ca-config.json -profile=kubernetes metrics-server-csr.json|cfssljson -bare metrics-server apiserver开启聚合配置 错误：I0313 05:18:36.447202 1 serving.go:273] Generated self-signed cert (apiserver.local.config/certificates/apiserver.crt, apiserver.local.config/certificates/apiserver.key)Error: cluster doesn’t provide requestheader-client-ca-file 12345678--proxy-client-cert-file=/etc/kubernetes/pki/metrics-server.pem \--proxy-client-key-file=/etc/kubernetes/pki/metrics-server-key.pem \--runtime-config=api/all=true \--requestheader-client-ca-file=/etc/kubernetes/pki/ca.crt \--requestheader-allowed-names=aggregator \--requestheader-extra-headers-prefix=X-Remote-Extra- \--requestheader-group-headers=X-Remote-Group \--requestheader-username-headers=X-Remote-User 容器网络配置 错误【容器解析的主机名不是节点ip】：E0313 08:23:41.193222 1 manager.go:102] unable to fully collect metrics: [unable to fully scrape metrics from source kubelet_summary:192.168.209.130: unable to fetch metrics from Kubelet 192.168.209.130 (192.168.209.130) 12- --kubelet-insecure-tls- --kubelet-preferred-address-types=InternalIP prometheus架构 数据采集(pull模型)：pushgateway(short-lived jobs)、exporter、service discovery 数据聚集存储：node-hdd/ssd(storage)、promQL(查询语言) 报警：altermanager 展示：api clients、grafana、web UI 与k8s集成：基于prometheus收集和存储指标数据，借助于k8s-prometheus-adapter将这些指标数据查询接口转换为标准的kubernetes自定义指标 插件 kube-eventer：阿里开源的k8s事件离线通知工具 各类exporter node_exporter：收集主机指标数据 kubelet/ccadvisor：收集容器数据 APIServer：收集APIServer的性能指标数据 etcd：收集etcd存储集群的指标数据 kube-state-metrics：能通过API Service监听资源对象的状态并生成相关的指标；包含资源类型相关的计数器和元信息，包含指定类型对象总数、资源限额、容器状态、pod资源标签 各类api clients 部署kubernetes上部署prometheus 日志分类 主机内核日志：网络栈异常、驱动异常、文件系统异常 runtime日志：docker日志，可以排查删除pod hang等问题 核心组件日志： apiserver日志用来审计 scheduler日志可以诊断调度 etcd日志可以查看存储状态 ingress日志可以分析接入层流量 部署应用的日志：查看业务层状态 日志采集 方案1： fluentd:采集、聚合 elsticsearch：索引、存储 kibanna：可视化、分析 方案2： fluentd:采集、聚合 influxdb：索引、存储 grafana：可视化、分析 阿里云产品实践 云监控 SLS：日志服务 ARMS(java/php)：性能监控 AHAS(应用高可用服务)： 架构感知 故障演练 流控降级]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>metrics-server</tag>
        <tag>prometheus</tag>
        <tag>监控</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-包管理器helm]]></title>
    <url>%2F2020%2F03%2F08%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-%E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8helm%2F</url>
    <content type="text"><![CDATA[简介实现目标 能够管理复杂的程序结构 方便升级：可使用就地升级和自定义钩子 便于分享：使用charts构建和分享程序 便于回滚：使用helm rollback快速回滚 核心术语 Helm：是k8s的应用程序管理器，也是helm的客户端；相当于linux系统的apt、yum；主要完成如下工作 本地charts开发 管理charts仓库 与tiller服务交互：发送charts以安装、查询Release的相关信息、升级或卸载已有的Release Tiller server：它是运行于k8s集群中的应用；helm的服务端程序，接收helm客户端请求，与kubernetes API Server交互，完成以下任务： 监听来自helm客户端的请求 安装应用，合并charts和Config为一个Release 跟踪Release状态 升级或卸载Release Chart：是helm的核心打包组件，用于将kubernetes的资源(deployments/service/configmap等)打包进一个charts中 Charts：一个Helm程序包，相当于linux的rpm、deb包 Repository：charts仓库，存储charts程序，相当于linux的yum或apt仓库源 Config：charts程序实例化运行时使用的配置文件 Release：charts实例化配置后运行于k8s集群中的一个charts实例；在同一个集群中，一个charts可以使用不同的Config重复安装多次，每次安装都会创建一个新的Release；相当于linux的进程 应用管理流程 从0开始创建charts：helm create 将charts及相关的文件打包为归档格式：helm package 将charts存储于仓库中并与之交互：helm repo 在kubernetes集群中安装或卸载charts：helm install、delete 管理经Helm安装的应用的版本发行周期：helm rollback helm安装安装helm-client [源码下载] 官方【被墙不可用，可以查询版本】 google:可基于github版本和google地址前缀下载源码 linux windows 解压：tar -xzvf helm-v2.14.1-linux-amd64.tar.gz 移动二进制文件：mvn linux-amd64/helm /usr/local/bin/ 注意事项：helm命令运行的节点应该可以正常运行kubectl命令，或者至少有可用kubeconfig配置文件，这样才可以和运行于k8s集群中的tiller server进行通信 安装tiller-server rbac配置–资源清单方式 123456789101112131415161718apiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system---apiVersion: rbac.authoriation.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: tillerRoleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: tiller namespace: kube-system rbac配置–命令行方式 kubectl create serviceaccount --namespace kube-system tiller kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller 初始化安装tiller server：helm init --service-account tiller --tiller-image registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.14.1 --stable-repo-url https://apphub.aliyuncs.com --debug 卸载： kubectl delete deploy tiller-deploy -n kube-system helm reset 操作命令 helm repo update：更新本地仓库元信息 helm search charts_name：搜索软件包 helm inspect charts_name：显示包详情 helm install charts_name -n release_name：安装软件包 -n release_name：部署的release名称 –dry-run：测试 –debug：调试 -f Config：使用自定义配置文件 –set key=value：使用自定义配置 安装源(charts_name)：目录、压缩包、仓库、URL helm list：显示已安装的Release helm status release_name：显示release的状态和提示信息 helm delete release_name：删除release helm upgrade：升级 helm rollback：回滚 helm history：显示版本历史 charts语法charts是helm使用的kubernetes程序打包格式，一个charts就是一个描述k8s资源文件的集合 目录结构12345678910111213141516mychart #charts名称├── Chart.yaml charts元数据信息├── LICENSE 许可证信息【可选】├── README.md README文件【可选】├── requirements.yaml 当前charts的依赖关系【可选】├── charts 当前charts依赖的其他charts文件│ ├── mysql-6.8.0.tgz├── templates 模板文件，用于生成kubernetes资源│ ├── deployment.yaml│ ├── _helpers.tpl│ ├── ingress.yaml│ ├── NOTES.txt 模板注解文件，描述如何使用charts；helm status命令也会输出此内容│ ├── service.yaml│ └── tests│ └── test-connection.yaml└── values.yaml #默认配置文件，helm install -f参数会覆盖此默认配置 Chart.yaml123456789101112131415161718192021apiVersion: v1 appVersion: 5.0.7 #程序版本，redis版本description: Open source, advanced key-value store. It is often referred to as a data structure server since keys can contain strings, hashes, lists, sets and sorted sets. #描述信息engine: gotpl #模板引擎，go模板home: http://redis.io/ #项目主页icon: https://bitnami.com/assets/stacks/redis/img/redis-stack-220x234.png #项目图标keywords: #项目关键词- redis- keyvalue- databasemaintainers: #项目维护者- email: containers@bitnami.com name: Bitnami- email: cedric@desaintmartin.fr name: desaintmartinname: redis #charts名称sources: #项目源码- https://github.com/bitnami/bitnami-docker-redisversion: 10.5.3 #charts版本 requirements.yaml12345dependencies:- name: mysql #被依赖的charts名称 version: 6.8.0 #被依赖的charts版本 repository: https://apphub.aliyuncs.com #依赖的软件所属仓库（需要事前添加仓库） alias：给被依赖的charts建立别名 使用helm dependency update命令更新依赖关系，自动下载被依赖的charts到charts目录 自定义charts 创建空charts：helm create mychart 修改配置： values.yaml中的默认配置、镜像信息 chart.yaml中的描述信息 语法检查：helm lint mychart 安装部署：helm install –name myapp ./mychart –set service.type=NodePort 打包：helm package ./mychart charts仓库公有仓库 bitnami web地址：http://hub.kubeapps.com/ 仓库：https://cetic.github.io/helm-charts/ helm web地址：https://hub.helm.sh/ 仓库：https://kubernetes-charts.storage.googleapis.com、http://storage.googleapis.com/kubernetes-charts 阿里云： web地址：https://developer.aliyun.com/hub/ 仓库：https://apphub.aliyuncs.com 源码：https://github.com/cloudnativeapp/charts 内置仓库服务 helm serve：运行charts仓库服务 helm search local：搜索本地仓库 仓库服务实践 任何支持传输文件的的web服务器都可以作为charts仓库，如apache、nginx 仓库中有一个index.yaml用于描述仓库的所有charts信息(本地制作的charts可以使用helm repo index生成索引文件) repo命令 添加仓库：helm repo add name URL 显示仓库列表：helm repo list 更新仓库元信息：helm repo update 删除仓库：helm repo remove]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>helm</tag>
        <tag>charts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-service和ingress]]></title>
    <url>%2F2020%2F03%2F06%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-service%E5%92%8Cingress%2F</url>
    <content type="text"><![CDATA[service实现目标 服务发现：在pod的弹性伸缩变化过程中，保持外部访问入口不变 负载均衡：定义访问pod资源的策略 实现方式 服务发现：service定义一个访问入口(service_name、clusterIP)，并基于标签选择器选择一组pod 负载均衡：kube-proxy根据service和pod的映射关系(endpoints)，在节点上创建相应的iptables或ipvs规则 服务发现的实现 环境变量方式：在创建pod对象时，kubelet将活动的service对象的一系列环境变量注入到pod中【缺点：仅有那些与创建的pod对象处于同一名称空间且事先存在的service对象才会以环境变量方式注入】 DNS方式(例如CoreDNS)：集群中的DNS服务会为每个创建的service对象生成相应的解析记录(服务名称：service_name.namespace_name.svc.domain_name) 拥有ClusterIP的service：A记录【服务名称映射clusterIP】 Headless类型service(无ClusterIP)：A记录【服务名称映射endpointIP】 ExternalName类型service：CNAME记录【服务名称映射externalName】 负载均衡的实现实现方式 iptables：使用灵活、功能强大；但是规则更新和匹配时间随条目数的增加而线性增加 ipvs：工作在内核态，性能更优异；支持丰富的调度算法 参数配置 配置：kube-proxy配置–proxy-mode kubeadm方式部署集群kube-proxy变更 1231. 编辑kube-proxy configmap配置：kubectl edit cm kube-proxy -n kube-system 2. 重启kube-proxy pod【删除pod后自动重建】4. 查看pod日志 ipvs配置查看 配置条目：ipvsadm -Ln 使用网卡：kube-ipvs0 service类型 ClusterIP：默认的service类型，提供的ip只可以在集群内部访问 NodePort：建构于clusterIP类型之上，在节点绑定端口，可以在集群外部访问；实现方式：【NodePort==》ClusterIP:port】 LoadBalancer：建构于NodePort类型之上，指向云厂商设置的负载均衡设备(如阿里云SLB)，可以在集群外部访问；实现方式：【LoadBalancer==》NodePort==》ClusterIP】 ExternalName：不是定义k8s集群提供的服务，而是把集群外部的某服务以CNAME记录的方式映射到集群内，从而让集群内的pod资源能够访问外部的service;externlName只能是外部服务的域名(不能是ip)123456789101112apiVersion: v1kind: Servicemetadata: name: redis-svc namespace: defaultspec: type: ExternalName externalName: redis.example.com ports: - protocol: TCP port: 6379 targetPort: 6379 Headless类型service 设置：【clusterIp:None】 实现：不为service对象创建clusterIP，客户端直接通过pod-ip访问pod 实现方式： 有标签选择器(selector)：DNS直接将service_name解析为后端各pod对象的ip；客户端访问时，每次接入的pod资源则是由DNS服务器接收到查询请求时以轮询(roundrobin)方式返回的IP地址 无标签选择器 为ExternalName类型创建CNAME记录，例子如上 对其他类型来说，为那些与当前service共享名称的所有Endpoints对象创建一条记录 service语法范例 service部署 1234567891011121314apiVersion: v1kind: Servicemetadata: name: nginx-servicespec: ports: - port: 31222 #服务端口：ClusterIP protocol: TCP targetPort: 80 #pod/容器端口 nodePort: 32222 #节点端口【不设置或设置为0，系统自动配置】 selector: #选择的pod app: nginx type: NodePort #端口类型 # clusterIP: None 相关deployment 123456789101112131415161718192021apiVersion: apps/v1 kind: Deploymentmetadata: #Deployment元信息 name: nginx-deployment labels: app: nginxspec: replicas: 3 #期望的pod数量 selector: #pod选择器 matchLabels: app: nginx template: #pod模板 metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.12.2 ports: - containerPort: 80 service与ingress对比 service：工作于传输层(TCP)，构建于pod资源之上 基于netfilter之上进行的四层调度，如iptables、ipvs 支持调度http、mysql等应用层服务 Ingress：工作于应用层(HTTP/HTTPS)，构建于service资源之上 可以实现基于URL的请求调度机制 支持https证书 支持对后端服务器进行健康检查 Ingress 实质：将访问指定主机名或URL路径的请求转发到特定service资源的规则 实现：实现Ingress规则的组件就是Ingress Controller Ingress-Controller 与k8s核心组件关系：Ingress Controller不是集群kube-controller-manager的一部分，它是k8s集群的一个组件(类似于CoreDNS)，需要单独部署 本质：Ingress控制器本身也是作为一个pod资源在集群中运行，它可以由deployment或daemonset创建；由于需要接入外部流量，还需要为其创建相关的NodePort或LoadBalancer类型的Service资源对象 实现原理：Ingress控制器基于Ingress定义的规则将流量转发到service对应的后端pod上，service对象仅仅用于辅助Ingress识别pod对象；这种转发机制会绕过service资源，从而省去了kube-proxy实现的端口代理开销 实现软件：Ingress控制器可以由任何实现反向代理(HTTP/HTTPS)的软件实现，如nginx、traefik、Istio ingress-nginx： 资源文件 资源文件修改 镜像地址修改：registry.cn-hangzhou.aliyuncs.com/simple00426/nginx-ingress-controller:0.34.0 控制器类型修改(确保controller高可用及知晓部署节点)，可选方式例如：Deployment(默认)、DaemonSet 网络及端口设置(将ingress的访问入口暴露给集群外部)，可选方式例如：hostNetwork、hostPort、NodePort(默认) traefik-1.7 官方安装 第三方安装 traefik配置https Istio：服务治理 Ingress语法范例基于域名的虚拟主机123456789101112131415# traefik.jimmysong.io==》traefik-ingress-service:8080apiVersion: extensions/v1beta1kind: Ingressmetadata: name: traefik-ingress namespace: kube-systemspec: rules: #转发规则定义 - host: traefik.jimmysong.io #匹配的主机名【不支持ip、端口形式；字段留空表示所有主机名】 http: paths: - path: / backend: #处理请求的后端 serviceName: traefik-ingress-service #后端服务名 servicePort: 8080 #后端服务端口 基于URL路径-rewrite123456789101112131415161718192021# myapp.abc.com/tomcat==》tomcat-service:38080# myapp.abc.com/nginx==&gt;nginx-service:31222apiVersion: extensions/v1beta1kind: Ingressmetadata: name: traefik-ingress annotations: traefik.ingress.kubernetes.io/rewrite-target: /spec: rules: - host: myapp.abc.com http: paths: - path: /tomcat backend: serviceName: tomcat-service servicePort: 38080 - path: /nginx backend: serviceName: nginx-service servicePort: 31222 HTTPS设置 创建自签名证书 openssl genrsa -out tls.key 2048 openssl req -new -x509 -key tls.key -out tls.crt -subj /C=CN/ST=Beijing/L=Beijing/O=DevOps/CN=test.abc.com -days 3650 将证书放入k8s的secret中：kubectl create secret tls tomcat-ingress-secret –cert=tls.crt –key=tls.key -n testing 在ingress中设置123456789101112131415161718kind: IngressapiVersion: extensions/v1beta1metadata: name: tomcat namespace: testingspec: tls: #包含支持https的对象 - hosts: - test.abc.com #使用证书的主机名列表 secretName: tomcat-ingress-secret #基于证书创建的secret对象名称 rules: - host: test.abc.com http: paths: - path: backend: serviceName: tomcat-svc servicePort: 80 个性化设置-annotation1234567891011kind: IngressapiVersion: extensions/v1beta1metadata: name: tomcat-https annotations: kubernetes.io/ingress.class: &quot;nginx&quot; #部署多种ingress控制器时选择使用 nginx.ingress.kubernetes.io/ssl-redirect: &apos;true&apos; nginx.ingress.kubernetes.io/proxy-connect-timeout: &quot;600&quot; nginx.ingress.kubernetes.io/proxy-send-timeout: &quot;600&quot; nginx.ingress.kubernetes.io/proxy-read-timeout: &quot;600&quot; nginx.ingress.kubernetes.io/proxy-body-size: &quot;10m&quot; ingress-controller高可用 选用daemonset或deployment在多个节点部署多个pod 通过标签/标签选择器、污点/容忍度选定特定的几个节点方便前端代理 前端代理使用nginx+keepalived]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>service</tag>
        <tag>ingress</tag>
        <tag>服务发现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-网络模型和策略控制]]></title>
    <url>%2F2020%2F03%2F03%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%AD%96%E7%95%A5%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[kubernetes网络模型 要求所有容器都处于同一个ip网络中 集群中的ip地址分配是以pod为单位的，同一个pod内的所有容器共享同一个网络命名空间 pod和service对象分别使用各自专有的网络；pod网络由网络插件提供，serivce网络由kubernetes集群指定；pod ip是实际存在于某个网卡(可以是虚拟设备)上，而service地址却是一个虚拟IP地址。 实现目标 pod内容器间通信：一个pod内的所有容器共享同一个网络名称空间，它由构建pod对象的infra containers提供； pod之间通信：通过桥接方式连通多个网络名称空间(pod),也是各网络插件(flannel/calico)解决的问题，包含叠加网络模型(overlay)和路由网络模型(underlay) pod与service间通信：k8s将service的cluster-ip到pod-ip的映射转换为相应节点的iptables、ipvs规则，从而实现service到pod的通信 service与集群外部通信：k8s根据service的代理类型转换为相应节点的iptables或ipvs规则，从而实现外部流量到pod的通信 CNI插件 CNI插件连接容器管理系统和网络插件 CNI插件分类 main：实现特定的网络功能，如：bridge、loopback meta：调用其他插件，如：flannel、calico ipam：分配ip地址，如：dhcp CNI插件安装 安装cni插件集成包：kubernetes-cni，cni插件在/opt/cni/bin目录下 部署calico、flannel时会在/etc/cni/net.d/下生成插件的配置文件 kubelet启动后(–network-plugin=cni)会加载cni插件及其配置文件 如果kubelet开启cni后，缺少部分插件【failed to find plugin “portmap” in path [/opt/cni/bin]]】，则可以通过安装包补全插件123456789101112cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF yum clean allyum install kubernetes-cni -y 常见CNI插件对应的项目 flannel：一个为kubernetes提供overlay(叠加网络)的插件，它基于linux tun/tap，使用udp封装ip报文来创建叠加网络，并借助etcd维护网络分配情况；不支持网络策略 calico：一个基于BGP的三层网络插件，并且支持网络策略(network policy)实现访问控制；它在每台机器上运行一个vRouter，利用Linux内核来转发网络数据包，并借助iptables实现防火墙功能 canal：包含flannel和calico功能的插件，支持网络策略 weavenet：多主机容器网络方案，采用UDP封装实现L2 Overlay，支持用户态(慢，可加密)/内核态(快，不能加密)两种方式 kube-router：kubernetes提供的网络解决方案，采用BGP提供网络直连，集成基于LVS的负载均衡能力；支持网络策略 flannel网络模型/后端 vxlan：使用内核vxlan模块封装报文 host-gw：直接在节点创建到目标容器的路由，要求各节点处于同一个二层网络 udp：性能较低，仅适用于前两者不可用的情况【已废弃】 云厂商类型：Alivpc、AWSvpc、Alloc、GCE vxlan后端 vxlan(virtual extentsible local area network)：是vlan扩展方案草案，采用的是MAC in UDP封装方式，是NVo3(network virtualization over layer3)中的一种网络虚拟化技术 vxlan实现：将虚拟网络的数据帧添加到vxlan首部后，封装在物理网络的udp报文中，然后以传统的通信方式传送该udp报文，待其到达目的主机后，去掉物理网络报文的头部信息以及vxlan首部，然后将报文交付给目的终端 Directrouting：vxlan的直接路由模式，兼具vxlan后端和host-gw后端的优势，既保证了传输性能，又具备了跨二层网络转发报文的能力 配置样例：”Backend”:{“Type”:”VxLAN”, “Directrouting”: true} 部署-手动etcd方式 安装并配置etcd etcd中创建flannel网络配置 etcdctl mkdir /kube-centos/network etcdctl mk /kube-centos/network/config ‘{“Network”:”172.33.0.0/16”,”SubnetLen”:24,”Backend”:{“Type”:”host-gw”}}’ 参数详解： Network：全局使用CIDR格式ipv4网络 SubnetLen：节点使用的子网的掩码 Backend：flannel要使用的后端类型 安装flannel flannel服务配置(centos示例-/etc/sysconfig/flanneld) 123FLANNEL_ETCD_ENDPOINTS=&quot;http://172.17.8.101:2379&quot;FLANNEL_ETCD_PREFIX=&quot;/kube-centos/network&quot;FLANNEL_OPTIONS=&quot;-iface=eth1&quot; 启动flannel 部署-k8s资源清单方式 资源清单 配置调整 网络设置(net-conf.json) 主机间的内部通信端口设置(kube-flannel–&gt;DaemonSet)：--iface=eth1 基于calico的网络策略部署概要主要通过使用flannel(pod间通信)和calico(pod间访问控制)两个软件实现为了充分利用flannel的易用性和calico的丰富功能，可以通过以下方式部署实现(不含calico单独部署) 只部署canal【canal是一个整合了flannel和calico的综合项目，其中calico用于策略控制、flannel用于网络通信】 协同部署flannel实现网络功能、部署calico实现访问控制功能 部署要求 flannel的后端必须是vxlan模型【host-gw、vxlan-Directrouting均不行】 kubelet必须开启cni支持：–network-plugin=cni kube-controller-manager开启配置：-cluster-cidr=&lt;your-pod-cidr&gt;和–allocate-node-cidrs=true 其他要求：官网 canal部署 下载清单文件 etcd存储：curl https://docs.projectcalico.org/manifests/canal-etcd.yaml -O k8s存储：curl https://docs.projectcalico.org/manifests/canal.yaml -O 更改配置： 12POD_CIDR=&quot;&lt;your-pod-cidr&gt;&quot;sed -i -e &quot;s?10.244.0.0/16?$POD_CIDR?g&quot; canal.yaml 执行清单创建资源：kubectl apply -f canal.yaml flannel和calico协同部署flannel部署 下载清单文件:部署：curl https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml -o 配置调整 网络设置(net-conf.json) 主机间的内部通信端口设置(kube-flannel–&gt;DaemonSet)：–iface=eth1 执行清单创建资源：kubectl apply -f kube-flannel.yml calico部署 下载清单文件：curl https://docs.projectcalico.org/manifests/calico-policy-only.yaml -O 更改配置 12POD_CIDR=&quot;&lt;your-pod-cidr&gt;&quot;sed -i -e &quot;s?192.168.0.0/16?$POD_CIDR?g&quot; calico.yaml 执行清单创建资源：kubectl apply -f calico.yaml 网络策略控制控制pod到pod、node、外接网络的访问限制，包含流入(Ingress)和流出(Egress)两个方向的控制规则 默认规则 默认情况下，所有pod处于非隔离状态，所有方向的流量都可以自由流动 一旦有策略应用于pod，那么所有未明确声明允许的流量都将被拒绝 如果在policyTypes中定义了生效规则(Ingress/Egress)： spec定义了空值【{}】表示不限制相关方向的访问 spec中没有定义相应的Ingress或Egress规则，则表示拒绝相关方向上的一切流量。范例如下【定义默认规则】123456789101112apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: deny-all-traffic namespace: testingspec: podSelector: &#123;&#125; #所有pod policyTypes: # 进口、出口流量都管控；没有定义出站(Egress)详细规则，则拒绝所有出站流量 - Ingress - Egress Ingress: #定义了入站规则，但是为空，表示允许所有入站流量 - &#123;&#125; 语法定义 podSelector：通过pod选择器选定的一组pod资源，它是规则生效的对象 matchLabel、matchExpression Egress：出站规则 to：目标对象 ports：目标对象端口 Ingress：入站规则 from：源对象 ports：本地pod资源端口 ports：tcp或udp端口 protocol：默认tcp port：端口 to/from：目标对象或源对象 ipBlock：IP地址块 namespaceSelector：名称空间选择器 podSelctor：pod选择器 Ingress12345678910111213141516171819202122apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: allow-myapp-ingress namespace: defaultspec: podSelector: #选择策略生效目标 matchLabels: app: myapp policyTypes: [&apos;Ingress&apos;] #策略管控的流量方向，此处为入站流量(Ingress) ingress: - from: #入站来源 - ipBlock: #ip选择 cidr: 10.244.0.0/16 except: #排除部分选项 - 10.244.3.0/24 - podSelector: # 标签选择 matchLabels: app: myapp ports: #目标端口 - protocol: TCP port: 80 from:入站流量来源 多个项目之间为“逻辑或”关系 若未设置此字段或字段为空，则允许一切来源 如果设置至少一个值，则设置的值为白名单，只有名单中的地址的流量才被放行 ports：入站流量的目标端口，其他说明如上 from和ports之间为“逻辑与”关系；仅定义from隐含本地pod资源的所有端口；仅定义ports隐含所有来源；两者都定义则精确匹配来源及目标端口 Egress对于具有app=tomcat标签的对象，它到【app=nginx】对象80端口的流量被放行到【app=mysql】对象3306端口的流量也被放行。 12345678910111213141516171819202122232425apiVersion: networking.k8s.io/v1kind: NetworPolicymetadata: name: allow-tomcat-egress namespace: defaultspec: podSelector: matchLabels: app: tomcat policyTypes: [&quot;Egress&quot;] egress: - to: - podSelector: matchLabels: app: nginx ports: - protocol: TCP port: 80 - to: - podSelector: matchLabels: app: mysql ports: - protocol: TCP port: 3306 名称空间隔离允许当前名称空间内部各pod之间，以及当前名称空间与kube-system名称空间内各pod的通信 12345678910111213141516171819202122232425262728293031apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: namespace-deny-all name: testingspec: podSelector: &#123;&#125; policyTypes: [&quot;Ingress&quot;, &quot;Egress&quot;]---apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: namespace-allow name: testingspec: policyTypes: [&quot;Ingress&quot;, &quot;Egress&quot;] podSelector: &#123;&#125; ingress: - from: - namespaceSelector: matchExpressions: - key: name operator: In values: [&quot;testing&quot;, &quot;kube-system&quot;] Egress: - to: - namespaceSelector: matchExpressions: - key: name operator: In values: [&quot;testing&quot;, &quot;kube-system&quot;] 网络策略应用案例实现目标 testing名称空间下运行app=nginx和app=myapp两个应用 myapp仅允许来自nginx访问其TCP/80端口，但可以向nginx的所有端口发出出站流量 nginx允许所有源站点访问其TCP/80端口，并能向任意端点发出出站流量 myapp和nginx都可以与kube-system名称空间内的任意pod通信 运行应用 myapp：kubectl run myapp --image=ikubernetes/myapp:v1 --replicas=1 --namespace=testing --port 80 --expose --labels app=myapp nginx：kubectl run nginx --image=nginx:alpine --replicas=1 --namespace=testing --port 80 --expose --labels app=nginx 调试客户端：kubectl run debug --namespace=default --rm -it --image=nicolaka/netshoot -- sh 为kube-system添加标签：kubectl label namespace kube-system ns=kube-system 配置清单1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: testing-default # testing默认策略，拒绝所有进出流量 namespace: testingspec: podSelector: &#123;&#125; policyTypes: - Ingress - Egress---apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: myapp-policy # myapp策略 namespace: testingspec: policyTypes: - Ingress - Egress podSelector: matchLabels: app: myapp ingress: - from: #允许来自nginx访问其80端口 - podSelector: matchLabels: app: nginx ports: - port: 80 - from: #允许来自kube-system的pod访问 - namespaceSelector: matchLabels: ns: kube-system egress: - to: #允许访问nginx的所有端口 - podSelector: matchLabels: app: nginx - to: # 允许访问kube-system的pod - namespaceSelector: matchLabels: ns: kube-system---apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: nginx-policy #nginx策略 namespace: testingspec: podSelector: matchLabels: app: nginx policyTypes: - Ingress - Egress ingress: - ports: #允许所有源站点访问80端口 - port: 80 - from: # 允许来自kube-system访问 - namespaceSelector: matchLabels: ns: kube-system egress: - &#123;&#125; #出口流量不限制]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>ingress</tag>
        <tag>cni</tag>
        <tag>flannel</tag>
        <tag>canal</tag>
        <tag>calico</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-pod对象管理]]></title>
    <url>%2F2020%2F02%2F24%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-pod%E5%AF%B9%E8%B1%A1%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[容器与pod容器 容器的本质是一个进程，是一个视图被隔离、资源受限制的进程 容器里pid=1的进程就是应用本身 管理虚拟机就是管理基础设施(操作系统)，管理容器就是管理应用本身(进程) kubernetes相当于云时代的操作系统，容器镜像相当于操作系统的软件安装包 Pod 容器设计本身就是一种“单进程”模型；可以运行多个进程，但是不便于直接管理 如果需要运行多进程，则pid=1的进程要具有管理其他进程的能力(systemd) 也可以直接运行systemd，由systemd管理多进程；但是，此时：【容器管理】=【管理systemd】!=【直接管理应用本身】 作为类比，容器相当于进程(linux中的线程)，pod相当于进程组(linux进程，包含至少一个线程) 在k8s中，pod是一个逻辑单位，它包含多个相互协作的容器，共享某些资源(volume/网络) pod是资源分配单位【类比，进程是操作系统资源分配的单位】 pod也是原子调度单位 pod与多容器 如果只是亲密关系，可以通过调度器让俩个应用部署在同一台宿主机上 如果是超亲密关系(比如：产生日志的应用和写日志的应用)，则需要将多个应用定义在一个pod中 会发生直接的文件交互 使用localhost或socket进行本地通信 会发生频繁的RPC调用 会共享某些namespace pod实现网络实现 启动一个infra container容器，pod里的其他容器通过join namespace的方式加入infra container的network namespace中 pod的网络地址即是infra的地址 pod的生命周期也即infra的生命周期 存储实现在pod级别创建volume，然后pod内的所有容器挂载这个volume 1234567891011121314151617181920212223apiVersion: v1kind: Podmetadata: name: two-containersspec: restartPolicy: Never volumes: - name: shared-data hostPath: path: /data containers: - name: nginx-container image: nginx volumeMounts: - name: shared-data mountPath: /usr/share/nginx/html - name: debian-container image: debian volumeMounts: - name: shared-data mountPath: /pod-data command: [&quot;/bin/sh&quot;] args: [&quot;-c&quot;, &quot;echo Hello from the debian container &gt; /pod-data/index.html&quot;] 容器设计模式 sidecar：在pod里定义一些专门的容器，来执行主业务容器所需要的辅助工作 通过sidecar方式，可以实现功能的解耦和重用 应用场景 日志收集(log) Debug应用(debug) 容器代理(proxy)：单独写一个proxy用来处理对外部集群的交互 适配器(adapter)：单独写一个应用用来处理URL变更、数据格式变更的操作，以完成对现有业务的兼容 应用范例-war包 可选方式 将war包和tomcat都打包进镜像中，但是代码和tomcat的更新都需要更新镜像 制作单独的tomcat镜像，在容器运行时将war包挂载到容器内，此时则需要单独维护war包和一个分布式文件系统 sidecar方式-initContainer 先启动一个initContainer，将war包拷贝到共享目录 再启动container，这个容器启动tomcat(共享目录webapps中包含war包) 12345678910111213141516171819202122232425apiVersion: v1kind: Podmetadata: name: javaweb-2spec: initContainers: - image: resouer/sample:v2 name: war command: [&quot;cp&quot;, &quot;/sample.war&quot;, &quot;/app&quot;] volumeMounts: - mountPath: /app name: app-volume containers: - image: resouer/tomcat:7.0 name: tomcat command: [&quot;sh&quot;, &quot;-c&quot;, &quot;/root/apache-tomcat-7.0.42-v2/bin/start.sh&quot;] volumeMounts: - mountPath: /root/apache-tomcat-7.0.42-v2/webapps name: app-volume ports: - containerPort: 8080 hostPort: 8001 volumes: - name: app-volume emptyDir: &#123;&#125; pod容器定义spec.containers 镜像-images 范例 1234567891011kind: PodapiVersion: v1metadata: name: nginx-podspec: imagePullSecrets: - name: aliyun-simple containers: - name: nginx #容器名称 images: nginx:latest #镜像名称 imagePullPolicy: Always 设置选项 仓库认证：imagePullSecrets【参见secret章节】 镜像获取策略：imagePullPolicy Always：镜像版本为latest或本地不存在的镜像则从远端仓库拉取 IfNotPresent：本地镜像不存在则从远端仓库拉取 Never：禁止从远端仓库拉取镜像，只使用本地镜像 端口-ports 范例 12345678910111213apiVersion: v1kind: Podmetadata: name: pod-examplespec: containers: - name: myapp images: ikubernetes/myapp:v1 ports: - name: http #端口名称 containerPort: 80 #指向容器监听的端口 protocol: TCP #端口协议类型 hostPort: 8000 选项说明：端口设置仅为说明性内容；为端口设置名称，方便被service调用 设置选项 hostPort：将节点端口映射到容器端口 hostIP：节点端口绑定的ip【默认为0.0.0.0，一般不设置】 注意事项：hostPort和service下的NodePort区别 hostPort在pod下设置，只绑定到pod所在节点 NodePort在service下设置，绑定到所有节点 自定义命令-command 范例 12345678910kind: PodapiVersion: v1metadata: name: pod-examplespec: containers: - name: myapp image: alpine:latest command: [&quot;/bin/sh&quot;] #命令 args: [&quot;-c&quot;, &quot;while true;do sleep 30;done&quot;] #参数 说明：查看镜像默认运行的命令 cmd方式：docker inspect nginx:1.13 -f {\{\.Config.Cmd}\} entrypoint方式：docker inspect nginx:1.13 -f {\{\.Config.Entrypoint}\} 设置选项：命令和参数 command：会覆盖默认运行命令 args：则会给command或默认的运行命令提供参数 环境变量-env 范例 1234567891011121314151617kind: PodapiVersion: v1metadata: name: pod-envspec: containers: - name: filebeat image: ikubernetes/filebeat:5.6.5-alpine command: [&quot;echo&quot;] args: [&quot;$(HOSTNAME)&quot;] env: - name: HOSTNAME valueFrom: fieldRef: fieldPath: spec.nodeName - name: REDIS_HOST #变量名称 value: db.ilinux.io:6379 #变量值 选项说明：向pod传递变量有两种方式：env和envFrom env value：自定义变量 valueFrom：读取pod环境变量 configMapKeyRef secretKeyRef fieldRef：【metadata.name, metadata.namespace,metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs】 resourceFieldRef：【limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu,requests.memory and requests.ephemeral-storage】 envFrom【从ConfigMap和secret获取值】 configMapRef secretRef 使用节点网络-hostNetwork 范例 1234567891011kind: PodapiVersion: v1metadata: name: pod-networkspec: containers: - name: myapp image: ikubernetes/myapp:v1 hostNetwork: true #共享节点网络 hostPID: true #共享节点PID hostIPC: true #共享节点IPC 选项说明:默认情况下，pod的所有容器会建立一个独立的网络名称空间；但是一些特殊的pod需要运行在节点的网络名称空间下，执行系统级的任务 应用范例： 使用kubeadm部署的kube-controller-manager、kube-apiserver、kube-scheduler、kube-proxy组件 flannel网络部署 其他选项 hostPID: 共享节点PID hostIPC: 共享节点IPC 安全上下文-securityContextsecurityContext主要用于容器运行时的安全管控，类似linux的selinux、sudo等内容，通过限制容器的行为，从而保障系统和其他容器的安全 选项位置 容器级别的securityContext：对指定容器生效 pod级别的securityContext：对指定pod中的所有容器有效 Pod Security Policies(PSP)：对集群内的所有pod有效 选项类别 根据用户id和组id控制访问对象 基于selinux的安全标签 以特权或非特权方式运行(privileged) 是否能够权限升级(allowPrivilegeEscalation) 通过Linux Capablities为其提供部分特权 基于seccomp过滤进程可以操作的系统调用 范例 以uid为1000的非特权用户运行容器，并禁止提权 12345678910111213apiVersion: v1kind: Podmetadata: name: pod-with-securitycontextspec: containers: - name: busybox image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 86400&quot;] securityContext: #容器级别securitycontext runAsNonRoot: true runAsUser: 1000 allowPrivilegeEscalation: false pod状态和重启状态 pending：api server创建了pod资源对象，但尚未被调度完成；或者处于拉取镜像的过程中 running：pod已被调度到某节点，并且所有容器都被kubelet创建完成 succeeded：pod中的所有容器已成功终止并且不会被重启 failed：所有容器都已被终止，但至少有一个容器终止失败 unknown：api server无法获取pod的正常状态信息，通常是由api无法与kubelet通信所致 pod异常状态诊断 pod停留在pending状态：pending表示调度器没有介入，使用【kubectl describe pod】命令查看事件排查，通常和资源使用有关 pod停留在waiting状态：pod拉取镜像失败 pod不断被拉起且可以看到crashing：pod已被调度，但是启动失败；通常是由于配置、权限造成，需要查看pod日志【kubectl logs pod】 pod处于running但是没有正常工作：通常时由于部分字段拼写错误造成的，恶意通过校验部署来排查【kubectl apply –validate -f pod.yml】 service无法正常工作：在排除网络插件自身的问题外，最有可能是label配置有问题，可以通过查看endpoint的方式进行查看 重启策略-restartPolicy 重启策略适用于所有容器(包含initContainer)首次需要重启时立即重启，后续重启操作时延为10/20/40/80/160/300，最大时延为300 Always：pod对象终止就将其重启，此为默认值 OnFailure：仅在pod对象出错时才将其重启 Never：从不重启 全生命周期操作包含操作 运行初始化容器(init container) 创建主容器(main container)【必须】 容器启动检查(startup probe) 容器启动后钩子(post start hook) 容器就绪型检查(readiness probe) 容器存活性检查(liveness probe) 容器终止前钩子(pre stop hook) 初始化容器-initContainer可用于普通containers启动前的初始化或前置条件检验(如检测网络连通性) 与普通containers区别 initContainer会先于普通containers启动执行，所有initContainer执行成功后，普通containers才会被启动 pod中多个initContainer之间是按定义顺序依次启动执行，而pod中多个普通containers时并行启动的 initContainer执行成功就退出，而普通containers可能会一直执行或重启 范例1234567891011121314apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: initContainers: - name: init-something image: busybox command: [&quot;sh&quot;, &quot;-c&quot;, &quot;sleep 10&quot;] containers: - name: myapp-container image: ikubernetes/myapp:v1 钩子函数使用说明 生命周期节点 postStart：容器建立后立即运行的功能，但是k8s无法保证它一定运行在entrypoint之前 preStop：容器终止前执行的功能，此操作完成前阻塞删除容器的操作 实现方式： exec：执行用户定义的命令 http：向执行url发起http请求 范例1234567891011121314151617apiVersion: v1kind: Podmetadata: name: lifecycle-demospec: containers: - name: lifecycle-demo-container image: ikubernetes/myapp:v1 lifecycle: #定义钩子函数 postStart: #容器启动后执行 exec: #执行用户自定义命令 command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo &apos;lifecycle hooks handler&apos; &gt; /usr/share/nginx/html/test.html&quot;] preStop: #容器终止前执行 httpGet: #发起http请求 host: blog.csdn.net path: zhangmingli_summer/article/details/82145852 port: 443 健康检查检查种类 livenessProbe(存活性检查)：检查容器是否处于running状态，检测不通过时根据重启策略(restartPolicy)确定是否重启 readinessProbe(就绪性检查)：判断容器是否准备就绪，可以对外提供服务；未通过时，会将此pod从endpoint(如service对象)中移除，直到pod就绪 startupProbe(启动检查)：判断容器是否启动完成 检查方式 exec：执行用户自定义命令 命令参数：command 注意事项：exec检查会消耗容器资源，所以需要检查命令简单、轻量 httpGet：向指定url发起get请求，响应码2xx、3xx为成功 命令参数： host：请求主机，默认pod ip port：端口，必选字段 httpHeaders：自定义header信息 path：请求的http资源url scheme：连接协议，HTTP/HTTPS,默认HTTP 注意事项：在多层架构中，只能针对当前服务层进行检查(其他两种方式也一样)；如果后端服务不可用，会造成pod一次次重启，直到后端服务可用 tcpSocket：与容器tcp端口建立连接，端口打开即为成功 命令参数： host：请求主机，默认pod ip port：端口，必选字段 通用检查属性 initialDelaySeconds：容器启动多长时间后进行首次检查，默认0s timeoutSeconds：检查超时时间，默认1s periodSeconds：检查频率，默认间隔10s，最小1s successThreshold：处于失败状态时，多少次成功才认为是成功；默认1，最小1 failureThreshold：处于成功状态时，多少次失败才认为是失败；默认3，最小1 最佳实践 调大判断的阈值(超时、次数等)，防止容器压力过大时出现误判 exec执行shell脚本时，在容器内执行的时间会比较长(可以使用go等编译型语言执行) 使用tcpSocket时遇到TLS，需要判断业务层是否有影响 范例 readinessProbe 12345678910111213141516apiVersion: v1kind: Podmetadata: name: readiness-exec labels: test: readiness-execspec: containers: - name: readiness-exec-demo image: busybox args: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;while true;do rm -f /tmp/ready;sleep 30;touch /tmp/ready;sleep 300;done&quot;] readinessProbe: exec: command: [&quot;test&quot;, &quot;-e&quot;, &quot;/tmp/ready&quot;] initialDelaySeconds: 5 periodSeconds: 5 livenessProbe 12345678910111213141516171819202122apiVersion: v1kind: Podmetadata: name: liveness-http labels: test: liveness-httpspec: containers: - name: liveness-http-container image: nginx:1.12-alpine ports: - name: http containerPort: 80 lifecycle: postStart: exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Healthy &gt; /usr/share/nginx/html/Healthz&quot;] livenessProbe: httpGet: path: /Healthz port: http scheme: HTTP 资源需求和限制 cpu：单位：millicore(1core=1000millicore) 500m相当于0.5个核心 memory:单位：Bytes，与日常使用单位相同 300M ephemeral(临时存储)：单位：Byte 自定义资源：配置时必须为整数 范例1234567891011121314151617apiVersion: v1kind: Podmetadata: name: frontendspec: containers: - name: wp image: wordpress resources: requests: #请求的资源 memory: 64Mi cpu: 250m ephemeral-storage: 2Gi limits: # 最多可以使用的资源 memory: 128Mi cpu: 500m ephemeral-storage: 4Gi pod服务-QOS依据容器对cpu、memory资源的request/limits需求，pod服务质量分为 Guaranteed: 每个容器都为cpu设置了具有相同值的requests、limits属性 每个容器都为memory设置了具有相同值的requests、limits属性 Burstable：至少一个容器设置了cpu或memory的requests属性，但不满足Guaranteed的要求 BestEffort：没有为pod中的任何一个容器设置requests、limits属性 当节点上的memory资源不足时，将依据BestEffort、Burstable、Guaranteed的优先级顺序驱逐pod]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>初始化容器</tag>
        <tag>钩子函数</tag>
        <tag>健康检查</tag>
        <tag>资源</tag>
        <tag>pod定义</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-配置管理]]></title>
    <url>%2F2020%2F02%2F24%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[ConfigMap使用场景 主要管理容器运行所需的配置文件、环境变量、命令行参数等可变配置 用于解耦容器镜像和可变配置，从而保证工作负载(pod)的可移植性 创建configMap清单文件方式123456789101112131415161718192021apiVersion: v1kind: ConfigMapmetadata: name: test-cfg namespace: defaultdata: cache_host: memcached-gcxt cache_port: &quot;11211&quot; cache_prefix: gcxt my.cnf: | [mysqld] log-bin = mysql-bin app.properties: | property.1 = value-1 property.2 = value-2 property.3 = value-3 cni-conf.json: | &#123; &quot;name&quot;: &quot;cbr0&quot;, &quot;type&quot;: &quot;flannel&quot; &#125; 命令行-文件方式 key是文件名，value是文件内容；可以针对单个文件或目录(目录的所有文件) 范例-目录：kubectl create configmap test-config –from-file=./configs 范例-文件：kubectl create configmap test-config2 –from-file=./configs/cache.conf 命令行-key/value方式 范例：kubectl create configmap test-config3 –from-literal=name=yuanshuo –from-literal=age=23 使用ConfigMap configMap主要被pod使用,必须在pod使用前创建ConfigMap 创建的pod使用envFrom读取configmap时，如果configmap中的某些key无效，则该环境变量不会注入容器，但是pod可以正常创建 只有通过k8s api创建的pod才能使用configmap，其他方式创建的pod(如manifest创建的static pod)不能使用configmap pod只能使用在同一namespace下的ConfigMap 范例使用的ConfigMap 12345678apiVersion: v1kind: ConfigMapmetadata: name: special-config namespace: defaultdata: special.how: very special.type: charm 环境变量方式123456789101112131415161718192021222324252627282930apiVersion: v1kind: Podmetadata: name: special-env-pod namespace: defaultspec: containers: - name: test-container image: busybox # 使用$(VAR_NAME)方式引用变量 # command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo $(SPECIAL_TYPE)&quot;] command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo $(special.how)&quot;] # 加载全部变量 envFrom: - configMapRef: name: special-config optional: false # 加载部分变量 # env: # - name: SPECIAL_HOW # valueFrom: # configMapKeyRef: # name: special-config # key: special.how # - name: SPECIAL_TYPE # valueFrom: # configMapKeyRef: # name: special-config # key: special.type restartPolicy: Never volume挂载方式1234567891011121314151617181920212223242526272829apiVersion: v1kind: Podmetadata: name: spec-volume-pod namespace: defaultspec: containers: - name: test-contaner1 image: busybox # 文件名为key，文件内容为value # command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;cat /etc/config/special.how&quot;] command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;cat /etc/config/ok/special.how&quot;] volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config # 加载部分变量,只将special.how这个key挂载到/etc/config目录下的相对路径ok/special.how items: - key: special.how path: ok/special.how # 加载全部变量 # volumes: # - name: config-volume # configMap: # name: special-config restartPolicy: Never Secret使用场景 Secrete是在集群中存储密码、token等敏感信息的对象 secret的存储和打印格式均是base64编码的字符串，因此用户创建secret时也要提供此种编码格式的数据 Secret类型 Opaque：一般密文类型【默认类型】 Kubernetes.io/service-account-token：集群身份认证【创建serviceaccount时自动创建】 kubernetes.io/tls：tls证书类型 kubernetes.io/dockerconfigjson：docker拉取私有仓库镜像时的认证信息 bootstrap.kubernetes.io/token：节点bootstrap初始化加入集群时的认证信息 创建secret命令行方式一般创建使用kubectl create命令创建opaque(generic)、tls、dockerregistry类型 opaque-key/value形式：kubectl create secret generic mysecret –from-literal=username=hejingqi –from-literal=password=yuanshuo opaque-文件形式：kubectl create secret generic ssh-key-secret –from-file=ssh-priviatekey=C:\Users\simple.ssh\gitee –from-file=ssh-publickey=C:\Users\simple.ssh\gitee.pub dockerregistry创建：kubectl create secret docker-registry aliyun-simple --docker-username=perfect@qq.com --docker-password=123456 --docker-server=registry.cn-hangzhou.aliyuncs.com tls证书创建：kubectl create secret tls k8s-ca --cert=&#39;ca.pem&#39; --key=&#39;ca-key.pem&#39;清单文件方式 一般用于创建opaque类型，核心参数如下： spec.data：key的value数据需要先进行base64编码 spec.stringData：key的value数据无需进行base64编码 123456789apiVersion: v1kind: Secretmetadata: name: mysecret1 namespace: defaulttype: OpaquestringData: username: hejingqi password: yuanshuo 使用secret和ConfigMap使用基本一致，但是由于使用环境变量方式时会存在信息泄露(容器继承、打印日志等方式)，所以基本上使用volume挂载方式 Opaque类型1234567891011121314151617apiVersion: v1kind: Podmetadata: name: secret-podspec: containers: - image: busybox name: secret-container command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;ls /etc/config&quot;] volumeMounts: - name: ssh-key mountPath: /etc/config readOnly: true volumes: - name: ssh-key secret: secretName: ssh-key-secret dockerconfigjson类型使用imagePullSecrets设置认证信息，使用方式如下： 在ServiceAccount对象中定义imagePullSecrets，则所有使用该ServiceAccount的pod都能使用此认证信息 在pod中使用imagePullSecrets123456789101112apiVersion: v1 kind: Podmetadata: name: ssh-podspec: imagePullSecrets: - name: aliyun-simple containers: - name: ssh image: registry.cn-hangzhou.aliyuncs.com/simple/ubuntu14_sshd ports: - containerPort: 22 应用程序动态更新配置 pod会周期性获取配置(configmap和secret)，但是要自行处理应用程序如何动态加载配置 应用程序监听本地配置文件变动，自行处理热加载 使用sidecar通过inotify机制监听配置文件变更，动态更新 与程序迭代更新一起滚动更新 【不使用k8s的configmap/secret】采用配置中心(如disconf、Apollo)]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>secret</tag>
        <tag>configMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-存储和持久化]]></title>
    <url>%2F2020%2F02%2F24%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-%E5%AD%98%E5%82%A8%E5%92%8C%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[volumes类型 本地存储(临时存储)：emptyDir、hostpath 网络存储： in-tree(插件代码在k8s仓库中)：nfs、awsElasticBlockStorage、gcePersistentDisk out-of-tree(插件代码不在k8s仓库中)：flexvolume、csi等网络存储 配置存储：secret、ConfigMap、downwardAPI、ServiceAccountToken pv(persistent volumes)与pvc(persistent volume claim) 资源级别 pv是集群级别的资源 pvc与pod高度相关，必须位于同一个名称空间 职责 pv包含后端存储实现的细节(存储类型、访问路径、认证信息等) pvc包含用户对存储的需求声明(size/accessmode) emptyDir用途 用于同一个pod内的多个容器间文件的共享 做诶容器数据的临时存储目录用于数据缓存系统 范例12345678910111213141516171819202122232425apiVersion: v1kind: Podmetadata: name: volume-emptydir-podspec: volumes: #pod的volume定义 - name: html emptyDir: &#123;&#125; #emptydir类型的volume与pod生命周期相同 containers: - name: nginx image: nginx:1.12-alpine volumeMounts: #容器加载volume - name: html mountPath: /usr/share/nginx/html - name: pagegen image: alpine volumeMounts: #容器加载volume - name: html mountPath: /html command: [&quot;/bin/sh&quot;, &quot;-c&quot;] args: - while true;do echo $(hostname) $(date) &gt;&gt; /html/index.html; sleep 10; done hostPath用途 将节点的文件或目录挂载到pod中，独立于pod的生命周期 一般适用于管理任务的pod(如daemonset)，它运行于集群中的每个工作节点，负责收集工作节点系统级的相关数据 范例12345678910111213141516171819202122232425262728293031apiVersion: v1kind: Podmetadata: name: volume-hostpathspec: containers: - name: filebeat image: ikubernetes/filebeat:5.6.7-alpine env: - name: REDIS_HOST value: 192.168.2.124 - name: LOG_LEVEL value: info volumeMounts: - name: varlog mountPath: /var/log - name: socket mountPath: /var/run/docker.sock - name: var-lib-docker-containers mountPath: /var/lib/docker/contaners readOnly: true volumes: - name: varlog hostPath: path: /var/log - name: var-lib-docker-containers hostPath: path: /var/lib/docker/contaners - name: socket hostPath: path: /var/run/docker.sock oss使用ossfs oss作为共享存储直接挂载到操作系统(类似nfs) ossfs安装 使用 将认证信息存入文件（权限640）：echo ${bucket}:${access-key-id}:{access-key-secret} &gt; /etc/passwd-ossfs 挂载：ossfs bucket_name mount_point -ourl=endpoint kubernetes存储管理 将oss部署到kubernetes集群中有两种方式：flexvolume或csi，以下使用均以flexvolume为例 flexvolume需要先安装插件 CSI 使用flexvolume需要kubelet关闭–enable-controller-attach-detach选项 在kube-system用户空间中部署flexvolume oss目前只支持静态存储卷，oss静态存储卷有两种使用方式： 使用pv/pvc 直接使用volume方式 pv-pvcpv创建pv-范例123456789101112131415161718apiVersion: v1kind: PersistentVolumemetadata: name: pv-ossspec: capacity: storage: 5Gi accessModes: - ReadWriteMany storageClassName: oss flexVolume: driver: &quot;alicloud/oss&quot; options: bucket: &quot;docker&quot; url: &quot;oss-cn-hangzhou.aliyuncs.com&quot; akId: *** akSecret: *** otherOpts: &quot;-o max_stat_cache_size=0 -o allow_other&quot; pv-参数 capacity：pv存储空间 accessModes：访问模式 ReadWriteOnce：单节点读写 ReadOnlyMany：多节点读) ReadWriteMany：多节点读写 persistentVolumeReclaimPolicy：pv空间被释放时的处理机制 Retain：默认，保持不动 Recycle：空间回收（目前仅nfs、hostpath支持） Delete：删除存储卷，仅部分云端存储支持 volumeMode：卷模型，当做块设备还是文件系统，默认文件系统(Filesystem) storageClassName:当前pv所属的StorageClass名称 mountOptions：挂载选项 pvc创建pvc-范例1234567891011kind: PersistentVolumeClaimapiVersion: v1metadata: name: pvc-ossspec: storageClassName: oss accessModes: - ReadWriteMany resources: requests: storage: 5Gi pvc-参数 accessModes：访问模式 resources：申请资源 selector：标签 storageClassName：所依赖的存储类的名称 volumeMode：卷模型，当做块设备还是文件系统，默认文件系统(Filesystem) volumeName：用于直接指定要绑定的pv的卷名 pod使用1234volumes:- name: pvc-oss persistentVolumeClaim: claimName: pvc-oss 动态存储-storageclass创建storageclass 通用参数 provisioner:提供存储资源的存储系统 parameters：存储类使用参数描述要关联的存储卷 reclaimPolicy：动态创建pv的回收策略，默认delete，可选retain mountOptions：pv挂载选项 volumeBindingMode：如何给pvc完成供给和绑定 范例：阿里云nas123456789101112apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: alicloud-nas-subpathmountOptions:- nolock,tcp,noresvport- vers=3parameters: volumeAs: subpath server: &quot;xxxxxxx.cn-hangzhou.nas.aliyuncs.com:/k8s/&quot;provisioner: nasplugin.csi.alibabacloud.comreclaimPolicy: Retain 创建pvc1234567891011kind: PersistentVolumeClaimapiVersion: v1metadata: name: storageclass-pvcspec: storageClassName: &quot;standard&quot; accessModes: - ReadWriteOnce resources: requests: storage: 2Gi]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>volume</tag>
        <tag>oss</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-pod控制器]]></title>
    <url>%2F2020%2F02%2F24%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-pod%E6%8E%A7%E5%88%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[pod控制器需求来源 自主式pod被调度到节点后，由kubelet负责容器的存活性； 容器主进程崩溃后，kubelet自动重启相应的容器； 非主进程崩溃类型的容器错误，需要用户自定义存活性探测(liveness probe),以便kubelet可以探测到此类故障 pod意外删除或节点故障，需要节点以外的pod控制器负责其重建 原理 pod控制器由master的kube-controller-manager组件提供，确保各资源的当前状态(status)匹配用户期望的状态(spec) 常见控制器(workload)：ReplicationController、Replicaset、Deployment、Daemonset、Job、CronJob、Statefulset 语法定义 selector：标签选择器 replicas：期望的副本数量；scale命令支持对Deployment, ReplicaSet, Replication Controller, or StatefulSet进行扩容、缩容 template：pod模板 minReadySeconds：新建pod等待多久才会将其视为就绪可用 Replicaset它是新版本的ReplicationController，相较于RC，它支持基于集合的标签选择器(set-based) 与自主式pod区别 确保pod资源对象数量符合期望值 确保pod健康运行(节点故障时被调度到其他节点运行) 弹性伸缩 范例1234567891011121314151617181920apiVersion: apps/v1kind: ReplicaSetmetadata: name: rs-examplespec: replicas: 2 #副本数 selector: #pod模板选择器，包含mathLabels和matchExpressions两种 matchLabels: app: rs-demo template: # pod模板 metadata: labels: #模板标签 app: rs-demo spec: containers: - name: myapp image: ikubernetes/myapp:v2 ports: - name: http containerPort: 80 变更操作 均可以通过修改资源文件，使用命令kubectl apply/replace应用修改 副本数量 影响：可以随时修改，并能实时生效 命令：kubectl scale rs rs-example --replicas=5 --current-replicas=3 标签选择器【一般不操作】 影响：修改后，可能会影响控制器和pod对象的映射关系，使pod对象不受控制器管理 命令：kubectl label pod rs-example-5s745 app= --overwrite pod模板 影响：修改后，仅对新建的pod副本有影响 修改镜像文件命令：kubectl set image rs rs-example myapp=ikubernetes/myapp:v2 Deployment定义 Deployment构建于replicaset之上，大部分功能由replicaset控制器实现，Deployment管理不同版本的replicaset 相较于Replicaset，新增的功能有： 可以查看Deployment对象的升级过程 可以保存对Deployment的每一次修改，出现问题时可以执行回滚操作 可以随时暂停和启动更新 多种自动更新方案 Recreate：全面停止、删除旧的pod后用新版本替代 RollingUpdate：滚动更新，逐步替换旧的pod至新版本 关键配置项12345678spec字段 - revisionHistoryLimit: 保留历史revision数量 - progressDeadlineSeconds: 判断Deployment status condition为failed的最大时间strategy: rollingUpdate: maxSurge: 25% 升级过程中最多存在多少个超过期望数量的pod maxUnavailable: 25% 升级过程中最多有多少个pod不可用 type: RollingUpdate【升级策略】 范例123456789101112131415161718192021apiVersion: apps/v1 kind: Deploymentmetadata: #Deployment元信息 name: nginx-deployment labels: app: nginxspec: replicas: 3 #期望的pod数量 selector: #pod选择器 matchLabels: app: nginx template: #pod模板 metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.12.2 ports: - containerPort: 80 变更操作 滚动更新镜像：kubectl set image deployment nginx-deployment nginx=nginx:1.13 金丝雀部署： 设置maxSurge=1，maxUnavailable确保升级过程中仅生成一个新的pod 在升级镜像之后，暂停更新：kubectl set image deployment nginx-deployment nginx=nginx:1.13 &amp;&amp; kubectl rollout pause deploy nginx-deployment 通过service或ingress及相关策略路由将一部分流量导入新的pod进行验证 验证通过后恢复滚动升级：kubectl rollout resume deploy nginx-deployment 查看滚动更新状态:kubectl rollout status deploy nginx-deployment 回滚镜像到上一版本：kubectl rollout undo deployment nginx-deployment 扩容缩容：kubectl scale --replicas=2 deployment/nginx-deployment Job相当于linux系统下的一次性任务at 使用场景 创建一定数量的pod，并保证可以成功地运行终止 跟踪pod状态，并根据重试策略进行失败重试 确定依赖关系，保证任务依次执行 控制任务并发度 范例 一次性任务 12345678910111213apiVersion: batch/v1kind: Job #job类型metadata: #元信息 name: pispec: template: #pod模板 spec: containers: - name: pi image: perl:slim command: [&quot;perl&quot;, &quot;-Mbignum=bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;] restartPolicy: Never # 重试策略，其他类型为：Onfailure、Always backoffLimit: 4 #重试次数 并发参数 123456789101112131415apiVersion: batch/v1kind: Jobmetadata: name: paralspec: completions: 8 #执行的pod总数 parallelism: 2 #并行执行的pod数 template: spec: containers: - name: param image: ubuntu command: [&quot;/bin/sh&quot;] args: [&quot;-c&quot;, &quot;sleep 30; date&quot;] restartPolicy: OnFailure #失败重启 CronJob周期性任务,相当于linux中的crontab 123456789101112131415161718192021apiVersion: batch/v1beta1kind: CronJobmetadata: name: hellospec: schedule: &quot;*/1 * * * *&quot; #周期参数，与crontab相同 jobTemplate: spec: template: spec: containers: - name: hello image: busybox args: - /bin/sh - -c - date; echo Hello from the kubernetes cluster restartPolicy: OnFailure startingDeadlineSeconds: 10 #最长启动时间 concurrencyPolicy: Allow #是否允许并行运行(解决情况：任务的执行时间超过周期间隔) successfulJobsHistoryLimit: 3 #允许留存的成功job数 DaemonSet相当于linux的守护进程，例如supervisor 使用场景 保证集群中的每个节点都运行一个相同的pod 节点加入或删除时，节点部署或删除对应的pod 应用场景 集群存储进程：glusterd，ceph 日志收集进程：fluentd，logstash 节点状态监控进程 范例 文件 123456789101112131415161718192021222324apiVersion: apps/v1kind: DaemonSetmetadata: name: fluentd-elasticsearch labels: k8s-app: fluentd-loggingspec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: containers: - name: fluentd-elasticsearch image: fluent/fluentd:v1.4-1 resources: #资源设置 limits: memory: 200Mi requests: cpu: 100m #相当于0.1cpu memory: 200Mi 更新镜像：kubectl set image ds/fluentd-elasticsearch fluentd-elasticsearch=fluent/fluentd:v1.4 回滚：kubectl rollout undo ds/fluentd-elasticsearch]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>Deployment</tag>
        <tag>Job</tag>
        <tag>CronJob</tag>
        <tag>DaemonSet</tag>
        <tag>Replicaset</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins-gitlab部署实践]]></title>
    <url>%2F2020%2F02%2F11%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%8E%E9%83%A8%E7%BD%B2%2Fjenkins%2Fjenkins-gitlab%E9%83%A8%E7%BD%B2%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[创建项目 类型：pipeline 名称：spring-hello-demo 触发器设置 以webhook方式 设置token信息，如：123456 webhook触发的URL(gitlab中设置)：JENKINS_URL/job/spring-hello-demo/build?token=TOKEN_NAME 如：http://192.168.2.162:7005/job/spring-hello/build?token=123456 pipeline设置 方式：pipeline script from SCM SCM：git Repository URL：包含项目源码、Jenkinsfile的源码库地址，示例代码 Credentials：jenkins连接gitlab的认证信息，可使用【用户名+密码】形式 Branches to build：构建的分支 脚本路径：Jenkinsfile文件位置 jenkins设置 在用户(如root)中创建API Token，此token用于：gitlab连接jenkins 全局安全设置： 访问控制-》授权策略-》【启用】匿名用户具有读权限 跨站请求伪造保护：【禁用】防止跨站点请求伪造 gitlab设置 设置：settings-》integrations URL：jenkins中的hook地址，如：http://192.168.2.162:7005/job/spring-hello-demo/build?token=123456 Secret Token：jenkins中创建的API Token 【启用】Push events 【禁用】Enable SSL verification 点击【add webhook】按钮 测试：Project Hooks-》test-》push events 错误处理 错误：Url is blocked: Requests to the local network are not allowed 解决【admin area】 位置：settings-》network-》Outbound requests 设置：【启用】Allow requests to the local network from web hooks and services 设置：允许哪些局域网的webhook请求 代码详解Jenkinsfile12345678910111213141516pipeline&#123; agent any stages&#123; stage(&apos;build&apos;)&#123; steps&#123; script&#123; echo &quot;WORKSPACE: $&#123;env.WORKSPACE&#125;&quot; //工作目录 echo &quot;NODE_NAME: $&#123;env.NODE_NAME&#125;&quot; //节点名称 if (&quot;$&#123;env.NODE_NAME&#125;&quot; == &quot;master&quot;)&#123; //如果是在master上，则执行脚本 sh &quot;sh build-prod.sh&quot; &#125; &#125; &#125; &#125; &#125;&#125; build-prod.sh12345678910111213141516171819202122232425262728#!/bin/sh# 服务端口targetPort=8080# 镜像版本号vendor=1.0.0# 项目名称projectName=spring-hello-demo# 软件打包cd $WORKSPACEmvn clean package -D skipTests# 删除基于镜像的所有容器if [ $(docker ps -aqf &quot;name=$projectName&quot;) ];then docker rm -f $projectNamefi# 删除旧镜像if [ $(docker images -qf &quot;reference=$projectName:$vendor&quot;) ];then docker rmi -f $projectName:$vendorfi # 创建镜像docker build -t $projectName:$vendor . # 基于镜像启动容器docker run --name $projectName -d -p $targetPort:$targetPort $projectName:$vendor Dockerfile1234FROM openjdk:8-jdk-alpineVOLUME /tmpCOPY target/*.jar app.jarENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;]]]></content>
      <categories>
        <category>CICD</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins之声明式pipeline]]></title>
    <url>%2F2020%2F02%2F10%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%8E%E9%83%A8%E7%BD%B2%2Fjenkins%2Fjenkins%E4%B9%8B%E5%A3%B0%E6%98%8E%E5%BC%8Fpipeline%2F</url>
    <content type="text"><![CDATA[pipeline插件 pipeline blue ocean(图形化/更直观的查看pipeline执行状态) 基础语法结构stages12345678910111213141516171819202122232425pipeline &#123; agent any //指定构建环境 stages &#123; //构建步骤，至少包含一个stage stage(&apos;build&apos;) &#123; parallel&#123; //指定多个stage并行构建 stage(&apos;build-1&apos;)&#123; steps&#123; //在一个stage构建中的详细步骤 echo &apos;build stage 1&apos; &#125; &#125; stage(&apos;build-2&apos;)&#123; steps&#123; echo &apos;build stage 2&apos; &#125; &#125; &#125; &#125; stage(&apos;test&apos;) &#123; steps &#123; echo &apos;test stage&apos; &#125; &#125; &#125;&#125; 参数化构建 参数类型 参数说明 string 字符串 text 文本，容纳多于字符串的信息 booleanParam 布尔类型 choice 下拉框多选 file 添加构建过程需要的文件 password 密码类型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657pipeline&#123; agent any parameters&#123; choice( description: &apos;你需要选择哪个模块进行构建？&apos;, name: &apos;modulename&apos;, choices: [&apos;Module1&apos;, &apos;Module2&apos;, &apos;Module3&apos;] ) string( description: &apos;你需要在哪台机器上进行部署？&apos;, name: &apos;deploy_hostname&apos;, defaultValue: &apos;host131&apos;, ) text( name: &apos;release_note&apos;, defaultValue: &apos;Release Note 信息如下所示:\n \ bug-Fixed: \n \ Feature-Added: &apos;, description: &apos;Release Note的详细信息是什么？&apos; ) booleanParam( name: &apos;test_skip_flag&apos;, defaultValue: true, description: &apos;你需要在部署之前执行自动化测试么？&apos; ) password( name: &apos;deploy_password&apos;, defaultValue: &apos;hejingqi&apos;, description: &apos;部署机器连接时需要用到的密码信息是多少？&apos; ) file( name: &apos;deploy_property_file&apos;, description: &quot;你需要输入的部署环境的设定文件是什么？&quot; ) &#125; stages&#123; stage(&apos;Build&apos;)&#123; steps&#123; echo &quot;Build stage:选中的构建Module为：$&#123;params.modulename&#125;...&quot; &#125; &#125; stage(&apos;Test&apos;)&#123; steps&#123; echo &quot;Test stage:是否执行自动化测试：$&#123;params.test_skip_flag&#125;&quot; &#125; &#125; stage(&apos;Deploy&apos;)&#123; steps&#123; echo &quot;Deploy stage:部署机器的名称：$&#123;params.deploy_hostname&#125;...&quot; echo &quot;Deploy stage:部署连接的密码：$&#123;params.deploy_password&#125;...&quot; echo &quot;Deploy stage:Release Note的新的：$&#123;params.release_note&#125;...&quot; &#125; &#125; &#125;&#125; when处理【pre处理】 条件类型 使用说明 备注 branch 指定分支构建时触发 只支持多分支pipeline buildingTag 构建tag时触发 - changelog SCM的变更日志包含指定内容时触发 常与正则表达式结合使用 changeset SCM的changeset包含指定文件时触发 常与*等表达式结合使用，缺省不区分大小写，可通过caseSensitive为true实现区分大小写 changeRequest 变更请求发生时触发（比如Github的Pull Request、Gitlab的Merge Request以及Gerrit的变更等） 如未指定参数，每次请求都会触发；也可以指定【分支信息/标题/author/邮件地址】等信息作为参数触发 environment 环境变量被设为某值时触发 - equals 变量设为某值时触发 - expression 表达式为true时触发 返回的字符串必须转换为布尔类型才能操作 tag TAG_NAME变量满足匹配模式时被触发 - not 当条件为false时触发 - allOf 当所有条件都为true才会被触发 - anyOf 当所有嵌套条件至少一个为true时会被触发 - triggeredBy 当前构建为指定方式时触发【触发条件：SCMTrigger/TimerTrigger/UpstreamCause】 - 12345678910111213141516171819202122232425262728293031323334353637383940414243pipeline&#123; agent any environment&#123; //设置环境变量 ENVIRONMENT_TEST_FLAG = &apos;NO&apos; &#125; stages&#123; stage(&apos;Init&apos;)&#123; steps&#123; script&#123; //可以写grovy脚本，此处只定义变量 BUILD_EXPRESSION = true DEPLOY_USER = &apos;liumiaocn&apos; &#125; &#125; &#125; stage(&apos;Build&apos;)&#123; when&#123; expression &#123;BUILD_EXPRESSION&#125; //表达式为真则执行 &#125; steps&#123; sh &apos;echo Build stage ...&apos; &#125; &#125; stage(&apos;Test&apos;)&#123; when&#123; environment name: &apos;ENVIRONMENT_TEST_FLAG&apos;, //环境变量是指定值则执行 value: &apos;YES&apos; &#125; steps&#123; sh &apos;echo Test stage ...&apos; &#125; &#125; stage(&apos;Deploy&apos;)&#123; when&#123; equals expected: &apos;liumiaocn&apos;, //变量是指定值则执行 actual: DEPLOY_USER &#125; steps&#123; sh &apos;echo Deploy stage ...&apos; &#125; &#125; &#125; &#125; post处理 根据pipeline或stage执行结果进行后续处理 内置条件 always：无论pipeline或stage执行结果如何，都会执行下面的操作 changed：只有pipeline或stage执行结果与之前相比，状态发生变化，才会执行下边的操作 fixed：前一次执行结果为不稳定或失败状态，本次执行成功，才会执行下边的操作 regression：本次执行结果为不稳定、失败或中止状态，上次为成功状态 aborted：本次执行操作被手动中止，UI显示为灰色 failure：本次执行为failed状态，UI显示为红色 success：本次执行成功，UI显示为绿色 unstable：由于测试失败或代码规范性检查失败产生的状态，UI显示为黄色 unsuccessful：执行结果不是success cleanup：在其他post条件后，无论执行结果如何都会执行 范例123456789101112131415pipeline&#123; agent any stages&#123; stage(&apos;Example&apos;)&#123; steps&#123; echo &apos;Hello World&apos; &#125; &#125; &#125; post&#123; always&#123; echo &apos;I will always say Hello World&apos; &#125; &#125;&#125; if语句 grovvy编程，等同于pipeline下的when 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364pipeline&#123; agent any environment&#123; ENVIRONMENT_TEST_FLAG = &apos;NO&apos; &#125; stages&#123; stage(&apos;Init&apos;)&#123; steps&#123; script&#123; BUILD_EXPRESSION = true DEPLOY_USER = &apos;liumiaocn&apos; &#125; &#125; &#125; stage(&apos;Build&apos;)&#123; steps&#123; script&#123; if(BUILD_EXPRESSION)&#123; sh &apos;echo Build stage...&apos; &#125; &#125; &#125; // when&#123; // expression &#123;BUILD_EXPRESSION&#125; // &#125; // steps&#123; // sh &apos;echo Build stage ...&apos; // &#125; &#125; stage(&apos;Test&apos;)&#123; steps&#123; script&#123; if(ENVIRONMENT_TEST_FLAG == &apos;YES&apos;)&#123; sh &apos;echo Test stage...&apos; &#125; &#125; &#125; // when&#123; // environment name: &apos;ENVIRONMENT_TEST_FLAG&apos;, // value: &apos;YES&apos; // &#125; // steps&#123; // sh &apos;echo Test stage ...&apos; // &#125; &#125; stage(&apos;Deploy&apos;)&#123; steps&#123; script&#123; if(DEPLOY_USER == &apos;liumiaocn&apos;)&#123; sh &apos;echo Deploy stage...&apos; &#125; &#125; &#125; // when&#123; // equals expected: &apos;liumiaocn&apos;, // actual: DEPLOY_USER // &#125; // steps&#123; // sh &apos;echo Deploy stage ...&apos; // &#125; &#125; &#125; &#125;]]></content>
      <categories>
        <category>CICD</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins安装与配置]]></title>
    <url>%2F2020%2F02%2F10%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%8E%E9%83%A8%E7%BD%B2%2Fjenkins%2Fjenkins%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装配置java8运行环境jenkins安装 centos安装 123wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.reporpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.keyyum install jenkins -y ubuntu安装 1234wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add -sudo sh -c &apos;echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list&apos;sudo apt-get updatesudo apt-get install jenkins 源码包安装 软件源：https://mirrors.tuna.tsinghua.edu.cn/jenkins/ debian-stable|redhat-stable deb包安装失败 sudo apt-get update # 更新 sudo apt-get -f install # 解决依赖关系 sudo dpkg -i xxx.deb # 重新安装 安装错误 错误：ERROR: No Java executable found in current PATH: /bin:/usr/bin:/sbin:/usr/sbin 解决：ln -s /usr/local/jdk1.8.0_241/bin/java /usr/bin/ docker部署 启动参数 123456789101112docker run --name jenkins \ -u root -d \ -p 80:8080 -p 50000:50000 \ -v /data/jenkins/:/var/jenkins_home \ -v /var/run/docker.sock:/var/run/docker.sock \ -v /usr/bin/docker:/usr/bin/docker \ -v /usr/local/maven:/usr/local/maven \ -v /usr/local/jdk:/usr/local/jdk \ -v /etc/localtime:/etc/localtime \ -e JAVA_OPTS=&quot;-Dhudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION=true&quot; \ --restart=always \ jenkins/jenkins:lts 参数详解： –name：设置容器名称 -u：以root启动，防止出现权限问题 -d：后台运行 -p 7005:8080：映射服务端口【宿主机7005-》容器8080】 -p 50000:50000：agent连接master的端口 -v /data/jenkins/:/var/jenkins_home：jenkins主目录持久化存储 -v /var/run/docker.sock:/var/run/docker.sock：确保jenkins容器内可以操作宿主机的docker -v /usr/local/maven:/usr/local/maven：挂载宿主机maven到jenkins容器 -v /usr/local/jdk:/usr/local/jdk：挂载宿主机jdk到容器 -v /etc/localtime:/etc/localtime：设置容器时间 -e JAVA_OPTS=”-Dhudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION=true”：关闭csrf保护 csrf设置：由于jenkins2.0版本默认开启CSRF且不能关闭，所以需要在启动jenkins服务时关闭csrf 官方说明 网友设置 web设置 访问地址：http://JENKINS_URL:8080 初始化密码：/var/jenkins_home/secrets/initialAdminPassword 使用国内镜像的步骤 修改插件更新中心URL：https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json 修改json配置【/var/jenkins_home/updates/default.json】 12sed -i &apos;s/http:\/\/updates.jenkins-ci.org\/download/https:\/\/mirrors.tuna.tsinghua.edu.cn\/jenkins/g&apos; default.json &amp;&amp; \sed -i &apos;s/http:\/\/www.google.com/https:\/\/www.baidu.com/g&apos; default.json 重启jenkins：docker restart jenkins 邮件设置(Mailer插件) 系统管理员帐户 SMTP服务器户 SMTP认证 用户名 密码 发送测试【如果设置的邮件为163，则收件人和发件人一样；否则会显示为垃圾邮件不能发送】 测试用户邮箱地址 节点管理【添加slave节点(SSH Slaves插件)】 远程工作目录 设置启动方式（ssh） 设置环境变量：JAVA_HOME 工具集成集成maven 安装apache maven，并配置环境变量 插件：Maven Integration plugin 全局工具配置 maven配置–》settings文件 Maven–》Maven name、MAVEN_HOME设置 jenkinsfile中使用（此处使用tools配置加载maven）1234567891011121314151617181920212223pipeline&#123; agent any tools&#123; maven &apos;maven3.6.3&apos; &#125; stages&#123; stage(&apos;Build&apos;)&#123; steps&#123; sh &apos;echo Build stage...&apos; sh &apos;java -version&apos; &#125; &#125; stage(&apos;Test&apos;)&#123; steps&#123; sh &apos;echo Test stage...&apos; sh &apos;mvn --version&apos; &#125; &#125; &#125;&#125; 集成docker 插件 Docker Commons Plugin：给各种docker插件提供基础的API docker-build-step：在job中执行docker命令 配置(docker-build-step插件)：系统配置–》Docker Builder–》unix:///var/run/docker.sock【确保jenkinis用户对此socket有读权限】 使用方式-tools：通过在全局工具配置中定义特定版本的docker 12345678910111213pipeline &#123; agent any tools &#123; &apos;org.jenkinsci.plugins.docker.commons.tools.DockerTool&apos; &apos;docker1903&apos; &#125; stages &#123; stage(&apos;foo&apos;) &#123; steps &#123; sh &quot;docker version&quot; &#125; &#125; &#125;&#125; 使用方式-agent：加载PATH变量下默认的docker 123456789101112131415161718192021222324252627pipeline&#123; agent&#123; docker&#123; image &apos;maven:3.6.3-jdk-8&apos; label &apos;agent01&apos; &#125; &#125; stages&#123; stage(&apos;Build&apos;)&#123; steps&#123; sh &apos;echo jdk version...&apos; sh &apos;java -version&apos; &#125; &#125; stage(&apos;Test&apos;)&#123; steps&#123; sh &apos;echo maven version...&apos; sh &apos;mvn --version&apos; &#125; &#125; stage(&apos;Deploy&apos;)&#123; steps&#123; sh &apos;echo Deploy stage...&apos; &#125; &#125; &#125;&#125; 并行使用多个docker镜像(parallel) 1234567891011121314151617181920212223242526stage(&apos;Build&apos;)&#123; parallel&#123; stage(&apos;Front End Build: Angular&apos;)&#123; agent&#123; docker&#123; image &apos;liumiaocn/angular:8.3.8&apos; &#125; &#125; steps&#123; sh &apos;echo Front End Build stage...&apos; sh &apos;ng --version&apos; &#125; &#125; stage(&apos;Back End build: Marven&apos;)&#123; agent&#123; docker&#123; image &apos;maven:3.6.3-jdk-8&apos; &#125; &#125; steps&#123; sh &apos;echo Back End Build stage ...&apos; sh &apos;mvn --version&apos; &#125; &#125; &#125;&#125; dockerfile中定义构建环境 默认，需要在多分支pipeline或SCM-pipeline中使用 为了手动测试，可以在jenkins宿主机的绝对目录定义dockerfile1234567agent&#123; dockerfile&#123; filename &apos;Dockerfile&apos; dir &apos;/tmp&apos; label &apos;agent01&apos; &#125;&#125;]]></content>
      <categories>
        <category>CICD</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab之ci-runner使用]]></title>
    <url>%2F2020%2F01%2F18%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%8E%E9%83%A8%E7%BD%B2%2Fgitlab%2Fgitlab%E4%B9%8Bci-runner%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[ci-runner安装与配置gitlab CI服务最好不要部署于gitlab服务器上【因为CI(持续集成)任务会很消耗资源】 安装dockerdocker是CI(持续集成)任务的基础环境，当然CI(持续集成)任务也可以直接利用CI服务器的shell环境 安装gitlab-runner gitlab-runner是部署于gitlab CI服务器上的代理服务，用于接收gitlab服务器上发送的构建指令并执行构建操作 curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh | sudo bash sudo apt-get install gitlab-runner gitlab-runner status 设置权限使gitlab-runner运行的用户可以执行docker命令 将ci-runner注册到gitlab 执行命令：gitlab-runner register 注册输入内容 gitlab服务器地址【管理员界面–》runners】 注册秘钥【管理员界面–》runners】 描述信息：说明这个runner用途 标签信息：标识这个runner，可以让.gitlab-ci.yml中的job使用指定的runner运行任务 执行环境：命令执行的环境，可以是docker【python27、python34、maven等环境】、shell等 CICD入门范例 项目源代码的根目录下创建.gitlab-ci.yml文件 123456789101112131415161718192021# 定义构建的步骤stages: - build - test# 定义执行的任务job1: stage: test # 任务和构建步骤绑定 tags: # 定义构建的基础环境(即runner的标签信息) - shell script: # 定义构建执行的命令 - echo &quot;I am job1&quot; - echo &quot;I am in test stage&quot;job2: stage: build tags: - shell script: - echo &quot;I am job2&quot; - echo &quot;I am in build stage&quot; 默认，项目代码库有变动，CICD–》pipeline就会执行 CICD综合范例 学习示例代码 gitlab-ci.yml示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556stages: - style - test - deploy - releasepep8: stage: style script: - pip install tox - tox -e pep8 #执行python pep8代码检查 tags: - python2.7 except: #代码库有版本(tag)变动时不执行 - tagsunittest-py27: stage: test script: - pip install tox - tox -e py27 #执行python2.7环境下的单元测试 tags: - python2.7 except: - tagsunittest-py34: stage: test script: - pip install tox - tox -e py34 #执行python3.4环境下的单元测试 tags: - python3.4 except: - tagsdocker-deploy: stage: deploy script: - docker build -t flask-demo . - if [ $(docker ps -qf &quot;name=web&quot;) ];then docker rm -f web;fi - docker run -id -p 5000:5000 --name web flask-demo tags: - shell only: #仅当master分支有变动时才执行此任务 - masterdocker-build: stage: release script: - docker build -t registry.cn-hangzhou.aliyuncs.com/simple00426/flask-demo:$CI_COMMIT_TAG . - docker push registry.cn-hangzhou.aliyuncs.com/simple00426/flask-demo:$CI_COMMIT_TAG tags: - shell only: #仅当代码库有版本(tag)变动时才执行此任务 - tags CICD使用建议 保护master分支，只允许其他分支merge，不允许直接push【settings–》repository–》Protected Branches–》allow to push(no one)】 分支合并到master时，必须通过pipeline检测【settings–》general–》merge request–》pipeline must succeed】 在项目的readme文件中添加项目的pipeline实时状态信息【settings-》CICD–》General pipelines–》Pipeline status】]]></content>
      <categories>
        <category>CICD</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>runner</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-k8s的CICD实践预览]]></title>
    <url>%2F2020%2F01%2F18%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%8E%E9%83%A8%E7%BD%B2%2Fdocker-k8s%E7%9A%84CICD%E5%AE%9E%E8%B7%B5%E9%A2%84%E8%A7%88%2F</url>
    <content type="text"><![CDATA[docker/k8s的CICD实现 开发人员从镜像仓库harbor中拉取基础镜像，对应用进行容器化开发 开发人员提交代码到代码仓库gitlab中 gitlab收到代码提交请求后通过webhook方式触发jenkins jenkins收到请求后对代码进行打包，生产可执行程序(如，marven打包) 打包完成后，基于dockerfile生成docker images docker images产生后上传到镜像仓库harbor 通过jenkins的pipeline在kubernetes的测试、生产环境拉取镜像、部署应用]]></content>
      <categories>
        <category>CICD</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>harbor</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose学习]]></title>
    <url>%2F2019%2F12%2F10%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fdocker%2Fdocker-compose%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[介绍docker compose是一个用于定义和管理多容器的docker工具，可以通过使用yaml格式的compose文件定义多个服务应用（这些应用也就是容器），并通过compose命令管理这些服务的创建、运行、停止、销毁等工作。 核心概念 services：它定义了一个应用包含的多个服务(服务的载体即是容器) 容器可以从docker hub的image创建 也可以从本地的Dockerfile build出来的镜像来创建 networks：应用包含的服务(即容器)使用的网络 volumes：应用包含的服务(即容器)使用的存储 compose文件 默认使用docker-compose.yml作为文件名，命令行下可使用-f参数指定特定compose文件 默认连接在同一个自定义网络下的多个service（service即容器）可以通过service name实现容器间互连 123456789101112131415161718192021222324252627version: &apos;3&apos;services: wordpress: image: wordpress ports: - 8080:80 environment: WORDPRESS_DB_HOST: mysql WORDPRESS_DB_PASSWORD: root networks: - my-bridge depends_on: - mysql mysql: image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: wordpress volumes: - mysql-data:/var/lib/mysql networks: - my-bridgevolumes: mysql-data:networks: my-bridge: driver: bridge services定义 build：构建启动服务所需要的镜像，等同于docker build命令，， 可以直接包含Dockerfile目录位置：【build .】 也可以包含更复杂的数据结构：123build: context: . dockerfile: Dockerfile image：定义要使用的image，或在build时给image命名 depends_on：定义各服务间的依赖关系，比如启动、关闭的先后顺序；依赖的服务会先于此服务启动，后于此服务关闭。 environment：定义环境变量，可以是列表(- SHOW=true)或字典(SHOW: ‘true’) ports：将主机端口绑定到容器暴露的端口 同时定义主机和容器端口：host_port:container_port 只定义容器端口：此时将容器端口发布到主机随机端口上 networks：定义要使用的网络 volumes：将主机的的路径或命名的数据卷和容器的路径建立映射关系 volumes定义见如上示例 networks定义可选参数【driver】定义网络类型，在单机情况下默认是bridge，在Swarm中是overlay bridge swarm host none docker-compose命令安装 sudo curl -L “https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)” -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose 命令参数 docker-compose命令默认使用当前目录下的docker-com.yml文件，可以使用-f参数指定要使用的文件 up [-d]：构建并启动一个服务下的多个容器，-d参数以后台方式执行 –scale service=num：增容或兼容容器数量 down：停止并销毁一个服务下的多个容器及使用的网络，但是不会销毁数据卷 start：启动服务(多个容器) stop：停止服务(多个容器) ps：显示正在运行的服务 exec [service]：进入service中执行命令 弹性伸缩容器数量123456789101112131415161718version: &quot;3&quot;services: redis: image: redis web: build: context: . dockerfile: Dockerfile environment: REDIS_HOST: redis lb: image: dockercloud/haproxy links: - web ports: - 8080:80 volumes: - /var/run/docker.sock:/var/run/docker.sock 启动服务：docker-compose up 扩容web服务： docker-compose up –scale web=3 -d]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker网络]]></title>
    <url>%2F2019%2F12%2F02%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fdocker%2Fdocker%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[linux网络命令空间命名空间管理 netns(net name space)：网络命名空间 查看命名空间：ip netns list 添加命名空间：ip netns add test 删除命名空间：ip netns delete test 端口和地址操作 veth(virtual ethernet)：虚拟以太网卡，和物理网卡类似，用于网络连通 添加端口(一次添加网络互通的链接对(即两个端口))：ip link add veth-test1 type veth peer name veth-test2 将链接对的两端分配到命名空间中 ip link set veth-test1 netns test1 ip link set veth-test2 netns test2 添加ip地址： ip netns exec test1 ip addr add 192.168.100.1/24 dev veth-test1 ip netns exec test2 ip addr add 192.168.100.2/24 dev veth-test2 启动端口 ip netns exec test1 ip link set dev veth-test1 up ip netns exec test2 ip link set dev veth-test2 up 状态查询 查看端口状态：ip netns exec test2/test1 ip link 查看ip地址：ip netns exec test2 ip addr 网络测试(test1中ping test2)：ip netns exec test1 ping 192.168.100.2 网络类型-bridge互通原理 每个容器通过veth(虚拟以太网链接对)和宿主机连通 多个veth包含在一个bridge(桥接网络)中，因此多个容器可以互通 桥接网卡(一般为docker0)和宿主机出口(例如eth0)通过iptables的nat转换，从而可以让容器连接互联网 操作docker-network命令 查看桥接网卡列表：docker network ls 查看桥接网卡详情(容器、veth对等)：docker network inspect 4c44ab01e956 创建桥接网卡：docker network create 范例(指定网卡名称)：docker network create -d bridge my-bridge 范例(指定网络地址)：docker network create –subnet 192.168.200.0/24 –gateway 192.168.200.1 my-bridge 创建容器并连接指定网络：docker run –network 范例：docker run -idt –name test3 –network my-bridge busybox:latest /bin/sh -c “while true;do sleep 3600;done” 已存在的容器连接指定网络：docker network connect my-bridge test1 brctl命令 软件安装：bridge-utils【centos】 查看桥接网卡包含的容器链接对(veth)：brctl show 添加桥接网卡 brctl addbr bridge0 ip addr add 172.19.0.1/24 dev bridge0 ip link set dev bridge0 up 容器端口映射docker run -p host_port:container_port 网络类型-none/host none：容器绑定此网络后，除了回环接口外，容器没有其他网络地址 host：容器绑定此网络后，容器直接使用宿主机的所有网络地址 网络类型-overlay简介 使用etcd分布式存储，docker创建的overlay网络可以实现跨主机容器互联 以下操作都是在双机(192.168.2.151,192.168.2.152)上运行，且需要先安装并配置etcd docker配置调整并重启123456&#123; &quot;registry-mirrors&quot;: [&quot;https://2x97hcl1.mirror.aliyuncs.com&quot;], &quot;host&quot;: [&quot;tcp://0.0.0.0:2375&quot;, &quot;unix:///var/run/docker.sock&quot;], &quot;cluster-advertise&quot;: &quot;192.168.2.151:2375&quot;, &quot;cluster-store&quot;: &quot;etcd://192.168.2.151:2379&quot;&#125; 建立并使用overlay网络 创建网络：docker network create -d overlay demo 查看网络：docker network ls 在两台宿主机使用此网络启动：docker run -d –name test2 –network demo busybox sh -c “while true;do sleep 3600;done” 在两个容器内ping测试：docker exec -it test1 /bin/sh 在etcd中查看网络信息：etcdctl ls /docker 分布式kv存储-etcd简介etcd是分布式key-value存储系统，安装etcd可用于存储docker的overlay网络信息 版本 docker engine 19.03.5和 flannel v0.11版本不支持etcd v3.4.3版本，但支持3.3.x系列 v2版本api下docker连接到etcd 1234Dec 2 14:45:40 node2 dockerd[4339]: time=&quot;2019-12-02T14:45:40.105655602Z&quot; level=info msg=&quot;2019/12/02 14:45:40 [INFO] serf: EventMemberJoin: node2 192.168.2.152\n&quot;Dec 2 14:45:40 node2 dockerd[4339]: time=&quot;2019-12-02T14:45:40.108328635Z&quot; level=info msg=&quot;2019/12/02 14:45:40 [INFO] serf: EventMemberJoin: node1 192.168.2.151\n&quot; v3版本api下docker无法连接etcd 1234Dec 2 14:27:47 node2 dockerd[4032]: time=&quot;2019-12-02T14:27:47.113424521Z&quot; level=warning msg=&quot;Registering as \&quot;192.168.2.152:2375\&quot; in discovery failed:client: response is invalid json. The endpoint is probably not valid etcd cluster endpoint.&quot;Dec 2 14:27:47 node2 dockerd[4032]: time=&quot;2019-12-02T14:27:47.274972145Z&quot; level=error msg=&quot;discovery error: client: response is invalid json. The endpoint is probably not valid etcd cluster endpoint.&quot; 安装 以下操作都是在双机(192.168.2.151,192.168.2.152)上运行 下载并解压：https://github.com/etcd-io/etcd/releases/download/v3.3.18/etcd-v3.3.18-linux-amd64.tar.gz 配置并启动 配置文件etcd.yml 123456789101112131415161718# 节点名称name: &quot;node1&quot;# 存储位置data-dir: &quot;/home/etcd&quot;# 集群通信端口[本机]listen-peer-urls: &quot;http://192.168.2.151:2380&quot;# 集群服务端口[本机]listen-client-urls: &quot;http://192.168.2.151:2379,http://127.0.0.1:2379&quot;# 初始化时,告知其他节点本地集群通信端口[本机]initial-advertise-peer-urls: &quot;http://192.168.2.151:2380&quot;# 初始化时，发布的服务端口[本机]advertise-client-urls: &quot;http://192.168.2.151:2379&quot;# 新建集群initial-cluster-state: &quot;new&quot;# 集群标识initial-cluster-token: &quot;etcd-cluster&quot;# 集群节点initial-cluster: &quot;node1=http://192.168.2.151:2380,node2=http://192.168.2.152:2380&quot; 启动(使用supervisor)：etcd –config-file etcd.yml 控制命令 集群成员：etcdctl member list 集群状态： v2版本：etcdctl cluster-health v3版本：etcdctl –write-out=table –endpoints=192.168.2.151:2379,192.168.2.152:2379 endpoint status/health 其他跨主机容器互联方式静态路由 阿里云ecs需要在vpc上添加静态路由 案例 主机192.168.99.101 docker容器网络172.18.0.1/16 主机192.168.99.102 docker容器网络172.17.0.1/16 操作： 101主机：route add -net 172.17.0.0/16 gw 192.168.99.102 102主机：route add -net 172.18.0.0/16 gw 192.168.99.101 overlay网络第三方实现-ovs ovs：open vswitch ovs封装方式： vxlan：udp报文封装 gre：点对点tcp报文封装 架构设计 192.168.99.102 192.168.99.101 ubuntu centos7 ovs安装方式： apt-get install openvswitch-switch 安装参考：http://blog.csdn.net/xinxing__8185/article/details/51900444 使用默认的docker0，网络为172.17.0.0 使用自定义网桥bridge0，网络为172.18.0.0 102主机操作12345678ovs-vsctl add-br br0 #添加名称为br0的ovs网桥ovs-vsctl add-port br0 gre0 -- set interface gre0 type=gre options:remote_ip=192.168.99.101 #创建到另一台主机的gre tunnelbrctl addif docker0 br0 #将br0网桥添加到docker0网桥中ip link set dev br0 up #启动br0ip link set dev docker0 up #启动docker0ip route add 172.18.0.0/16 dev docker0 #添加到172.18.0.0/16的路由，使其通过docker0service docker restart #重启dockerdocker start mysql-instance #启动容器 101主机操作12345678ovs-vsctl add-br br0ovs-vsctl add-port br0 gre0 -- set interface gre0 type=gre options:remote_ip=192.168.99.102brctl addif bridge0 br0ip link set dev br0 upip link set dev bridge0 upip route add 172.17.0.0/16 dev bridge0systemctl restart docker.servicedocker start registry 持久化设置 以centos7为例 建立网桥文件(/etc/sysconfig/network-scripts/ifcfg-bridge0) 123456789ONBOOT=yesBOOTPROTO=staticIPADDR=172.18.0.1NETMASK=255.255.0.0GATEWAY=172.18.0.0USERCTL=noTYPE=BridgeDEVICE=bridge0IPV6INIT=no 其他设置(/etc/rc.local) 123ip route del 172.17.0.0/16 dev bridge0brctl addif bridge0 br0ip link set dev br0 up 保证rc.local执行：chmod +x /etc/rc.d/rc.local]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>overlay</tag>
        <tag>网络命名空间</tag>
        <tag>bridge</tag>
        <tag>etcd</tag>
        <tag>ovs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb副本集与分片]]></title>
    <url>%2F2019%2F12%2F01%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmongodb%E5%89%AF%E6%9C%AC%E9%9B%86%E4%B8%8E%E5%88%86%E7%89%87%2F</url>
    <content type="text"><![CDATA[副本集部署架构 主机：172.16.0.201、172.16.0.215、172.16.0.205 201已建立用户及其权限 readWriteAnyDatabase clusterAdmin userAdminAnyDatabase dbAdminAnyDatabase 配置文件12345678net: # 网络设置 port: 27017 bindIp: 0.0.0.0security: authorization: enabled # 开启用户认证 keyFile: /etc/mongo_key.txt #集群认证秘钥replication: replSetName: &quot;rs0&quot; # 副本集名称设置 集群认证秘钥 产生：openssl rand -base64 32 -out mongo_key.txt 变更用户和权限 chmod 0600 mongo_key.txt chown mongodb mongo_key.txt 集群配置 登录其中一个节点(201)配置，配置后此节点即为主节点 12345678rs.initiate( &#123; _id : &quot;rs0&quot;, members: [ &#123; _id: 0, host: &quot;172.16.0.201:27017&quot; &#125;, &#123; _id: 1, host: &quot;172.16.0.215:27017&quot; &#125;, &#123; _id: 2, host: &quot;172.16.0.205:27017&quot; &#125; ]&#125;) 集群操作命令 查看状态：rs.status() 查看配置：rs.conf() 查看从机状态：db.printSlaveReplicationInfo(); 查看复制状态：db.printReplicationInfo(); 从机读设置 默认，读写都在primary节点操作，如果在从机操作，则会报错：”not master and slaveOk=false” 从机客户端连接中设置可读：rs.slaveOk() 主机客户端设置读取策略： mongo连接级别：db.getMongo().setReadPref(‘secondary’) 连接内的指针级别：db.inventories.find().readPref(‘secondary’) 分片集群注意事项 此部署文档适用于MongoDB 4.2 由于从3.6开始，所有分片集群必须是副本集；所有低于3.6版本的分片想要升级，必须 先将独立的分片集群转换为副本集 后将副本集升级为分片副本集集群 集群架构 3节点数据副本集rs0【rs0/172.16.0.201:27017,172.16.0.215:27017,172.16.0.205:27017】 3节点数据副本集rs1【rs1/172.16.0.201:27027,172.16.0.215:27027,172.16.0.205:27027】 3节点配置副本集【configReplSet/172.16.0.201:29017,172.16.0.215:29017,172.16.0.205:29017】 单节点路由服务【172.16.0.201:30001】 架构部署预览 创建3节点数据副本集rs0，批量插入测试数据 创建配置副本集(configsrv) 创建路由服务(mongos) 将数据副本集添加为分片节点 创建第二个分片节点，即副本集rs1 将期望的集合分片 创建数据副本集 参靠mongodb副本集部署 使用自定义目录方式启动服务 创建目录：mkdir -p /data/mongodb/rs0/{data,conf,log} 创建用户：useradd mongodb 对目录授权：chown -R mongodb.mongodb /data/mongodb/rs0 设置副本集名称：replication.replSetName: “rs0” 命令行以指定用户启动服务：chroot --userspec &quot;mongodb:mongodb&quot; &quot;/&quot; sh -c &quot;/usr/bin/mongod -f /data/mongodb/rs0/conf/mongod.conf&quot; 批量插入测试数据 12345678910use testvar bulk = db.test_collection.initializeUnorderedBulkOp();people = [&quot;Marc&quot;, &quot;Bill&quot;, &quot;George&quot;, &quot;Eliot&quot;, &quot;Matt&quot;, &quot;Trey&quot;, &quot;Tracy&quot;, &quot;Greg&quot;, &quot;Steve&quot;, &quot;Kristina&quot;, &quot;Katie&quot;, &quot;Jeff&quot;];for(var i=0; i&lt;1000000; i++)&#123; user_id = i; name = people[Math.floor(Math.random()*people.length)]; number = Math.floor(Math.random()*10001); bulk.insert( &#123; &quot;user_id&quot;:user_id, &quot;name&quot;:name, &quot;number&quot;:number &#125;);&#125;bulk.execute(); 将副本集转换为可分片模式 连接集群从节点：关闭服务后、添加配置【sharding.clusterRole: shardsvr】、重启服务 连接集群主节点：主节点置为从【rs.stepDown()】、添加配置【sharding.clusterRole: shardsvr】、重启服务 创建配置副本集 参靠mongodb副本集部署 设置配置集群选项 replication.replSetName: “configReplSet” sharding.clusterRole: configsvr 初始化配置集群123456789rs.reconfig( &#123; _id : &quot;configReplSet&quot;, configsvr: true, members: [ &#123; _id: 0, host: &quot;172.16.0.201:29017&quot; &#125;, &#123; _id: 1, host: &quot;172.16.0.215:29017&quot; &#125;, &#123; _id: 2, host: &quot;172.16.0.205:29017&quot; &#125; ]&#125;) 创建路由服务 配置选项： sharding.configDB: configReplSet/172.16.0.201:29017,172.16.0.215:29017,172.16.0.205:29017 security.keyFile: /etc/mongo_key.txt 启动服务：chroot --userspec &quot;mongodb:mongodb&quot; &quot;/&quot; sh -c &quot;/usr/bin/mongos -f /data/mongodb/mongos/conf/mongos.conf&quot; 将数据副本集添加为分片节点 连接到mongos并授权登录 添加副本集为分片节点：sh.addShard( “rs0/172.16.0.201:27017,172.16.0.215:27017,172.16.0.205:27017” ) 查看集群分片状态：sh.status() 将期望的集合分片 连接到mongos并授权登录 数据库开启分片：sh.enableSharding( “test” ) 在非空集合上添加索引：use test; db.test_collection.createIndex( { number : 1 } ) 对集合分片：use test; sh.shardCollection( “test.test_collection”, { “number” : 1 } ) 确认分片处于平衡状态123use testdb.stats()db.printShardingStatus() 配置文件数据节点mongod.conf123456789101112131415161718192021storage: dbPath: /data/mongodb/rs0/data journal: enabled: truesystemLog: destination: file logAppend: true path: /data/mongodb/rs0/log/mongod.lognet: port: 27017 bindIp: 0.0.0.0processManagement: timeZoneInfo: /usr/share/zoneinfo fork: truesecurity: authorization: enabled keyFile: /etc/mongo_key.txtreplication: replSetName: &quot;rs0&quot;sharding: clusterRole: shardsvr 配置节点configsrv.conf123456789101112131415161718192021storage: dbPath: /data/mongodb/configdb/data journal: enabled: truesystemLog: destination: file logAppend: true path: /data/mongodb/configdb/log/config.lognet: port: 29017 bindIp: 0.0.0.0processManagement: timeZoneInfo: /usr/share/zoneinfo fork: truesecurity: authorization: enabled keyFile: /etc/mongo_key.txtreplication: replSetName: &quot;configReplSet&quot;sharding: clusterRole: configsvr 路由服务mongos.conf1234567891011121314systemLog: destination: file logAppend: true path: /data/mongodb/mongos/log/mongos.lognet: port: 30001 bindIp: 0.0.0.0processManagement: timeZoneInfo: /usr/share/zoneinfo fork: truesharding: configDB: configReplSet/172.16.0.201:29017,172.16.0.215:29017,172.16.0.205:29017security: keyFile: /etc/mongo_key.txt]]></content>
      <categories>
        <category>mongodb</category>
      </categories>
      <tags>
        <tag>副本集</tag>
        <tag>分片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb入门与管理]]></title>
    <url>%2F2019%2F11%2F21%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmongodb%E5%85%A5%E9%97%A8%E4%B8%8E%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[简介存储引擎 3.2之后增加存储引擎WiredTiger 4.2之后移除对MMAPv1引擎的支持 若要将数据从MMAPv1迁移到WiredTiger，参考官方文档 数据目录下包含的文件必须和存储引擎匹配，否则无法启动 WiredTiger存储引擎默认支持document级别锁（类似关系型数据库的行级锁） 软件版本由于mongodb的不同版本的区别较大，需要确认不同操作系统版本支持的软件版本 数据可靠性 Journal：使用Journal，即预写式日志保证数据可靠性 副本集：在4.0之后的版本，使用WiredTiger引擎、开启主从复制时不能关闭日志功能（storage.journal.enabled: false） 安装安装要求 时钟同步 目的：为了保证mongodb组件或集群成员之间保证正常工作，应该开启ntp服务以同步主机时间 错误示例：【waited 189s for distributed lock configUpgrade for upgrading config database to new format v5】 设置文件描述符：ulimit 禁用Transparent Huge Pages 禁用NUMA选项 关闭selinux 安装组件主要是安装mongodb-org，它包含如下的组件： mongodb-org-server：mongodb的服务端主进程mongod mongodb-org-mongos：mongodb的分片功能主进程mongos mongodb-org-shell：mongodb的客户端程序mongo mongodb-org-tools：mongodb的工具软件，比如mongodump,mongorestore, mongostat等 centos安装 设置yum源 123456[mongodb-org-4.2]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/4.2/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-4.2.asc yum源更新：yum makecache 软件安装：sudo yum install -y mongodb-org ubuntu安装 设置软件源 123wget -qO - https://www.mongodb.org/static/pgp/server-4.2.asc | sudo apt-key add -echo &quot;deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/4.2 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-4.2.listsudo apt-get update 软件安装：sudo apt-get install -y mongodb-org 避免自动升级12345echo &quot;mongodb-org hold&quot; | sudo dpkg --set-selectionsecho &quot;mongodb-org-server hold&quot; | sudo dpkg --set-selectionsecho &quot;mongodb-org-shell hold&quot; | sudo dpkg --set-selectionsecho &quot;mongodb-org-mongos hold&quot; | sudo dpkg --set-selectionsecho &quot;mongodb-org-tools hold&quot; | sudo dpkg --set-selections tar包安装 依赖安装：sudo yum install libcurl openssl 软件下载及解压 编译安装（根据内置的参考文档） 将二进制文件路径添加到PATH 建立用户、日志目录、数据目录(对目录授权：mongod程序必须 有dbPath目录的读写权限) 编辑配置文件mongod.conf 启动服务：/usr/bin/mongod –config /etc/mongod.conf 服务控制 目录设置(mongod.conf)： 数据目录：storage.dbPath 日志目录：systemLog.path 启停：service mongod start/stop/restart 客户端连接：mongo 结构操作库操作 db：显示当前数据库 show dbs：查看所有数据库 use db：切换数据库（不存在则创建） db.dropDatabase()：删除当前库 集合操作 查看库的所有集合： show collections 创建集合： 单独创建一个资源受限的空集合，超过限制则删除最早的数据 语法范例：db.createCollection(“profile”,{size: 1024, capped: true, max: 5}) size：使用空间大小限制 capped：是否开显示 max：最多保存多少条数据 删除集合：db.collection.drop() 重命名集合：db.collection.renameCollection(“new_name”) 数据操作增加 集合不存在则自动创建 插入数据：db.collection.insert() 1db.inventory.insert(&#123;&quot;item&quot;: &quot;test&quot;, &quot;qty&quot;: 11, &quot;status&quot;: &quot;B&quot;, &quot;size&quot;: &#123;&quot;h&quot;: 12, &quot;w&quot;: 2, &quot;uom&quot;: &quot;cm&quot;&#125;, &quot;tags&quot;: [&quot;orange&quot;]&#125;) 批量插入数据：db.collection.insertMany() 12345678db.inventory.insertMany([ &#123; item: &quot;journal&quot;, qty: 25, status: &quot;A&quot;, size: &#123; h: 14, w: 21, uom: &quot;cm&quot; &#125;, tags: [ &quot;blank&quot;, &quot;red&quot; ] &#125;, &#123; item: &quot;notebook&quot;, qty: 50, status: &quot;A&quot;, size: &#123; h: 8.5, w: 11, uom: &quot;in&quot; &#125;, tags: [ &quot;red&quot;, &quot;blank&quot; ] &#125;, &#123; item: &quot;paper&quot;, qty: 10, status: &quot;D&quot;, size: &#123; h: 8.5, w: 11, uom: &quot;in&quot; &#125;, tags: [ &quot;red&quot;, &quot;blank&quot;, &quot;plain&quot; ] &#125;, &#123; item: &quot;planner&quot;, qty: 0, status: &quot;D&quot;, size: &#123; h: 22.85, w: 30, uom: &quot;cm&quot; &#125;, tags: [ &quot;blank&quot;, &quot;red&quot; ] &#125;, &#123; item: &quot;postcard&quot;, qty: 45, status: &quot;A&quot;, size: &#123; h: 10, w: 15.25, uom: &quot;cm&quot; &#125;, tags: [ &quot;blue&quot; ] &#125;]);// MongoDB adds an _id field with an ObjectId value if the field is not present in the document 删除 语法：db.collection.remove() db.inventory.remove({“item”: “test”}) 修改 语法：db.collection.update( [查询条件]，[更新内容]，[不存在时是否添加(默认false)]，[是否更新多行(默认false,只更新第一行)]) 范例： 内容变更：$set：db.inventory.update({“status”: “A”}, {$set: {“qty”: 35}},false,true) 数值增减：$inc：db.inventory.update({“status”: “A”}, {$inc: {“qty”: -34}}) 查询 查询所有内容： db.collection.find() 格式化输出(pretty)：db.inventory.find({}).pretty() 精确查询：db.inventory.find( { “size.uom”: “in” } ) 指定返回字段(默认返回id) 语法：db.collection.find([查询字段]， [返回字段(1：包含，0：排除)]) 范例：db.inventory.find({},{_id:0, item:1, status:1})【不返回id，返回status】 用户和权限 mongodb默认没有启用用户访问控制，可以无限制的访问数据库 权限由指定的数据库资源(resource)和指定资源上的操作(action)组成 资源：数据库、集合、集群 操作：增、删、改、查（CRUD） mongodb通过角色对用户授予相应数据库资源的操作权限，每个角色中的权限可以显式指定，也可以继承其他角色的权限，也可以两者兼有+ 在同一个数据库中，新建的用户可以继承其他用户的角色 + 在admin库中，创建的角色可以继承其他任意数据库中角色的权限 mongodb中的角色分类 系统内置角色 用户自定义角色 系统内置角色 数据库用户角色 read：读取非系统集合数据 readWrite：读写非系统集合数据 数据库管理角色 dbAdmin：执行某些管理任务(与schema相关、索引、收集统计信息)的权限，但不包含用户管理 userAdmin：创建、修改角色、用户的权限 dbOwner：对数据库的所有的权限：readWrite、userAdmin、userAdmin 集群管理角色 clusterMonitor：监控工具（MongoDB Cloud Manager、Ops Manager）有只读权限 hostManager：包含针对数据库服务器的监控和管理操作 clusterManager：包含针对集群的监控和管理操作 clusterAdmin：拥有集群的最高权限：clusterManager、clusterMonitor、hostManager、dropDatabase 备份恢复角色 backup：拥有备份mongodb数据的最小权限 restore：含有从数据文件恢复数据的权限 全体数据库级别角色：只存在于admin库，适用于除了config和local之外的所有库 readAnyDatabase：对所有库的只读权限 readWriteAnyDatabase：对所有库的读写权限 userAdminAnyDatabase：类似于userAdmin对所有库的用户管理权限 dbAdminAnyDatabase：类似于dbAdmin对所有库的管理权限 超级用户角色 用户拥有以下角色时，可以对任意用户授予任意数据库任意权限 admin库的dbOwner的角色 admin库的userAdmin的角色 userAdminAnyDatabase root角色拥有的权限：readWriteAnyDatabase、dbAdminAnyDatabase、userAdminAnyDatabase、clusterAdmin、restore和backup 内部角色：__system 用户管理和访问控制管理用户 创建管理用户：db.createUser({user: &quot;user_admin&quot;, pwd: &quot;user_admin&quot;, roles: [{role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot;}]}) 开启访问控制(重启服务)：security.authorization：enabled 授权登录 交互终端内：use admin；db.auth(‘user_admin’,’user_admin’) 命令行模式：mongo –host 172.16.0.201 –port 27017 -u user_admin -p user_admin –authenticationDatabase admin 普通用户 查询数据库所有用户：db.getUsers()、show users 创建用户并添加角色： 1234567db.createUser(&#123; user: &quot;user_dba&quot;, pwd: &quot;user_dba&quot;, roles: [&quot;read&quot;], customData: &#123;info: &quot;user for dba&quot;&#125;&#125;) 更新用户角色：db.updateUser(“user_dba”, {roles:[{role: “read”, db: “admin”},{role: “readWrite”,db: “examples”}]}) 查询用户角色信息：db.getUser(“user_dba”,{showPrivileges: true}) 添加用户角色：db.grantRolesToUser(“user_dba”,[{role: “readWrite”, db: “admin”}]) 回收用户角色：db.revokeRolesFromUser(“user_dba”, [{role: “read”, db: “admin”}]) 变更用户密码：db.changeUserPassword(“user_dba”,”new_passwd”) 删除用户：db.dropUser(“user_dba”) 备份和恢复 用户授权：db.grantRolesToUser(&quot;user_admin&quot;,[{role: &quot;backup&quot;, db: &quot;admin&quot;},{role: &quot;restore&quot;, db: &quot;admin&quot;}]) 备份数据：mongodump --port 30001 -u user_admin -p user_admin --authenticationDatabase=admin -d test -o ./backup/ 导出数据：mongoexport 命令参数 -f：指定要导出的字段 –type：指定导出格式，默认json格式，也可指定csv -d：数据库 -c：集合 mongoexport –host=host.com –port=3717 -u root -p passwd –authenticationDatabase=admin -d fubu -c fubu_forum -f username,phone,qq,email,homepage,recently_posted,last_reply_time –type=csv -o ./fubu_forum.csv 恢复数据：mongorestore --port 30001 -u user_admin -p user_admin --authenticationDatabase=admin -d test --dir=./backup/test 操作日志原理MongoDB Profile 记录是直接存在系统 db 里的，记录位置 system.profile ，所以，我们只要查询这个 Collection 的记录就可以获取到我们的 Profile 记录了 设置 日志设置状态查询：db.getProfilingStatus(); 命令行设置 只能在非mongos的主设置 设置：db.setProfilingLevel(1,500); 设置解读：0代表关闭，1代表只记录slowlog，2代表记录所有操作，这里设置成了500，即500ms。 配置文件设置 开关：operationProfiling.mode: [off/slowOp/all] 阈值：operationProfiling.slowOpThresholdMs: N 查询 交互式命令行：db.system.profile.find({millis:{$gt:500}}) shell命令行：echo “db.system.profile.find({millis:{\$gt:500}})”|mongo 10.86.0.150:27017 服务性能优化 连接池【客户端设置】 内存：默认使用50% of (RAM - 1 GB)或256 MB中的大的数值 cpu：默认的线城池数量和cpu核心数相关 swap：系统设置swap分区，并设置swap【低度使用swap】 cat /proc/sys/vm/swappiness sysctl vm.swappiness=1 文件系统 尽量使用xfs文件系统 不建议使用NFS等远程文件系统 使用的文件系统支持目录级别fsync()【HGFS、virtualbox的共享目录不支持此操作】 磁盘：建议使用RAID-10. RAID-5 存储方式：将数据、预写日志、日志、索引存放在不同磁盘以改善性能 数据压缩存储 snappy：默认压缩方式，压缩率较低，cpu使用也低 zlib：压缩率较高，cpu使用也高 zstd：4.2版本出现的压缩选项，在压缩率和cpu中折中选择 NUMA使用介绍现在的机器上都是有多个CPU和多个内存块的。以前我们都是将内存块看成是一大块内存，所有CPU到这个共享内存的访问消息是一样的。这就是之前普 遍使用的SMP模型。但是随着处理器的增加，共享内存可能会导致内存访问冲突越来越厉害，且如果内存访问达到瓶颈的时候，性能就不能随之增加。NUMA（Non-Uniform Memory Access）就是这样的环境下引入的一个模型。 比如一台机器是有2个处理器，有4个内存块。我们将1个处理器和两个内存块合起来，称为一个NUMA node，这样这个机器就会有两个NUMA node。在物理分布上，NUMA node的处理器和内存块的物理距离更小，因此访问也更快。 比如这台机器会分左右两个处理器（cpu1, cpu2），在每个处理器两边放两个内存块(memory1.1, memory1.2, memory2.1,memory2.2)，这样NUMA node1的cpu1访问memory1.1和memory1.2就比访问memory2.1和memory2.2更快。所以使用NUMA的模式如果能尽量保证本node内的CPU只访问本node内的内存块，那这样的效率就是最高的。 缺点当你的服务器还有内存的时候，发现它已经在开始使用swap了，甚至已经导致机器出现停滞的现象。这个就有可 能是由于numa的限制，如果一个进程限制它只能使用自己的numa节点的内存，那么当自身numa node内存使用光之后，就不会去使用其他numa node的内存了，会开始使用swap，甚至更糟的情况，机器没有设置swap的时候，可能会直接死机！所以你可以使用numactl –interleave=all来取消numa node的限制。 使用建议 如果你的程序是会占用大规模内存的，你大多应该选择关闭numa node的限制。因为这个时候你的程序很有几率会碰到numa陷阱。 如果你的程序并不占用大内存，而是要求更快的程序运行时间。你大多应该选择限制只访问本numa node的方法来进行处理 mongodb使用mongod=”numactl –interleave=all /usr/local/mongod/bin/mongod”]]></content>
      <categories>
        <category>mongodb</category>
      </categories>
      <tags>
        <tag>安装</tag>
        <tag>用户权限</tag>
        <tag>管理</tag>
        <tag>numa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker入门介绍]]></title>
    <url>%2F2019%2F11%2F19%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fdocker%2Fdocker%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[docker引入传统IT面临问题 部署流程繁琐(采购服务器、安装软件环境)、软件环境臃肿、难于扩展(不利于迅速应对业务高峰对资源需求) 环境不一致：开发、测试、生产环境不一致 资源浪费：硬件需要预采购，成本很高；但是会面临cpu、内存等资源使用不足 容器优势 更快且保持一致性的交付应用程序【保持多阶段环境的一致性】 响应式部署和扩展【可以在物理机、虚拟机、云等多种环境部署，并可以根据负载弹性伸缩】 在同一个硬件上运行更多的负载 容器化devops通过标准化“应用运行环境”，沟通开发(dev)和运维(ops)流程 容器与虚拟机 区别：容器是在操作系统层面实现虚拟化，直接复用本地操作系统内核，它的技术基础是linux容器技术（LXC，即cgroups）；传统虚拟化方式则基于硬件层面实现虚拟化。 融合：由于目前docker不支持热迁移，可以将docker容器放在KVM虚拟机里，通过虚拟机的迁移完成容器的迁移 docker介绍docker架构 docker daemon(dockerd)：监听API请求、管理docker对象（镜像、容器、网络、卷） docker client：用户管理docker的入口 docker registry：镜像仓库 docker对象 容器：视图隔离、资源可限制、独立文件系统的进程集合 可以把容器看做是一个简易的linux环境和运行在其中的应用程序 docker利用容器来运行应用 容器是从镜像创建的运行实例，它可以被开始、停止、删除。 每个容器都是相互隔离的 镜像：容器运行所需的所有文件集合 它是一个只读模板，用来创建容器 容器在启动时会创建一个可写层作为多层文件系统的最上层 核心技术 视图隔离(namespace)：pid、net、ipc、mnt、uts 资源限制(cgroups)：cpu、内存 联合文件系统(union file system)：容器和镜像的分层，即分层文件系统 镜像拆分成多个模块，可以并行下载，提高分发效率 镜像数据是共享的，每次下载或构建镜像时，可以复用已存在的部分数据，此时，只需存储本地不存在的数据。 容器在启动时会创建一个可写层作为多层文件系统的最上层 容器格式(container format)：docker engine将namespace、cgroups、UnionFS组合到容器格式的包装器中，默认的容器格式为libcontainer docker产品 docker engine：docker服务端引擎 docker compose：简单的多容器部署工具，通过简单的命令和配置，管理服务于某个应用的多个容器 docker desktop：适用于Mac或Windows环境的易于安装的应用程序，可让您构建和共享容器化的应用程序和微服务； docker hub：公共镜像仓库 过时的工具集 machine：将docker安装在指定主机，比如虚拟机、本地、远端云主机 kitematic：桌面版的docker客户端 toolbox：将docker安装在mac和windows下的传统方式，安装包含如下 docker machine docker engine【docker command】 docker compose kitematic shell command-line Oracle VirtualBox swarm：docker默认支持的容器编排工具 docker安装与配置软件安装 官方(较慢) 阿里云镜像 engine配置 /etc/docker/daemon.json 1234567891011&#123; &quot;registry-mirrors&quot;: [&quot;https://2x97hcl1.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;reg.cnabke.com&quot;], &quot;data-root&quot;: &quot;/data/docker-data&quot;, &quot;bridge&quot;: &quot;bridge0&quot;, &quot;storage-driver&quot;: &quot;devicemapper&quot;, &quot;debug&quot;: true, &quot;storage-opts&quot; : [ &quot;dm.basesize=5G&quot; ]&#125; registry-mirrors：公有registry或加速器地址 insecure-registries：私有registry地址 data-root：容器、镜像等资源的存储位置 bridge：设置docker容器的默认网络地址 绑定网络地址(docker engine启动参数)：–bip 172.18.0.1 绑定网桥(docker engine启动参数)：-b, –bridge bridage_name storage-driver：容器存储驱动 storage-opts：存储驱动的选项 dm.basesize=5G：限制容器磁盘的最大容量 常见问题问题1 现象：通过路由实现跨主机docker容器互联，如果ping对端容器出现：Dest Unreachable, Unknown Code: 10或Destination Host Prohibited 解决：则是由于对端宿主机开启防火墙或iptables原因导致 问题2 现象：docker容器网络不通 解决 确定net.ipv4.conf.all.forwarding=1 重启docker服务【单独重启即可】 问题3 现象：禁止普通用户使用docker命令 1Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/images/json: dial unix /var/run/docker.sock: connect: permission denied 解决： 将当前用户加入docker组中：gpasswd -a python docker 重启docker进程：systemctl restart docker 重新登录服务器终端 运维管理图形化 使用软件：portainer 启动：docker run -d -p 9000:9000 --restart=always -v /var/run/docker.sock:/var/run/docker.sock --name portainer portainer/portainer web访问：http://ip:9000 数据采集 使用软件：cadvisor 服务启动1234567891011docker run \ --volume=/:/rootfs:ro \ --volume=/var/run:/var/run:ro \ --volume=/sys:/sys:ro \ --volume=/var/lib/docker/:/var/lib/docker:ro \ --volume=/dev/disk/:/dev/disk:ro \ --publish=8080:8080 \ --detach=true \ --name=cadvisor \ --device=/dev/kmsg \ google/cadvisor:latest 监控报警 使用软件：prometheus 、github地址 服务启动：docker run --name prometheus -d -p 9090:9090 prom/prometheus 添加cadvisor数据【重启prometheus】：/etc/prometheus/prometheus.yml1234567- job_name: &apos;cadvisor&apos; # metrics_path defaults to &apos;/metrics&apos; # scheme defaults to &apos;http&apos;. static_configs: - targets: [&apos;172.17.8.51:8080&apos;,&apos;172.17.8.52:8080&apos;] 度量分析和可视化系统 使用软件：grafana 服务启动：docker run -d -p 3000:3000 --name grafana grafana/grafana 添加数据源-prometheus 添加docker监控模板【ID：193】]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机管理-vagrant]]></title>
    <url>%2F2019%2F11%2F18%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%AE%A1%E7%90%86-vagrant%2F</url>
    <content type="text"><![CDATA[简介 vagrant是一个命令行下的虚拟机管理程序，默认使用virtualbox(内置于vagrant)作为后台虚拟化技术，但也可以使用其他虚拟化技术（比如VirtualBox、Docker、Vmware、Hyper-V等） 软件安装 vagrant下载与安装 VirtualBox下载与安装 存储位置设置 box镜像位置(vagrant管理)：设置变量VAGRANT_HOME 虚拟机位置(virtualbox管理)：vboxmanage setproperty machinefolder “D:\virtualbox\vbox_home” 使用步骤 添加box 建立目录并进入：mkdir test &amp;&amp; cd test 创建Vagrantfile：vagant init box_name 配置Vagrantfile 启动虚拟机：vagrant up 进入虚拟机：vagrant ssh box管理 作用：作为运行中虚拟机的基础镜像（类似docker的镜像） box镜像下载 ubuntu系列下载 centos系列下载 命令： 添加box：vagrant box add 【box_name local.box】、URL、username/box 可以使用本地box文件【local.box】 可以指定远程的下载地址【URL】 可以指定vagrantcloud上的box【username/box】 查看box列表：vagrant box list 删除box：vagrant box remove box_name 虚拟机管理 vagrant up：启动虚拟机 如果本地没有box，则从远程下载box镜像 启动后，默认将宿主机Vagrantfile所在目录映射到/vagrant vagrant ssh：登录虚拟机 vagrant halt：关闭虚拟机 vagrant status：查看虚拟机状态 vagrant destroy：销毁虚拟机 vagrant package：打包运行中的虚拟机到一个box vagrant reload：以新的配置文件重启虚拟机 vagrant resume：恢复一个挂起的虚拟机【vagrant up也可以恢复一个挂起的虚拟机】 vagrant suspend：挂起一个虚拟机 vagrant validate：检测Vagrantfile语法 vagrant snapshot：快照管理 list：显示快照列表 save [vm_name] snapshot_name：保存快照 restore [vm_name] snapshot_name：恢复快照 delete [vm_name] snapshot_name：删除快照 插件管理-scp 查看已安装插件列表：vagrant plugin list 安装插件(scp)：vagrant plugin install vagrant-scp scp命令使用 vagrant scp ..\docker-k8s-devops node1:~/docker-k8s-devops 注解：vagrant scp 源文件或目录名 虚拟机名称(Vagrantfile包含多机时):目标文件或目录名 注意事项： windows下不支持将跨盘符的文件或目录复制到虚拟机 不在当前目录进行复制操作时，需要指定复制的目标文件或目录名（不指定时，复制的目标文件或目录名会包含源路径） Vagrantfile网络设置 端口转发（宿主机4567映射虚拟机80）：config.vm.network :forwarded_port, guest: 80, host: 4567 设置公网ip(与宿主机同一个网络)：config.vm.network :public_network, ip: “10.150.20.180” 目录映射 设置：config.vm.synced_folder “src/“, “/srv/website”【src为宿主机目录，website为虚拟机目录】 虚拟化后台providercpu和内存设置123config.vm.provider :virtualbox do |vb| vb.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, &quot;1024&quot;, &quot;--cpus&quot;, &quot;4&quot;]end 多机设置可以在一个Vagrantfile中配置多个虚拟机12345678910111213141516config.vm.define &quot;web&quot;, primary: true do |web| #设置此机为默认主机 web.vm.box = &quot;ubuntu&quot; web.vm.provision :shell, inline: &quot;echo web&quot; web.vm.provider &quot;virtualbox&quot; do |vb| vb.memory = &quot;1024&quot; vb.cpus = &quot;1&quot; endendconfig.vm.define &quot;db&quot;, autostart: false do |db| #设置此机默认不启动 db.vm.box = &quot;ubuntu&quot; db.vm.provision :shell, inline: &quot;echo db&quot; db.vm.provider &quot;virtualbox&quot; do |vb| vb.memory = &quot;512&quot; vb.cpus = &quot;1&quot; endend 使用docker作为虚拟化后台 Dockerfile 1234567891011FROM ubuntu:14.04COPY sources.list /etc/apt/sources.listRUN apt-get updateRUN apt-get install -y openjdk-7-jdk git wgetRUN ln -fs /usr/lib/jvm/java-7-openjdk-amd64/jre/bin/java /etc/alternatives/javaRUN mkdir -p /usr/local/vertx &amp;&amp; cd /usr/local/vertx &amp;&amp; \wget http://dl.bintray.com/vertx/downloads/vert.x-2.1.2.tar.gz -qO -|tar -xzENV PATH /usr/local/vertx/vert.x-2.1.2/bin:$PATHRUN mkdir -p /usr/local/srcWORKDIR /usr/local/srcCMD [&quot;bash&quot;] Vagrantfile 1234567891011121314ENV[&apos;VAGRANT_DEFAULT_PROVIDER&apos;] = &apos;docker&apos;Vagrant.configure(&apos;2&apos;) do |config| config.vm.define &quot;vertxdev&quot; do |a| a.vm.provider &quot;docker&quot; do |d| d.build_dir = &quot;.&quot; d.build_args = [&apos;-t=vertxdev&apos;] d.ports = [&quot;8080:8080&quot;] d.name = &quot;vertxdev&quot; d.remains_running = true d.cmd = [&quot;vertx&quot;, &quot;run&quot;, &quot;vertx-examples/src/raw/java/httphelloworld/HelloWorldServer.java&quot;] d.volumes = [&quot;/home/show/docker/vertx:/usr/local/src&quot;] end endend 构建镜像：vagrant docker-run vertxdev – git clone https://github.com/vert-x/vertx-examples.git 启动虚拟机：vagrant up 查看日志：vagrant docker-logs 初始化工具Provision 作用：provision可以看作初始化系统的工具 运行： 在第一次启动(vagrant up)时自动执行 在vm运行时使用vagrant provision执行 重启时使用vagrant reload –provision 执行 使用： 使用shell 123config.vm.provision &quot;shell&quot;, inline: &quot;route add default gw 10.10.10.254&quot;config.vm.provision &quot;shell&quot;, inline: &quot;route del default gw 10.0.2.2&quot;config.vm.provision &quot;shell&quot;, path: &quot;script.sh&quot; 使用ansible 1234567config.vm.provision :ansible do |ansible| ansible.host_key_checking = false ansible.playbook = &quot;ansible/playbook.yml&quot; ansible.inventory_path= &quot;ansible/hosts&quot; ansible.sudo = true ansible.verbose = &apos;vvv&apos;end 磁盘管理磁盘扩容 进入VirtualBox\ VMs下的虚拟机目录 克隆vmdk类型磁盘为vdi类型[因为其可调整大小]vboxmanage clonehd box-disk1.vmdk clone-disk1.vdi --format vdi 磁盘扩容[以Mb为单位]vboxmanage modifyhd clone-disk1.vdi --resize 1048576 将调整的磁盘绑定在控制器上 1vboxmanage storageattach mg-s1_default_1414060662361_97909 --storagectl &quot;SATA Controller&quot; --port 0 --device 0 --type hdd --medium clone-disk1.vdi 虚拟机磁盘控制器查看:vboxmanage showvminfo mg-s1_default_1414060662361_97909 |grep &quot;Storage&quot; 增加磁盘虚拟机必须先存在,后通过更改Vagrantfile配置增加磁盘Vagrantfile配置: 1234config.vm.provider &quot;virtualbox&quot; do |vb| vb.customize [&quot;createhd&quot;, &quot;--filename&quot;, &quot;vd1.vdi&quot;, &quot;--size&quot;, &quot;20480&quot;] vb.customize [&quot;storageattach&quot;, &quot;test&quot;, &quot;--storagectl&quot;, &quot;SATA Controller&quot;, &quot;--port&quot;, &quot;1&quot;, &quot;--type&quot;, &quot;hdd&quot;, &quot;--medium&quot;, &quot;vd1.vdi&quot;]end 问题汇总win10启动错误 现象 12Stderr: VBoxManage.exe: error: Call to WHvSetupPartition failed: ERROR_SUCCEVBoxManage.exe: error: Details: code E_FAIL (0x80004005), component ConsoleWrap, interface IConsole 解决：关闭windows系统的虚拟化相关程序【程序和功能-》启动或关闭windows功能】，如：containers、hyper-v、windows沙盒、虚拟机平台 虚拟机无法挂载文件系统 错误 1234Failed to mount folders in Linux guest. This is usually because the &quot;vboxsf&quot; file system is not available. Please verify that the guest additions are properly installed in the guest and can work properly. The command attempted was: mount -t vboxsf -o uid=id -u vagrant,gid=getent group vagrant | cut -d: -f3 vagrant /vagrant mount -t vboxsf -o uid=id -u vagrant,gid=id -g vagrant vagrant /vagrant The error output from the last command was: stdin: is not a tty /sbin/mount.vboxsf: mounting failed with the error: No such device 解决方案 虚拟机安装软件：sudo apt-get install virtualbox-guest-utils 重启虚拟机：vagrant reload 虚拟机连接超时 错误 1default: Error: Connection timeout. Retrying... 解决 12vboxmanage list runningvmsvboxmanage controlvm new_3_default_1446007372853_19687 keyboardputscancode 1c 参考 linux下用vmware-mount挂载vmdk虚拟硬盘分区 如何访问vmdk磁盘上的lvm分区]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>vagrant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程基础]]></title>
    <url>%2F2019%2F11%2F12%2F%E9%80%9A%E7%94%A8%E6%8A%80%E8%83%BD%2F%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[同步与异步 同步和异步的区别就在于是否等待IO执行的结果 好比你去麦当劳餐厅点餐，你说“来个汉堡”，服务员告诉你，对不起汉堡要现做，需要等待5分钟，于是你就站在收银台前等了5分钟，拿着汉堡取逛商场，这是同步IO 你说“来个汉堡”，服务员告诉你，汉堡需要等待5分钟，你可以先去逛商场，等做好了，我们再通知你，这样你可以立即去干别的事（逛商场），这就是异步IO 很明显，使用异步IO来编写程序性能会远远高于同步IO，但是异步IO的缺点是编程模型复杂。想想看，你得知道什么时候通知你“汉堡做好了”，而通知你的方法也各不相同。如果是服务员跑过来找到你，这是回调模式，如果服务员发短信通知你，你就得不停地检查手机，这是轮询模式。总之，异步IO的复杂度远远高于同步IO。 队列与堆栈 堆栈：后进先出 队列：先进先出 动态语言 变量本身类型不固定的语言称之为动态语言 静态语言在定义变量时在定义变量时必须指定变量类型，如果赋值的时候类型不匹配就会报错 微服务服务特点 先天分布式【每个服务都有多个实例进行负载均衡】 无状态 服务状态 http://kyfxbl.iteye.com/blog/1831869 有状态【stateful】:对单次请求的处理依赖保存的数据【比如商城购物，放入购物车、确认订单、支付等步骤需要session来实现有状态的服务】；容易实现事务；但不利于水平扩展。 无状态【stateless】:对单次请求的处理不依赖其他请求；容易水平扩展；为了实现事务机制，需要额外的动作【隐藏表单、sessionstorage、cookie】剥离session来实现服务从有状态到无状态转变。]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker容器和镜像]]></title>
    <url>%2F2019%2F11%2F11%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fdocker%2Fdocker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[容器运行(run)范例docker run -idt -v /home/Logs/:/root/Logs:ro -m 100m –memory-swap=100m –cpus 0.5 -p 10086:22 sshd 运行参数 -t：分配一个伪终端tty -i：保持容器的标准输入一直打开，常与-t结合使用 -d：让容器以后台方式运行 -e key=value：在容器内设置环境变量 –name：给运行的容器绑定一个名称 -h：配置容器主机名 –rm：容器存在就删除【运行一次性容器，运行后立即删除】 -v ：映射宿主机目录或数据卷到容器 -m 100m：设置容器内存为100m –memory-swap=100m：设置容器内存和swap总和是100m –oom-kill-disable：关闭系统oom，避免系统内存不足时杀死容器 –cpus 0.5：设置容器可以使用的cpu百分比（最大值为cpu的核心数，最小值为0.1，可以是小数） –cpu-shares int：设置多个容器使用cpu的相对权重 -p 10086:22（可多次使用）：映射宿主机端口10086到容器端口22 publish：将容器端口映射到宿主机【命令行参数-p或-P】 expose：曝露端口用于容器间的访问【Dockerfile文件中的关键字EXPOSE】 -P：将主机的49000~49900的端口随机映射到内部容器的开放端口 –link name:alias：链接容器【容器名称：别名】，这种链接关系可以在容器hosts文件看到 –network：容器链接到特定网桥 –restart：容器异常退出时的重启策略，默认no，可选【always|on-failure】 最佳实践 操作系统镜像，没有默认启动命令，需要设置-it及-d，保持容器运行 应用程序镜像，只需设置-d，就可保持容器运行 容器管理 start、stop、restart：启动、停止、重启一个容器 create、rm：创建、删除容器 container prune：移除所有停止的容器 logs [-f]：日志查看，-f相当于tailf效果 cp：在宿主机和容器直接复制文件或目录 exec：在容器中执行命令 进入bash环境：docker exec -it 5c8f798e206e /bin/bash 查看ip地址：docker exec -it flask ip a ps：查看运行中的容器 参数 -a：查看所有存在的容器 -q：只显示容器id -f：根据条件过滤容器 -l：最新创建的容器 批量操作范例：docker rm $(docker ps -qf “status=exited”) inspect：查看docker对象信息 stats：查看容器资源使用情况 top：查看容器进程列表 commit：将当前运行的容器制作为镜像【被称为黑箱镜像，由于不确定镜像的具体操作，不利于镜像的传播使用】 volume管理使用原因 docker存储引擎device mapper、aufs等实现的copy on write机制，在高频写操作下性能不高；使用volume，可以直接写磁盘 可以实现数据持久化 启动时需要初始化数据，例如配置文件 运行过程中产生的业务数据、日志 可以实现宿主机与容器、容器之间的数据共享 使用方式 映射宿主机目录到容器（bind Mounts） 作用：可以实现宿主机和容器相关目录内容的同步更新，方便开发环境的实时调试 范例：docker run -idt –name test1 -v ~/nginx:/webapps ubuntu /bin/bash 数据卷使用（data volume） 作用：此时建立的数据卷不随容器的销毁而消失 建立数据卷：docker volume create hello 查看数据卷列表：docker volume ls 使用数据卷(使用未创建的数据卷时docker会自动创建)：docker run -d -v hello:/world busybox ls /world 删除数据卷：docker volume rm hello 镜像管理 build：构建镜像 history：查看镜像制作历史(分层文件系统) inspect：查看docker对象信息 rmi：删除本地镜像 search：查询docker公共仓库中的镜像 pull：从registry获取镜像 push：推送镜像到镜像仓库 登录仓库：docker login --username=perfect_0426@qq.com registry.cn-hangzhou.aliyuncs.com 本地打包：docker build -t registry.cn-hangzhou.aliyuncs.com/simple00426/flask_test:latest . 推送镜像到仓库：docker push registry.cn-hangzhou.aliyuncs.com/simple00426/flask_test:latest tag：给镜像添加一个标签 image prune [-a]：移除没有标签的镜像、移除没有使用及没有标签的镜像(-a) images：查看本地镜像列表 根据label过滤：docker images -f &#39;label=maintainer=istyle.simple@gmail.com‘ 根据镜像名称过滤：docker images -f reference=&#39;p*/*:latest&#39;【用户/镜像:标签】 根据是否有tag过滤(删除不完整的image)：docker images -qf “dangling=true” 根据某个镜像的前后时间：docker images -qf “before=portainer/portainer” before：早于此镜像 since：此镜像之后 导出tar包 从容器导出tar包：docker export adb102099609 &gt; adb102099609.tar 从镜像导出tar包：docker save -o ubuntu-ruby.tar ubuntu:ruby 导入tar包创建镜像 load方式：docker load &lt; ubuntu-ruby.tar import方式：cat adb102099609.tar |sudo docker import - ubuntu:temp 镜像制作镜像分类 基础镜像，如centos、ubuntu 环境镜像，基于基础镜像构建，如java、php 项目镜像，基于环境镜像构建，是最终的交付物 Dockerfile指令 FROM image：使用的基础镜像 FROM scratch【scratch是一个基础的空镜像】 LABEL key=value：标签信息 maintainer=”istyle.simple@gmail.com“ version=”1.0” description=”This is simple” ENV key value：设置环境变量，它会被后续RUN命令使用，并在容器运行时保持 WORKDIR /path：为后续的RUN、CMD指定工作目录(建议使用绝对目录)，没有则创建 RUN command param1 param2：在创建镜像的过程中执行的命令 有shell、exec两种执行方式，示例为shell方式 Dockerfile中可以写多条RUN指令，但是为了避免一次RUN增加一层文件层，应当将多条命令合并到一行中执行 CMD command param1 param2：指定容器启动时执行的命令 有shell、exec两种执行方式，示例为shell方式 定义了多个命令时，只有最后一条被执行 如果docker run指定了其他命令，CMD命令被忽略 ENTRYPOINT [‘excutable’, ‘param1’, ‘param2’]：容器启动后运行的服务 有shell、exec两种执行方式，示例为exec方式 让容器以应用程序或者服务的形式运行，只可添加一条 此命令默认不被docker run提供命令的覆盖 ENTRYPOINT和CMD ENTRYPOINT和CMD都可以单独使用 ENTRYPOINT和CMD联合使用时 ENTRYPOINT提供可执行程序和默认参数 CMD提供可选参数 COPY src dest：复制本地主机的src到容器的dest， ADD src dest： add和copy功能类似(复制指定的src到容器的dest)，优先使用copy 额外功能：解压src到dest【但必须是gzip, bzip2 or xz格式的tar包】 其中src可以是Dockerfile所在目录的相对路径，也可以是一个url EXPOSE port：告诉宿主机容器暴露的端口 VOLUME [“/data”]：容器运行时，自动创建一个绑定到特定目录的数据卷 这是为了保证某些数据(比如mysql等数据库)不随容器销毁而丢失 可以通过run -v参数覆盖相关目录 ONBULID [instruction]：当所创建的镜像作为其他镜像的基础镜像时，所执行的命令 build构建镜像 范例：docker build -t=&quot;ubuntu:ruby&quot; . 参数： -t 仓库名:标签 -f 指定dockerfile文件名称，默认文件名称Dockerfile . 注明dockerfile的文件位置 Dockerfile最佳实践 减少镜像层：一次RUN指令形成新的一层，因此，多条shell命令要尽可能的写在一行； 使用&amp;&amp;连接多个命令 过长的行使用反斜线续行 优化镜像大小：一次RUN形成新的一层，如果没有字同一层删除，无论文件最后是否删除，都会带到下一层，所以要在每一层清理对应的残留数据，减小镜像大小 减少网络传输事件：使用软件包、maven仓库等 多阶段构建：代码编译、部署写在一个Dockerfile 选择尽可能小的基础镜像：如alpine Dockerfile范例1234567891011121314151617181920212223FROM ubuntu:14.04LABEL maintainer hejingqi@zj-inv.cnENV LANG C.UTF-8RUN echo &apos;deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse\n\truedeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse\n\truedeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse\n\truedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse\n\truedeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse\n\truedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse\n\truedeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse\n\truedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse\n&apos;\true&gt; /etc/apt/sources.list &amp;&amp; \truerm -rf /etc/apt/sources.list.d/* &amp;&amp; \trueapt-get update &amp;&amp; \trueapt-get install -y openssh-server vim iputils-ping net-tools lrzsz &amp;&amp; \truemkdir -p /var/run/sshd &amp;&amp; \truesed -i &apos;/^PermitRootLogin/s/without-password/yes/&apos; /etc/ssh/sshd_config &amp;&amp; \truesed -i &apos;/^#PasswordAuthentication/s/#//&apos; /etc/ssh/sshd_config &amp;&amp; \trueecho &quot;root:zjht4321&quot;|chpasswd &amp;&amp; \trueln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \truerm -rf /var/cache/apt/*EXPOSE 22CMD /usr/sbin/sshd -D 多阶段构建范例123456789101112131415161718192021# stage build# 使用as为多阶段构建中的某一阶段命名FROM maven:3.6.3-jdk-8 as buildRUN sed -i '/&lt;mirrors&gt;/a\ \&lt;mirror&gt; \n\ &lt;id&gt;nexus-aliyun&lt;/id&gt; \n\ &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; \n\ &lt;name&gt;Nexus aliyun&lt;/name&gt; \n\ &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;\n\&lt;/mirror&gt;' /usr/share/maven/conf/settings.xmlCOPY . /tomcat-java-demoWORKDIR /tomcat-java-demoRUN mvn clean package -Dmaven.test.skip=true# stage prodFROM tomcat:8.5.47 as prodRUN rm -rf /usr/local/tomcat/webapps/*# 从构建的某一阶段复制文件COPY --from=build /tomcat-java-demo/target/*.war /usr/local/tomcat/webapps/ROOT.warWORKDIR /usr/local/tomcat/binEXPOSE 8080CMD ["catalina.sh", "run"] 应用运行镜像内固定运行参数 Dockerfile 1234567FROM python:2.7LABEL maintainer=&quot;istyle.simple@gmail.com&quot;RUN pip install flaskCOPY app.py /app/WORKDIR /appEXPOSE 5000CMD [&quot;python&quot;, &quot;app.py&quot;] app.py 1234567from flask import Flaskapp = Flask(__name__)@app.route(&apos;/&apos;)def hello(): return &quot;hello docker&quot;if __name__ == &apos;__main__&apos;: app.run(host=&quot;0.0.0.0&quot;, port=5000) 容器运行时指定参数 Dockerfile 12345FROM ubuntu:xenialCOPY sources.list /etc/apt/sources.list RUN apt update &amp;&amp; apt install -y stressENTRYPOINT [&quot;/usr/bin/stress&quot;] #基础运行命令CMD [] #指定可添加参数 sources.list 123456789101112deb http://mirrors.aliyun.com/ubuntu/ xenial maindeb-src http://mirrors.aliyun.com/ubuntu/ xenial maindeb http://mirrors.aliyun.com/ubuntu/ xenial-updates maindeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates maindeb http://mirrors.aliyun.com/ubuntu/ xenial universedeb-src http://mirrors.aliyun.com/ubuntu/ xenial universedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb http://mirrors.aliyun.com/ubuntu/ xenial-security maindeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security maindeb http://mirrors.aliyun.com/ubuntu/ xenial-security universedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security universe 容器运行 前台：docker run -it ubuntu_stress:latest -m 1 –verbose -t 10s 后台：docker run -itd –name stress ubuntu_stress:latest -m 1 –verbose 公有仓库镜像自动化构建可选仓库 阿里云容器镜像服务 docker hub 自动化构建 将Dockerfile等文件放入代码库管理，比如：https://github.com/simple0426/tomcat-java-demo.git 在镜像仓库新建镜像，配置自动化构建关联到代码仓库(具体关联到Dockerfile所在目录) 只要Dockerfile所在仓库有代码变动，镜像仓库就会自动构建新的镜像]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>镜像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列RabbitMQ]]></title>
    <url>%2F2019%2F11%2F01%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97RabbitMQ%2F</url>
    <content type="text"><![CDATA[使用对比与python中的queue 线程queue：同一个进程下不同线程间的交互 进程Queue：父子进程交互，或同属于一个进程下的多个子进程间交互 消息中间件(rabbitmq)：不同程序间的交互 同类产品对比 RabbitMQ Mozilla出品，由高并发语言Erlang编写 基于AMQP协议实现 为了保证消息的可靠性，有消息确认机制、支持事务，不支持批量操作 Kafka linkedin开源的产品，目前归属apache基金会 追求吞吐量，内部采用消息的批量处理 数据的存储和获取是本地磁盘顺序批量操作 RocketMQ：阿里巴巴基于kafka，使用java重写的产品 基本概念 broker：简单来说就是消息队列服务器实体 Exchange：消息交换机，它指定消息按什么规则，路由到哪个队列；目前支持的规则类型 Direct：精确匹配，完全根据key进行消息投递 Topic：模式匹配，对key进行模式匹配后进行消息投递（符 号”#”匹配一个或多个词，符号”*“匹配正好一个词。例如”abc.#”匹配”abc.def.ghi”，”abc.*“只匹配”abc.def”） fanout：广播功能，不需要key，此时会把所有发送到该exchange的消息路由到与它绑定的Queue中 Queue：消息队列载体，每个消息都会被投入到一个或多个队列 Binding：绑定，它的作用就是把exchange和queue按照路由规则绑定起来 Routing Key：路由关键字，exchange根据这个关键字进行消息投递 vhost：虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离 producer：消息生产者，就是投递消息的程序 consumer：消息消费者，就是接受消息的程序 channel：消息通道，在客户端的每个连接里，都可以建立多个channel，每个channel代表一个会话任务 软件安装 ubuntu/centos仓库安装：install rabbitmq-server 自定义版本安装 安装erlang语言 下载指定格式rabbitmq-server软件包 配置管理基本设置 rabbitmqctl add_vhost celery 添加虚拟机 rabbitmqctl add_user ever01 Theistyle 添加用户 rabbitmqctl set_permissions -p celery ever01 &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 对虚拟机进行用户授权【后面三个”.*”代表ever01用户拥有对celery的配置、写、读全部权限】 rabbitmqctl list_queues –vhost celery：查看队列信息及数量 web界面管理 开启console：rabbitmq-plugins enable rabbitmq_management 建立管理用户：rabbitmqctl add_user full_access qaz123 管理用户设置权限：rabbitmqctl set_user_tags full_access administrator url访问：http://127.0.0.1:15672 持久化设置rabbitMQ支持消息持久化，持久化包含三个部分： exchange：声明时指定durable queue：声明时指定durable message：在投递时指定delivery_mode =》2（1是非持久化） 只有exchange和queue都是持久化的，那么他们的binding才是持久化的；如果两者之一不能持久化，就不允许建立绑定。 使用方式 客户端连接到消息队列服务器（vhost、账号、密码），打开一个channel 客户端声明一个exchange，并设置相关属性 客户端声明一个queue，并设置相关属性 客户端使用routing key，在exchange和queue之间建立绑定关系 客户端投递消息到exchange python客户端-pika 生产者producer 1234567891011121314151617181920212223242526272829303132333435363738394041424344import pika, sys# 建立链接auth = pika.credentials.PlainCredentials(&apos;ever01&apos;, &apos;Theistyle&apos;)conn_para = pika.ConnectionParameters( host=&apos;127.0.0.1&apos;, port=5672, virtual_host=&apos;celery&apos;, credentials=auth)conn = pika.BlockingConnection(parameters=conn_para)# 创建channelchannel = conn.channel()# direct模式# channel.exchange_declare( # 创建exchange# exchange=&apos;direct_log&apos;,# exchange_type=&apos;direct&apos;,# durable=True)# topic模式# channel.exchange_declare( # 创建exchange# exchange=&apos;topic_log&apos;,# exchange_type=&apos;topic&apos;,# durable=True)channel.exchange_declare( # 创建exchange exchange=&apos;fanout_log&apos;, exchange_type=&apos;fanout&apos;, durable=True)# 定义发送的key和内容keys = sys.argv[1] if len(sys.argv) &gt; 1 else &apos;anonymous.info&apos; # 定义keymessage = &apos;&apos;.join(sys.argv[2:]) or &apos;Hello World!&apos; # 定义message# 发布消息channel.basic_publish( # exchange=&apos;direct_log&apos;, # exchange=&apos;topic_log&apos;, exchange=&apos;fanout_log&apos;, routing_key=keys, body=message, properties=pika.BasicProperties(delivery_mode=2))print(&quot;[x] Sent %r:%r&quot; % (keys, message))conn.close() 消费者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import pika, sys# 建立链接auth = pika.credentials.PlainCredentials(&apos;ever01&apos;, &apos;Theistyle&apos;)conn_para = pika.ConnectionParameters( host=&apos;127.0.0.1&apos;, port=5672, virtual_host=&apos;celery&apos;, credentials=auth)conn = pika.BlockingConnection(parameters=conn_para)# 创建channelchannel = conn.channel()channel.queue_declare(queue=&apos;hello&apos;, durable=True) # 创建queue# direct模式# channel.exchange_declare( # 创建exchange# exchange=&apos;direct_log&apos;,# exchange_type=&apos;direct&apos;,# durable=True)# topic模式# channel.exchange_declare( # 创建exchange# exchange=&apos;topic_log&apos;,# exchange_type=&apos;topic&apos;,# durable=True)channel.exchange_declare( # 创建exchange exchange=&apos;fanout_log&apos;, exchange_type=&apos;fanout&apos;, durable=True)# 定义接收的key，并将queue和exchange绑定【建立通道接收消息】# key = sys.argv[1] # 命令行接收routing_key# if not key:# sys.stderr.write(&quot;Usage:%s key \n&quot; % sys.argv[0])# sys.exit(1)channel.queue_bind( # exchange=&apos;direct_log&apos;, # exchange=&apos;topic_log&apos;, exchange=&apos;fanout_log&apos;, queue=&apos;hello&apos;, # routing_key=key # fanout模式下无需绑定绑定key)# 消费消息def callback(ch, method, properties, body): # 消息的具体功能 print(&quot;[x] Received %r:%r&quot; % (method.routing_key, body))channel.basic_consume( queue=&apos;hello&apos;, on_message_callback=callback, auto_ack=True)print(&apos;[*] Waiting for logs.To exit press CTRL+C&apos;)channel.start_consuming() # 开启阻塞式消费，持续接收发布的消息 python客户端-celerycelery架构celery+rabbitmq+redis celery worker：任务执行单元【单独开启进程提供任务执行】 rabbitmq：消息中间件【传递消息和定义消息队列】 redis：存储worker执行结果 软件安装和配置 安装rabbitmq-server、redis-server 配置mq和redis 安装python模块celery、celery-with-redis 开启一个任务调度进程1234567from celery import Celeryapp = Celery(&apos;task01&apos;, backend=&apos;redis://127.0.0.1:6379/0&apos;, broker=&apos;amqp://ever01:Theistyle@127.0.0.1:5672/celery&apos;)@app.taskdef add(x,y): return x + y 开启任务：celery -A tasks worker -l info【-A 指定一个模块，即文件名】 客户端测试123456789from celery import Celeryfrom tasks import addimport timeresult = add.delay(4, 4)print(&quot;waiting result...&quot;)while not result.ready(): time.sleep(2)print(&quot;Result:&quot;, result.get()) 测试：python3 test.py 信息监控 查看celery worker输出 12[2019-11-01 18:15:07,708: INFO/MainProcess] Received task: tasks.add[05d41d34-9e5d-4e59-bb15-23ddc74f2e08] [2019-11-01 18:15:07,715: INFO/ForkPoolWorker-2] Task tasks.add[05d41d34-9e5d-4e59-bb15-23ddc74f2e08] succeeded in 0.00482514314353466s: 8 查看redis存储 123456127.0.0.1:6379&gt; keys *1) &quot;celery-task-meta-05d41d34-9e5d-4e59-bb15-23ddc74f2e08&quot;127.0.0.1:6379&gt; type celery-task-meta-05d41d34-9e5d-4e59-bb15-23ddc74f2e08string127.0.0.1:6379&gt; get celery-task-meta-05d41d34-9e5d-4e59-bb15-23ddc74f2e08&quot;&#123;\&quot;date_done\&quot;: \&quot;2019-11-01T10:15:07.710361\&quot;, \&quot;task_id\&quot;: \&quot;05d41d34-9e5d-4e59-bb15-23ddc74f2e08\&quot;, \&quot;status\&quot;: \&quot;SUCCESS\&quot;, \&quot;result\&quot;: 8, \&quot;children\&quot;: [], \&quot;traceback\&quot;: null&#125;&quot;]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
        <tag>celery</tag>
        <tag>pika</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis数据操作]]></title>
    <url>%2F2019%2F10%2F30%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E7%BC%93%E5%AD%98%E4%B8%8Enosql%2Fredis%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[数据类型及抽象key定义 不建议使用非常长的key，因为在查找比较时需要消耗更多的资源；如果确实需要存储较长的key，可以存储key的hash值 也不建议使用较短的key，较短的key可读写太差 key定义时的格式要统一，比如使用冒号、点、横杠等 key的最大长度512MB 字符串 字符串是redis key最简单的数据类型 字符串类型在抓取html碎片和页面时非常有用 字符串中可以包含各种数据（包含二进制数据），所以可以在值中存储jpeg等的图片内容 字符串长度最大值512MB key过期设置 支持秒和毫秒级别设置 过期的设置以日期形式保存在磁盘或被复制 服务停止，时间也会被计算 独立操作命令 expire key seconds：设置key过期 pexpire key milliseconds：设置key过期 persist key：取消过期设置 ttl：查看过期时间（秒） pttl：查看过期时间（毫秒） 列表 redis列表通过链接列表实现 列表可以实现快速的插入数据，而有序集合(sorted sets)则可以实现快速的访问集合中间位置的元素 使用ltrim可以始终只保留一定数量的元素：ltrim mylist 0 999 列表的阻塞操作（blpop/brpop）可以实现队列功能 阻塞命令(brpop/blpop)一次可以操作多个列表、阻塞时间可以设置为0(永不超时) 阻塞命令返回一个两元素的数组（列表名、元素） 一般用法 在社交网络展示最新发布的文章 使用lpush将最新文章的id放入列表 使用lrange 0 9展示最新发布的10篇文章 进程间的通信（生产者-消费者模型） 数据类型字符串 set key value：设置key ex seconds：设置键的过期秒数 px milliseconds：设置键的过期毫秒数 nx：键不存在才能对键操作 xx：键存在才能对键操作 mset key value key1 value1：一次设置多个key mget key key1：一次获取多个值 get key：获取key的值 getset key：设置key并返回key的旧值 incr counter：计数器加1 decr counter：计数器减1 incrby counter n：计数器加n decrby counter n：计数器减n getrange key start end：获取子串 setrange key index value：从索引处开始替换子串 列表 lpush/rpush key value：从列表左或右侧向列表添加值 lrange key start end：获取列表从start到end的值 索引可以是负值，比如-1表示最后一个元素 索引从0开始，0表示第一个元素 llen key：返回列表长度 ltrim key start end：只保留start到end的值 lpop/rpop key：弹出列表左侧或右侧的元素 blpop key key1… timeout：阻塞式弹出列表的值 集合特点 成员间无固定顺序 成员不重复 支持交集、并集、差集 成员最大数量2^32-1（512MB） 命令 sadd key value：集合添加成员 smembers key：查看集合成员 sismember key member：查看元素是否是集合成员 scard key：获取集合成员数量 sinter key key1：查看集合间的交集 sunionstore des_key key key1：获取集合间的并集并存储在新的key中 spop key：弹出集合中的成员 srandmember key：获取集合中随机一个成员 有序集合特点 与集合对比，有序集合的每个成员都关联一个分数值，这个分数值用于排序 可以通过分数、或索引获取一个范围内的成员 命令 特殊定义：【-inf：负无穷】【inf：正无穷】 zadd key socre member：向有序集合key中添加分数为socre的成员member zrank key member：获取成员索引位置 zrevrank key member：成员的倒序 zrange key start end [withscores]：根据索引区间获取成员 zrevrange key start end：反向排序 zrangebyscore key min max：根据socre区间获取成员 zremrangebyscore key start end：根据score删除成员 zrangebylex key min mex：根据key的首字符区间获取成员 (表示开区间、[表示闭区间 范例：ZRANGEBYLEX hackers [B [P【key首字母在B和P之间的key】 哈希/字典 hmset key field value [field value …]：一次设置字典的多个字段 hset key field value：一次设置字典的一个字段 hgetall key：一次返回字典的所有字段及其值 hget key field：一次返回字典中某个字段的值 hmget key field1 field2：一次返回字典中多个字段的值 hincrby key field n：对字典中的某个字段自增n 位图 setbit key offset value：设置offset处为0或1 getbit key offset：获取offset处的值 bitop operation destkey key：在字符串之间进行位操作（AND, OR, XOR and NOT.） bicount key：统计键中设置为1的位的数量 bitpos key bit start end：返回键中1或0第一次出现的索引位置 HyperLogLog 用途：主要用于唯一性事务的概率统计 语法： pfadd key element element1：添加元素 pfcount key key1:唯一性统计 应用范例：https://www.cnblogs.com/ysuzhaixuefei/p/4052110.html 管理命令 type key：判断键的数据类型 exists key：判断键是否存在 del key：删除特定key keys foo*：返回特定匹配的key列表 flushdb：删除当前库的所有key flushall：删除所有数据库的key redis命令参考]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>数据类型</tag>
        <tag>操作命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群]]></title>
    <url>%2F2019%2F10%2F26%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E7%BC%93%E5%AD%98%E4%B8%8Enosql%2Fredis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[集群介绍 redis3.0之后提供集群模式 集群功能 自动将数据拆分到多个节点 在一部分节点不可用时，依然可以进行数据操作 集群端口 服务端口(client port，如6379)：集群的其他节点(key迁移)、客户端都可以访问到 集群总线端口(client port+10000)：用于集群节点间的通信，如：失败检测、配置更新、故障切换授权等 集群与docker 当前redis集群不支持nat网络环境和ip、port都重新映射的通用环境 为了使docker兼容redis集群，docker应当使用host网络模式（–net=host） 数据分片： 集群共有16384个hash槽，分布在集群的所有节点上 每个key在逻辑上都是hash槽的一部分 在给定一个key时，通过对key的CRC16相对于16384取模来确定key要存储的hash槽 只需来回迁移hash槽到不同节点，就可以在线添加或删除节点 集群支持在一个命令（整个事务、lua脚本执行）执行多键操作，只需要所有的键都在同一个hash槽中 用户可以使用hash标签将多个键存储在同一个hash槽中 支持主从复制功能 数据一致性保证 redis集群不保证强的数据一致性：比如在数据刷新到磁盘前宕机、数据复制到从机前宕机等都会丢失部分数据 可以通过如下措施增加一致性 变更数据刷新策略（fsync），即数据写入磁盘后才向客户端返回确认信息，但这回造成性能损失 使用WAIT命令后，启用同步复制功能 网络隔离也会造成数据丢失 产生网络隔离后，客户端Z1和至少一个主节点B位于其中一个网络，其他节点（A、A1、B1、C、C1）位于另一个网络 在节点超时前(cluster-node-timeout)，Z1依然可以向B发送写操作； 节点超时后，不能和其他主节点通信的主节点(B)会被认为是失败节点，不再接收写操作，集群也会将失败节点的从节点(B1)提升为主节点 由于B在不能和从节点通信时依然接收写操作，当从节点B1提升为主节点时会丢失部分数据 集群配置参数 cluster-enabled：是否开启集群模式，集群模式和独立模式不能互相切换 cluster-config-file：集群状态文件，用户不可编辑 cluster-node-timeout：集群超时时间，超时则失败主停止写，从机执行故障切换 cluster-slave-validity-factor：【超时时间*衡量因子】之后从机执行故障切换，为了高可用，可以设置为0【从机一直尝试接管主机】 cluster-migration-barrier：主机应当保留的从机个数，超过的从机可以迁移到孤立主机上 cluster-require-full-coverage：数据不全时是否对外提供查询服务 创建集群内置脚本方式utils/create-cluster/create-cluster start/create/stop 手动创建方式 创建并启动多个redis实例(包含集群参数) 创建集群 版本5之后已在redis-cli命令中内置集群功能，可以实现：创建集群、集群分片检查和重新分片等功能 范例：redis-cli –cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 –cluster-replicas 1 解释：使用create创建集群，并保证每个主一个从节点 版本4和3需要使用ruby工具：redis-trib.rb 安装 redis gem： apt-get install rubygems gem install redis 使用ruby工具创建集群 ./redis-trib.rb create –replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 手动创建范例 解压redis源码，并将src目录绝对路径添加到PATH变量中 安装redis gem 执行创建脚本creat.sh 1234567891011121314151617181920# create.shresult=&quot;redis-trib.rb create --replicas 1 &quot;for port in `seq 7000 7005`do mkdir $&#123;HOME&#125;/$&#123;port&#125; cp redis.conf $&#123;HOME&#125;/$&#123;port&#125;/$&#123;port&#125;.conf sed -i &apos;s/7000/&apos;$port&apos;/g&apos; $&#123;HOME&#125;/$&#123;port&#125;/$&#123;port&#125;.conf sed -i &apos;s%/home/redis%&apos;$&#123;HOME&#125;&apos;%g&apos; $&#123;HOME&#125;/$&#123;port&#125;/$&#123;port&#125;.conf echo $port redis-server $&#123;HOME&#125;/$&#123;port&#125;/$&#123;port&#125;.conf ip_port=&quot;127.0.0.1:&quot;$port result=$&#123;result&#125;\ $&#123;ip_port&#125;doneecho &quot;yes&quot; |$result# stop.shfor port in `seq 7000 7005`do cat $&#123;HOME&#125;/$&#123;port&#125;/$&#123;port&#125;.pid |xargs -i kill &#123;&#125;done 客户端支持 程序语言支持：https://redis.io/topics/cluster-tutorial#playing-with-the-cluster redis-cli支持(-c参数)：例如：redis-cli -c -p 7000 集群管理 hash槽迁移： 命令行(redis-trib)：redis-trib.rb reshard –from source_id –to dest_id –slots slot_num –yes ip:port 参数解释 连接的节点ip和端口需要放在最后 源和目标节点id可以从【cluster nodes】中获取，源节点可以有多个(逗号分隔，all表示其他所有节点) –from/–to：迁移的源和目标节点 –slots：迁移的槽数量 –yes：免交互确认 手动故障切换(主从状态切换)：cluster failover（在从节点执行） 添加主节点： 命令行方式：redis-trib add-node new_host:new_port existing_host:existing_port 交互式命令行：cluster meet ip port 添加从节点： 命令行方式：redis-trib add-node –slave –master-id new_host:new_port existing_host:existing_port【不指定master-id时，默认将其随机添加到具有最少从节点的主节点】 交互式命令行：cluster replicate master-id 此种模式首先添加一个没有数据的空节点，然后连接到此节点后使用上述复制命令将其添加为从节点 此命令也可以用于改变从机的主节点 删除节点： 删除方式： 命令行：redis-trib del-node host:port node_id 交互式命令行：cluster forget node_id 主从处理： 从节点可以直接删除 主节点没有数据时才可以删除 可用性预处理为了提高系统可用性，事先在每个实体机上预留1~2个多余的从节点作为备份，当某个主节点或从节点挂掉时，多余的从节点可以自动的迁移(cluster-migration-barrier)过来以达到集群所有主节点至少有一个从节点。 少数主或从节点故障 预处理：配置备份飘逸参数cluster-migration-barrier 主节点故障：客户端写操作会报错；不会形成备份飘逸；8、9秒后，从节点提升为主，客户端可以进行写操作。 从节点故障：客户端无影响；会形成备份飘逸 少数主和它的从节点同时挂掉 预处理：配置cluster-require-full-coverage为no，集群出故障时可读不可写 多数主节点同时宕机集群处于不可用状态 数据迁移 redis支持迁移到集群的情况 没有使用多键操作、事务、包含多键的lua脚本 使用hash标签的多键、事务、包含多键的lua脚本 手动迁移步骤 停止客户端连接。当前版本不能进行在线迁移 产生aof文件【BGREWRITEAOF】 拷贝aof文件到其他位置，停止旧实例 创建包含N个主和0个从的集群【从机稍后添加，并确保使用aof做持久化化】 停止所有集群节点，将迁移前产生的aof文件替换到集群中 重启集群 使用redis-trib fix让键值对自动迁移 使用redis-trib check查看迁移结果 重启客户端，连接到集群任意节点 向当前集群添加从节点 5.0版本内置迁移命令：redis-cli –cluster import 支持将一个运行中的实例数据迁移到一个预先搭建好的集群中（同时会删除源实例中的数据） 当2.8版本作为源实例时，由于没有实现迁移连接缓存，迁移过程会很慢，解决方案是使用3.x版本实例加载源数据 故障处理 交互式迁移报错 报错：[ERR] Calling MIGRATE: ERR Syntax error, try CLIENT (LIST | KILL | GETNAME | SETNAME | PAUSE | REPLY) 原因：官方bug 解决：安装低版本gem redis：gem install redis -v 3.3.5 节点状态不一致 现象 连接不同的节点，获取cluster nodes输出不一致 使用./redis-trib [check|fix]命令得到如下报错：【 Nodes don’t agree about configuration】，并显示个别slot处于importing状态 由于状态不一致，所以不能进行slot迁移【不能使用reshard命令】 解决：由于只是个别节点状态不一致，只需处理个别节点即可 步骤 手动设置异常节点的slot：for i in {5461..10922};do redis-cli -h 172.29.88.117 -p 7004 -c cluster setslot $i node ca4757c010e6b6c028006bb4b8c1cd0852ab3033;done 5461…10922为状态异常的slot -h/-p 连接异常节点 ca4757c0… 为这些slot的正确节点id【根绝大多数节点返回获得】 修复异常节点状态（循环：每次修复一个slot）：for i in {5461..10922};do ./redis-trib.rb fix 172.29.88.117:7004;done]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis简介与管理]]></title>
    <url>%2F2019%2F10%2F25%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E7%BC%93%E5%AD%98%E4%B8%8Enosql%2Fredis%E7%AE%80%E4%BB%8B%E4%B8%8E%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[简介 redis是一个开源的、基于内存的数据结构存储，但也可以根据需要开启持久化存储（rdb、aof） 可以被当做数据库、缓存、消息代理使用 使用C语言编写，不需要外部依赖，官方默认支持linux系统，也可以使用在windows上运行 microsoft实现的3.0版本 第三方实现的4/5版本 内置功能 主从异步复制 lua脚本 数据过期策略：LRU 事务 数据持久化策略：rdb、aof 高可用：Redis Sentinel 自动分区：redis Cluster 发布、订阅、取消订阅（消息代理）：Pub/Sub 数据类型 strings：二进制安全的字符串 hash：是由字段和其值构成的映射，字段和值都是字符串；和ruby、pyhon中的字典类似 lists：根据插入顺序排序的字符串元素的集合 sets：由独一无二的、未排序的元素构成的集合 sorted sets：排序的集合，每个字符串成员都关联一个浮点数值用于排序 bitmaps：位图，可以处理字符串中的每一位(设置、清除)，找到第一个设置或未设置的位 hyperloglogs：这是一个概率数据结构，用于估计集合的基数 streams geospatial indexes 支持的原子操作 字符串追加 增加hash中的值 向列表中添加元素 计算集合的交集、并集、差集 获取排序集合中最高排名的成员 下载与安装 下载：http://download.redis.io/releases/redis-4.0.14.tar.gz 安装 1234$ wget http://download.redis.io/releases/redis-5.0.5.tar.gz$ tar xzf redis-5.0.5.tar.gz$ cd redis-5.0.5$ make 复制操作同异步 异步：redis复制是异步的，主实时发送操作的命令到从机 部分同步：主从复制出现异常，从机可以通过部分同步功能(repl-backlog-size)与主机重新建立复制关系 可以通过rdb文件(非aof)实现部分同步功能（例如从机重启或升级时，可以SHUTDOWN(save &amp; quit)保存数据） 同步：使用WAIT命令可以实现同步复制 主从架构 主可以有多个从(从机只读)，这样可以分担主的读压力，同时增加数据安全性 从也可以有从，即构成级联架构，此时sub-slave从master接收复制流 主从结构 为了安全性，主应当开启数据持久化（rdb、aof），从机也可以开启持久化（rdb） 如果主没有开启持久化，而从开启了持久化时：当主机重启，由于内存数据丢失，重启后复制流也会删除从机的数据 非阻塞式 在master端，复制是非阻塞的 在slave端，大部分情况下，复制也是非阻塞的； 在同步初始化阶段，可以配置允许从机向客户端提供旧的数据(slave-serve-stale-data )以避免阻塞 在同步后，依然会有一小段阻塞时间（4.0之前删除数据、加载新的数据都会阻塞；4.0之后会用单独的线程执行删除操作，但是加载数据依然会阻塞） 从机过期key处理 不依赖于主从间的同步时钟 从主上接收处理过期的命令(del)，然后本地执行此命令 为了保持数据一致性，对于应当删除而没有删除的key，从机返回错误 在lua脚本执行期间，主的数据会被冻结，不会产生过期删除操作 复制选项 无盘复制：repl-diskless-sync 默认设置下，为了实现复制功能，即使没有开启持久化设置，也会写rdb文件，除非使用无盘复制功能（repl-diskless-sync） 只读设置：slave-read-only 如果从机可写，在4.0之前会存在内存泄漏（key过期，客户端不可见，但依然在内存中） 4.0之后的版本，当数据库序列小于63时，不会出现内存泄漏 4.0之后的版本，从机只是本地可写，即不会将本地变更传递给它的从机（sub-slave从master接收复制流） 连接设置： slaveof 192.168.1.1 6379 masterauth password 设置少于指定数量主机或大于某个延迟时停止写操作 min-slaves-to-write 3 min-slaves-max-lag 10 nat和端口转发环境下的配置（docker） slave-announce-ip slave-announce-port 状态查看 INFO replication ROLE 服务端管理配置和优化 开启系统swap 内存调优： 允许过量使用内存：sysctl vm.overcommit_memory=1 关闭影响内存使用和延迟的因素：echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled 内存大小设置： maxmemory限制的内存：数据、数据外的开销、碎片开销、rdb保存和aof重写占用的内存（最多会占用常规使用量的2倍） 复制缓冲区（repl-backlog-size）：确保从机可以更容易的重连（支持部分同步） 当使用守护进程工具时(如supervisor、systemd)，设置daemonize为no 基于安全性，设置listen和requirepass参数 有用的工具 延迟诊断：latency doctor【需要设置latency-monitor-threshold】 内存诊断：memory doctor 升级或重启主从模式 把要操作的实例作为从机与主机同步 检测同步日志，确保初始化同步完成 使用INFO命令，确保主从有相同数量的key 从机开启写权限：CONFIG SET slave-read-only no 停止主机写操作：CLIENT PAUSE 通过监控命令【redis-cli monitor】确保主不再接收到任何数据操作命令，此时： 从提升为主：SLAVEOF NO ONE 旧主机关闭 高可用或集群模式 常规流程：升级从机，执行主从手动切换 注意：由于4.0版本在集群总线协议级别与3.2版本不兼容，此时集群需要整体重启；5.0版本集群总线向后兼容4.0版本 客户端管理参数设置 最大连接数：maxclients；与os最大文件描述符相关，同时需要保留部分描述符用于redis内部使用 redis可以设置最大文件描述符时，所需的最大文件描述符为：fd=maxclients+32(内部使用) redis不可设置最大文件描述符时(即maxclients大于最大文件描述符)，maxclients=fd-32 输出缓冲区限制： client-output-buffer-limit normal 0 0 0 client-output-buffer-limit slave 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 查询缓冲区：client-query-buffer-limit，主要用于避免客户端bug引起服务端崩溃；默认1GB，一般不做限制。 客户端超时：timeout，不是很精确的计算，只用于一般类型的客户端（非repl、pub/sub类型） tcp心跳设置：tcp-keepalive，避免客户端”假死”(虽然连接，但是已不可用) 管理命令 client list：显示客户端列表，参数含义如下： addr：客户端ip和port name：客户端名称 client setname：设置当前会话名称 client getname：获取当前会话名称 age：连接存在时间 idle：连接空闲时间 flags：连接类型 S：复制客户端 N：一般客户端 omem：已使用的输出缓冲区大小 cmd：最近执行的命令 client kill：关闭客户端连接 主从架构高可用 中文参考：http://redisdoc.com/topic/sentinel.html 官方参考：https://redis.io/topics/sentinel]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构设计]]></title>
    <url>%2F2019%2F10%2F23%2F%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AE%89%E5%85%A8%2F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[架构设计目标 可伸缩性（Scalability），当服务的负载增长时，系统能被扩展来满足需求，且不降低服务质量。 负载均衡技术是实现网站架构伸缩性的主要手段 高可用性（Availability），尽管部分硬件和软件会发生故障，整个系统的服务必须是每天24小时每星期7天可用的。 可管理性（Manageability），整个系统可能在物理上很大，但应该容易管理。 价格有效性（Cost-effectiveness），整个系统实现是经济的、易支付的。 负载均衡技术 基于客户端调度访问：客户端存储服务器集群配置信息，当有请求时，通过算法向不同服务器发送请求【redis的集群即使用此方法，redis的客户端需要存储redis集群的ip及端口列表】 基于DNS域名轮流解析：一个域名映射多个服务器 基于应用层系统负载调度：nginx、haproxy 基于网络及传输层的IP地址调度：lvs、haproxy 阿里云高可用 同一个城市的多个可用区网络互通，用户无感知 为了保证应用的高可用，应该在不同可用区部署服务 rds的主库默认会在同一可用区建立备库（用户不可见，主库故障时，rds自动切换），用户可购买不同可用区的容灾备 架构层次设计 缓存服务【CDN】 负载均衡器 web服务 应用层服务 数据库 高并发实现 应用层横向扩展 负载均衡器（四层/七层实现） 弹性伸缩服务（动态增减服务器容量） 使用应用层缓存（如memcache、redis服务等key-value服务） 同步转异步（消息队列） 提供数据库访问能力（读写分离） 应用层缓存 原因：数据库服务横向扩展支持高并发 特点 key-value存储 内存中缓存数据 支持热点数据缓存 数据访问速度要求高 更新评率低，读取频率高 产品 memcache：数据不存盘 redis：数据存盘 同步转异步 重点：业务流程设计中拆分出同步和异步 两种模式： 同步：支付要求实时返回信息 异步：消息队列 消息队列： 生产者 消息平台【存储、路由】 消费者 数据库架构 读写分离原因 写操作严格，并发不高 由于写操作加锁原因，会影响读操作，间接造成读操作并发不高 写操作频率一般比读操作频率低很多 读写分离操作 读写操作拆分到不同数据库实例上，由于磁盘io限制，一般也要求数据库实例分布在不同主机上 读写分离关键：复制技术（一般才去日志重做机制-redo） 读写分离应用：能够接受读写操作微小的延迟和不一致]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云原生技术简介]]></title>
    <url>%2F2019%2F10%2F23%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2F%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[总览云原生以”云”为基础的软件架构设计的思想，应用从设计到部署都在云上进行 官方支持CNCF：云原生基金会 云原生技术生态 云原生实现流程 即CNCF路线图Trail map 容器化 一般使用docker作为容器 任何程序及其依赖都可以容器化 使用微服务切割程序、开发新的功能 CI/CD 设置持续集成和持续部署（CI/CD）以使源代码的变更能自动反映在容器化的构建、测试，部署到准生产环境甚至是生产环境 设置自动发布、回滚、测试 编排和程序定义 kubernetes(成熟)是市场领先的编排解决方案 应当选用一个认证的kubernetes发行版、主机平台、或安装器：cncf.io/ck Helm Charts(孵化中)可以实现定义、安装、升级大多数复杂的kubernetes应用 观察和分析 选取合适的监控、日志、调用链追踪解决方案 考虑使用CNCF项目，Prometheus(成熟)作为监控、Fluentd(成熟)作为日志、jaeger(孵化中)作为调用链追踪的解决方案 对于调用链追踪，寻找open-tracing(孵化中)兼容的实现方式，比如jaeger 以下为可选内容服务代理/发现/网格 CoreDNS(成熟)是一个快速且富有弹性的工具，适用于服务发现 Envoy(成熟)和Linkerd(孵化中)都可以开启服务网格编排 它们也可以提供健康检查、路由和负载均衡功能 网络和策略 为了开启更富弹性的网络，可以使用CNI(Container Network Interface 成熟)兼容的网络项目，比如Calico、Flannel、Weave Net Open Policy Agent(OPA 孵化中)是一个通用的策略引擎，可以用于授权、认证许可、数据过滤 分布式数据库和存储 如果想要从单一数据库之外获取更多的弹性和可扩展性，vitess(孵化中)是通过分片大规模运行mysql的好选择 Rook(孵化中)是一个存储编排器，可将各种存储解决方案集成到kubernetes中 作为kubernetes的大脑，etcd(孵化中)提供了跨主机的集群级别可靠数据存储 TiKV(孵化中)使用Rust实现了一个高性能的分布式事务级别的KV存储 流和消息 如果需要比JSON-REST更高的性能，考虑使用gRPC或者NATS gRPC(孵化中)是一个通用RPC框架 NATS(孵化中)是一个多模式消息系统，包含请求/响应、发布/订阅、负载均衡队列 容器仓库和运行环境 harbor(孵化中)是一个实现存储、鉴权、扫描内容的仓库 也可以使用其他容器运行环境 最常见的，containerd(成熟)和CRI-O(孵化中)都是符合OCI规范的 软件分发假如需要实现安全的软件分发，可以评估Notary(孵化中)，一个实现更新的框架 核心思想 不可变基础设施：即容器镜像； 应用编排理论：即容器设计模式，当前为kubernetes的内容 核心技术 容器技术： cgroups：google早期的容器技术 docker：当前容器事实标准；docker是应用运行的最小单位，不依赖任何paas 容器编排技术 swarm，docker维护的项目，偏重生态；2017年，docker公司核心产品内置kubernetes服务，swarm项目停止维护 mesos：技术较强 kubernetes：兼顾生态和技术，在swarm停止维护后，从三者【swarm、mesos、k8s】竞争中胜出，是容器编排的事实标准 技术范畴 应用定义和开发流程 应用定义与镜像制作 CI/CD 消息和流 数据库 应用编排和管理【kubernetes关注的部分】 应用编排和调度 服务发现治理 远程调用 API网关 service mesh 监控和分析 监控 日志收集 tracing 破坏性测试【即混沌工程】 底层技术：运行、存储、网络 容器运行时 存储 网络 工具集 流程自动化与配置管理 镜像仓库 安全技术 云端密码管理 serverless paas的特殊形态，是一种应用编写方式，包含faas和baas 典型特点就是按实际使用计费]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>cncf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis客户端redis-cli]]></title>
    <url>%2F2019%2F10%2F22%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E7%BC%93%E5%AD%98%E4%B8%8Enosql%2Fredis%E5%AE%A2%E6%88%B7%E7%AB%AFredis-cli%2F</url>
    <content type="text"><![CDATA[非交互模式 命令行使用：redis-cli incr mycounter 重定向输出：redis-cli incr mycounter &gt; /tmp/output.txt 额外信息控制： –raw：只显示命令结果 –no-raw：显示操作的数据类型及操作结果【这是默认模式，但是客户端也会判断如果有tty终端则显示数据类型，没有tty（重定向）则不显示数据类型】 连接 -h：连接主机 -p：连接端口，默认6379 -a：连接密码 -n：指定指定连接的库【默认连接数据库0】 -u：使用redis协议通过URI连接，如：redis-cli -u redis://password@redis-16379.hosted.com:16379/0 ping 重定向输入： -x：读取最后一个参数：redis-cli -x set foo &lt; /etc/services 执行文件内的命令：cat /tmp/commands.txt | redis-cli1234set foo 100incr fooappend foo xxxget foo 重复执行命令 -r：执行次数 -i：时间间隔，单位是秒，最小为0.1，默认为0 批量插入：–pipe【cat data.txt | redis-cli –pipe】 导出csv格式：–csv【redis-cli –csv lrange mylist 0 -1】 交互模式 默认可以浏览历史命令、命令补全功能 选择数据库：select 2 数据库大小：dbsize 认证：auth 连接其他实例：connect 执行命令n次：n command 帮助信息： 分类帮助：help @&lt;category&gt; @generic @list @set @sorted_set @hash @pubsub @transactions @connection @server @scripting @hyperloglog 特定命令帮助：help command 清屏：clear 特殊模式 状态监控 参数：–stat （-i interval） 范例：redis-cli –stat 数据库中扫描出最大key 参数：–bigkeys 范例：redis-cli –bigkeys 获取key列表 参数：–scan【对比交互模式下keys *，scan参数以非阻塞方式获取key列表】 范例：redis-cli –scan | head -10 模式匹配参数：–pattern 模式匹配范例：redis-cli --scan --pattern &#39;*-11*&#39; 发布订阅模式 订阅：redis-cli psubscribe ‘*’ 发布：redis-cli PUBLISH mychannel mymessage 监控实例执行的命令：redis-cli monitor 用不同方式检测服务端实例延迟 –latency：每秒100次向服务端发送ping信号 –latency-history：每15秒开启一个新的会话连接用于压测【-i指定时间间隔】 –latency-dist：以带颜色的光谱图形式显示延迟信息 检测客户端延迟： –intrinsic-latency 【test-time】：redis-cli客户端所在主机的固有延迟【如内核调度，虚拟化开销等】 远程备份rdb 参数：–rdb 范例：redis-cli -h 172.15.22.9 -a 123456 –rdb /tmp/dump.rdb 测试复制模式下从机接收的内容 参数：–slave 范例：redis-cli -h 172.15.22.9 -a 123456 –slave 测试不同LRU策略下的key命中率 影响因素：测试样本数量、最大可用内存(maxmemory ) 参数：–lru-test sample-number 范例：./redis-cli –lru-test 10000000]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis-cli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis服务端配置]]></title>
    <url>%2F2019%2F10%2F22%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E7%BC%93%E5%AD%98%E4%B8%8Enosql%2Fredis%E6%9C%8D%E5%8A%A1%E7%AB%AF%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[服务端配置方法 文件指令格式：keyword argument1 argument2 … argumentN 使用引号处理包含的空格：requirepass “hello world” 命令行传参：./redis-server –port 6380 –slaveof 127.0.0.1 6379 运行状态下变更配置： 获取配置：config get keyword 设置参数：config set keyword value 将运行配置写入文件：config rewrite 专项配置慢日志格式 日志条目id 日志记录时间戳 执行时间（微秒） 执行命令数组 客户端ip和端口（4.0版本） 通过client setname设置的客户端名称（4.0版本） 配置参数 slowlog-log-slower-than：执行时间阈值 slowlog-max-len：记录日志条数 控制命令 查看（指定数目）日志：slowlog get （number） 查看日志记录总数：slowlog len 清空日志：slowlog reset 配置文件redis.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532# redis.conf必须作为第一个参数，例如：./redis-server /path/to/redis.conf# 涉及内存时的计量单位# 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes################################## INCLUDES #################################### include包含的文件不能被【config rewrite】命令改写# 针对相同的配置项，后面的配置会覆盖前面的配置，所以需要注意include的位置【首行？尾行】# include /path/to/local.conf################################## MODULES ###################################### 加载自定义模块# loadmodule /path/to/my_module.so################################## NETWORK ###################################### 如果没有指定bind参数，redis运行在所有网络接口上# redis可以指定一个或多个网络接口# bind 192.168.1.100 10.0.0.1# bind 127.0.0.1 ::1bind 127.0.0.1# 公网保护模式（默认开启）# 如果没有配置bind指令或密码认证信息，则只能从127.0.0.1等回环接口访问protected-mode yes# 监听端口（默认6379，设置为0，则不在tcp上监听）port 6379# 定义tcp队列长度# 在linux环境下，linux内核会自动将其值变更为/proc/sys/net/core/somaxconn的值，# 以确保可以通过提高somaxconn的值达到最终目的tcp-backlog 511# 设置unix socket文件（默认不产生socket文件）# unixsocket /tmp/redis.sock# unixsocketperm 700# 客户端连接超时时间timeout 0# tcp连接心跳检测（3.2.1之后，默认值为300s）tcp-keepalive 300################################# GENERAL ###################################### 是否开启后台运行模式（默认no）# 如果设置为后台模式，则会产生一个pid文件daemonize no# 如果使用其他控制程序(如upstart、systemd)控制redis服务启停，需要如下相关设置# supervised no - no supervision interaction# supervised upstart - signal upstart by putting Redis into SIGSTOP mode# supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET# supervised auto - detect upstart or systemd method based on# UPSTART_JOB or NOTIFY_SOCKET environment variables# Note: these supervision methods only signal &quot;process is ready.&quot;# They do not enable continuous liveness pings back to your supervisor.supervised no# 后台运行时产生的pid文件位置（如果没有指定，默认写入/var/run/redis.pid）pidfile /var/run/redis_6379.pid# 日志级别# debug (a lot of information, useful for development/testing)# verbose (many rarely useful info, but not a mess like the debug level)# notice (moderately verbose, what you want in production probably)# warning (only very important / critical messages are logged)loglevel notice# 日志文件位置logfile &quot;&quot;# 是否使用系统的syslog方式写日志# syslog-enabled no# Specify the syslog identity.# syslog-ident redis# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.# syslog-facility local0# 设置数据库数量，每个库都有独立的命名空间databases 16# 交互模式下，是否显示redis logo信息always-show-logo yes################################ SNAPSHOTTING ################################# 设置保存数据到rdb文件的频率：save &lt;seconds&gt; &lt;changes&gt;# 取消所有保存频率的设置：save &quot;&quot;# # 以下设置的含义：# 900秒后至少有1个key发生变更# 300秒后至少有10个key发生变更# 60秒后至少有10000个key发生变更save 900 1save 300 10save 60 10000# 开启rdb写入时，如果后台持久化存储失败则停止客户端写操作stop-writes-on-bgsave-error yes# rdb文件压缩存储rdbcompression yes# rdb校验【增加可用性，但会增加存储或加载开销】rdbchecksum yes# rdb文件名dbfilename dump.rdb# 指定rdb和aof文件的存储目录dir ./################################# REPLICATION ################################## 主从复制从机设置# slaveof &lt;masterip&gt; &lt;masterport&gt;# 主机要求的验证密码（requirepass）# masterauth &lt;master-password&gt;# 主从复制中断时，从机的处理（默认yes）：# 设置为yes，则从机可以使用过期的数据为客户端提供服务# 设置为no，则从机会对除了INFO和SLAVEOF的其他命令返回错误信息：&quot;SYNC with master in progress&quot;slave-serve-stale-data yes# 从机只读设置slave-read-only yes# rdb文件传输方式（复制同步策略）：# 有盘方式：主开启写进程在本地写rdb文件，在rdb文件阶段性写完后，# 就可以和（多个）从机通信，然后由父进程传输文件到从机# 无盘方式（网络）：主开启写进程直接将rdb文件写入从机网络socket，# 当阶段性写操作完成后，主和另一个从机通信进行复制操作## 无盘复制同步要点：# 1.无盘模式当前是实验性功能# 2.新建一个从机或从机重连时会执行一个全量同步# 3.使用无盘方式，会配置一个等待时间，以便所有从机可达以并行方式传输# 4.磁盘容量小或磁盘io小，同时网络带宽大的情况更适合使用无盘方式repl-diskless-sync no# 无盘方式工作时，复制开始前主机的等待时间（默认5s，0则不等待）# 一旦同步开始，新的从机并不会被主接纳，所以需要配置一个等待时间，确保所有从机已连上。repl-diskless-sync-delay 5# 从机检测主机可达的时间间隔# repl-ping-slave-period 10# 复制超时时间# 它包含：主机视角的ping响应超时、从机角度的ping和数据传输超时# 它必须比repl-ping-slave-period时间长# repl-timeout 60# 是否关闭tcp nodelay功能（默认no，不关闭延迟）# 设置为yes，会传输更小的数据包并使用更小的带宽，但延迟会增加（linux内核限制，最多40ms）# 设置为no，延迟会更低，但是需要更大的带宽repl-disable-tcp-nodelay no# 允许从机断开并重连时可以继续同步的缓冲区大小【避免全量同步】# repl-backlog-size 512mb# 超时则主释放同步缓冲区，0则永不释放# repl-backlog-ttl 3600# 从机提升为主机时的优先级（数越小优先级越高）# 主要是redis sentinel使用，当主出现异常时提升从机为主slave-priority 100# 当少于指定数量的从机或复制延迟大于某个阈值时，主停止写操作（设置为0则关闭此功能）# 范例：至少3个从机的延迟小于10，否则master停止写入操作# min-slaves-to-write 3# min-slaves-max-lag 10# 主从复制时，主查看从机ip的方式：INFO replication 和 ROLE# 在端口转发和nat网络情况下，上述命令获取的信息会有误# 通过在从机声明如下变量，可以告诉主机自己真实的ip和port【可选设置】# slave-announce-ip 5.5.5.5# slave-announce-port 1234################################## SECURITY #################################### 客户端认证密码（也是主从复制的密码），由于redis没有防爆破的手段，所以需要设置一个强密码# requirepass foobared# 重命名命令：# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52# 也可通过空字符串“删除”命令# rename-command CONFIG &quot;&quot;# 【注意】重命名命令在写入aof或传输到从机时会出问题################################### CLIENTS ##################################### 客户端最大连接数# 如果redis不能设置最大文件描述符数量，# 则maxclients被设置为当前最大文件描述符数量减32（redis保留部分描述符供内部使用）# maxclients 10000############################## MEMORY MANAGEMENT ################################# 最大可用内存（超过后根据驱逐策略删除key）# 1. 超过此阈值，如果驱逐策略为noeviction，则对于写命令则返回错误，读命令则正常返回# 2. 作为LRU或LFU缓存，或使用noeviction驱逐策略时，都应该设置硬限制# 3. 不包含主从复制的输出缓冲区大小（repl-backlog-size）# maxmemory &lt;bytes&gt;# 内存使用达到限制时的key删除策略（默认noeviction）：# volatile-lru -&gt; 使用LRU策略驱逐具有过期设置的key# allkeys-lru -&gt; 使用LRU策略驱逐任意的key# volatile-lfu -&gt; 使用LFU策略驱逐具有过期设置的key# allkeys-lfu -&gt; 使用LFU策略驱逐任意的key# volatile-random -&gt; 从具有过期设置的key中随机删除一个# allkeys-random -&gt; 从所有key中随机删除一个# volatile-ttl -&gt; 删除最接近过期的key# noeviction -&gt; 不驱逐任何key，向写操作返回错误## LRU：Least Recently Used【最近最少使用】# LFU：Least Frequently Used【经常最少使用】# LRU, LFU 和 volatile-ttl都使用了近似的随机算法## 即使使用上述策略，如果没有合适的key被删除，依然会对写操作返回错误，包含的写操作如下：# set setnx setex append# incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd# sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby# zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby# getset mset msetnx exec sort## maxmemory-policy noeviction# 启动内存回收时，单次取样数量：# 3个速度最快，但是策略执行不精确；5个足够；10个最精确，但是更消耗cpu# maxmemory-samples 5############################# LAZY FREEING ##################################### 非阻塞式释放内存## redis有两种删除key的模式：# 1.阻塞式：del命令是一种阻塞式删除，即在进行删除操作的同时停止处理新命令，阻塞时间的长短根据删除对象的大小而定# 2.非阻塞式：redis（4.0.0之上版本）也提供非阻塞式删除命令，比如unlink（非阻塞del）、flushdb|flushall的async选项# 这些命令会在限定时间内执行完，但是会在后台开启一个新线程持续释放内存空间## 情景设置：# 一、在下列情景中，redis默认会以阻塞方式删除key或清空库：# 1.根据最大内存和驱逐策略删除key# 2.由于key的过期设置（EXPIRE）# 3.对一个已存在的key进行操作，如RENAME# 4.在复制操作时，从机执行全量复制时，会清空从机rdb# # 二、可以单独设置以上情况以非阻塞方式释放内存，具体命令如下：lazyfree-lazy-eviction nolazyfree-lazy-expire nolazyfree-lazy-server-del noslave-lazy-flush no############################## APPEND ONLY MODE ################################ 是否开启预写日志模式（aof和rdb可以同时开启）# 默认情况下，redis异步导出数据到磁盘（基于rdb的不同刷新策略（save）可能会有部分数据丢失）# 当aof开启时，redis启动时会将加载aof文件appendonly no# aof文件名appendfilename &quot;appendonly.aof&quot;# fsync为数据写入磁盘的策略# no: 让操作系统处理什么时候刷新数据到磁盘，此时速度最快# always: 每次都等待数据写入aof文件，速度最慢，安全性最好# everysec: 每秒刷新数据到磁盘，折中选择【默认选项】appendfsync everysec# 在后台执行BGSAVE或BGREWRITEAOF命令时，是否阻止主进程进行磁盘刷新操作# 这个选项是为了减轻磁盘写压力，但会造成数据丢失【默认不开启】no-appendfsync-on-rewrite no# 自动重写aof文件时，增长的大小所占的百分比auto-aof-rewrite-percentage 100# 自动重写aof文件时，最小增加的文件大小auto-aof-rewrite-min-size 64mb# 是否允许加载不完整（被截断）的aof文件（如果设置为no，必须使用redis-check-aof修复aof文件）aof-load-truncated yes# 使用aof和rdb混合方式持久化数据【可以更快的执行重写和恢复操作，默认关闭】aof-use-rdb-preamble no################################ LUA SCRIPTING ################################ lua脚本执行超时时间（毫秒，0或负值则不限制时间）# 超过时间，redis会记录脚本依然在执行，并对查询信息返回错误# 【SCRIPT KILL】命令会停止一个不含写操作的脚本# 【SHUTDOWN NOSAVE】可以停止包含写操作的脚本lua-time-limit 5000################################ REDIS CLUSTER ################################ 是否开启redis集群功能# redis单实例模式和集群模式不能相互转换，只能在一开始就确定使用的方式# cluster-enabled yes# 集群节点的配置文件（集群自动创建和更新，一般不需要手动编辑）每个节点都有一个配置文件# cluster-config-file nodes-6379.conf# 节点断开超时时间（毫秒，其他内部限制时间都是这个值的倍数）# 超过这个时间，节点被认为是失败状态# cluster-node-timeout 15000# 定义从机选举为主的因子（避免数据太旧的从机执行故障切换）# # 数据新旧情况判断：# 1.当有多个从机时：会根据他们从主上接收数据的多少（offset）选择谁执行故障切换# 2.单个从机角度计算：则根据距离上次接收ping响应、接收命令的时间（连接状态下）或与主断开的时间# # 第2点可以由用户控制，超过【(node-timeout * slave-validity-factor) + repl-ping-slave-period】# 的从机不能提升为主；其中slave-validity-factor是从机选举为主的因子：# 1）定义为n，则超过（n*timeout+ping）后选举为主，此段时间内，集群不可用除非原来的主恢复# 2）如果：非常大的值允许有非常旧数据的从机执行故障切换，值太小则无法在众多从机中选出提升为主的从机# 3）默认为0，超时即选为主；此设置保证了最大可用性，允许从机立即提升为主，但是依然会根据从主机接收数据的多少选择提升为主的从机## cluster-slave-validity-factor 10# 主机在有如下数量的从机时，其他从机可以自动迁移到孤立的主机（没有从机的主机）# cluster-migration-barrier 1# 是否要求所有数据槽都可用时集群才可用# 设置为no时，允许集群数据不完整时依然可以提供查询服务# cluster-require-full-coverage yes# 主故障时，禁止从机执行故障切换（此时会手动处理主机故障切换操作）# 在有多个数据中心时非常有用，此时会期望只有这个数据中心的节点全部出现故障时才执行切换# cluster-slave-no-failover no########################## CLUSTER DOCKER/NAT support ######################### 当遇到nat网络或端口转发时【如docker等容器环境】集群节点地址发现会失败，所以# 每个集群节点都需要知道一个公共地址，即如下配置：# * cluster-announce-ip# * cluster-announce-port# * cluster-announce-bus-port## Example:## cluster-announce-ip 10.1.1.5# cluster-announce-port 6379# cluster-announce-bus-port 6380################################## SLOW LOG #################################### 慢日志在内存中记录超过一定执行时间的命令：# 不包含io操作，比如：和客户端通信、发送响应# 仅包含：命令的实际执行时间，此时线程被阻塞不能服务于其他请求# 执行时间阈值（微秒，负值则关闭slowlog功能，0则记录每一个命令）slowlog-log-slower-than 10000# 保存多少条慢日志，超过则删除最旧的记录（【SLOWLOG RESET】强制回收内存）slowlog-max-len 128################################ LATENCY MONITOR ############################### 超过阈值的延迟因素会被记录（毫秒；默认为0，关闭功能 ）latency-monitor-threshold 0############################# EVENT NOTIFICATION ############################### redis可以通知发布/订阅的客户端发生在键空间的事件，# 相关文档：http://redis.io/topics/notifications## redis通过单字符定义要通知的事件：# K Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.# E Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.# g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...# $ String commands# l List commands# s Set commands# h Hash commands# z Sorted set commands# x Expired events (events generated every time a key expires)# e Evicted events (events generated when a key is evicted for maxmemory)# A Alias for g$lshzxe, so that the &quot;AKE&quot; string means all the events.# # notify-keyspace-events使用0或多个字符构成的字符串串作为参数：# 1. 0个字符串表示关闭事件通知功能（默认）# 2. 至少需要指定K或E，否则会没有事件通知## 范例1：开启列表和通用事件，从事件名称的角度，使用如下# notify-keyspace-events Elg## 范例2：获取提交给频道&lt;__keyevent@0__:expired&gt;的过期key流# notify-keyspace-events Exnotify-keyspace-events &quot;&quot;############################### ADVANCED CONFIG ################################ ziplist是一个解决空间紧凑的数据存储结构，但是当数据超过此阈值时，将采用原生的数据存储结构# # 数据类型为hash，设置使用ziplist的条目数量、最大条目值的阈值hash-max-ziplist-entries 512hash-max-ziplist-value 64# 数据类型是list，设定使用ziplist的阈值# 定义为正值时，表示单个列表最大元素数量# 定义为负值时（-5到-1）表示单个列表的最大存储空间# -5: max size: 64 Kb &lt;-- not recommended for normal workloads# -4: max size: 32 Kb &lt;-- not recommended# -3: max size: 16 Kb &lt;-- probably not recommended# -2: max size: 8 Kb &lt;-- good# -1: max size: 4 Kb &lt;-- goodlist-max-ziplist-size -2# 数据类型是list，也可以被压缩存储# 压缩深度定义如下# 0：关闭列表所有节点的压缩# 1：列表的首尾节点不压缩，其他节点都压缩# 2：列表的首及相邻节点、尾及相邻节点不压缩，其他节点都压缩# n：以此类推，首尾的n个节点不压缩，中间节点压缩list-compress-depth 0# 数据类型为set，且仅由基数为10的整数（64为有符号整数）组成的字符串# 当set类型的大小小于阈值时，可以使用这种节省内存的编码set-max-intset-entries 512# 数据类型sorted sets（zset），设定使用ziplist的阈值zset-max-ziplist-entries 128zset-max-ziplist-value 64# HyperLogLog的稀疏表示限制（建议值是3000，取值范围是0到15000）# 1. 大于这个阈值，数据使用稠密数据结构；# 2. 小于此值，数据使用稀疏数据结构。# 3. 大于16000的值是无意义的，因为此时稠密表示法更能有效使用内存hll-sparse-max-bytes 3000# 是否开启对主字典的二次哈希（hash会释放内存，但因为使用cpu会造成微量延迟）activerehashing yes# 客户端输出缓冲区限制，如果客户端读取数据的速度不够快，则强制断开# 参数0不限制；一般的客户端（normal）不限制，因为他们使用应答模式返回数据# # 语法：# client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;## redis：定义了3种不同类型的客户端# normal -&gt; normal clients including MONITOR clients# slave -&gt; slave clients# pubsub -&gt; clients subscribed to at least one pubsub channel or pattern# # 如果客户端使用达到硬限制或软限制（同时达到字节大小和持续时间）则断开客户端client-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60# 客户端查询缓冲区限制（如果有特殊需求可以设置）# client-query-buffer-limit 1gb# 使用redis协议时，单个大数据量请求的字符串长度限制（默认512mb）# proto-max-bulk-len 512mb# redis调用内部函数执行后台任务（如：超时关闭客户端，删除过期的key）的频率：# 1. 增大数值可以更精确的处理各类超时、删除过期key等问题，但是会消耗更多的cpu、也会增加redis的延迟# 2. 取值范围1到500，但是不建议使用超过100的值hz 10# 当aof文件重写时，每产生32MB数据就会执行一次刷新磁盘操作# 以这种渐进的方式进行重写操作可以降低磁盘写压力（从而降低常规写aof的延迟）aof-rewrite-incremental-fsync yes# 【LFU算法调节】# 可调节参数：计数器对数因子（lfu-log-factor）和计数器衰减时间（lfu-decay-time）## 【计数器对数因子-原理】# 针对每个key，LFU计数器只有8位，最大值是255；# 给旧的计数器一个值，当key被访问时，计数器以下面方式增长# 1.产生一个0~1之间的随机数R# 2.计算一个概率值P：1/(old_value*lfu_log_factor+1)# 3.只有当概率值P大于随机数R时，计数器才递增## 下边是不同对数因子在不同访问次数下的频率计数器变化# （计数器的初试值为5，以便计算对象的累积命中率；测试命令如下）：# 1. redis-benchmark -n 1000000 incr foo# 2. redis-cli object freq foo# +--------+------------+------------+------------+------------+------------+# | factor | 100 hits | 1000 hits | 100K hits | 1M hits | 10M hits |# +--------+------------+------------+------------+------------+------------+# | 0 | 104 | 255 | 255 | 255 | 255 |# +--------+------------+------------+------------+------------+------------+# | 1 | 18 | 49 | 255 | 255 | 255 |# +--------+------------+------------+------------+------------+------------+# | 10 | 10 | 18 | 142 | 255 | 255 |# +--------+------------+------------+------------+------------+------------+# | 100 | 8 | 11 | 49 | 143 | 255 |# +--------+------------+------------+------------+------------+------------+## 【计数器衰减时间-原理】# 必须是经过的时间，以便将key计数器除以2或直接递减（小于等于10时） ## 【计数器对数因子-设置】（0-255）（因子越高，为了达到最大值，需要更多的访问）# 如下表示：每100万个请求使计数器饱和# lfu-log-factor 10## 【LFU衰减时间周期-设置】（分钟），默认1分钟；# 如下表示：每分钟使计数器衰减一次# lfu-decay-time 1########################### ACTIVE DEFRAGMENTATION ######################## 开启实时内存碎片整理功能# activedefrag yes# 内存碎片化达到多少字节后开启整理# active-defrag-ignore-bytes 100mb# 内存碎片化达到多大比率时开启整理# active-defrag-threshold-lower 10# 碎片整理的最大百分比# active-defrag-threshold-upper 100# 碎片整理占用的最小cpu使用率# active-defrag-cycle-min 25# 碎片整理占用的最大cpu使用率# active-defrag-cycle-max 75]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis.conf</tag>
        <tag>慢日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pgsql-pgpool使用]]></title>
    <url>%2F2019%2F10%2F13%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fpgsql-pgpool%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[pgpool简介pgpool是一个位于数据库服务端和客户端之间的中间件，可以实现如下功能： 连接池 复制功能：可以实时的把数据备份到单独的磁盘 负载均衡：将查询语句拆分到多台后端数据库 限制过量的连接：将超过限制的连接排队，但不直接返回错误 看门狗功能：同时在两个节点部署pgpool，通过vip偏移执行高可用 基于内存的查询缓存 软件安装./configure –prefix=/usr/local/pgpool –with-pgsql=/usr/local/pgsql/makemake install 安装插件pgpool_recovery$ cd pgpool-II-x.x.x/src/sql/pgpool-recovery$ make$ make install$ psql -f pgpool-recovery.sql template1$ 【vim postgresql.conf】：pgpool.pg_ctl = ‘/usr/local/pgsql/bin/pg_ctl’$ pg_ctl reload -D /usr/local/pgsql/data pgpool-regclass PostgreSQL 9.4 or later可以省略 insert_lock表如果打算使用原生的复制模式和insert_lock，需要创建：$ cd pgpool-II-x.x.x/src/sql$ psql -f insert_lock.sql template1 配置pgpool.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#连接listen_addresses = &apos;*&apos;port = 9833pcp_listen_addresses = &apos;*&apos;pcp_port = 9898#后端backend_hostname0 = &apos;10.86.0.10&apos;backend_port0 = 5432backend_weight0 = 16backend_data_directory0 = &apos;/home/postgres/db0/db/9.3/data/&apos;backend_flag0 = &apos;ALLOW_TO_FAILOVER&apos;backend_hostname1 = &apos;10.86.0.12&apos;backend_port1 = 5432backend_weight1 = 128backend_data_directory1 = &apos;/home/postgres/db0/db/9.3/data&apos;backend_flag1 = &apos;ALLOW_TO_FAILOVER&apos;#安全enable_pool_hba = onpool_passwd = &apos;&apos;authentication_timeout = 60ssl = off#连接池num_init_children = 64max_pool = 16child_life_time = 300child_max_connections = 200connection_life_time = 120client_idle_limit = 60connection_cache = onreset_query_list = &apos;ABORT; DISCARD ALL&apos;relcache_expire = 0relcache_size = 256check_temp_table = on#日志log_destination = &apos;syslog&apos;print_timestamp = onlog_connections = offlog_hostname = offlog_statement = offlog_per_node_statement = offlog_standby_delay = &apos;none&apos;syslog_facility = &apos;LOCAL0&apos;syslog_ident = &apos;pgpool&apos;debug_level = 0#文件位置pid_file_name = &apos;/home/postgres/pgpool2/run/pgpool.pid&apos;logdir = &apos;/home/postgres/pgpool2/log/&apos;#基于流复制的负载均衡模式（主备模式）replication_mode = offinsert_lock = onload_balance_mode = onmaster_slave_mode = onmaster_slave_sub_mode = &apos;stream&apos;ignore_leading_white_space = onwhite_function_list = &apos;&apos;black_function_list = &apos;nextval,setval&apos;sr_check_period = 3sr_check_user = &apos;replication&apos;sr_check_password = &apos;repl-pg-0232&apos;delay_threshold = 0#健康检查health_check_period = 10health_check_timeout = 20health_check_user = &apos;postgres&apos;health_check_password = &apos;YUTR0-Lew&amp;4-DE74GF-qePi8&apos;health_check_max_retries = 0health_check_retry_delay = 3#故障切换failover_command = &apos;/home/postgres/bin/failover_stream.sh %d %H /home/postgres/db0/tmp/trigger_file&apos;failback_command = &apos;/bin/rm -f /home/postgres/db0/tmp/trigger_file&apos;fail_over_on_backend_error = on #设置health_check_max_retries则关闭此选项search_primary_node_timeout = 10#在线恢复recovery_user = &apos;postgres&apos;recovery_password = &apos;YUTR0-Lew&amp;4-DE74GF-qePi8&apos;recovery_1st_stage_command = &apos;/home/postgres/bin/basebackup.sh&apos;recovery_2nd_stage_command = &apos;&apos;recovery_timeout = 90client_idle_limit_in_recovery = 0#双击热备配置use_watchdog = on # 开启看门狗，用于监控pgpool 集群健康状态wd_hostname = &apos;10.86.0.10&apos; # 本地看门狗地址wd_port = 9000 #wd_priority = 1 # 看门狗优先级，用于pgpool 集群中master选举delegate_IP = &apos;10.86.0.100&apos; # VIP 地址if_up_cmd = &apos;ip addr add $_IP_$/24 dev eth0 label eth0:0&apos; # 配置虚拟IP到本地网卡if_down_cmd = &apos;ip addr del $_IP_$/24 dev eth0&apos; # wd_lifecheck_method = &apos;heartbeat # &apos; 看门狗健康检测方法wd_heartbeat_port = 9694 # 看门狗心跳端口，用于pgpool 集群健康状态通信wd_heartbeat_keepalive = 2 # 看门狗心跳检测间隔wd_heartbeat_deadtime = 30 #heartbeat_destination0 = &apos;10.86.0.12&apos; # 配置需要监测健康心跳的IP地址，非本地地址，即互相监控，配置对端的IP地址heartbeat_destination_port0 = 9694 # 监听的端口heartbeat_device0 = &apos;eth0&apos; # 监听的网卡名称wd_life_point = 3 # 生命检测失败后重试次数wd_lifecheck_query = &apos;SELECT 1&apos; # 用于检查 pgpool-II 的查询语句。默认为“SELECT 1”。wd_lifecheck_dbname = &apos;postgres&apos; # 检查健康状态的数据库名称wd_lifecheck_user = &apos;pgcheck&apos; # 检查数据库的用户，该用户需要在Postgres数据库存在，且有查询权限wd_lifecheck_password = &apos;123456&apos; # 看门狗健康检查用户密码other_pgpool_hostname0 = &apos;10.86.0.12&apos; # 指定被监控的 pgpool-II 服务器的主机名other_pgpool_port0 = 9999 # 指定被监控的 pgpool-II 服务器的端口号other_wd_port0 = 9000 # 指定 pgpool-II 服务器上的需要被监控的看门狗的端口号 配置pcp.confpcp为pgpool管理接口，pcp.conf里包含有管理接口的认证信息，内容如下：12# USERID:MD5PASSWDpostgres:e10adc3949ba59abbe56e057f20f883e md5密码产生：pg_md5 123456 配置pool_hba.conf pool_hba和pg_hba类似，是客户端连接pgpool的认证 当pgpool使用pg原生模式或只有一个后端服务器时，可以不使用pool_hba 配置： 从数据库中查询用户及密码：select rolpassword from pg_authid where rolname=’pgtest’; 建立文件pool_passwd，并写入查询到的账号信息：【pgtest:md5adbe22045e9d4ebb5254ed06a0987528】 服务启停控制 启动服务：pgpool 前台debug模式：pgpool -n -d 停止服务：pgpool 【-m smart|fast|immediate】stop 重载配置：pgpool reload 服务状态查看sql命令行下执行如下命令： 节点状态：show pool_nodes; 进程池：show pool_processes; 配置信息：show pool_status; 连接池：show pool_status; 节点管理 卸载节点：pcp_detach_node -h 127.0.0.1 -p 9898 -n 1 添加节点：pcp_attach_node -h 127.0.0.1 -p 9898 -n 1 恢复节点为可用状态：pcp_recovery_node【配合pgpool.conf中的ONLINE RECOVERY配置】 故障自动切换配置 failover_command = ‘/usr/local/pgpool/failover.sh’ failover.sh 1ssh -T 172.16.0.215 &quot;/usr/local/pgsql/bin/pg_ctl -D /usr/local/pgsql/data/ -l /home/postgres/logfile promote&quot;]]></content>
      <categories>
        <category>pgsql</category>
      </categories>
      <tags>
        <tag>pgpool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pgsql-归档和流复制]]></title>
    <url>%2F2019%2F10%2F13%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fpgsql-%E5%BD%92%E6%A1%A3%E5%92%8C%E6%B5%81%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[文件级别备份限制条件 在开始备份或恢复前，需要关闭服务【只是停止对外服务是不可行的，因为无法产生原子快照或服务的内部缓冲机制】 无法单独恢复表【表文件和事务数据单独存储，只使用表文件和事务状态日志(pg_clog)则会造成其他表不可用】，文件级别备份只能用于完整备份和集群级别的恢复 不停机处理 获取数据目录的一致性”快照”； 数据目录和WAL日志在不同磁盘，或表空间文件在不同文件系统时，获取一致性快照则比较困难 可以使用归档备份【continuous archiving base backup】来获取一致性的数据 由于此”快照”是在服务运行时的数据，当此数据目录快照在执行恢复时会认为服务没有正常关闭，服务会应用上次checkpoint之后WAL日志【即，此时数据恢复也需要pg_xlog目录下的wal日志】； 在获取快照前，执行CHECKPOINT可以减少恢复时间。 归档备份和恢复注意事项 wal文件不包含索引信息，所以索引需要手动处理 基础备份进行中，如果有 CREATE DATABASE执行会出现意料之外的事 创建表空间时，使用的是字面意思的绝对路径，在跨主机恢复会有问题 归档设置 参数设置【postgresql.conf】 wal_level = replica archive_mode = on archive_command = ‘test ! -f /mnt/server/archivedir/%f &amp;&amp; cp %p /mnt/server/archivedir/%f’ 【pg_baseback命令使用】max_wal_senders = 5 【pg_baseback命令使用】wal_keep_segments = 10 【pg_baseback命令使用】添加复制用户（pg_hba.conf） 【local replication postgres trust】 建立归档目录，并设置目录权限为pg server运行用户 重启数据库 测试归档是否正常 checkpoint; select pg_switch_xlog(); 基础备份 方式1：使用pg_basebackup命令 方式2：使用sql命令行下的API手动处理 开启归档设置 打开强制检查点【保持会话连接】：SELECT pg_start_backup(‘label’, false, false); 备份数据目录，并排除如下文件和目录 postmaster.pid、postmaster.opts recovery.conf、recovery.done pg_log pg_xlog pg_replslot 关闭强制检查点【同一会话】：SELECT * FROM pg_stop_backup(false); 【可选】：删除检查点之前的归档文件 手动模式备份实践 备份数据目录：tar czf /home/postgres/backup/data_$(date +%F).tar.gz data/ –exclude=pg_xlog &gt;/dev/null 2&gt;&amp;1 跨主机同步数据目录：rsync -C -a –delete -e ssh –exclude pg_log –exclude pg_xlog –exclude recovery.conf –exclude recovery.done data/ 10.150.10.41:~/db0/data/ 跨主机同步归档目录：rsync -C -a –delete -e ssh archive/ 10.150.10.41:/home/postgres/db0/archive/ 恢复数据 停止服务 保留并转储pg_xlog目录内容，因为它们可能包含系统宕机时还没有归档的日志 删除数据目录及表空间根目录下的内容 从基础备份中恢复数据目录 删除基础备份中的pg_xlog的文件【因为它们可能比当前的数据陈旧】 将转储的pg_xlog文件复制到数据目录 在数据目录创建recovery.conf文件，并设置策略阻止普通用户连接并使用服务【pg_hba.conf或iptables】 【原理：恢复过程】：此时将使用上次基础备份以后的归档wal文件，及当前pg_xlog目录下的wal文件用于恢复数据 归档目录不存在的内容将认为存在于pg_xlog中，这样就允许使用最近没有归档的wal文件 归档目录中存在的内容优先于pg_xlog被应用 恢复时将不会覆盖现有pg_xlog下的内容 恢复完成后，服务会自动将recovery.conf重命名为recovery.done 确认恢复完成后，开启对外服务 recovery.conf 可以在安装目录的share目录下找到recovery.conf.sample作为范例 文件选项 恢复命令【必选】：restore_command = ‘cp /mnt/server/archivedir/%f %p’ 恢复截止时间：recovery_target_time (timestamp) 是否包含截止点：recovery_target_inclusive (boolean) 默认为true，包含截止点，即在截止点停止 false，不包含截止点，在截止点之前停止 流复制前置要求 表空间：如果使用表空间，因为表空间使用绝对路径的原因，需要主备可以建立相同的路径 硬件方面：主备的硬件架构需要一致，比如都是32或64位系统 软件版本：主备大版本要尽可能保持一致，备机小版本高于主是可以的，这是因为高版本可以读取低版本的wal文件 备机操作原理 重放wal的顺序 归档目录中的文件 pg_xlog中的文件 连接主机获取的wal 备机转换为正常的可读写主机 使用命令：pg_ctl promote 触发器文件：trigger_file 主机配置 归档目录可以被备机访问【如scp】，或直接在备机复制同样的归档文件 流复制设置： 建立复制权限用户 sql—》create user repl replication password ‘repl-123456’; pg_hba.conf —》【host replication repl 172.16.0.0/24 password】 其他配置： 开启流复制线程【根据备机数量调整大小】：max_wal_senders 保持主备一致的配置：hot_standby = on 【可选功能】 max_replication_slots 备机配置 【高可用】保持和主机相同的配置，如：归档、连接、授权等，其中archive_mode的设置参考如下 在非恢复模式时，on和always作用一样，都会产生归档文件 在恢复模式时，on并不会起作用（提升为主时才起作用）；always只有则会产生自己的归档文件【处理复杂，不建议使用】 从主机恢复一个基础备份：pg_basebackup -h 172.16.0.215 -U ‘repl’ -D data/ -RP 从主机复制归档文件：rsync -az -e ssh postgre@172.16.0.215:/usr/local/pgsql/archive archive 创建配置文件 recovery.conf【pg_basebackup自动创建】 standby_mode = ‘on’ primary_conninfo = ‘host=192.168.1.50 port=5432 user=foo password=foopass’ restore_command = ‘cp /path/to/archive/%f %p’ 【从机可读设置】 hot_standby = ‘on’（postgresql.conf） 【多备机故障切换设置】recovery_target_timeline=‘latest’ 状态监控 【主】pg_current_xlog_location：产生的wal记录 【备】pg_last_xlog_receive_location：已接收但未执行的wal记录 【主】pg_stat_replication：wal发送进程列表 sent_location与pg_current_xlog_location的差异表明主处于高负载状态 sent_location与pg_last_xlog_receive_location的差异表明主备的网络处于高负载，或从处于高负载状态 备升级为主 切换注意事项：需要保证同一时间只有一个主对外提供读写服务，通行的方案是heartbeat、vip偏移 切换方式 方式1：设置 trigger_file（recovery.conf） 方式2：使用 pg_ctl promote 其他复制技术复制槽 作用：保护wal文件避免被轮转或删除，与wal_keep_segments、archive_command作用相同 优势：相比其他两种凡是，它只保持最小量的wal文件 级联复制 max_wal_senders hot_standby host-based authentication 同步复制 原理与限制条件 主无需从库返回确认信息的情况 只读事务、事务回滚 顶层的事务需要备库返回信息、而子事务不需要 长时间运行的操作，包括数据加载、建立索引 主需要从库返回确认信息：两阶段的操作（prepare、commit） 因为主库必须知道从库的状态信息，主库和从库必须直连，所以级联不能使用同步复制 主服务器必须等待所有同步服务器返回事务确认信息，否则事务永远不会完成；但可以定义同步、半同步、异步服务器减弱这种影响（synchronous_standby_names） 在事务等待返回信息时创建备用服务器，应当在运行pg_start_backup和pg_stop_backup的同一个会话中设置synchronous_commit = off，否则事务提交会一直等待新的备用服务器出现才会完成 配置 synchronous_standby_names：从库名称信息，由application_name（recover.conf）组成，逗号分隔 范例：synchronous_standby_names = ‘2 (s1, s2, s3)’ 解释：如果有s1, s2, s3 and s4 4个备用服务器，则s1，s2是主的同步服务器，s3是备主同步服务器（s1或s2出故障时被提升为主同步），s4为异步服务器【无需设置，默认为异步】 synchronous_commit：数据持久化级别【也可以在整个数据库级别、连接、事务级别指定数据持久化级别？？？】 on：默认设置，从库写一大块wal数据到磁盘 remote_write：从库接收记录，并将内容写入操作系统，但不是持久化到磁盘 remote_apply：从库已经应用接收的事务提交，但没有到数据写入阶段 高可用方案 共享存储：NAS 块设备复制（文件系统级别）：DRBD 事务日志传送：文件级别的日志传送、流复制 基于触发器的主备复制：Slony-I 基于语句复制的中间件：Pgpool-II 异步多主复制：Bucardo 同步多主复制：无 商业解决方案 其他解决方案 数据分区（Data Partitioning）：数据拆分后分布式存储，需要使用时再组合返回给终端 并行查询【提高查询速度】 原理：将单个sql查询语句拆分成多个部分，分别交给不同后端处理，多个后端的查询结果经过聚合后返回给客户端 实现：Pgpool-II、PL/Proxy]]></content>
      <categories>
        <category>pgsql</category>
      </categories>
      <tags>
        <tag>高可用</tag>
        <tag>归档</tag>
        <tag>流复制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pgsql-sql操作]]></title>
    <url>%2F2019%2F10%2F13%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fpgsql-sql%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[系统管理会话管理 查看当前会话连接：select * from pg_stat_activity; 取消一个查询：pg_cancel_backend(pid int) 终止一个会话：pg_terminate_backend(pidint) 变量 查询：select current_setting(setting_name)或show var 设置：select set_config(setting_name, new_value, is_local)或【SET old_var TO new_val;】 如果 is_local 设置为 true，那么新数值将只应用于当前事务。 如果你希望新的数值应用于当前会话，那么应该使用 false。 数据库对象存储位置 pg_relation_filenode(relation regclass)：获取指定对象的文件节点编号(通常为对象的oid值)。 pg_relation_filepath(relation regclass)：获取指定对象的完整路径名。 12345678showba=# select pg_relation_filenode(&apos;auth_group&apos;);pg_relation_filenode---------------------- 16388select pg_relation_filepath(&apos;auth_group&apos;);pg_relation_filepath----------------------base/16387/16388 数据库对象尺寸大小 pg_column_size(any) pg_tablespace_size(oid/name) pg_relation_size(oid/name) pg_database_size(oid/name) pg_size_pretty(bigint):把字节计算的尺寸转换成一个人类易读的尺寸单位 select pg_size_pretty(pg_database_size(‘test’)); sql命令 \h：查看sql命令帮助 psql命令 \?：查看psql命令帮助 \a:切换对齐和非对齐模式 \l：查看数据库列表 \q：退出sql连接 \c db：切换数据库 \d：查看当前数据库的对象【表、视图、函数、索引】 \dt：查看当前路径下的表 \d table1:查看表结构 \du:查看用户【select * from pg_roles】 导入导出csv 设置编码【保证windows下excel可读不乱码】：set client_encoding=’gb18030’; 导出数据【括号内为可执行语句】：copy (select * from xueji) to ‘/home/postgres/nnn.csv’ with csv HEADER; 导入数据：copy xueji from ‘/home/postgres/nnn.csv’ with csv HEADER; 用户和权限 修改服务监听端口（postgresql.conf) listen_address=’*’ 允许连接的主机 添加连接授权（pg_hba.conf） 【host test aa 192.168.30.91/24 password】 允许用户aa在主机 .91上以密码登陆方式操作test数据库 建立用户和授予操作权限 create user aa superuser password ‘ceshi-aa123’; grant all on DATABASE test to aa; 更改用户密码：alter user postgres with password ‘123456’; 添加只读账号123456789101112131415161718192021create role xiu LOGIN NOSUPERUSER NOCREATEDB NOCREATEROLE encrypted password &apos;wiquxiu8&apos;;# showba库授权grant connect on database showba to xiu;grant usage on schema public to xiu;grant usage on schema topology to xiu;grant select on all tables in schema public to xiu;grant select on all tables in schema topology to xiu;grant select on all sequences in schema public to xiu;grant select on all sequences in schema topology to xiu;grant select on geography_columns to xiu;grant select on geometry_columns to xiu;grant select on raster_overviews to xiu;grant select on raster_columns to xiu;grant select on coupons_orders to xiu;grant select on subscribe_orders to xiu;grant select on total_orders to xiu;# 更改新建库默认权限ALTER DEFAULT PRIVILEGES IN SCHEMA public grant select on tables to xiu;ALTER DEFAULT PRIVILEGES IN SCHEMA public grant select on sequences to xiu;ALTER DEFAULT PRIVILEGES IN SCHEMA topology grant select on tables to xiu;ALTER DEFAULT PRIVILEGES IN SCHEMA topology grant select on sequences to xiu; 表空间 功能：可以指定数据库对象的存储位置，方便扩展存储空间 创建： 语法：CREATE TABLESPACE tb_space LOCATION ‘/home/postgres/db0/tb_space’; 说明：os_path必须是空的、postgresql帐号有权的目录。创建表空间的用户必须是superuser，创建完表空间之后，可以将表空间的create权限赋给普通用户使用！ 使用： 可使用对象：表、index、数据库：在创建这些对象时，可以显式的指定tablespace tals_name子句指示对象使用的表空间。 说明： postgresql允许通过符号链接简化表空间的实施，那在不支持符号链接的os上就无法简化，只能显式的创建所需的表空间了！ 表空间是和单个数据库无关的，他被所有的数据库使用。因为，表空间只有没有任何对象使用时，才能drop掉 语法：create database test tablespace tb_space; 逻辑备份和恢复备份特点 可以远程执行备份 可以备份全部库、库、表、表结构、数据 备份的数据可以在当前版本或新版本数据库恢复 备份的数据可以同时在32或64系统上使用 备份的数据是备份开始的一个快照，他不会阻塞其他操作，但例外是会添加一个排它锁【如alter table】 备份命令pg_dump 特点： 只备份单个库； 指定备份格式(custom、directory、tar)时，使用pg_restore命令恢复数据； 没有指定备份格式时，备份为文本格式，用psql命令恢复数据，示例如下 备份：pg_dump dbname &gt; dumpfile 恢复(先创建库)：psql dbname &lt; dumpfile 命令选项 -F：指定输出备份格式 -a：只导出库数据 -s：只导出数据库结构 -t：备份指定表 -T：不备份特定表 -C：包含创建数据库命令 -f：指定备份输出文件或目录 -d：需要备份的数据库 备份范例 备份数据库 pg_dump -Fc test &gt; test.all 备份表数据 pg_dump -Fc -a -t xuji test &gt; xuji.db 备份表结构 pg_dump -Fc -s -t xuji test &gt; xuji.sql pg_dumpall 特点：备份全部的库、用户信息、表空间信息 特例：单独导出全局信息【用户、表空间】：pg_dumpall –globals-only pg_restore 选项 -a：只恢复库数据 -s：只恢复数据库结构 -t：只恢复指定表 -d：连接的数据库 范例 恢复表结构 pg_restore -s -t xuji -d test xuji.sql 恢复表数据 pg_restore -a -t xuji -d test xuji.db 恢复表 pg_restore -t xuji -d test xuji.all 大数据量处理 使用压缩 pg_dump dbname | gzip &gt; filename.gz gunzip -c filename.gz | psql dbname 使用切分 pg_dump dbname | split -b 1m - filename cat filename* | psql dbname 使用pg_dump自定义备份格式 pg_dump -Fc dbname &gt; filename pg_dump -Fc dbname &gt; filename 并行处理 pg_dump -j num -F d -f out.dir dbname pg_restore -j]]></content>
      <categories>
        <category>pgsql</category>
      </categories>
      <tags>
        <tag>sql</tag>
        <tag>备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pgsql-安装与介绍]]></title>
    <url>%2F2019%2F10%2F13%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fpgsql-%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[依赖安装 示例为ubuntu16.04下的软件包 make gcc readline：libreadline6 libreadline6-dev【用于sql命令行提示】 zlib：zlib1g zlib1g-dev【备份和恢复时压缩】 libpython2.7 libpython2.7-dev libpython3.5 libpython3.5-dev【python语言支持】 ssl：OpenSSL【连接加密】 xml2：libxml2 libxml2-dev xslt：libxslt1.1 libxslt1-dev 软件安装 软件版本：v9.6.15 ./configure –with-python –with-openssl –with-libxml –with-libxslt make sudo make install 链接库设置 动态设置【官方参考】 【普通用户】LD_LIBRARY_PATH=/usr/local/pgsql/lib;export LD_LIBRARY_PATH 【root】/sbin/ldconfig /usr/local/pgsql/lib 持久化设置：echo /usr/local/pgsql/lib &gt;&gt; /etc/ld.so.conf;ldconfig 环境变量设置123echo &quot;PATH=/usr/local/pgsql/bin:\$PATH&quot; &gt;&gt; /etc/profileecho &quot;export PATH&quot; &gt;&gt; /etc/profilesource /etc/profile 初始化数据库12345678adduser postgresmkdir /usr/local/pgsql/datachown postgres /usr/local/pgsql/datasu - postgresinitdb -D /usr/local/pgsql/data --no-localepg_ctl -D /usr/local/pgsql/data -l logfile startcreatedb testpsql test postgis安装postgis是PostgreSQL的空间和地理对象 依赖安装 PostgreSQL9.4以上 gcc make proj4：proj-bin geos：libgeos-c1v5 libgeos-dev xml2：libxml2 libxml2-dev json-c：libjson-c2 libjson-c-dev gdal：libgdal20 gdal-bin libgdal-dev llvm：llvm-6.0 llvm-6.0-dev 软件安装 ./configure –with-pgconfig=/usr/local/pgsql/bin/pg_config make sudo make install 开启postgis postgis：psql -d test -c “CREATE EXTENSION postgis;” postgis_topology:psql -d test -c “CREATE EXTENSION postgis_topology;” 主要命令 createdb、createuser：创建库、用户 dropdb、dropuser：删除库、用户 initdb：初始化数据库 pg_basebackup：创建数据目录的备份【主要用于归档中建立基础数据备份】 pg_config：一般用于扩展插件编译时加载pgsql的header信息 pg_ctl：数据库服务启停控制 pg_dump：逻辑备份单个库表 pg_dumpall：备份整个数据库实例的全部信息 pg_restore：用于恢复非文本类型的备份 postgres：数据库服务运行程序 psql：pgsql的客户端 名词术语checkpointcheckpoint(sql命令：checkpoint)会把所有的脏数据flush到磁盘，部分参数如下： checkpoint_timeout：两次checkpoint间隔时长 checkpoint_segments:：两次checkpoint间隔最大的xlog日志文件数量 archivexlog(事务)日志归档，部分参数如下： archive_mode：是否开启归档 archive_command：将xlog拷贝到一个地方的命令 流复制 max_wal_senders：master上执行流复制协议的wal_sender数量 wal_keep_segments：xlog目录中最多容纳多少个wal日志文件，超过了则删掉最初的几个。（一个日志文件16M） hot_standby：是否允许standy节点执行查询功能 日志pgsql的各种日志的默认位置都是在PGDATA目录下，主要包含： pg_log：这个日志一般是记录服务器与DB的状态，比如各种Error信息，定位慢查询SQL，数据库的启动关闭信息，发生checkpoint过于频繁等的告警信 息，诸如此类，常见参数如下 log_destination = ‘csvlog’ logging_collector = on 【慢日志】log_min_duration_statement = 200：只记录大于200ms的sql语句；0为记录所有语句，-1关闭记录功能。 pg_xlog：是pgsql的wal信息，也就是事务日志，这些日志会在定时回滚恢复(PITR)，流复制(Replication Stream)以及归档时能被用到，不能随意删除或移动 pg_clog：事务的状态信息，这个日志告诉我们哪些事务完成了，哪些没完成。这个日志文件一般非常小，但是很重要。]]></content>
      <categories>
        <category>pgsql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>pgsql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql管理]]></title>
    <url>%2F2019%2F09%2F30%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmysql%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[管理命令mysqladminshell命令行下服务端mysqld的管理工具，帮助信息：mysqladmin –help mysql内建命令 system：调用系统命令 help：帮助信息 show [full]processlist;：进程列表 show variables;：变量信息 show [func_name] status;：状态和统计信息 使用优化 能用定长char的就不用varchar 查询时，尽量不要使用select *，同时要用where条件匹配 尽量使用批量插入 锁表处理情景1 现象与解释：mysql命令行执行时，sql挂起；使用show processlist查看，该sql线程状态为【waiting for table metadata lock】；这是由于该表有正在执行的其他长事务（sql），进而阻塞了同表的后续操作。 处理 使用【show processlist】查看长事务的线程id 使用kill命令杀死改线程 情景2 现象和解释：对该表进行操作时，客户端显示锁表（比如：java客户端中出现错误【Lock wait timeout exceeded; try restarting transaction】，但是通过show processlist命令看不到该表的任何操作；实际上该表存在未提交的事务，可以在information_schema.innodb_trx中查看到。 处理 使用【select * from information_schema.innodb_trx\G】查找相关表的线程id 使用kill命令杀死该线程【由于是事务类型操作，杀死线程后，事务会回滚】 读写分离 应用程序自己实现读写路由 官方代理插件：mysql-proxy(已停止维护)–》MySQL Router【需要在应用中配置读写端口】 第三方插件： Amoeba(已停止维护)–》Cobar(已停止维护)–》MyCAT atlas：360公司团队基于mysql-proxy进行的二次开发 高可用方案数据同步+故障切换 数据同步 异步-[半同步][replication-semisync]：主库事务的提交必须保证至少有一个从库也执行了相应操作【阿里云rds高可用即采用半同步】 故障切换 MMM(Master-Master replication managerfor Mysql) MHA（Master High Availability） MySQL阿里云ecs不支持虚拟ip，所以无法使用keepalived、heartbeat类高可用软件 需要添加多个多个节点之间的ssh免密登陆 共享存储 SAN：数据库服务器和存储分离 DRBD：DRBD是一种基于软件、基于网络的块复制存储解决方案，主要用于对服务器之间的磁盘、分区、逻辑卷等进行数据镜像，当用户将数据写入本地磁盘时，还会将数据发送到网络中另一台主机的磁盘上，这样的本地主机(主节点)与远程主机(备节点)的数据就可以保证实时同步。 分布式协议 mysql cluster(官方)：使用NDB存储引擎的集群，因为各种问题，国内应用的不多 group replication(官方)：mysql5.7出现的组复制功能 单主模式下，组复制具有自动选主功能，每次只有一个 Server成员接受更新，其它成员只提供读服务。 多主模式下，所有的Server 成员都可以同时接受更新，没有主从之分，成员角色是完全对等的。 Galera]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>存储过程</tag>
        <tag>mysqladmin</tag>
        <tag>锁表</tag>
        <tag>架构</tag>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql主从同步]]></title>
    <url>%2F2019%2F09%2F29%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[复制简介复制功能优势 横向扩展解决方案：更新和写操作在主库，读操作在从库 数据安全性：从库可以停止同步、延迟同步、执行数据备份 离线数据分析 远距离数据分发 复制方式 异步复制 一般结构【默认】 特点：单层结构、所有slave直接连接master 级联复制【操作如下】 主：开启binlog 主的从：开启binlog、log_slave_updates 从的从：正常配置 延迟复制【操作如下】 STOP SLAVE CHANGE MASTER TO MASTER_DELAY = N;【seconds】 START SLAVE 双向复制【官方无此说明】：正向、反向各做一次主从同步操作，配置文件如下： 123456789101112131415161718192021222324252627# server-Aserver-id=1log-bin=&quot;mysql-bin&quot;log_slave_updates = 1binlog-ignore-db=testbinlog-ignore-db=information_schemareplicate-ignore-db=testreplicate-ignore-db=information_schemarelay-log=&quot;mysql-relay-log&quot;auto-increment-increment = 2auto-increment-offset = 1expire_logs_days = 10max_binlog_size = 100M# server-Bserver-id=2log-bin=&quot;mysql-bin&quot;log_slave_updates = 1binlog-ignore-db=testbinlog-ignore-db=information_schemareplicate-ignore-db=testreplicate-ignore-db=information_schemarelay-log=&quot;mysql-relay-log&quot;auto-increment-increment = 2auto-increment-offset = 2expire_logs_days = 10max_binlog_size = 100M 问题 需要避免在两主上同时对一个表数据进行修改 不能解决磁盘io压力 同步复制：NDB集群 半同步：主库事务的提交必须保证至少有一个从库也执行了相应操作【阿里云rds高可用即采用此种方式】 binlog日志格式 SBR（Statement Based Replication）：复制全部的sql语句，默认方式 复制存储过程和触发器时，可能会有问题 binlog文件记录的内容少，备份和还原也更快 记录原始的sql语句，可以用于安全审计 RBR（Row Based Replication）：复制变更的字段内容 可以精确记录表和字段是如何更改的，因此binlog文件记录的内容较多 不能直观的看到sql执行历史，解析binlog时：【mysqlbinlog –base64-output=DECODE-ROWS –verbose】 MBR（Mixed Based Replication）：前两种方式的变种组合 GUIDs ：基于GUID的复制方式，不必直接基于binlog文件和文件中的position 主从复制的角色定位 主：只能开启binlog功能，并将全部事件（不能指定事件类型）记录在binlog中 从： 记录已经在从库上读取并执行的binlog文件名和文件内的偏移信息（position） 可以决定只执行binlog的部分内容【只同步部分库表，或不同步部分库表】 可以决定：断开、重连、恢复同步动作 复制原理和细节 主库配置log-bin后等待从机连接 从机使用change master命令配置连接和复制状态信息【存储在master.info文件】，使用start slave开启复制 从机的io线程和主机的binlog dump线程通信，传输binlog 从机的io线程将收到的binlog存入relay-log文件中 从机的sql线程读取relay-log中的日志，并在数据库中执行相应的sql操作【状态信息保存在relay-log.info】 操作步骤主配置【主】 配置后需要重启server server-id=1 log-bin=mysql-bin 以下为保持innodb事务一致性的设置： innodb_flush_log_at_trx_commit=1 sync_binlog=1 从配置【从】 配置后需要重启server server-id=2 建立复制账号【主】grant replication slave on . to ‘repl‘@’172.16.0.215’ identified by ‘repl20190926’; 导出数据【主】 为了保证数据一致性，在导出过程中需要锁表 在mysql的终端会话中锁表，退出该会话会导致锁表失效；因此需要，在一个会话终端中锁表，在另一个会话终端中导出数据 逻辑导出-手动方式 锁表【会话终端1】： FLUSH TABLES WITH READ LOCK； 导出数据【会话终端2】：mysqldump 查看同步信息【会话终端1】：SHOW MASTER STATUS; 解锁【会话终端1中unlock tables或直接退出会话终端1】 逻辑导出-一键方式 mysqldump使用–master-data参数时，会自动处理锁表解锁、显示同步信息（导出的sql文件中）等 mysqldump –all-databases –master-data &gt; dbdump.db 物理导出适用于数据量较多的数据库 导入数据【从】 从库已有同步时，则使用–skip-slave-start启动server，或stop slave停止同步 将导出的数据传送到从库所在主机 从库导入数据：mysql &lt; all.sql 使用命令同步【从】 连接主库 123456mysql&gt; CHANGE MASTER TO-&gt; MASTER_HOST=&apos;master_host_name&apos;,-&gt; MASTER_USER=&apos;replication_user_name&apos;,-&gt; MASTER_PASSWORD=&apos;replication_password&apos;,-&gt; MASTER_LOG_FILE=&apos;recorded_log_file_name&apos;,-&gt; MASTER_LOG_POS=recorded_log_position; 开启同步：START SLAVE; 查看同步状态【从】 SHOW SLAVE STATUS\G; Slave_IO_State：io线程状态 Slave_IO_Running：io线程是否在运行 Slave_SQL_Running：sql线程是否在运行 Seconds_Behind_Maste：主从延迟 其他复制选项防止从库写操作 从库配置read-only=yes参数【此时只允许从服务器线程或super权限用户执行更新操作】 复制忽略mysql、information_schema库，主从建立单独的应用连接用户，从库建立的用户只授予读权限（select） 过滤库表 数据库级别的设置(do-db、ignore-db)：会由于binlog格式SBR和RBR的不同产生不同效果 –replicate-do-db –replicate-ignore-db 表级别的设置：不会因binlog格式不同产生不同效果，因此要尽量使用table级别设置 –replicate-do-table –replicate-ignore-table –replicate-wild-ignore-table –replicate-wild-do-table 提升复制性能 级联复制 其他提升复制性能操作 数据文件、binlog文件、relay-log文件放到不同物理磁盘 将实例的不同数据库同步到不同从机 如果从机不作为其他从机的主，可以注释log_slave_updates，避免从机写binlog文件 主故障切换 从提升为主的配置：配置log-bin，禁止log_slave_updates 从机开启log-bin参数不会写binlog，同时配置log_slave_updates则会写binlog 禁止log_slave_updates：当从机【slave-1】配置log_slave_updates，如果主故障，需要切换此从机【slave-1】为主机时，其他从机【slave-2】会在已接收过原master的binlog更新的同时，也接收新master【slave-1】的binlog更新，此时会出现重复操作 所有从机停止io线程【STOP SLAVE IO_THREAD】，并确认sql线程已经完全读取并执行relay-log中的信息【show proceslist】 slave1【提升为master】 STOP SLAVE RESET MASTER slave2、slave3【其他从机】 STOP SLAVE CHANGE MASTER TO MASTER_HOST=’Slave1’【user, password, port】 START SLAVE 故障处理 确认master开启binlog【show master status】 确认master和slave的server-id不一样 确认slave的 Slave_IO_Running和Slave_SQL_Running状态正常【show slave status】 确认slave没有手动写入数据，造成数据不一致 跳过来自主服务器的下一个语句【事件：事务类的一条事务，非事务类的一条sql语句】 语法：SET GLOBAL sql_slave_skip_counter = N; N=1的情况：来自主服务器的下一个语句不使用AUTO_INCREMENT或LAST_INSERT_ID() N=2的情况：使用AUTO_INCREMENT或LAST_INSERT_ID()时，此时它们从主服务器的二进制日志中取两个事件 配置跳过指定的错误号【比如：由于重复造成的不能入库】 语法：slave-skip-errors=1032,1062,1007]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>主从复制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql备份与恢复]]></title>
    <url>%2F2019%2F09%2F25%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[备份命令mysqldump -u 用户名 -p 密码 -h 主机 -P 端口 -S 指定链接mysql的socket –default-character-set 设置导出的字符集 -F, –flush-logs 在每个数据库备份前，刷新binlog日志 –compact 去除注释部分 –master-data：主要用于主从复制，–single-transaction会覆盖此选项 在导出数据前，对所有表添加读锁【turn –lock-all-tables on】； 导出数据后，自动解锁【turns –lock-tablesoff】，并显示binlog文件名和文件内的position信息【CHANGE MASTER】。 –single-transaction 适用于innodb，保持数据一致性，隔离级别为：repeatable-read -A, –all-databases 备份所有库，等同于–databases DB1 DB2 。。。 -B, –databases 导出多个数据库 –ignore-table=database.table 备份库时忽略指定的表【可多次使用，每次一个表】 -d, –no-data 导出表结构【不导出数据】 -t, –no-create-info 导出数据【不添加create table语句】 -R, –routines 导出存储过程和自定义函数 -E, –events 导出事件 –skip-triggers 不导出触发器【默认导出–triggers】 备份库表备份所有库mysqldump [OPTIONS] --all-databases [OPTIONS] 备份多个库mysqldump [OPTIONS] --databases [OPTIONS] DB1 [DB2 DB3...] 备份单个库mysqldump [OPTIONS] database [tables] 第1个字符串为数据库 第2个字符串及之后字符串为数据表 备份表mysqldump db1 table1 &gt; db1_table1.sql 备份表数据mysqldump db1 table1 -t &gt; db1_table1.sql 备份表结构mysqldump db1 table1 -d &gt; db1_table1.sql 分库分表备份123456789101112131415161718DB_NAME=`mysql -uadmin -pzjht0724# -e &quot;show databases;&quot;|sed &apos;1,2d&apos;`mkdir /home/zj-db/backup/$(date +%F) -pcd /home/zj-db/backup/$(date +%F)# backup every database with every tablefor db in $DB_NAMEdo if [[ &quot;$db&quot; != &apos;information_schema&apos; &amp;&amp; &quot;$db&quot; != &apos;performance_schema&apos; &amp;&amp; &quot;$db&quot; != &apos;mysql&apos; &amp;&amp; &quot;$db&quot; != &apos;sys&apos; ]];then mkdir /home/zj-db/backup/$(date +%F)/$db -p TB_NAME=`mysql -uadmin -pzjht0724# -e &quot;show tables from $db;&quot;|sed &apos;1d&apos;` for tb in $TB_NAME do mysqldump -uadmin -pzjht0724# --lock-tables=0 $db $tb &gt; /home/zj-db/backup/$(date +%F)/$&#123;db&#125;/$&#123;tb&#125;.sql done # 备份压缩及加密 zip -r -Pzjht1234 $&#123;db&#125;.zip $db rm -rf $db fidone 导出存储过程与函数 注意事项：必须结合数据的导出 查看存储过程与函数 查看自定义函数：show function status; 查看存储过程：show procedure status; 操作：mysqldump crm_test -R &gt; crm_test.sql 备份选项全量备份与增量备份 全量备份：使用mysqldump命令导出的数据 增量备份：由于mysql的数据修改操作都记录在binlog中，执行日志文件切割轮转后，新增的binlog文件即视为增量备份 可以使用mysqldump -F或mysqladmin flush-logs切割轮转binlog文件 物理备份和逻辑备份 逻辑备份 物理备份 导出sql语句 直接复制数据文件 mysqldump scp、cp、rsync等 速度较慢 速度较快 支持server跨版本备份与恢复 要求导入和导出的server版本尽量一致 数据量小于100G使用逻辑备份 数据量大于100G使用物理备份 备份策略 每天凌晨做一个全量备份 在全量备份的同时执行日志轮转切割【flush-logs】作为增量备份点 binlog介绍binlog介绍 数据恢复：当数据库误删或者发生不可描述的事情时，可以通过 binlog 恢复到某个时间点的数据。 主从复制：当有数据库更新之后，主库通过 binlog 记录并通知从库进行更新，从而保证主从数据库数据一致； binlog功能设置 功能开关及文件名设置：log_bin=mysql-bin binlog日志格式：binlog_format=statement，可选参数值如下 statement：记录数据库执行的原始 SQL 语句 row：记录具体的行的修改，这个为目前默认值 mixed ：因为上边两种格式各有优缺点，所以就出现了 mixed 格式 binlog文件切换条件 文件大小达到max_binlog_size参数大小 执行 flush logs 命令 重启 mysql 服务 binlog删除 设置日志过期变量： 查看：show variables like ‘expire_logs_days’; 设置：set global expire_logs_days = 3; 手动删除日志 删除全部：reset master; 清除MySQL-bin.010之前的日志文件：PURGE MASTER LOGS TO ‘MySQL-bin.010’; 删除3天前：PURGE MASTER LOGS BEFORE DATE_SUB( NOW( ), INTERVAL 3 DAY); 删除指定日期前：PURGE MASTER LOGS BEFORE ‘2008-06-22 13:00:00’; binlog查看因为 binlog 是二进制文件，不能像其他文件一样，直接打开查看。但 mysql 提供了 binlog 查看工具 mysqlbinlog，可以解析二进制文件。不同格式的binlog查看方式也有不同，具体如下： statement：执行 mysqlbinlog /path/bin-log.000001，可以直接看到原始执行的 SQL 语句 row：则可读性没有那么好，但仍可通过参数使文档更加可读 mysqlbinlog -v /path/bin-log.000001 binlog解析命令mysqlbinlog -u, –user=name -h, –host=name -p, –password[=name] -P, –port=# -S, –socket=name -r, –result-file=name：导出内容到文件【重定向输出】 –server-id=#：只导出指定server-id的内容 –set-charset=name：设置字符集 –base64-output=DECODE-ROWS：将base64编码的内容解码，以便于查看内容 -d, –database=name 只导出指定数据库的内容 -o, –offset=# 跳过开始的n行内容 -start-datetime、–stop-datetime 解析两个时间点之间的 binlog，时间类型为DATETIME和TIMESTAMP 范例：mysqlbinlog mysql-bin.000001 -d seo -vv –base64-output=DECODE-ROWS –start-datetime=’2019-06-01 00:00:00’ –stop-datetime=’2019-07-01 00:00:00’ -r seo2.sql -start-position、–stop-position 解析两个position 之间的 binlog【包含开始点，不包含结束点】 范例：mysqlbinlog mysql-bin.000001 -d seo -vv –base64-output=DECODE-ROWS –start-position=46301253 –stop-position=46328958 -r seo3.sql binlog恢复数据指定库恢复将全量备份之后的binlog使用-d参数后导出指定数据库 指定表恢复 在测试库上将指定表所在库的数据恢复 将指定表的数据导出 将导出的表数据恢复到指定的库 备份与恢复操作 开启binlog，并且binlog不能有过期删除操作 【备份】mysqldump备份数据【全量备份】，添加-F参数切换binlog文件，并获取备份后的第一个binlog文件名【增量备份】 【问题】服务出现异常，查明是因为mysql出现问题操作 【停止服务】停止mysql的对外服务【可通过iptables封禁3306端口】 【保护现场】备份全量备份数据和所有的binlog文件，防止数据二次破坏 【获取增量备份（删除问题sql）】找到全量备份后的所有binlog，并使用mysqlbinlog工具将binlog转换为sql，同时删除有问题的sql语句 【恢复全量备份】 【恢复增量备份】 【开启服务】检查恢复结果，确认正常后，开启对外服务 参考 MySQL 通过 binlog 恢复数据]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysqlbinlog</tag>
        <tag>mysqldump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql安装与配置]]></title>
    <url>%2F2019%2F09%2F24%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmysql%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[官方参考参考手册：https://dev.mysql.com/doc/refman/5.6/en/ 源码安装依赖安装 cmake make OR gmake GCC 4.2.1 or later centos系列使用gcc* SSL library ncurses ubuntu16：libncurses5-dev、libncurses5 预配置 groupadd mysql useradd -r -g mysql -s /bin/false mysql mkdir /application 软件解压tar zxvf mysql-VERSION.tar.gz 编译配置 cd mysql-VERSION 保持源码位置干净 mkdir bld cd bld 编译配置： 安装基础目录：-DCMAKE_INSTALL_PREFIX=/application/mysql 数据存储目录：-DMYSQL_DATADIR=/application/mysql/data 建立mysql库文件libmysqld ：-DWITH_EMBEDDED_SERVER=ON 添加ssl支持：-DWITH_SSL=yes 默认字符集：-DDEFAULT_CHARSET=utf8 默认字符序：-DDEFAULT_COLLATION=utf8_general_ci 开启debug支持：-DWITH_DEBUG=1 显示当前编译变量列表及对应帮助信息：-LH 12345678cmake .. -DCMAKE_INSTALL_PREFIX=/application/mysql \-DMYSQL_DATADIR=/application/mysql/data \-DWITH_EMBEDDED_SERVER=ON \-DWITH_SSL=yes \-DDEFAULT_CHARSET=utf8 \-DDEFAULT_COLLATION=utf8_general_ci \-DWITH_DEBUG=1 \-LH 编译与安装 make make install 初始化数据 初始化数据：/application/mysql/scripts/mysql_install_db –basedir=/application/mysql –datadir=/application/mysql/data/ –user=mysql 变更目录权限：chown -R mysql.mysql /application/mysql 变更为系统服务 cp /application/mysql/support-files/mysql.server /etc/init.d/mysqld chmod +x /etc/init.d/mysqld sed -i ‘/^basedir=/s#=#&amp;/application/mysql#’ /etc/init.d/mysqld sed -i ‘/^datadir=/s#=#&amp;/application/mysql/data#’ /etc/init.d/mysqld 添加为系统服务：systemctl daemon-reload 设置开机启动 systemctl enable mysqld systemctl is-enabled mysqld 变更pid文件位置（/etc/init.d/mysqld） 示例：mysqld_pid_file_path=/application/mysql/mysqld.pid 用法：sed -i ‘/^mysqld_pid_file_path/s#=#&amp;/application/mysql/mysqld.pid#’ /etc/init.d/mysqld 系统重载配置：systemctl daemon-reload 正常启停控制：systemctl start mysql 配置环境变量 echo “export PATH=/application/mysql/bin:\$PATH” &gt;&gt; /etc/profile source /etc/profile 配置文件读取顺序 mysql不会读取其他人有写权限的配置文件【o+w】读取顺序如下，但是后读取的文件有高优先级 /etc/my.cnf、/etc/mysql/my.cnf SYSCONFDIR/my.cnf：默认是安装目录的etc子目录 $MYSQL_HOME/my.cnf【服务端】：MYSQL_HOME为用户自定义设置，或BASEDIR、DATADIR defaults-extra-file： 命令行选项–defaults-extra-file ~/.my.cnf：用户自定义 ~/.mylogin.cnf【客户端，较少使用】：用户登录类型配置定义 语法 配置文件和命令行语法类似【mysqld –verbose –help】，但是不包含命令行选项前导的双横向 井号#或分号;开始的行是注释，井号也可以出现在行中间 [group]：选项分组，分组名称和程序名称相同，如： [mysqld]：mysqld程序 [mysql]：mysql程序 [client]：所有客户端程序 [mysqldump]：mysqldump程序 opt_name：选项，与命令行–opt_name作用一样 opt_name=value：与命令行–opt_name=value作用一样 !include、!includedir：包含其他配置文件或目录 服务端配置项 mysqld读取[mysqld] and [server]配置项，类似的mysqld_safe读取[mysqld], [server], [mysqld_safe], and [safe_mysqld] 配置项 运行时查看与设置 查看变量：SHOW VARIABLES; 设置变量：SET [GLOBAL] var_name = value; 统计信息和状态值查看：SHOW STATUS; 配置文件设置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 服务端配置包含以下内容# 命令选项：https://dev.mysql.com/doc/refman/5.6/en/server-options.html# 系统变量：https://dev.mysql.com/doc/refman/5.6/en/server-system-variables.html# innodb参数：https://dev.mysql.com/doc/refman/5.6/en/innodb-parameters.html# 主从复制从配置：https://dev.mysql.com/doc/refman/5.6/en/replication-options-slave.html[client]default-character-set = utf8 socket = /application/mysql/mysqld.sock# user=&quot;root&quot;# password=&quot;root[mysqld]# 杂项lower_case_table_names = 0 #表名大小写敏感# 连接basedir = /application/mysql/datadir = /application/mysql/datasocket = /application/mysql/mysqld.sockpid_file = /application/mysql/mysqld.pidback_log = 300 #操作系统监听队列保持的连接数【默认50 + (max_connections / 5)】max_connections = 300 # mysql允许的连接数# 日志# log_err 自定义设置有bug：mysqld_safe error: log-error set to# https://bugs.mysql.com/bug.php?id=84427log_error = /application/mysql/mysqld.errslow_query_log = 1long_query_time = 1slow_query_log_file = /application/mysql/slow.log# binlog设置# expire_logs_days = 10 #保留的日志天数log-bin = mysql-binlog-bin-index = mysql-bin.indexbinlog_format = statement # binlog格式# 复制操作从配置server-id = 1 # replicate-ignore-db = mysql #忽略库mysql更新 # replicate-ignore-table=db_name.tbl_name #忽略表db_name.tbl_name更新 # log-slave-updates # 默认从库不写binlog；但，从库作为其他从库的主库时，需开启binlog写入【配合log-bin设置】# read-only=yes # 只读设置# slave-skip-errors = 1032,1062,126,1114,1146,1048,1396 #从库更新时跳过指定错误# relay-log-index = /usr/local/mysql/log/relaylog.index # relay-log设置# relay-log-info-file = /usr/local/mysql/log/relaylog.info# relay-log = /usr/local/mysql/log/relaylog 启动错误 现象：【Can’t start server : Bind on unix socket: Permission denied】 解决：查看my.cnf文件，找到.sock文件设置的路径，给此文件所在文件夹更改为mysql的用户所有，并且增加所有用户的读写权限]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>安装</tag>
        <tag>my.cnf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql介绍]]></title>
    <url>%2F2019%2F09%2F19%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmysql%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[版本 mysql-5.5 mysql-5.6【牧客，测试环境版本：5.6.43】 mysql-5.7【中冀汇通，全环境版本：5.7.17】 mariadb mysql-8.0 下载地址 mysql相关资源下载目录：https://www.mysql.com/products/community/ 社区版server下载地址：https://dev.mysql.com/downloads/mysql/ 体系架构 连接池组件 管理服务和工具组件 SQL接口、分析器、优化器、缓冲组件 存储引擎 物理文件 存储引擎 查看 查看支持的存储引擎：show engines;【常见引擎如上】 查看当前的存储引擎选项：show variables like ‘%engine%’; 查看表的存储引擎：show create table tb_name; 设置与修改 alter table table_name engine=innodb； 将表结构导出使用sed替换，将数据导出，再将表结构导入，数据导入 使用mysql_convert_table_format命令 建表时使用engine=innodb参数 InnoDB与MyISAM对比 MyISAM InnoDB 不支持事务 支持事务、分区、表空间 写操作时表级别锁定 写操作时行级别锁定 只缓存索引 缓存索引和数据 读操作会阻塞写操作 读写操作相对独立【根据事务隔离级别】 支持全表索引，不支持外键约束 支持外键约束，不支持全表索引 MyISAM 物理文件：每一个myisam表对应于硬盘上的3个文件。这三个文件有一样的文件名，但是有不同的扩展名以指示其用途： frm：保存表的定义，但这个文件不是myisam引擎的一部分，而是mysql数据库本身的一部分 MYD(data)：保存表的数据 MYI(index)：表的索引文件 应用： 并发较低的业务 以读为主的业务 不需要事务支持的业务 优化： 尽量索引及使用缓存 尽量顺序操作将数据插入尾部 分解复杂操作，延迟写入，批量插入 降低并发数，高并发应用引入排队机制 InnoDB 物理文件： ibdata1，默认表空间文件，通过innodb_data_file_path参数设置，所有基于innodb存储引擎的表都会存储在该文件中 如果想基于每个表单独生成一个表空间文件，可以设置参数innodb_file_per_table为ON，这样表的数据、索引、插入缓冲等信息会存储在单独的表空间文件中，但是其余的信息还是存储在默认的表空间文件中 frm：表结构定义文件，mysql里每个表和视图都对应一个frm文件。frm文件时mysql数据库的一部分，和存储引擎无关 ibd：单独的表空间文件 ib_logfile：innodb存储引擎的事务日志；在数据库实例意外宕机，重启后可以利用重做日志恢复到宕机前的一致性状态 应用： 支持高并发，但需要确保查询时通过索引完成 支持事务 数据更新频繁 优化： 避免全表扫描，因为会使用表锁 尽可能缓存所有索引和数据，提高响应速度，降低磁盘io 在大批量小插入时，尽量自己控制事务而不要使用autocommit自动提交 合理设置innodb_flush_log_at_trx_commit参数值，不要过度追求安全性 避免主键更新，因为这会带来大量的数据移动 主键尽可能小，避免给secondary index带来过大的空间负担 事务简介 在mysql中只有使用了innodb引擎的数据库才支持事务 事务处理可以用来维护数据库的一致性，保证多条sql语句要么全部执行，要么全部不执行 事务用来管理insert、update、delete语句 特点-ACID 原子性（Atomicity）：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性（Consistency）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。 隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。 持久性（Durability）：事务处理结束后，对数据的修改是永久性的 隔离级别 查询：SELECT @@tx_isolation;【默认REPEATABLE-READ】 设置：set session transaction isolation level 隔离级别 隔离级别 描述 解决的问题 引发的新问题 serializable 串行读取数据 虚读 数据库就变成了单线程访问的数据库，导致性能降低很多 repeatable read 可重复读 不可重复读 虚读：前后读取到表中的记录数不一样，读取到了其他事务插入的数据 read committed 读取提交的记录 脏读 不可重复读：一个事务读取表中的某一行数据时，多次读取结果不一致 read uncommitted 读取未提交的数据 - 脏读：一个事务读取了另外一个事务未提交的数据 开启事务mysql命令行下默认设置下，事务都是自动提交的；开启事务有以下两种方式： 关闭事务自动提交模式：SET AUTOCOMMIT=0 自动提交模式下，使用命令显式开启一个事务：begin或start transaction 事务控制语句 begin或start transaction：开启一个事务 commit：提交一个事务 rollback：结束用户的事务，并撤销之前的修改 savepoint identifier：在事务中创建一个保存点 release savepoint identifier：删除一个事务保存点 rollback to identifier：把事务回滚到保存点 字符集概念 字符集（character set）：字符和编码对组成的集合 字符序（collection）：同一个字符集内字符之间的比较规则 字符集变量字符集相关变量 查看支持的字符集：SHOW CHARACTER SET; 查看当前的字符集设置：show variables like ‘%character%’; character_set_client ：客户端使用的字符集，相当于网页中那个的字符集设置 character_set_connection：客户端连接数据库的使用的字符集 character_set_results：数据库给客户端返回时使用的字符集设定 character_set_system：数据库所在操作系统使用的字符集，character_set_system是个只读数据不能更改 character_set_server：数据库实例启动时的默认字符集，也是建库时的默认字符集 character_set_database：当前数据库的字符集设置，可通过建库语句查看。 字符序相关变量 查看支持的字符序：show collation; 查看当前的字符序设置：show variables like ‘%collation%’; collation_server：数据库实例默认校对规则 collation_database ：当前数据库的字符序设置 collation_connection：连接字符集校对规则 字符集的转换过程 客户端连接数据库时，如果不指定字符集【default-character-set】，则使用服务端默认设置【character-set-server】 mysql server收到请求时将请求从character_set_client转换为character_set_connection 进行内部操作前将请求数据从character_set_connection转换为内部操作字符集，确定顺序如下： 使用字段的字符集 使用表的字符集 使用库的字符集【建库时，未指定则使用character-set-server】 将操作结果从内部操作字符集转换为character_set_results返回给客户端 客户端设置 设置参数：default-character-set【服务端已不支持此参数】 影响变量： character_set_client character_set_connection character_set_results collation_connection 服务端设置字符集的继承关系 创建数据库没有指定字符集，使用character_set_server设定值 创建表没有指定字符集，默认使用数据库的的字符集 字段没有设置字符集，默认使用表的字符集 server级别设置 设置参数：character-set-server、collation-server 影响变量： character_set_server character_set_database collation_server collation_database 设置方式 服务启动时命令行指定：mysqld –character-set-server=latin1 配置文件my.cnf指定：character-set-server = utf8 运行时修改：SET character_set_server = utf8 ; database级别设置 查看库字符集：SHOW CREATE DATABASE db_name; 建库时设置：CREATE DATABASE db_name [[DEFAULT] CHARACTER SET charset_name] [[DEFAULT] COLLATE collation_name] 修改数据库的默认字符集：ALTER DATABASE db_name DEFAULT CHARACTER SET character_name [COLLATE ...]; 范例：alter database shiyan default character set utf8 COLLATE utf8_general_ci; table级别设置 查看表字符集：SHOW CREATE TABLE tbl_name; 建表时设置：CREATE TABLE tb_name ( id INT NOT NULL) DEFAULT CHARACTER SET = utf8; 修改表默认字符集：ALTER TABLE tbl_name DEFAULT CHARACTER SET character_name [COLLATE...]; 范例：ALTER TABLE logtest DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; 修改表的当前字符集：ALTER TABLE tbl_name CONVERT TO CHARACTER SET character_name [COLLATE ...] 范例：ALTER TABLE logtest CONVERT TO CHARACTER SET utf8 COLLATE utf8_general_ci; column级别设置 查看字符字符集：SHOW FULL COLUMNS FROM tbl_name; 新增字段设置：ALTER TABLE test_table ADD COLUMN char_column VARCHAR(25) CHARACTER SET utf8; 修改当前字段：alter table table_name modify column column_attr character set character_name [COLLATE ...] 范例：alter table test1 modify name char(10) character set utf8 COLLATE utf8_general_ci; 日志分类 一般日志：记录 mysql 正在运行的语句，包括查询、修改、更新等的每条 sql 功能开关：general_log=OFF 文件位置：general_log_file 错误日志：mysql运行过程中的错误信息 功能开关：无 文件位置：log_error 慢查询日志：记录查询比较耗时的 SQL 语句 功能开关：slow_query_log=OFF 阈值设置：long_query_time 文件位置：slow_query_log_file binlog日志：记录数据修改记录，包括创建表、数据更新等 功能开关：log_bin=ON 文件位置：log_bin_index、log_bin_basename SQL操作分类 DDL(数据定义语言)：create、alter、drop DML(数据修改语言)：insert、delete、update DQL(数据查询语言)：select、order by、group by、having DCL(数据控制语言)：create user、grant、revoke、drop user 参考 字符集设置]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>InnoDB</tag>
        <tag>存储引擎</tag>
        <tag>字符集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[站点到站点vpn]]></title>
    <url>%2F2019%2F09%2F17%2F%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AE%89%E5%85%A8%2F%E7%AB%99%E7%82%B9%E5%88%B0%E7%AB%99%E7%82%B9vpn%2F</url>
    <content type="text"><![CDATA[实现目标 IDC服务器和AWS云服务器在都只有一个公网出口的情况下【即：服务器只有内网ip，通过nat转换访问公网】实现内网ip互通【即：IDC服务器和AWS服务器可以ping通对方的内网ip地址】 使用openvpn软件架设穿透公网的vpn隧道 网络规划实现要点 在网关设备上采用SNAT，使内部网络可上互联网（跟普通家用wfi一个原理） 在网关设备上采用DNAT，将其wan address 的指定端口映射到内部openvpn-server的指定端口，(默认udp1194) 引流，在网关设备上将去往对端内网的流量，重定向到openvpn-server IDC机房 使用华为AR2240作为出口网关 内网1:10.86.0.0/24【作为主要内网，通过地址映射或地址转换实现内部服务器的联网】 内网2: 172.16.10.0/24【辅助内网，增加网络冗余】 选择一台内网服务器作为openvpn服务的宿主机【为了保证两端vpn服务可以建立连接，openvpn的服务端口应该被发布到公网】 AWS云 使用10.0.0.0/24作为内网 任意选择一台EC2作为代理服务器【此代理服务器应当具有外网ip】，代理内网服务器的Internet联网 另选一台EC2作为openvpn服务宿主机【为了保证两端vpn服务可以建立连接，openvpn的服务端口应该被发布到公网】 内网服务器访问公网 在只保留一个公网出口的情况下，内网服务器可以访问互联网 IDC机房 需要有公网ip的服务器通过地址映射将公网ip留在路由器上 不需要公网ip的服务器，只配置默认网关即可 AWS云 在aws上建立vpc，内网规划为10.0.0.0/24 在aws新建2个ec2，地址分别为10.0.0.60、10.0.0.61，申请弹性ip并绑定至61 在61上开启代理【作为代理服务器】 sysctl -w net.ipv4.ip_forward=1 iptables -t nat -A POSTROUTING -s 10.0.0.0/24 -o eth0 -j MASQUERADE 将其他ec2的默认网关更改为10.0.0.61 route del default gw 10.0.0.1 route add default gw 10.0.0.61 架设vpn隧道AWS云 将vpn服务端口发布到公网：iptables -t nat -A PREROUTING -i eth0 -d 1.1.1.1/32 -p tcp –dport port 8000 -j DNAT –to-destination 10.0.0.60:8000 生成用于安全认证的静态key文件：openvpn –genkey –secret /etc/openvpn/vpn.key 开启路由转发：sysctl -w net.ipv4.ip_forward=1 在60上开启vpn服务，配置如下： 1234567891011121314151617181920remote 42.62.65.23 #对端公网ipfloatport 8000dev tunifconfig 10.10.0.1 10.10.0.2 #设置本端和对端的隧道地址persist-tunpersist-keypersist-local-ippersist-remote-ipcomp-lzo #开启压缩secret /etc/openvpn/vpn.keyroute 10.86.0.0 255.255.255.0 #设置到对端私网的路由route 172.16.10.0 255.255.255.0route 192.168.10.0 255.255.255.0route 10.150.10.0 255.255.255.0chroot /var/emptyuser vpngroup vpnlog /var/log/vpn.log #配置日志verb 3 为了保证网络的可用性，使用supervisor守护openvpn服务 IDC机房 将vpn服务端口发布到公网 拷贝在aws生成的key文件到本地 余下操作参照aws上的操作即可 路由设置在网关设备上设置路由，将到对方内网的流量转发到vpn隧道所在服务器上 AWS云 在代理服务器61上设置 123route add -net 10.86.0.0 netmask 255.255.255.0 gw 10.0.0.60route add -net 172.16.10.0 netmask 255.255.255.0 gw 10.0.0.60route add -net 10.10.0.0 netmask 255.255.255.0 gw 10.0.0.60 IDC机房 在路由器AR2240设置静态路由【类命令如下】 12route add -net 10.0.0.0 netmask 255.255.255.0 gw 10.86.0.103route add -net 10.10.0.0 netmask 255.255.255.0 gw 10.86.0.103]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>vpn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高可用服务-keepalived]]></title>
    <url>%2F2019%2F09%2F16%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E4%BB%A3%E7%90%86%E4%B8%8E%E9%AB%98%E5%8F%AF%E7%94%A8%2F%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9C%8D%E5%8A%A1-keepalived%2F</url>
    <content type="text"><![CDATA[简介keepalived起初是专门为lvs设计的，专门用来监控lvs集群系统中各个服务节点的状态，后来又加入了VRRP（Virtual Router Redundancy Protocol）虚拟路由冗余协议。VRRP的出现是为解决静态路由出现的单点故障问题，他能保证网络的不间断、稳定的运行。所以keepalived有两个功能： 对lvs集群节点的健康检查【healthcheck】 对lvs集群LB节点的故障转移【failover】 VRRP keepalived directors 之间故障转移时通过VRRP协议实现的。 原理：在keepalived directors正常工作时，主director会不断的向备节点广播心跳消息，用以告诉备节点自己还活着；当主节点发生故障时，备节点就无法继续检测到主节点的心跳，进而调用自身的接管程序，接管主节点的ip资源和服务。而当主节点恢复故障时，备节点会释放自身接管的ip资源和服务，恢复到原来的备用角色 vrrp协议要点 通过竞选机制从backup中选出优先级最高的为master 只有master有发送vrrp广播的权利 vrrp广播可以告诉节点更新arp表信息 安装 下载 依赖安装：yum install openssl openssl-devel -y 安装 tar xzvf keepalived-1.1.17.tar.gz ./configure –sysconf=/etc make &amp;&amp; make install 规范化：ln -s /usr/local/sbin/keepalived /usr/sbin 配置主配置文件 即：keepalived.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051global_defs &#123; # 全局定义部分 notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id lvs_master #运行keepalived服务的服务器标识，主要用于发送邮件时显示&#125;vrrp_instance VI_1 &#123; # vrrp实例定义部分 state MASTER # 定义keepalived的角色：MASTER表示主服务器，BACKUP表示备用服务器 interface eth0 # 定义HA集群检测的服务接口 lvs_sync_daemon_interface eth1 # 定义HA集群检测的心跳接口【默认使用服务接口】 virtual_router_id 60 # 虚拟路由器标识，一个vrrp实例下的主备必须相同，不同vrrp实例的标识不同 priority 100 # 一个实例中主服务器优先级高于备用服务器 advert_int 1 # 心跳间隔 authentication &#123; auth_type PASS # 主备之间的认证类型 auth_pass 1234 # 主备之间的认证密码 &#125; virtual_ipaddress &#123; 192.168.100.120 #vip地址 &#125;&#125;virtual_server 192.168.100.120 80 &#123; # 虚拟服务器部分，虚拟服务器的ip和端口 delay_loop 6 # director的健康检查间隔 lb_algo wrr # 负载调度算法 lb_kind DR # 实现负载均衡的方式 persistence_timeout 50 # 会话保持时间 protocol TCP # director向RS转发的协议类型 real_server 192.168.100.111 80 &#123; # 真实服务器的ip和端口 weight 1 # 服务器在被调度时的权重 TCP_CHECK &#123; # director对real-server的检测类型 connect_timeout 3 # 连接超时时间 nb_get_retry 3 # 重试次数 delay_before_retry 3 # 重试间隔 &#125; &#125; real_server 192.168.100.112 80 &#123; weight 1 TCP_CHECK &#123; connect_timeout 3 nb_get_retry 3 delay_before_retry 3 &#125; &#125;&#125; 服务启动参数 /etc/sysconfig/keepalived【centos】或/etc/default/keepalived【ubuntu】 12345678910111213# Options for keepalived. See `keepalived --help&apos; output and keepalived(8) and# keepalived.conf(5) man pages for a list of all options. Here are the most# common ones :## --vrrp -P Only run with VRRP subsystem.# --check -C Only run with Health-checker subsystem.# --dont-release-vrrp -V Dont remove VRRP VIPs &amp; VROUTEs on daemon stop.# --dont-release-ipvs -I Dont remove IPVS topology on daemon stop.# --dump-conf -d Dump the configuration data.# --log-detail -D Detailed log messages.# --log-facility -S 0-7 Set local syslog facility (default=LOG_DAEMON)KEEPALIVED_OPTIONS=&quot;-D -d -S 0&quot; 日志设置 设置系统syslog 配置设置：echo “local0.* /var/log/keepalived.log” &gt;&gt; /etc/rsyslog.conf 重启syslog服务：/etc/init.d/rsyslog restart 服务控制 启动服务：/etc/init.d/keepalived start 开机自启：chkconfig keepalived on]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[负载均衡器-lvs]]></title>
    <url>%2F2019%2F09%2F15%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E4%BB%A3%E7%90%86%E4%B8%8E%E9%AB%98%E5%8F%AF%E7%94%A8%2F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8-LVS%2F</url>
    <content type="text"><![CDATA[原理LVS的全称是Linux virtual server，即Linux虚拟服务器。之所以是虚拟服务器，是因为LVS自身是个负载均衡器(director)，不直接处理请求，而是将请求转发至位于它后端真正的服务器realserver上。 lvs技术实现 四层负载均衡：网络及传输层实现的IP虚拟服务器软件IPVS；ipvs是集成在内核中的框架，可以通过用户空间的程序ipvsadm工具来管理，该工具可以定义一些规则来管理内核中的ipvs，就像iptables和netfilter的关系一样。这也是本文介绍的功能。 七层负载均衡：基于内容请求分发的内核Layer-7交换机KTCPVS【功能尚不完善，使用的人不多】 集群管理软件：redhat公司从其6.1发行版起已包含LVS代码，他们开发了一个LVS集群管理工具叫Piranha，用于控制LVS集群，并提供了一个图形化的配置界面。【但此工具已被Redhat官方废弃，相应功能已使用haproxy和keepalived代替】 ipvs技术术语 LB：负载均衡器所在服务器 RS：提供真实服务的服务器 CIP（client IP）：客户端ip地址 RIP（realserver IP）：真实提供服务的服务器ip地址 DIP（director IP）：负载均衡器（director）上转发数据包到realserver的网卡地址 VIP（virtual IP）：负载均衡器（director）上用于向客户端提供服务的ip地址 ipvs的工作模式当用户的请求到达负载调度器后，调度器如何将请求发送到提供服务的Real Server节点，而Real Server节点如何返回数据给用户，这正是IPVS实现的重点技术，IPVS实现负载均衡的机制有三种: VS/NAT（virtual server via network address translation）：通过网络地址转换将一组服务器构成一个高性能、高可用的虚拟服务器 VS/TUN（vertual server via tunneling）：在分析VS/NAT的缺点和网络服务的非对称性的基础上提出的通过ip隧道实现虚拟服务器 VS/DR（vertual server via director routing）：通过直接路由实现虚拟服务器 FULLNAT：淘宝开源实现的模式，数据包进入LB时，同时对源地址和目标地址进行转换，从而实现RS可以跨VLAN通信，RS只需要连接内网，这样可以保证安全性。进站和出站的LB不一定是同一台机器。 NAT模式 原理：通过网络地址转换，调度器LB重写请求报文的目标地址，根据预设的调度算法，将请求分派给后端的真实服务器，真实服务器的响应报文处理之后，返回时必须通过调度器（节点服务器的网关为负载均衡服务器），经过调度器时报文的源地址被重写，再返回给客户端，完成整个负载调度过程。 实现要点 节点服务器需要将网关配置为LB的ip地址，这样才能保证报文经过LB，报文才能被改写 LB节点配置VIP和内核转发功能 nat模式支持对ip及端口的转换 优缺点：由于请求和响应的报文都经过LB【也就是像7层负载的处理方式一样，但却没有7层负载那么”多功能”】，而响应数据一般比请求数据大得多，LB的负载压力过大，调度器Director容易出现瓶颈 TUN模式 原理：调度器把请求的报文通过ip隧道（将请求的报文封装在另一个ip报文中）转发至真实服务器，而真实服务器将处理后的响应报文直接返回给客户端。 实现要点： LB和RS节点都需要配置ip隧道功能 LB和RS服务器lo网卡都要绑定VIP【防止真实网卡绑定vip造成ip冲突】，同时在RS上配置不对vip的arp广播请求响应，这样可以保证目标地址为vip的数据包只被director接受。 优缺点： 调度器就只处理请求的入站报文。由于一般网络服务应答数据比请求报文大很多，采用此模式后，系统吞吐量可以提高10倍。 TUN模式的LAN环境转发不如DR模式效率高，而且还要考虑系统对ip隧道的支持问题 LAN环境一般多采用DR模式，WAN环境可以用TUN模式，但在当前WAN环境下，请求转发更多被haproxy、nginx、dns调度取代，因此应用不多。 DR模式 原理：DR模式通过改写请求报文的目标MAC地址【请求地址仍为VIP】，将请求转发给真实的服务器，而真实服务器将响应后的处理结果直接返回给客户端。 实现要点 要求调度器LB与真实服务器RS都有一块网卡连接在同一物理网段上。 在LB和RS节点都需要配置VIP，并在RS配置抑制对vip的arp广播响应 调度器不需要开启内核转发功能 RS与director的监听端口必须一致 优缺点： 这种模式没有IP隧道的开销，对集群中的真实服务器也没有必须支持ip隧道协议的要求 模式对比 项目 vs/nat vs/tun vs/dr server any Tnuneling Non-arp device server network private LAN/WAN LAN server number low High High server gateway load balancer own router own router 在性能上，VS/DR和VS/TUN远高于VS/NAT，因为调度器只处于从客户到服务器的半连接中，按照半连接的TCP有限状态机进行状态迁移，极大程度上减轻了调度器的压力(真正建立TCP连接的是RS和Client)。VS/DR性能又稍高于VS/TUN，因为少了隧道的开销 VS/DR和VS/TUN的主要区别是VS/TUN可以跨网络实现后端服务器负载均衡(也可以局域网内)，而VS/DR只能和director在局域网内进行负载均衡。 ipvs调度算法IPVS在内核中的负载均衡调度是以连接为粒度的。在HTTP协议（非持久）中，每个对象从WEB服务器上获取都需要建立一个TCP连接，同一用户 的不同请求会被调度到不同的服务器上，所以这种细粒度的调度在一定程度上可以避免单个用户访问的突发性引起服务器间的负载不平衡。在内核中的连接调度算法上，IPVS已实现了八种调度算法，其中，又根据运行方式不同，分为两大类：静态调度和动态反馈调度 静态调度 不管RS的繁忙程度，根据调度算法计算后轮到谁就调度谁。 轮叫调度（Round-Robin Scheduling，rr） 加权轮叫调度（Weighted Round-Robin Scheduling，wrr），按照权重比例作为轮询标准 目标地址散列调度（Destination Hashing Scheduling，dh），目标地址哈希，对于同一目标IP的请求总是发往同一服务器； 源地址散列调度（Source Hashing Scheduling，sh），源地址哈希，在一定时间内，只要是来自同一个客户端的请求，就发送至同一个realserver。源地址散列调度和目标地址散列调度可以结合使用在防火墙集群中，它们可以保证整个系统的唯一出入口。 动态反馈调度 根据RS的繁忙程度反馈，计算出下一个连接应该调度谁(动态反馈负载均衡算法考虑服务器的实时负载和响应情况，不断调整服务器间处理请求的比例，来避免有些服务器超载时依然收到大量请求，从而提高整个系统的吞吐率)。 最小连接调度（Least-Connection Scheduling，lc），调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某服务器，其连接数加1；当连接中止或超时，其连接数减1。当各个服务器的处理能力不同时，该算法不理想。 加权最小连接调度（Weighted Least-Connection Scheduling，wlc）：ipvs默认调度算法 基于本地的最少连接（Locality-Based Least Connections Scheduling，lblc） 带复制的基于局部性最少连接（Locality-Based Least Connections with Replication Scheduling，lblcr）：目前主要用于Cache集群系统；因为在Cache集群中客户请求报文的目标IP地址是变化的。 综合负载计算算综合负载时，我们主要使用两大类负载信息：输入指标和服务器指标输入指标：主要是在单位时间内服务器收到新连接数与平均连接数的比例，它是在调度器上收集到的。服务器指标： 主要记录服务器各种负载信息，如服务器当前CPU负载LOADi、服务器当前磁盘使用情况Di、当前内存利用情况Mi和当前进程数目 Pi。【有两种方法可以获得这些信息；一是在所有的服务器上运行着SNMP（Simple Network Management Protocol）服务进程，而在调度器上的Monitor Daemon通过SNMP向各个服务器查询获得这些信息；二是在服务器上实现和运行收集信息的Agent，由Agent定时地向Monitor Daemon报告负载信息。】 一个重要的服务器指标是服务器所提供服务的响应时间，它能比较好地反映服务器上请求等待队列的长度和请求的处理时间。调度器上的Monitor Daemon作为客户访问服务器所提供的服务，测得其响应时间。 权重计算 在实际使用中，若发现所有服务器的权值都小于他们的DEFAULT_WEIGHT，则说明整个服务器集群处于超载状态，这时需要加入新的服务器结点 到集群中来处理部分负载； 反之，若所有服务器的权值都接近于SCALE*DEFAULT_WEIGHT，则说明当前系统的负载都比较轻。 源码安装 由于官方文档及网络均无ubuntu下源码安装参考，所以此处源码安装特指centos下的源码安装 lvs官方下载地址 最新版本ipvsadm 依赖安装 依赖安装：yum install gcc* make kernel-devel libnl* popt* -y 编译安装参考 设置内核软链接：ln -s /usr/src/kernels/$(uname -r) /usr/src/linux 编译安装 tar xzf ipvsadm.tar.gz make make install 安装结果测试 命令是否存在：ipvsadm 模块是否存在：lsmod |grep ip_vs 配置准备1台LB和2台RS服务器；节点关闭防火墙和selinux LB节点设置 LB主机添加vip地址：ifconfig eth0:0 192.168.100.10/24 up 设置tcp超时参数：ipvsadm –set 30 5 60 LB添加vip及设置调度算法：ipvsadm -A -t 192.168.100.10:80 -s rr LB添加RS节点： ipvsadm -a -t 192.168.100.10:80 -r 192.168.100.1:80 -g ipvsadm -a -t 192.168.100.10:80 -r 192.168.100.2:80 -g RS节点设置 lo网卡配置vip：ifconfig lo:1 192.168.100.10/32 up 添加路由【多网卡环境】：route add -host 192.168.100.10 eth0 设置节点抑制arp 1234echo 1 &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt;/proc/sys/net/ipv4/conf/lo/arp_announceecho 1 &gt;/proc/sys/net/ipv4/conf/all/arp_ignore echo 2 &gt;/proc/sys/net/ipv4/conf/all/arp_announce 状态查看watch –interval=2 ipvsadm -Ln【watch持续监控LB状态】 其他操作命令 ipvsadm -L 查看LB-director信息 ipvsadm -C 清空配置信息 ipvsadm -d 删除配置条目 控制脚本 DR模式-LB节点控制脚本 DR模式-RS节点控制脚本 TUN模式-RS节点控制脚本 主LB对RS节点执行健康检查 在备LB上实现对主LB的健康检查和接管【类似keepalived】 故障与排查 负载不均 访问量较少，不均衡现象更加明显 会话保持【lvs或后端服务】 调度算法及用户请求的类型【时间长短、资源大小】 故障 调度器上lvs调度规则及ip地址的正确性 要在RS进行服务检查 RS节点绑定vip和抑制arp检查【对绑定的vip做实时监控并报警】 辅助排查工具tcpdump、ping 本文参考：https://www.cnblogs.com/wyzhou/p/9741790.html]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>lvs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[负载均衡器-haproxy]]></title>
    <url>%2F2019%2F09%2F10%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E4%BB%A3%E7%90%86%E4%B8%8E%E9%AB%98%E5%8F%AF%E7%94%A8%2F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8-haproxy%2F</url>
    <content type="text"><![CDATA[软件安装 yum或apt方式安装 源码安装 12make TARGET=linux2628 USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 make install 配置主配置haproxy.cfg详细配置，请查看 ！！！ global：全局设置，通常和操作系统相关，如进程 defaults：默认配置，可以被frontend、backend、listen部分继承 fontend：用来接收客户端请求，根据域名、uri等定义不同的匹配规则，并将请求转发给不同的backend backend：定义后端服务器集群，并设置后端服务器的权重、连接超时、调度、健康检查等 listen：可以理解为backend和fontend的组合体 日志设置 haproxy使用系统syslog的方式写日志【udp协议，514端口】 123$ModLoad imudp$UDPServerRun 514local0.* /usr/local/haproxy/logs/haproxy.log 服务控制服务控制 重载配置：service haproxy reload 启动、停止、重启：start/stop/restart haproxy命令选项 -f：指定配置文件 -c：检测配置文件语法 -D：守护进程模式 -p pid：指定启动后的pid文件 -sf/-st [pid ]*：终止旧的pid【hard、soft】 socket命令 前置要求：在配置文件haproxy.cfg的global区段配置【stats socket /var/run/haproxy.sock mode 600 level admin】 作用：连接socket后，管理负载均衡器代理的前后端服务器【fontend、backend】 工具：socat是类似于netcat的工具，名字来由是Socket CAT，可以看作是netcat的N倍加强版，主要特点就是在两个数据流之间建立通道 socat用法： help信息：echo “”|sudo socat stdio /var/run/haproxy.sock 状态查看：echo “show stat”|sudo socat stdio /var/run/haproxy.sock 启停server：echo “enable server service_marketinfo/172.17.134.60”|sudo socat stdio /var/run/haproxy.sock]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[域名解析服务-bind9]]></title>
    <url>%2F2019%2F09%2F09%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E8%BE%85%E5%8A%A9%E5%BC%80%E5%8F%91%2F%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E6%9C%8D%E5%8A%A1-bind9%2F</url>
    <content type="text"><![CDATA[软件安装sudo apt-get install bind9 -y 配置修改 named.conf.options 1234forwarders &#123; 202.106.196.115; //配置将不能解析的请求转发到哪[配置转发时，可不需配置根区域文件] &#125;; allow-query &#123;0.0.0.0/0;&#125;; //接收哪个网段下的解析请求 named.conf.local 1234zone &quot;example.com&quot; &#123; type master; file &quot;/etc/bind/db.example.com&quot;;&#125;; db.example.com 1234567891011121314151617181920;此域的权威授权服务器为本机@ IN NS localhost.;解析example.com IN A 1.1.1.1;www.example.com解析设置www IN A 1.1.1.1test1 IN A 10.10.10.244;test2.example.com 与test1.example.com互为别名test2 IN CNAME test1;test3.example.com 与 www.abc.com互为别名test3 IN CNAME www.abc.com.;邮件服务器解析@ IN MX 10 mail.example.com.mail IN A 192.168.1.2;基于域名解析的负载均衡www2 IN A 1.1.1.2www2 IN A 1.1.1.3www2 IN A 1.1.1.4;泛域名解析* IN A 1.1.1.5 功能测试 nslookup 123&gt;www.example.com&gt;set type=mx #测试此域名下的邮件服务&gt;example.com dig dig www.example.com 非常用功能 反向解析 主从复制 主配置 12345 zone &quot;abc.com&quot; IN &#123; type master; file &quot;abc.com.zone&quot;; allow-transfer &#123; 192.168.0.98; &#125;; //允许从机复制&#125;; 从配置 12345zone &quot;abc.com&quot; IN &#123; type slave; file &quot;abc.com.zone&quot;; masters &#123; 192.168.0.99; &#125;; //从哪个主机复制内容&#125;; 分离解析[内外网解析不同的结果] 123456789101112131415161718view &quot;lan&quot; &#123; match-clients &#123; 192.168.0.0/24; &#125;; zone &quot;abc.com&quot; IN &#123; type master; file &quot;abc.com.lan&quot;; &#125;; zone &quot;.&quot; IN &#123; type hint; file &quot;named.ca&quot;; &#125;;&#125;;view &quot;wan&quot; &#123; match-clients &#123; any; &#125;; zone &quot;abc.com&quot; IN &#123; type master; file &quot;abc.com.wan&quot;; &#125;;&#125;; 子域委派【父域abc.com 不解析对子域da.abc.com的dns请求，将对子域的解析请求传给子域】 123# zone区域配置da IN NS ds-dns.abc.com.ds-dns IN A 192.168.0.98]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>bind9</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux系统原理-文件系统]]></title>
    <url>%2F2019%2F09%2F03%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2Flinux%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[文件系统实质：组织和存储数据的一种机制 文件类型 以ls -l命令的输出的第一个符号为区别标志，其中字符设备、块设备、FIFO文件可使用mknod命令创建 普通文件：文本文件、二进制文件、数据文件 ll表示：首字符显示为”-“ 范例：lsof.txt文件：-rw-rw-r-- 1 muker muker 135522 Jul 18 13:17 lsof.txt 目录 ll表示：首字符显示为“d” 范例：roles目录：drwxrwxr-x 7 muker muker 4096 Jun 21 17:31 roles/ 符号链接：表示软连接 ll表示：首字符显示为”l” 范例：lrwxrwxrwx. 1 root root 7 Oct 15 2017 /bin/python -&gt; python2 套接字文件：用于网络通信 ll表示：首字符显示为“s” 范例：supervisor程序的socket文件：srwx------ 1 root root 0 May 22 14:33 /var/run/supervisor/supervisor.sock 字符设备文件：表示串行端口设备、管道类型设备，提供输入输出功能 ll表示：首字符显示为”c“ 范例：pts虚拟终端：crw--w---- 1 muker tty 136, 0 Jul 19 09:16 /dev/pts/0 块设备文件：表示提供存储功能的设备 ll表示：首字符显示为”b“ 范例：vda磁盘：brw-rw---- 1 root disk 253, 0 May 22 17:12 /dev/vda FIFO文件：命名管道文件，提供双向通信 ll表示：首字符显示为“p” 管道的不同区别：FIFO是命名的双向通道，任何程序任何时间都可以通过此管道进行双向通信；而“|”是无名的单向通道，管道运行完即销毁 软链接与硬链接 实质： 软链接是新建一个文件（软链接使用不同于源文件的新inode号），文件内容记录源文件或目录的路径信息，相当于windows的快捷方式 硬链接相当于为文件建立一个新的索引别名（硬链接和源文件使用相同的inode号），源文件和硬链接除了名称不一样外，其他属性信息完全相同 不能对目录建立硬链接，也不能跨文件系统对文件建立硬链接 可以在同一文件系统或跨文件系统，对目录或文件建立软链接 删除源文件，软链接失效，硬链接依然可以显示文件内容 生产现场经常使用软链接【相对硬链接限制更少】；而许多硬件设备的快照功能则类似硬链接 文件删除 原理：linux系统对文件的删除是通过控制文件的link数达到的，而link数主要由i_nlink（硬链接数，磁盘引用次数）和i_count（文件被进程调用的次数，内存引用次数），只有当这两个数值同时为0时，文件（确切的说是文件名及相应的inode）才从文件系统中消失。但此时若无新数据写入或系统未执行磁盘检查收回空间，数据还是可以找回的 删除条件： 硬链接都被删除（i_nlink为0） 没有被进程调用（i_count） 实际存储空间没有被覆盖或回收 范例：磁盘幽灵空间 现象：df与du统计相差巨大 原因：文件被删除，但是使用这些文件的进程还在，造成空间不能释放 解决：使用 lsof|grep deleted 查看占用删除文件的进程，重启或删除相关进程 范例：web服务日志写满磁盘，删除日志后，磁盘空间依然充满未被释放；此时重启apache服务，磁盘空间释放，日志可重新写入。 tmpfs简介默认系统就会启用tmpfs，以实现特殊功能，如保存系统运行状态；tmpfs是临时文件系统，是一种基于内存的文件系统，它和虚拟磁盘ramdis比较类似，但不完全相同。和ramdisk一样，tmpfs可以使用RAM，但它也可以使用swap分区来存储；ramdisk是个传统的块设备，需要使用mkfs格式化后才能使用；tmpfs是一个文件系统，直接挂载就可以使用。 使用 查看使用情况：df -h fstab设置：tmpfs /dev/shm tmpfs defaults,size=64g 0 0 卸载：umount /dev/shm 加载：mount /dev/shm 实时修改tmpfs大小：mount -o remount,size=64G /dev/shm 范例 oracle启动错误：ORA-00845: MEMORY_TARGET not supported on this system 原因与解决：tmpfs管理下的物理内存或swap不足，此时可通过增加tmpfs大小解决问题（首先增加swap大小） 磁盘 fdisk -l命令结果 1234Disk /dev/sda: 120.0 GB, 120034123776 bytes255 heads, 63 sectors/track, 14593 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytes 磁盘容量大小 255个磁头(heads)，63个扇区(sectors)/磁道(track)，14593个柱面(cylinders) 每个柱面大小(units)=扇区数(25563)扇区大小(512) 扇区大小512 组成 纵切图看，一个磁盘有多个盘片，每个盘片对于2个盘面，一个盘面对应一个磁头(heads) 横切图看，一个盘面有多个磁道(track)，一个磁道有多个扇区(sector)【磁盘存储的最小单位】 俯视图看，多个盘面相同半径的磁道共同构成一个柱面(cylinders)【磁盘分区的最小单位】 容量计算 磁盘容量：磁头数*磁道/柱面数*每道扇区数*扇区大小，即：255*14593*63*512=120031511040 缩写式：柱面大小(units)*柱面数(cylinders) 数据三维地址：磁头、柱面/磁道、扇区 读写 读写原理：将磁粒子的极性转换为电脉冲信号 读写流程：从盘片的边缘向里依次从0磁道开始读写 raid 简介：RAID(redundant arrays of independed disk)：廉价且具有冗余功能的磁盘阵列 功能：提供比单个物理磁盘更大的存储容量及不同级别的数据冗余备份 raid0 生产中使用单盘也要做成raid0，否则无法使用 原理：将连续的数据交叉存储在多个磁盘上（stripe-条带存储）， 容量计算：最少需要1个磁盘，总容量=各盘容量之和 优点：磁盘利用率高【100%】 缺点：无冗余备份，1块磁盘损坏raid就不能使用 raid1 原理：将数据分成完全一样的两份写入两块磁盘【mirror-镜像存储】 容量计算：2个磁盘，总容量=最小的那块磁盘 优点：有冗余备份，安全性好 缺点：磁盘利用率低【50%】，成本高 raid5 原理：将数据和数据的奇偶校验码交叉存储在不同的磁盘 容量计算：最少需要3个磁盘，总容量=最小磁盘容量*（磁盘数-1） 优点：兼顾安全性和成本【可以损坏1块磁盘，当损坏磁盘大于等于2块时，数据彻底损坏】 热备盘【hot spare】：当阵列中的某颗磁盘损毁时，spare disk被主动拉进阵列，坏磁盘被移除阵列，实时进行数据重建 raid10 也有raid01，但是服务器常用只有raid10 原理：先组成raid1，再组成raid0 容量计算：最少需要4个磁盘，且为偶数个磁盘，总容量=所有盘容量之和的一般 优点：安全性好 缺点：磁盘利用率低【50%】，成本高 分区 分区实质：划分起止柱面号 格式化实质：创建文件系统 分区工具：fdisk【小于2T】和pated【大于2T】 MBR MBR(广义)：每个磁盘只有一个主引导扇区，它不属于任何分区【所以格式化不能清除mbr】 物理位置：位于0柱面，0磁道，1扇区 组成：主引导程序、硬盘分区表、硬盘有效标志 主引导程序（boot-loader）占用446个字节 包含开机管理程序，直接指向可开机的程序区段，引导操作系统启动 提供多重引导选项，将控制权移交到其他boot-loader 分区表（DPT）占用64字节，每个分区表项长16个字节，一共4个，所以最多4个主分区(磁盘限制)或扩展分区（操作系统显示只能有一个扩展分区） 硬盘有效标志（MN）占2字节，内容：55AA 分区构成 组成(格式化后分区构成)：启动扇区、数个块组 启动扇区(boot sector) 每个分区都有一个启动扇区 可以装载开机管理程序【boot-loader】，以用于多重引导 对linux来说，安装时默认在分区boot-sector保存一份boot-loader，可选择是否在MBR保存另一份【只安装linux系统时，则必须在mbr也安装一份】 对windows来说，强制在MBR和分区boot-sector各保存一份boot-loader【所以双os需先安装windows后linux】 块组（block group） 块组（block group）：可通过dumpe2fs查看分区superblock和block group信息 super block：存储block和inode的大小、已用、未用数量，分区的挂载与否，挂载时间等【每个分区只有一个super block，块组中第一个块组包含超级块，其他块组可能包含super block，但只是作为第一个超级块的备份】 文件系统描述：说明block group、block bitmap、inode bitmap、inode table等的起止block号 block映射表：显示区块号是否被使用 inode映射表：显示inode号是否被使用 inode table：显示文件属性（不包含文件名），显示文件实际存储的block号，常用大小256字节；每个文件一个inode号(指向数据实际存储区域) data block：用于实际存储数据，块由扇区组成，常用块大小4K；文件根据大小占用数量不等的block 区块(block)是文件系统读写的最小单位（windows下为簇） block大小应当适量：block过大浪费磁盘空间；block过小则影响读写速度。 注意 安装linux时强制将/boot设为主分区，以使/boot分区位于磁盘的最前面 swap分区非必需的，内存较大负载不高时可以不分。 LVM LVM(logical volume manage)逻辑卷管理，一个灵活的扩展分区管理工具 新建LVM新建LVM分区 新建分区：fdisk /dev/sdb n,p,w 更改分区类型为lvm：t 8e 新建物理卷 新建：pvcreate /dev/sdb1、pvcreate /dev/sdc1 物理卷命令： pvcreate ：将实体 partition 建立成为 PV； pvscan ：搜寻目前系统里面任何具有 PV 的磁盘 pvdisplay ：显示出目前系统上面的 PV 状态； pvremove ：将 PV 属性移除，让该 partition不具有PV属性。 新建卷组 新建：vgcreate -s 8M cipan /dev/sdb1 /dev/sdc1【在磁盘分区sdb1，sdc1上创建pe大小为8M，名称为cipan的卷组】 卷组命令： vgcreate ：就是主要建立 VG 的指令 vgscan ：搜寻系统上面是否有 VG 存在 vgdisplay ：显示目前系统上面的 VG 状态 vgextend ：在 VG 内增加额外的 PV vgreduce ：在 VG 内移除 PV vgchange ：设定 VG 是否启动 (active) vgremove ：移除一个 VG 新建逻辑卷 新建：lvcreate -L 5G -n juan1 cipan【在卷组cipan中添加大小为5G名称为juan1的逻辑卷】 逻辑卷命令： lvcreate ：建立 LV 啦 lvscan ：查询系统上面的 LV lvdisplay ：显示系统上面的 LV 状态啊 lvextend ：在 LV 里面增加容量 lvreduce ：在 LV 里面减少容量 lvremove ：移除一个 LV lvresize ：对 LV 迚行容量大小的调整 格式化1234mkfs.ext4 /dev/cipan/juan1 mkdir /juanmount /dev/cipan/juan1 /juan/df -h LVM扩容 新建分区：fdisk /dev/sdd 新建物理卷：pvcreate /dev/sdd1 扩容卷组：vgextend /dev/cipan /dev/sdd1 扩容逻辑卷：lvextend -L 8G /dev/cipan/juan1 文件系统扩容：resize2fs -p /dev/cipan/juan1 逻辑卷重新挂载：mount -o remount,rw /juan/ LVM减容 卸载逻辑卷：umount /dev/cipan/juan1 文件系统减容：resize2fs /dev/cipan/juan1 4G 减容前 强制逻辑卷检查：fsck -f /dev/cipan/juan1 逻辑卷减容：lvreduce -L 4G /dev/cipan/juan1 挂载逻辑卷：mount /dev/cipan/juan1 /juan 卷组减容【后续】：vgreduce /dev/cipan /dev/sdc1 删除LVM 卸载逻辑卷：umount /dev/cipan/juan1 删除逻辑卷：lvremove juan1 删除卷组：vgremove cipan 删除物理卷：pvremove /dev/sdb1 开机过程 centos6系统启动过程 BIOS开机自检：检测硬件是否存在故障；根据bios设置确定引导次序 MBR引导：bios读取MBR中的boot-loader（grub程序） grub引导【可选】：grub程序读取grub配置(grub.conf)，显示grub菜单选项（将开机管理功能转交给其他loader（boot sector）负责） 加载kernel(此时kernel从bios取得系统控制权,并再次扫描硬件情况)和initrd，挂载根文件系统rootfs，并切换到根目录 initrd：虚拟文件系统，在内存中仿真成根目录；它包含一个可执行程序，能够帮助kenel加载真实根文件系统rootfs所需驱动程序 启动init进程，读取配置文件【/etc/inittab或/etc/init目录下所有文件】，确定启动级别 读取/etc/rc.sysinit文件，完成系统初始化设定 激活udev和selinux 设置内核参数/etc/sysctl.conf 设置系统时钟 设置网卡 启用交换分区 加载键盘映射 激活RAID和lvm逻辑卷 挂载额外的文件系统/etc/fstab 设置环境变量 根据启动级别加载相应级别/etc/rc*.d下的服务脚本 执行/etc/rc.local中用户自定义脚本 使用Mingetty命令调出tty终端或使用prefdm调出x-windows供终端用户登录 启动级别 0 关机 1 单用户模式 2 无网络多用户命令行模式 3 有网络多用户命令行模式 4 不可用 5 带图形界面的多用户模式 6 重启 grub.conf配置 inittab详解 参考 MBR和启动扇区]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>磁盘</tag>
        <tag>分区</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux系统-文件管理]]></title>
    <url>%2F2019%2F08%2F27%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2Flinux%E7%B3%BB%E7%BB%9F-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[cat：显示文件内容 -n：显示行号 -b：忽略空白行，显示行号 -A：显示所有非打印字符【比如tab、换行符等】 ls：显示目录内容 ln：在文件之间建立链接 无参数时建立硬链接 -s：建立软连接 pwd：显示当前绝对路径 cd：切换目录 mv：移动或重命名文件/目录 rm：删除文件或目录 -r：递归删除目录及其内容 -f：强制删除不提示 cp：复制文件和目录 touch：改变文件时间戳，没有则创建 mkdir：创建目录 -p 存在不报错，根据需要创建父目录 tar：建立归档文件 zip、unzip：压缩文件 gzip、gunzip：打包、压缩文件或目录 dos2unix/unix2dos：windows与unix文件格式转换 tree：树形态查看目录结构 file：查看文件类型【文件类型可以是：链接、二进制、可执行等】 stat：查看文件状态【包含属主组、权限、大小、inode、block、时间戳等】 dd：用指定大小的块复制文件 diff：显示两个文件之间的差异 du：显示文件占用磁盘空间大小 df：显示磁盘空间使用情况 fdisk：MBR分区工具 parted：GPT分区工具 mount：文件系统挂载 fsck、e2fsck：文件系统检查与修复 badblocks：检查磁盘是否有坏道（等同于mke2fs -c） dumpe2fs：显示分区superblock和blocks group信息 格式化： 格式化主分区(建立文件系统)-mkfs：(mkfs –t 分区类型/mkfs.分区类型) /dev/sdb1(设备) 格式化交互分区(建立swap)-mkswap：mkswap /dev/sdb5(设备) 启用交互分区：swapon (-a 所有) /dev/sdb5 关闭交互分区：swapoff (-a 所有) /dev/sdb5 dd参数 if=文件名：输入文件名 of=文件名：输出文件名 bs=bytes：同时设置输入/输出的块大小【默认bytes，可选单位(k)K/M/G】 ibs：输入块大小 obs：输出块大小 count=blocks：复制的块个数 范例 备份磁盘：dd if=/dev/hdb of=/dev/hdd 备份MBR【磁盘的前512个字节】：dd if=/dev/hda of=/root/image count=1 bs=512 建立swap分区【使用0字符建立空文件】 建立空文件：dd if=/dev/zero of=/home/swap bs=1024M count=2 格式化：mkswap /home/swapfile 挂载交互分区：swapon /home/swapfile 销毁磁盘【使用随机字符覆盖数据】：dd if=/dev/urandom of=/dev/hda1 磁盘读速度测试：dd if=/ceshi.txt of=/dev/null bs=512 count=1000 /dev/null为空设备，可以看作黑洞，向/dev/null写入的内容会被立即丢弃 磁盘写速度测试：dd if=/dev/zero of=/ceshi.txt bs=512 count=1000 /dev/zero可以提供无穷无尽的0【二进制0流】 ls参数 -l：以较长格式显示信息 -a：显示目录下的全部文件，包含以“.”开始的隐藏条目 -t：以最后修改时间【mtime】进行排序 -r：反向排序 -R：递归列出子目录 -F：在条目后加上文件类型指示符【*/=&gt;@|】 “/”：目录 “@”：符号链接 “*”：可执行程序 “=”：套接字 “|”：FIFOS -i：显示inode信息 -d：显示目录本身而非其子目录的属性，并且不跟随符号链接 -s：根据文件大小排序 -1：每行一个文件名 -X：根据扩展名排序 范例 统计文件数量：ls -lR|grep ‘^-‘|wc -l cp -a：复合参数，相当于-dR –preserve=all -d：不跟随符号链接，保持链接属性 -p：保持权限、属主、时间戳 -r、-R：递归复制文件、目录 -f：强制覆盖 -i：覆盖操作时交互式提醒【shell下cp命令默认为cp -i】 -s：建立软链接 -l：建立硬链接 gzip gzip只压缩文件gunzip是shell脚本（内容就是gzip -d） gzip压缩或解压时，不保留源文件 默认，gzip压缩保持文件名和时间戳 -d：解压数据 -f：强制压缩或解压 -N：解压时保持原有文件名和时间戳 -q：取消所有警告信息 -r：递归的处理目录【进入目录，然后压缩或解压文件】 -t：检测压缩文件的完整性 -c：压缩内容到标准输出，或解压内容到标准输出 范例：压缩并保留源文件：gzip -c 1.txt &gt; 1.gz zip 打包、压缩文件或目录 语法：zip 选项 压缩文件名 输入路径1 输入路径2 。。。 压缩文件名：可以是新的或已经存在的 如果是已存在的文件，zip将替换压缩文件中已存在的条目或向压缩文件中添加不存在的条目 压缩文件名可以不含zip后缀【默认添加】 范例1：持续向压缩文件添加内容：find . -maxdepth 1 -name “*.conf”|xargs -I {} zip conf {} 范例2：压缩当前目录： 不包含隐藏内容：zip aa * 包含隐藏内容：zip aa * .* 输入路径：可以是文件或目录，同时也可以使用通配符 选项 -r/–recurse-paths：压缩目录下的内容 -P/–password password：压缩时加密【非交互式】 -e/–encrypt：压缩时加密【交互式】 -i/–include：包含某些文件 范例：zip -r test test -i test/*.txt -x/–exclude：不包含某些文件 -j/–junk-paths：不包含路径【默认也打包路径】 -m/–move：移动后打包文件【相当于删除源文档】 -T/–test：测试压缩包完整性 -q/–quiet：安静模式【shell脚本】 -n【0-9】：压缩级别【默认6，9表示压缩级别最高，压缩后文件最小】 -sf：查看压缩文件包含的文件列表 unzip -d：解压到指定目录 -P：使用指定密码解压 -q：静默模式 tar 打包多个文件或目录到一个归档文件 -c：创建新的归档文件 -r：向归档文件末尾添加文件 -t：显示归档文件包含的文件列表 -x：从归档文件中提取文件 -C：切换到目录【打包的源路径、解压的目标路径】 范例：tar xzf conf.tar.gz -C ../conf/ -f：指定归档文件名【其后不加其他参数名】 -j：使用bzip2进行文件压缩、解压工作 -J：使用xz进行文件压缩解压工作 tar cJvf conf.xz * -g：使用gzip进行文件压缩解压工作 -p：保持文件属性 -v：显示操作过程 -h：跟随软链接，打包真实数据 -X, –exclude-from=FILE –exclude=PATTERN【与rsync类似】 范例：tar czvf conf.tar.gz * --exclude &quot;10-*&quot; df 统计文件系统的磁盘空间(block)和inode使用情况 -h：以可理解的换算单位输出文件系统占用磁盘情况 -i：显示inode使用情况 -t：显示指定类型文件系统使用情况【ext4、iso9660等】 -x：排除指定类型的文件系统 -T：显示文件系统类型 du 统计文件占用磁盘空间大小 -a：显示目录下所有文件大小【默认以k为单位】 -s：统计目录大小 -h：单位换算显示：du -sh backup/ fdisk fdisk -l：查看磁盘分区情况 fdisk /dev/sda：磁盘分区 n：新建 p：主分区 t：查看分区表 w：将变动写入分区表 q：退出 d：删除分区 parted分区形式 项目 MBR GPT 全称 Master boot record【主引导记录】 Guid partion table【全局唯一标示符分区表】 容量限制 磁盘或分区最大支持2T 大于2T 分区数 最多四个主分区或扩展分区 分区数无限制【操作系统限制】 常用命令 fdisk parted 特点 Fdisk：分区后保存写入分区表 Parted：分区实时写入分区表 分区形式转换 转换为GPT：parted /dev/sda mklabel gpt 转换为MBR：parted /dev/sda mklabel msdos GPT分区 建立分区：parted /dev/sdb mkpart primary ext4 1 50【命令+磁盘+操作类型+分区类型+文件系统类型+分区起始(M为单位)+分区结束】 查看分区：parted –l /dev/sdb 删除分区：parted /dev/sdb rm 2 mount 标准语法：mount -t type -o option device dir 范例：mount -o loop iso文件 目录 其他语法： 简单语法：mount device/dir：挂载fstab已存在的设备 挂载目录：mount –bind olddir newdir：挂载一个目录到另一个目录 卸载：umount 设备/目录【在fstab中配置后也可以卸载目录】 文件系统类型【-t】 ext2/3/4 iso9660：iso文件 vfat：U盘 nfs cifs：samba文件系统 挂载选项【-o】 rw/ro 读写、只读 async/sync 异步、同步 remount 重新挂载 user/password 用户名、密码 exec/noexec 二进制程序的可执行权限 suid/nosuid 二进制程序的suid权限 dev/nodev 设备文件的特殊属性 diratime/nodiratime 目录的访问时间 atime/noatime 文件的访问时间 hard/soft 硬挂载【持续呼叫至成功】软挂载【超时后呼叫挂载】 intr 持续挂载时允许中断 rsize/wsize 一次写的块大小，一次读的块大小 bg/fg 背景执行、前景执行 自动挂载【编辑/etc/fstab】 12345/kernel.iso /iso iso9660 defaults,loop 0 0/dev/sdb1 /sdb/sdb1 ext4 defaults 0 0/dev/sdb5 swap swap defaults 0 0设备 挂载目录 文件类型 默认规则 dup转储/系统扫描（1是0非）设备可以是UUID(由命令blkid产生)【如UUID=8a184dfc-5944-4552-ae89-d3a050c45997】，]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>文件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell命令行]]></title>
    <url>%2F2019%2F08%2F27%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2Fshell%E5%91%BD%E4%BB%A4%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[系统管理 crontab：设置周期性任务 at：一次性任务（使用较少） head -n：显示前n行内容【默认10】 tail：末尾显示 -n：显示末尾n行内容【默认10】 -f：持续追踪末尾输出 echo：回显文本 -e：支持特殊转义符：【\n \t等】 -n：移除末尾换行 read：从标准输入读取一行内容 seq [start [step]] end：打印数字序列 -f printf格式 -s 分隔符【默认\n】 -w 列表前加0使宽度相等 man：查看命令man文档 xargs：从标准输入读取内容，构建并执行命令【一般用于不支持管道的命令，如ls；或一次无法处理过多参数的命令，如rm】 -I {}：指定替换字符串（一般使用{}）：find . -type f|xargs -I {} mv {} .. -a file：从文件中读取内容：xargs -a /etc/hosts -I {} echo {} -d delimiter：定义输入分隔符【单字符，默认为换行符】 reboot、init、shutdown、poweroff、halt：服务器启停控制 history：查看命令历史【-c 清除命令历史】 which：查看命令全路径 time：执行时间统计 watch：周期性的执行程序，同时全屏显示输出 alias、unalias：命令别名 ulimit：控制shell终端可使用的资源 whatis：显示命令含义 logger：向syslog写入特定信息 -i 在每行都记录进程ID -t logger_test 每行记录都加上“logger_test”这个标签 -p local3.notice 设置记录的设备和级别 范例：echo “this is message”|logger -it logger_test -p local3.notice dmesg：系统启动过程 uname：显示系统信息 dmidecode：查询bios信息 date：时间 软件管理 chkconfig：自启动管理【centos6】 systemctl：服务控制【centos7】 rpm：rpm包安装、卸载、查询 yum dpkg apt 源码安装 系统服务管理 sysV是centos6之前控制系统服务的工具 chkconfig是管理系统各个运行级别下服务的启停 service则控制系统服务的启停 system是centos7控制系统服务的工具 systemctl 系统运行级别： 0：关机 1：单用户模式 2：无网络多用户命令行模式 3：有网络多用户命令行模式 4：不可用 5：带图形界面的多用户模式 6：重启 crontab配置文件 /etc/cron.deny：不允许使用cron的用户 /var/spool/cron：所有用户cron文件存放的目录 命令参数 -u：指定要操作cron的用户【默认操作自己的cron】 -l：查看crontab配置内容 -r：删除crontab -e：编辑crontab 字段含义 * 8-18 * 5 0,1,4 每分钟执行一次 8点到18点 忽略此项 5月份 周日，周一，周四 字段1：一个小时的第几分（0-59） 字段2：一天的第几小时（0-23） 字段3：一个月中的第几天（1-31） 字段4：一年中的第几月（1-12） 字段5：一周中的第几天（0-7）【0,7都是周日】 其他选项 *：所有时间点 -：连续的时间段 ,：间隔的时间点 /：时间频率 注意事项 命令行或脚本试验后【如变量、特殊字符处理】，crontab里书写 使用&amp;&amp;连接先后顺序的命令 定时任务结尾加&gt;/dev/null 2&gt;&amp;1 【重定向所有输出到空设备】 添加注释 read从标准输入读取一行内容，语法：read [选项] name-1 [... name-n] 选项 -a：将空格分隔的多个字符串组成一个数组赋值给变量name -d：定义行终止符【默认换行符\n】 -p：设置提示语 -s：隐藏输入内容【可用于密码输入】 -t：设置交互式超时时间 范例 readline：while read line;do echo $line;sleep 2;done &lt; /etc/hosts read：read -p &#39;pls input you name:&#39; -t 30 -d \# -s name 时间BIOS与系统时间系统每次启动时会读取BIOS时间，将之赋给系统时间；之后系统时间将独立运行。 date命令 显示或设置系统时间 -d, –date=STRING：显示指定描述的时间 -f, –file=DATEFILE：从文件中读取并显示指定描述的时间【一行一个】 -s, –set=STRING：根据字符串的描述设置时间 时间字符串时间字符串可以是任何人类可读的用于标识时间的字符串，比如： Sun, 29 Feb 2004 16:21:42 -0800 2004-02-29 16:21:42 next Thursday 3 hours -3 years 范例 简单表示法：“date +%D\ %T” 全量表示法：“date +%Y-%m-%d\ %H:%M:%S” 3天前表示：“date -d “-3 days”” 时间设置 手动设置系统时间：date -s “01/01/2014 13:16:13” 使用ntp同步时间服务器：ntpdate -u time.windows.com 将系统时间写入bios：clock -w ntpdate与ntpd的区别 ntpd在实际同步时间时是一点点的校准过来时间的，最终把时间慢慢的校正对。 ntpdate不会考虑其他程序是否会阵痛，直接调整时间。 rpm -qa：查询软件是否安装【grep】 -qf：查询文件属于哪个软件包 -ql：查询软件包的展开文件列表 -ivh：安装软件 -e：卸载软件 yum是一个在rhel、Centos、SUSE中的shell前端软件包管理器，能从指定的服务器自动下载和安装软件包，并解决软件之间的依赖性。 命令 yum list|grouplist：查看yum源上可用安装包、包组 yum info：查看软件信息 yum search：yum源搜索软件 yum install|groupinstall：安装单个软件、包组 yum reinstall： 重装软件 yum update|groupupdate： 软件更新【有参时更新个别，无参全部更新】 yum remove|groupremove：移除单个软件、包组 yum clean all：清除yum缓存 yum makecache：生成yum缓存 yum provides */command：查询包含命令command的软件包 软件源设置 文件必须位于/etc/yum.repos.d下 12345[local] --yum源标题name=local ---》yum源名称baseurl=file:///media ---》yum源路径enable=1 引导文件起作用gpgcheck=0 ---》不进行md5校验 dpkg -i：安装deb软件 -r：删除软件 -P：删除软件和配置 -l：显示软件列表 apt update：更新软件 upgrade：升级软件 install：安装软件 remove：删除已安装软件 purge：删除软件和配置文件 apt-cache search：在本地搜索软件【apt update更新后本地形成缓存】 软件源设置/etc/apt/sources.list chkconfig –add：添加服务，Chkconfig确保每个运行级别都有一项启动（S）或者停止（K）入口。若有缺少，则会从缺省的init脚本中自动创建。 范例：chkconfig –add httpd –del：删除服务，不再由chkconfig指令管理，并同时在系统启动的叙述文件中（/etc/rc[0-6].d）删除相关数据 范例：chkconfig –del httpd –list：默认显示所有运行级别下所有服务的运行状态（on或off）；若指定了服务，则显示指定服务所有运行级别的运行状态 范例：chkconfig –list mysqld –level：对指定运行级别下的指定服务进行操作（开启、关闭或初始化）；不加参数时，对于【on】或【off】命令，系统默认只对级别2,3,4,5进行操作； 范例：chkconfig –level httpd 2345 on systemctlsystemd添加服务 将服务控制文件放入/usr/lib/systemd/system/ systemd服务重载配置：systemctl daemon-reload systemd管理 查看已经启动的服务：systemctl list-units –type=service 查看所有服务：systemctl list-units –type=service –all 开机启动：systemctl enable crond 关闭开启启动：systemctl disable crond 是否开机启动：systemctl is-enabled crond 服务状态：systemctl status crond 开启服务：systemctl start crond 关闭服务：systemctl stop crond 重启服务：systemctl restart crond 程序源码安装概念 开放源码：人可以看懂的文本类型的程序源码 编译程序：将程序源码编译成机器可以看懂的语言，类似翻译者的角色 可执行程序：开放源码经过编译生成的二进制文件，机器可以看懂并执行 安装前置条件 系统核心是否适合本软件 是否有编译程序【gcc、make、autoconfig等】 是否存在本软件所需要的函数库或其他依赖软件 是否存在核心的头文件（header include） 源码安装 解压：将压缩类型文件【如tar.gz等格式】展开成文本类型普通文件 configure（配置编译参数）：测试系统环境是否满足软件安装的需求，满足后，根据某些用户的自定义项生成源码如何编译的规则文件makefile make：根据makefile的编译规则，使用源码、编译程序、依赖的库函数编译程序，生成二进制文件 make install：将make产生的二进制文件和配置文件安装在自己的主机上 函数库函数库依照是否被编译到程序内部分为动态库和静态库【查看可执行程序的动态库：ldd binary-file】 静态库 动态库 扩展名通常为libxxx.a 扩展名通常为libxxx.a 此类函数库在编译时直接整合到可执行程序中【生成的可执行程序较大】 编译时仅将函数库的位置点编入程序，因此生成的可执行程序较小 可执行程序可独立执行 程序不能被独立执行，要确保函数库位置不变且必须存在 函数库升级后，所有包含次函数的可执行程序必须重新编译 函数库升级后，程序无需变更【函数名不变】]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>命令行</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux系统-权限管理]]></title>
    <url>%2F2019%2F08%2F26%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2Flinux%E7%B3%BB%E7%BB%9F-%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[目录用户管理 useradd：添加用户 usermod：更改用户信息 userdel：删除用户【-r删除主目录】 id：查看用户id信息 passwd：设置或更改密码 -l：锁定用户 -u：解锁用户 chage：设置密码过期信息 范例要求：要求oldboy用户7天内不能更改密码，60天以后必须修改密码，过期前10天通知oldboy用户，过期后30天后禁止用户登陆 passwd实现：passwd -n 7 -x 60 -w 10 -i 30 oldboy chage实现：chage -m 7 -M 60 -W 10 -I 30 oldboy groupadd、groupdel、groupmod：添加、删除、变更组 groups：查看用户组信息 gpasswd：向组添加用户 -a：单用户添加 -M：多用户添加【逗号分隔】 -d：删除组用户 范例：gpasswd -a user group 权限管理 文件权限示例 权限表示 粘滞类权限 chmod：设置文件的基本权限 chown：设置文件属主属组 getfacl：查看文件访问控制列表 setfacl：设置文件访问控制列表 chattr：设置文件隐藏属性 lsattr：查看文件隐藏属性 sudo：权限提升 su：切换用户 登录查询 users：所有登录用户 w、who：查看所有用户登录详情 last：查看系统最近登录情况 lastlog：显示最近登录的用户名，登录端口及时间 lastb：登录失败信息 useradd 默认使用/etc/default/useradd配置 -d：指定用户用户主目录 -g：指定用户基本组 -G：指定用户附加组 -m：创建用户主目录 -M：不创建用户主目录 -r：创建一个系统账号【默认不会创建家目录，需-m创建】 -s：设置登录shell -u：设置用户uid usermod 注意：不能更改在线使用者的信息 -d：指定用户新的家目录，有-m参数时则将原有家目录内容移动至新家目录 -g/-G：指定基本组、附加组 -s：更改shell -l：更改用户名 -e mm/dd/yy：指定账号过期时间 文件权限示例ll命令结果【-rw-r–r– 2 root root 5 8月 14 19:55 1.txt】解读： -：说明此为普通文件 rw-：属主权限 r–：属组权限 r–：其他人权限 2：硬链接数 root：属主 root：属组 5：最后修改时间【日】 8月：最后修改时间【月】 14：文件大小 19:55：最后修改时间 1.txt：文件名 权限表示文件权限 写权限：对文件内容修改(但不包含删除文件本身) 执行权限：普通用户需要同时有读权限才能执行 删除文件：文件名放在上级目录的block中，删除文件是对上级目录的操作，需要有对上级目录的写权限 默认权限：权限掩码umask设置【默认0002】 root用户：目录755 文件644 普通用户：目录775 文件664 目录权限 读权限：具有查看目录内文件名（仅指文件名）列表的权限 写权限：具有增删移动目录内文件的权限【需配合x权限】 执行权限：具有进入目录，查看文件名称和属性的权限 权限表示法 数字表示法 数字表示法：4-读 2-写 1-执行 0-无权限(数字可叠加) 范例：644【3位数字式】 属主权限：6=4+2+0 属组权限：4=4+0+0 其他人权限：4=4+0+0 字母表示法 字母表示法：r-读 w-写 x-执行 -无权限 范例：rw-r–r– 属主权限：rw- 属组权限：r– 其他人权限：r– 用户组表示 a：所有用户 u：属主 g：属组 o：其他人 粘滞类权限suid设置 含义：作用于二进制文件，使文件在执行阶段具有文件所有者的权限 表示法： 数字表示法：4【4位数字式的首位】 字母表示法：(u+)s 范例：普通用户对/etc/shadow 无任何权限，但普通用户却可以修改自己的密码，结果是修改到其中的内容；这是由于/usr/bin/passwd具有suid权限，普通用户执行passwd命令过程中短暂获得root用户权限，从而可以修改/etc/shadow内容。 sgid设置 含义 文件：作用于二进制文件，使文件在执行阶段具有文件属组的权限 目录：用户有进入目录的权限，用户在此目录下的有效属组将变成该目录的属组 表示法： 数字表示法：2【4位数字式的首位】 字母表示法：(g+)s 范例：用于目录时，若用户对此目录有写权限，则在此目录下建立的目录或文件的属组为此目录的属组 sticky设置 含义：常用于目录，表示该目录下用户建立的文件只能自己删除 表示法： 数字表示法：1【4位数字式的首位】 字母表示法：(o+)t 大写S与大写T由于所设置的文件ugo位都没有x权限，所以当赋予suit，sgit，sbit权限时，对应为空权限，即字符s，t由小写变为大写S，T。 chmod 更改文件权限 语法：chmod 权限设置 文件 范例： 数字式设置权限：chmod nnnn file 字母式增加/减少/精确设置权限：chmod u+r,g-w,o=rwx file 所有用户权限设置：chmod a+/-/=rwx file 特殊权限设置：chmod u+s,g+s,o+t file chown 更改文件属主属组 语法：chown 参数 用户组 文件 参数 -R 递归更改属性 范例 chown user:group file chown user.group file chown user file chown .group file chown :group file getfacl 获取文件或目录的访问控制列表 1234567891011121314151: # file: somedir/2: # owner: lisa3: # group: staff4: # flags: -s-5: user::rwx6: user:joe:rwx #effective:r-x7: group::rwx #effective:r-x8: group:cool:r-x9: mask::r-x10: other::r-x11: default:user::rwx12: default:user:joe:rwx #effective:r-x13: default:group::r-x14: default:mask::r-x15: default:other::--- 1-3表示文件名、属主、属组 4显示特殊权限setuid (s), setgid (s), sticky (t)【3个权限都无时，不显示此行内容】 5、7、10对应属主、属组、其他人的权限，表示基本的acl条目 6、8是命名的用户和组的权限条目 9是有效的权限掩码，针对所有的组和命名的用户【但不包含属主、其他人】 11-15显示目录的默认权限【普通文件则没有】 setfacl 设置文件或目录的访问控制列表 语法：setfacl [-bkndRLPvh] [{-m|-x} acl_spec] [{-M|-X} acl_file] file ... 使用注意 命令行下操作权限时，多个ACL条目以逗号分隔 从文件中读取ACL时，最终会有getfacl式的结果输出 属主、属组、其他人这3个基本的权限条目不可移除，且只能有一个 当ACL包含命名的用户和组的条目时，必须包含有效的权限掩码 参数 -m(–modify)、-M (–modify-file)：定义ACL权限，-m在命令行定义，-M从文件中或标准输入读取要定义的ACl -x(–remove)、-X (–remove-file)：移除ACl权限，-x在命令行移除，-X从文件中或标准输入读取要移除的ACL -b、–remove-all：移除所有扩展的ACL【不包含对3个基本条目修改的恢复】 -k、–remove-default：移除默认的ACL -n, –no-mask：不计算掩码条目 –mask：计算掩码条目 -d、–default：使用默认ACL –restore=file：从文件中恢复ACL【使用getfacl -R备份的文件】 –test：测试模式 -R, –recursive：递归应用权限 -L, –logical：操作适用于符号链接关联的目录 -P, –physical：操作不适用于符号链接关联的目录 权限条目 用户权限：[d[efault]:] [u[ser]:]uid [:perms]：设置命名用户的权限，uid为空则表示属主的权限 组权限：[d[efault]:] g[roup]:gid [:perms]：设置命名组的权限，gid为空则表示属组的权限 权限掩码：[d[efault]:] m[ask][:] [:perms] 其他人权限：[d[efault]:] o[ther][:] [:perms] 范例 默认权限：setfacl -m d:u:hjq:rwx test 设置属主权限：setfacl -m u::r test/ 设置属组权限：setfacl -m g::rw test/ 设置权限掩码：setfacl -m d:m:rx test/ 移除所有扩展权限：setfacl -b test/ chattr 改变文件的隐藏属性 用法：chattr [ -RVf -v version ] [ mode ] files... 一般参数： -R：递归设置文件和目录 -V：显示设置过程 -f：屏蔽错误输出 -v version：设置文件版本 模式参数：+-=[acdeijstuADST] +表示增加模式 -表示较少模式 =表示只设置此种模式 模式参数 a：只允许增加内容，不允许修改和删除 A：不修改atime时间戳 c：文件存储时压缩，读取时自动解压 d：dump程序启动备份时，不对此文件备份 i：不能被修改和删除 s：删除数据的同时将数据从磁盘删除 S：将数据同步写入磁盘【一般为异步】 u：与s相反，删除文件但不从磁盘上删除【可以用于恢复】 范例 只许向文件追加内容：chattr +a 12 撤销追加属性：chattr -a 12 lsattr -d：显示目录本身隐藏属性 -R：递归显示目录及目录下的隐藏属性 查看文件的隐藏属性：lsattr 12 su su：切换用户【默认切换到root】 su -：切换用户的同时切换环境变量 sudo：权限提升，一般为切换为root sudo基础 时间：5分钟内无需再次输入密码 命令 visudo -c：语法检查 visudo -f：加载指定配置文件 sudo -l【查看用户sudo权限】 文件：/etc/sudoers 环境设置： Defaults env_reset【执行命令时环境变量被重置】 Defaults:muker !requiretty【允许用户远程执行sudo命令】 语法 范例： 单用户设置：admin ALL=(ALL) /usr/sbin/useradd 用户组设置：%admin ALL=(ALL) NOPASSWD: ALL 语法：用户或组+来源主机+可以切换到的用户+可以执行的命令 用户或组：admin 来源主机：ALL 可以切换的用户：ALL 可以执行的命令：/usr/sbin/useradd 命令需要使用全路径 命令前使用！表示取反【admin ALL=NOPASSWD:/sbin/*, !/sbin/fdisk】，禁止命令需要放在允许命令之后 命令前NOPASSWD表示执行sudo时无需输入密码 多个命令之间逗号分隔，且逗号与下个命令之间要有空格 别名 可以对sudo语法中的4个主要条目设置别名别名必须使用大写字母，%表示引用组名 用户：User_Alias ADMINS = admin, baby, %admin 来源主机：Host_Alias MAILSERVERS = smtp, smtp2 可切换用户：Runas_Alias OP = root, admin 可执行命令：Cmnd_Alias SOFTWARE = /bin/rpm, /usr/bin/up2date, /usr/bin/yum 远程sudo配置文件requiretty参数和命令行ssh -t参数的差异 以客户端角度看：ssh以-t参数远程运行命令(ssh -t host sudo comand)，无论requiretty如何配置都可以远程sudo执行 以服务端角度看 【!requiretty】不要求有tty终端，【ssh host sudo comand】命令可以执行（ansible的sudo方式也可以执行） 【requiretty】要求有tty终端，【ssh host sudo comand】无法执行执行 案例故障现象 修改密码时报错 passwd: Authentication token manipulation error 添加用户报错：unable to lock password file 分析 检查相关配置文件权限正常：/etc/passwd 和/etc/shadow df查看硬盘空间正常 使用命令strace -f passwd 追踪分析原因，看到关键报错信息：“No space left on device”，可是df查看硬盘空间没问题，有可能是inode满了，使用df –i查看inode使用情况，确实/var/spool/clientmqueue占用大量的inode /var/spool/clientmqueue 生成的文件占用完inode，此目录下文件的产生原因主要是crontab里面的命令没有添加“&gt;/dev/null 2&gt;&amp;1”标准输出、错误输出信息都输出到标准输出，以文件形似存储在clientmqueue 解决删除文件后正常，将crontab命令后面添加“&gt;/dev/null 2&gt;&amp;1”]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>权限</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql用户和权限]]></title>
    <url>%2F2019%2F08%2F23%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmysql%E7%94%A8%E6%88%B7%E5%92%8C%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[所有权限 ALL：全局或者全数据库对象级别的所有权限 ALTER：修改表结构的权限，但必须要求有create和insert权 限配合。如果是rename表名，则要求有alter和drop原表，create和 insert新表 ALTER ROUTINE：修改或者删除存储过程、函数 CREATE：创建存储过程、函数 CREATE ROUTINE：创建存储过程和函数 CREATE TABLESPACE：创建、修改、删除表空间和日志组 CREATE TEMPORARY TABLES：创建临时表 CREATE USER：创建、修改、删除、重命名用户 CREATE VIEW：创建视图 DELETE：删除行数据 DROP：删除数据库、表、视图的权限，包括truncatetable命令 EVENT：查询，创建，修改，删除MySQL事件 EXECUTE：执行存储过程和函数 FILE：在MySQL可以访问的目录进行读写磁盘文件操作，可使用 的命令包括load data infile,select … into outfile,load file()函数 INDEX：创建、删除索引 INSERT：插入数据，同时在执行analyze table,optimize table,repair table语句的时候也需要insert权限 LOCK TABLES：锁表 PROCESS：看MySQL中的进程信息，比如执行showprocesslist, REFERENCES：创建外键 RELOAD：执行flush命令，指明重新加载权限表到系统内存中， refresh命令代表关闭和重新开启日志文件并刷新所有的表 REPLICATION SLAVE：允许slave主机通过此用户连接master以便建立主从复制关系 REPLICATION CLIENT：执行show master status,show slave status,show binary logs命令 SELECT：查询 SHOW DATABASES：查看数据库 SHOW VIEW：执行show create view命令查看视图创建的语句mysqladmin processlist, show engine等命令 SHUTDOWN：允许关闭数据库实例，执行语句包括mysqladmin shutdown SUPER：执行一系列数据库管理命令，包括kill强制关闭某个连接 命令，change master to创建复制关系命令，以及create/alter/drop server等命令 UPDATE：修改数据 TRIGGER：允许创建，删除，执行，显示触发器 系统权限表 user：存放用户账户信息以及全局级别(所有数据库)权限 查询用户：select user,host mysql.user; db：存放数据库级别的权限 Tables_priv：存放表级别的权限 Columns_priv：存放列级别的权限 Procs_priv：存放存储过程和函数级别的权限 mysql用户用户定义 由用户名和主机名构成，形如：‘user_name‘@’host_name’ 单引号不是必须的，但有特殊字符时则必须使用 ‘‘@’localhost’代表匿名登录的用户 主机名可以是主机名或者ipv4/ipv6的地址。Localhost代表本机，127.0.0.1代表ipv4的 本机地址，::1代表ipv6的本机地址 允许使用%和_两个匹配字符，比如’%’代表所有主机，’%.mysql.com’代表 来自mysql.com这个域名下的所有主机，’192.168.1.%’代表所有来自192.168.1网段的主机 查看权限show grants for ‘用户名’@‘ip地址’; 创建和授权 方式1： 创建用户：CREATE USER &#39;finley&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;some_pass&#39;; 授权：GRANT ALL ON *.* TO &#39;finley&#39;@&#39;localhost&#39;; 方式2：grant all on *.* to &#39;finley&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;some_pass&#39;; 回收权限revoke DROP,RELOAD,SHUTDOWN,PROCESS,FILE,REPLICATION SLAVE, REPLICATION CLIENT,CREATE USER on *.* from &#39;finley&#39;@&#39;localhost&#39;; 删除用户DROP USER ‘jeffrey‘@’localhost’; 权限生效 执行grant,revoke,set password,renameuser命令修改权限之后，MySQL会自动将修改后的权限信息同步加载到系统内存中 如果执行insert/update/delete操作上述的系统权限表之后，则必须再执行刷新权限命令才能同步到系统内存中，刷新权限命令包括:flush privileges/mysqladmin flush-privileges/mysqladmin reload 如果是修改tables和columns级别的权限，则客户端的下次操作新权限就会生效 如果是修改database级别的权限，则新权限在客户端执行use database命令后 生效 如果是修改global级别的权限，则需要重新创建连接新权限才能生效 –skip-grant-tables可以跳过所有系统权限表而允许所有用户登录，只在特殊情况下暂时使用 变更密码 方式1：ALTER USER ‘jeffrey‘@’localhost’ IDENTIFIED BY ‘mypass’; 变更自身：ALTER USER USER() IDENTIFIED BY ‘mypass’; 方式2： update mysql.user set authentication_string=password(“新密码”) where user=”test” and host=”localhost”; flush privileges; 方式3：SET PASSWORD FOR ‘jeffrey‘@’localhost’ = PASSWORD(‘mypass’); 变更自身：SET PASSWORD = PASSWORD(‘mypass’); 方式4(mysqladmin)：mysqladmin -u user_name -h host_name password “new_password” 忘记密码 跳过授权表启动：mysqld_safe –defaults-file=my.cnf –skip-grant-tables &amp; 变更密码 刷新权限：flush privileges; 退出安全启动模式，以正常方式启动]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>权限</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux远程连接工具-ssh]]></title>
    <url>%2F2019%2F08%2F07%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2Flinux%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7-ssh%2F</url>
    <content type="text"><![CDATA[简介 Secure shell protocol：安全的shell协议 服务端软件：openssh 客户端软件：securecrt、putty、openssh-client 登录方式： 口令：交互式输入用户名和密码 秘钥：使用秘钥文件 产生秘钥对：ssh-keygen -t rsa -P “” -f ./bastion 传送公钥到远端：ssh-copy-id -i ~/.ssh/bastion.pub 配置文件服务端配置 /etc/ssh/sshd_config 12345PermitRootLogin no # 是否允许root登录PermitEmptyPasswords no # 是否允许无密码登录Port 22 # 端口设置ClientAliveInterval 60 #server每隔60秒发送一次请求给client，然后client响应，从而保持连接ClientAliveCountMax 3 #server发出请求后，client没有响应次数达到3，就自动断开连接，一般client会响应。 客户端配置 配置文件：/etc/ssh/ssh_config（全局）、~/.ssh/config（用户级） 用途1：通过ssh代理转发实现跳板机功能（主机A通过B登录C） 12345678910111213Host ops User muker #连接跳板机使用的用户名 HostName 47.99.78.151 #跳板机ip ProxyCommand none BatchMode yes #跳板机模式 IdentityFile ~/keyfiles/bastion #本地连跳板机时使用的私钥 StrictHostKeyChecking no #首次登录时禁止秘钥检查Host 172.16.0.* # 目标主机网络 ServerAliveInterval 60 TCPKeepAlive yes ProxyCommand ssh -qaY -i ~/keyfiles/bastion muker@ops &apos;nc -w 14400 %h %p&apos; # ssh代理转发 IdentityFile ~/keyfiles/internal #跳板机使用私钥internal连接目标主机 StrictHostKeyChecking no ssh命令ssh 选项 user@host command 命令选项 -a：禁用转发身份验证代理连接 -Y：启用可信的X11转发 -q：抑制警告和诊断信息输出 -F configfile：客户端配置文件 -i identity_file：私钥文件 -p port：远程ssh服务端口 -v：开启连接详细输出 主要用于故障调试 最多使用3个v scp命令 -P：设置连接端口 -p：保留文件时间戳 -r：递归复制目录下内容 常见问题 只允许秘钥登录 现象：Permission denied (publickey) 解决：变更配置sshd_config 【PasswordAuthentication yes】 不允许root登录 现象：ssh使用root登录时，密码正确但是拒绝登陆 解决：变更配置sshd_config【PermitRootLogin yes】 其他参考 Centos 6.5升级openssh到7.9p1]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时间格式]]></title>
    <url>%2F2019%2F08%2F07%2F%E9%80%9A%E7%94%A8%E6%8A%80%E8%83%BD%2F%E6%97%B6%E9%97%B4%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[格式符 含义 范例 %a 缩写的星期几 Sun %A 完整的星期几 Sunday %b/%h 缩写的月份 Mar %B 完整的月份 March %c 日期和时间表示法 Sun Aug 19 02:56:02 2012 %d 一月中的第几天（01-31） 19 %D 年月日格式%m/%d/%Y 08/07/19 %F 全格式年月日：%Y-%m-%d 2019-08-07 %H 24小时制的小时（00-23） 14 %I 12小时制的小时（01-12） 05 %j 一年中的第几天（001-366） 231 %m 十进制表示的月份（01-12） 08 %M 分（00-59） 55 %p AM或PM名称 PM %P 和%p一样，小写形式 am %s timestamp时间戳 - %S 秒 （00-59） 02 %T 时分秒格式%H:%M:%S 10:03:24 %U 一年中的第几周，以第一个星期日为第一周的第一天（00-53） 33 %w 十进制表示的星期几，星期日表示为0（0-6） 4 %W 一年中的第几周，以第一个星期一作为第一周的第一天（00-53） 34 %x 日期表示法 08/19/12 %X 时间表示法 02:50:06 %y 年份的最后两个数字（00-99） 01 %Y 年份 2012 %Z 时区的名称或缩写 CST %% 一个%符号 % %n 换行 - %t 制表符 -]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>时间格式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux系统-进程管理]]></title>
    <url>%2F2019%2F08%2F06%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2Flinux%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[命令目录 kill：向进程发送信号 pkill、killall、pgrep：根据进程名称过滤进程id或杀死进程【可能有误、不建议使用】 ps：查看进程状态的最近一个快照 fuser：显示打开文件或socket的进程 nohup：运行一个免于挂起的命令，同时输出到非tty终端 jobs、fg lsof：进程打开的文件 top、htop：实时查看进程状态 进程信号 1(HUP)： 重启 2(INT) ：中断【ctrl+c】 3(QUIT)： 退出 9(KILL) ：强制终止 15(TERM) ：正常结束【kill默认信号】 17(STOP) ：停止程序运行【ctrl+z】 19(CONT)： 停止的程序继续运行 kill 终止进程：kill pid 强制终止：kill -9 pid 重启进程：kill -HUP pid lsof简介list open file 列出打开的文件，文件可以是普通文件、目录、链接、字符设备、块设备、FIFO设备、socket 选项 没有任何选项时，lsof默认显示所有活跃进程打开的文件 -a：指明所有选项之间逻辑“与”关系【默认“或”关系】 -c ^ c：进程执行的命令(不)是以c开头的，c可以是正则表达式【以//进行包围】 -r t：周期性的显示输出信息【t定义时间间隔，默认15s】 -u ^ uid：(不)属于某个登录名或id的用户，多个用户之间逗号分隔 -p ^ pid：(不)属于某个进程的 -i 地址：选择与internet地址匹配的文件列表： 地址：[46][protocol][@hostname|hostaddr][:service|port] protocol：传输层协议tcp/udp hostname、hostaddr：主机名、ip地址 service：应用层协议(如smtp)、端口号 范例：lsof -i tcp@ops:ssh -t：只输出符合要求的进程pid -X：不关联TCP、UDP的文件 范例：lsof -p 22929 -X -s ^ [p:s]：(不)属于某个tcp、udp协议状态(如established)的 范例：lsof -a -i tcp -s tcp:established -c nginx【查看nginx并发连接】 –：表示选项的的结束，在文件名中包含“-”时有用 file-names：列出打开文件的进程 任务模式 cmd&amp;：将命令以”任务“方式放入后台执行 jobs：查看后台运行的任务 fg number：将后台任务调入前台执行 nohup 由于cmd&amp;方式产生的进程父id为tty或pts终端shell，当用户注销或网络断开时，终端会收到HUP（hangup）信号从而关闭其所有子进程 nohup不接收HUP信号，同时输出内容到非tty终端，因此可以使用【nohup cmd &amp;】方式将命令放入后台长期运行 ps 功能：显示当前的进程状态【whatis ps】 用法：【man ps】、【ps –help all】 常用组合 ps -ef ps -aux 常用选项 -A：显示所有进程 -a：显示所有终端下的进程 -r：显示正在运行的进程 -x：与a搭配使用，显示较完整的进程信息 -h：不显示header信息 -e：命令后显示环境变量 -f：全格式 -l：长格式 ef格式详解 UID：用户ID PID：进程ID PPID：父进程ID C：进程占用CPU的百分比 STIME：进程启动的时间 TTY：该进程在哪个终端上运行，若与终端无关，则显示？若为pts/0等，则表示由网络连接主机进程 TIME：该进程实际使用CPU运行的时间 CMD：命令的名称和参数 aux格式详解 USER：用户名 PID：进程ID %CPU：cpu使用率 %MEM：内存使用率 VSZ：该进程使用的虚拟内存量（KB） RSS：该进程占用的固定内存量（KB） TTY：该进程在哪个终端上运行，若与终端无关，则显示？若为pts/0等，则表示由网络连接主机进程 STAT：进程状态 START：进程开始的时间 TIME：进程实际占用cpu的时间 COMMAND：进程使用的命令 进程状态 状态码 状态 含义 R runnable（on run queue）运行 正在运行或在运行队列中等待 S sleeping休眠中 休眠中，受阻，在等待某个条件的形成或接受到信号 D uninterruptible sleep (usually IO)不可中断 收到信号不唤醒和不可运行，进程必须等待直到有中断发生 T stopped停止 进程收到SIGSTOP、SIGSTP、SIGTIN、SIGTOU信号后停止运行 Z zombie僵死 进程已终止，但进程描述符存在，直到父进程调用wait4()系统调用后释放 s 进程下有子进程 - &lt; 优先级高的进程 - N 优先级低的进程 - + 位于后台的进程 - l 多线程 -]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>kill</tag>
        <tag>ps</tag>
        <tag>nohup</tag>
        <tag>lsof</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2019%2F08%2F05%2F%E9%80%9A%E7%94%A8%E6%8A%80%E8%83%BD%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[POSIX正则表达式 常见的正则表达式记法，其实都源于Perl。实际上，正则表达式从Perl衍生出一个显赫的流派，叫做PCRE（Perl Compatible Regular Expression），\d、\w、\s 之类的记法，就是这个流派的特征。但是在PCRE之外，正则表达式还有其它流派，比如下面要介绍的POSIX规范的正则表达式。 POSIX表示可移植操作系统接口（Portable Operating System Interface of UNIX，缩写为 POSIX ），主要定义了unix系统的接口规范；相应的，POSIX正则表达式定义了类unix系统下的正则表达式规范 POSIX定义了两种类型的正则表达式： BRE(Basic Regular Expression)：基本正则表达式 包含的特殊字符：. \ [ ^ $ * grep/vim/sed使用的即是基本正则 ERE(Extended Regular Expressions)：扩展正则表达式 ERE相对于BRE多了7个特殊字符：? + { } | ( )；在BRE中要实现相应的功能，则需要使用转义符。 egrep/awk使用的即是扩展正则，同时也兼容PCRE BRE和ERE(PCRE与ERE基本相同)区别 功能含义 BRE ERE 定义子表达式的开始 \( ( 定义子表达式的结束 \) ) 匹配前一个字符(子表达式)的一次或多次 \+ + 匹配前一个字符(子表达式)的零次或一次 \? ? 大括号开始 \{ { 大括号结束 \} } 交替匹配 \&#124; &#124; POSIX与PCRE的区别 POSIX字符组中，反斜线\不是用来转义的。所以POSIX方括号表示法[\d]只能匹配\和d两个字符，而不是[0-9]对应的数字字符。 POSIX与PCRE的预定义字符不同 元字符 .：匹配任何字符，包含换行符 \：转义字符 方括号表达式 [012asdf89]：匹配任意单个字符 [^01asdf67]：字符列表取反 [a-d]：范围表达式，等同于[abcd]【和地区字典排序有关】 包含]时必须放在方括号的第一个位置 包含^不能放在第一个位置 包含-必须放在括号内的最后一个位置 预定义字符 即POSIX标准字符类【和地区字典无关的设置】主要用于补充POSIX标准不存在单词、数字等基本预定义字符【如：PCRE中存在\s \w \d等预定义字符】 [:alnum:]：字母和数字 [:alpha:]：字母 [:blank:]：空格或tab [:cntrl:]：控制字符 [:digit:]：数字 [:graph:]：任何可看到且可打印的字符 [:lower:]：小写字母 [:print:]：非控制字符 [:space:]：产生空白的字符 [:upper:]：大写字母 [:xdigit:]：十六进制数字 [:punct:]：标点符号 边界 ^：匹配字符串开始 $：匹配字符串结束 数量词 * 匹配前一个字符0或多次 ? 匹配前一个字符0或1次 【扩展正则示例,基本正则形式参见BRE与ERE区别】 + 匹配前一个字符1或多次 【扩展正则示例】 {n} 匹配前置条目n次 【扩展正则示例】 {n,} 匹配前置条目至少n次 【扩展正则示例】 {,m} 匹配前置条目至多m次 【扩展正则示例】 {n,m} 匹配前置条目n到m次 【扩展正则示例】 分组 |：交替匹配符号两边的内容 【扩展正则示例】 ()：分组 【扩展正则示例】 \n：分组后的后向引用功能]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell编程]]></title>
    <url>%2F2019%2F07%2F30%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2Fshell%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[变量变量定义 当变量值为数字或路径时，可以不适用引号 等号两边不能有空格 变量名的开头必须是字母 引用机制 是用于删除shell中某些特殊的字符或单词 反斜杠：转移符，保留字面含义【当行尾有反斜杠时表示续行】 特殊转义序列：\t \n 单引号：保留字符字面含义 双引号：可以解析变量及使用转移符 位置参数 $n表示shell脚本或shell函数的位置参数【n&gt;=1】 当数字n大于9时应该这样表示：${12} 特殊变量 $* $@：所有的位置参数 $*：相当于“$1空格$2空格$3…”，即空格分隔多个位置参数同时整体作为一个字符串 $@：相当于”$1” “$2”…，即空格分隔多个位置参数并作为多个独立的字符串 $#：位置参数个数 $?：上一个shell命令执行状态 $$：当前shell的pid $!：上一个放入后台执行的命令的pid $0：shell脚本的名字 波浪线(~)：表示当前用户家目录 数组定义数据 定义整个数组：name=(value1 … valuen) arry=(128 string http html) 定义数组的某个值：name[subscript]=value arry[4]=&quot;ceshi&quot; 数组使用 查看数组某个元素(下标从0开始)：${arry[0]} 查看全体元素：${arry[*]} 查看数组某个元素长度：${#arry[0]} 查看数组元素个数：${#arry[*]} 数组元素替换：${arry[*]/string/jing} 删除数组某个元素：unset arry[0] 删除数组整体：unset arry 范例 统计并发连接：netstat -ant|awk -F &#39;[ :]+&#39; &#39;$1 !~ /^Active|^Proto/ &amp;&amp; $6 !~ /0.0.0.0|^172.16/{if($5==443)++ip[$6]}END{for(i in ip)print i,ip[i]}&#39;|sort -rn -k2 变量扩展 赋值：将一个变量的值(值可能为空或不存在)赋值给另一个变量时的操作 截取： ${变量名:起始索引} 显示起始索引开始的字符串 ${变量名:起始索引:长度} 显示起始索引开始的指定长度字符串 ${#变量名} 显示变量长度 ${变量名#样式} 从行首开始截取符合样式的最短字符串：${PATH#/*:} ${变量名##样式} 从行首开始截取符合样式的最长字符串：${PATH##/*:} ${变量名%样式} 从行尾开始截取符合样式的最短字符串：${PATH%:/*} ${变量名%%样式} 从行尾开始截取符合样式的最长字符串：${PATH%%:/*} 替换和删除 ${变量名/样式/替换} 替换第一个样式字符串：${PATH/sbin/Sbin} ${变量名//样式/替换} 替换所有的样式字符串：${PATH//sbin/Sbin} ${变量名/样式/ } 删除第一个样式字符串：${PATH/sbin/} ${变量名//样式/ } 删除所有的样式字符串：${PATH//sbin/} 路径名匹配 即bash下的通配符 *：匹配任意字符串 ?：匹配任意单个字符 [...]： 匹配括号内任意字符 包含横杆【-】时表示匹配字符范围内的字符 首字符是!或^表示不匹配括号内字符 复合模式【由多个匹配模式构成】 ?(pattern-list)：匹配0或1个给定的模式 *(pattern-list)：匹配0或多个给定的模式 +(pattern-list)：匹配1或多个给定的模式 @(pattern-list)：匹配1个给定的模式 !(pattern-list)：不匹配模式列表中任何项 函数定义 name () { cmd-list } function name [()] { cmd-list } 定义局部变量：local 调用func_name 范例123456定义：usage ()&#123; echo &quot;usage: $0 &lt;git branch name&gt;&quot;&#125;调用：usage 管道 使用方式1：cmd1|cmd2：将cmd1命令的标准输出传递给cmd2的标准输入 使用方式2：cmd1|&amp;cmd2：【|&amp;等同于2&gt;&amp;1 |】将cmd1的标准输出和错误输出都传递给cmd2 管道与进程：管道中的每个命令都在单独的进程中执行【subshell】 重定向 重定向标准输入：&lt;word 重定向输出： 标准输出：&gt;word 错误输出：2&gt;word 追加重定向输出：[n]&gt;&gt;word 同时重定向标准输出和错误输出：&amp;&gt;word或&gt;word 2&gt;&amp;1 追加重定向标准输出和错误输出：&amp;&gt;&gt;word或&gt;&gt;word 2&gt;&amp;1 重定向多行输入123cmd &lt;&lt; 分隔符文本分隔符 123456789cat &lt;&lt; EOF &gt; ceshi.txthejingqiEOF# cat为接收文本的命令# EOF为分隔符【可以是任意的】# &gt;ceshi.txt为cat命令的重定向输出# he jing qi 为输入文本 括号使用 (list)：开启一个子shell执行命令列表，$(list)表示list命令的输出结果（也可以使用反撇号执行命令），常用于a=$(list)这样的赋值语句 ((expression))：括号里的进行的是数字运算(因此可以用+、-、*、/、&gt;、&lt;等算术运算符)，同样的，$((expression))表示计算的结果 []：条件表达式，其实是一个程序/usr/bin/[，相当于/usr/bin/test，后面多的那个]只是对称好看，所以[后要有空格 [[ expression ]]：表示里面进行的是逻辑运算，可以使用!、&amp;&amp;、||逻辑运算符 { list; }：内部分组，这个结构事实上创建了一个匿名函数。大括号内的命令不会开启一个子shell运行。括号内的命令用分号分隔，最后一个也要用分号，第一个命令和左括号之间必须要有一个空格。它也支持如下扩展： 扩展字母和数字：{1..n} {a..z} 逗号分隔的扩展：{1,5,a} 流程控制 for列表循环：for name [ [ in [ word ... ] ] ; ] do list ; done：循环列表中的内容 for自增循环：for((expr1;expr2;expr3))：条件循环；expr1为初始条件，expr2为终止条件，expr为循环条件。 范例：for((a=50;a&gt;=0;a–));do echo $a;done select循环：select name [in word];do list;done：交互式选择列表中的项目 范例：select name in a b c;do echo $name;done case循环：case word in [ [(] pattern [ | pattern ] ... ) list ;; ] ... esac：多条件选择 1234567891011121314case variable invalue1 | value2) // value1支持通配符和|作为or的关系 command1 ;;value3) command2 ;;[vV]alue4) command3 ;;*) command4 ;;esac if语句：if list; then list; [ elif list; then list; ] ... [ else list; ] fi 1234567if [ $1 -gt 5 ];then echo $1elif [ $1 -eq 5 ];then echo 5else echo &quot;$1 is less than 5&quot;fi while循环：while list-1; do list-2; done：list-1满足条件则执行list-2 123456declare -i i=0while ((i&lt;=10));do echo $i i=i+1done 123456789101112131415161718191. 读取文件方式1exec &lt; FILEwhile read linedo cmddone2. 读取文件方式2while read linedo cmddone&lt;FILE# 范例while read linedo echo $line sleep 1done &lt; $1 break和continue 只能用于for、while、until、select循环 单循环中：break终止循环；continue终止本次循环(不执行循环后语句)，继续下次循环 双循环中：break跳出内循环，执行外循环语句；break 2直接跳出外循环。continue跳出内循环中的本次循环，继续下次内循环；continue 2跳出内循环，继续下次外循环。 exit [n]：以n退出脚本 return [n]：以n作为返回值退出函数 数学运算运算符 id++，id–：变量后加减 ++id，–id：变量先加减 +-：加减 &amp; ^ | ~：位与、异或、同或、非 **：幂函数 */%：乘除取余 &lt;&lt; &gt;&gt;：向左位移、向右位移 &gt; &gt;= &lt;= &lt;：比较 == !=：等于、不等于 &amp;&amp; || !：逻辑与、或、非 expr?expr:expr：三元表达式 表达式 (())：echo $((5+4)) expr 1 + 4：空格分隔 declare：declare -i i=2;i=i+3;echo $i let：let a=3+2;echo $a 条件表达式 test或[命令使用 -a、-o：逻辑与、或 -n、-z：字符串长度不为0、为0 =、!=：字符串相等、不等 -ne、-eq、-lt、-le、-gt、-ge：数字上的大【等】于、小【等】于、【不】等于 -e：文件存在 内置命令 :：冒号表示空语句，什么也不做 ./source：在当前shell环境执行脚本，变量值可以回传给shell sh/bash：开启子shell执行脚本，变量值不能回传给父shell declare：声明变量 declare -r variable=value 声明只读变量. declare -a variable=(1 2 3 4) 声明数组 declare -i aa 声明整数型变量 eval text：将text文本转换为shell命令执行，如【eval “echo text”】即为执行echo text命令 export：设置全局变量，如export PATH=/data/tomcat:$PATH getopts：解析shell脚本位置参数 shift：解析shell脚本位置参数时用于移动参数位置 printf：格式化输出 set：显示所有shell变量 -n：读取命令但不执行，此用于检测脚本语法【bash/sh -n file】 -x：展开所有简单的命令，同时显示for、case、select的每一个循环，主要用于脚本调试 脚本内使用：set -x 命令行使用：sh -x file +x：关闭命令的展开显示：set +x unset：删除变量或函数 env：显示环境变量 命令执行命令列表 &amp;会将命令放入后台执行 以“;”分隔的命令会顺序执行，shell等待每个命令执行完成 cmd1&amp;&amp;cmd2 逻辑“与”连接两个命令，cmd1执行成功后才执行cmd2 cmd2||&amp;&amp;cmd2 逻辑“或”连接两个命令，cmd2执行不成功才执行cmd2 应用范例其他范例参考：https://github.com/simple0426/sysadm/tree/master/shell 菜单制作12345678910111213#!/bin/bashmenu_1 () &#123; echo -e &quot; ==================== 1.\033[32minstall lamp\033[0m 2.\033[32minstall lnmp\033[0m 3.\033[31mexit\033[0m please install your choice: &quot;&#125;menu_1read num1echo $num1 产生随机数 输入英文单词，产生1-100之间的随机数 12345678910111213141516#!/bin/bashwhile true # 输入循环do read -p &quot;Please input your name:&quot; name # 交互式输入 echo &quot;$name&quot;|grep -E -q -w &quot;^exit|^quit&quot; &amp;&amp; exit # 定义退出码 echo &quot;$name&quot;|grep -E -q -w &quot;[a-zA-Z]+&quot; || continue # 非字母则继续输入循环 [ $&#123;#name&#125; -eq 0 ] &amp;&amp; continue # 为空继续输入循环 grep -E -w &quot;$name&quot; random.list 2&gt;/dev/null &amp;&amp; continue # 内容已存在则继续输入循环 while true # 随机数循环 do random=$(awk &apos;BEGIN&#123;srand();val=int(rand()*100);print val&#125;&apos;) # 产生随机数 grep -E -w -q &quot;$random&quot; random.list 2&gt;/dev/null &amp;&amp; continue # 随机数存在则继续随机数循环产生新随机数 printf &quot;$name\t$random\n&quot; printf &quot;$name\t$random\n&quot; &gt;&gt; random.list &amp;&amp; break # 保存输入和随机数 donedone 99乘法表1234567891011121314151617#!/bin/bash# 一、处理顺序：第1行1-9列 第2行1-9列 。。。# 二、1-外层循环:行 2-内层循环:列# 三、显示：列位置*行位置=乘积结果for ((i=1;i&lt;=9;i++)) # 行do for ((j=1;j&lt;=9;j++)) # 列 do if [ $j -lt $i ];then # 列小于行则输出 printf &quot;$j*$i=$((j*i))\t&quot; elif [ $j -eq $i ];then # 列等于行则换行 printf &quot;$j*$i=$((j*i))\n&quot; else # 列大于行退出循环 break fi donedone]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux系统-网络管理]]></title>
    <url>%2F2019%2F07%2F17%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2Flinux%E7%B3%BB%E7%BB%9F-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[命令列表 tcpdump -i eth0：指定监听的网络接口 tcp port 3306：监听本机tcp协议3306端口 icmp：监听icmp协议 ip host 192.168.100.2：监听指定来源的主机 -t：不显示时间戳 -n：补办ip解析成域名 -nn：不把端口转换成对应的协议 -c：只抓取多少行数据 dst：指定数据流向【到本机还是离开本机】 范例：tcpdump -i eth1 -tnn dst port 80 -c 100 ping：测试网络连通性 traceroute：路由追踪 nslookup：域名解析【ip与mac对应关系】 dns设置：/etc/resolv.conf arp：地址解析协议 curl iptables tcp_wrapper netstat：显示网络链接 -a：显示所有链接状态 -n：以数字形式显示ip和端口 -u：显示udp链接 -t：显示tcp链接 -p：显示建立链接的进程信息【PID】 ifconfig：查看或临时设置网卡信息 ethtool：查看网口信息 route：查看或临时设置路由信息 iftop wget nc nmap ifconfig 永久修改网卡信息：/etc/sysconfig/network-scripts/ifcfg-eth0 ifconfig：查看处于开启状态的网卡信息 ifconfig -a：查看所有状态的网卡信息【包含down状态】 设置网卡： ifconfig eth0 192.168.1.1 netmask 255.255.255.0 ifconfig eth0 192.168.1.1/24 添加虚拟网卡：Ifconfig eth0:0 192.168.20.1/24 打开或关闭网卡：ifconfig eth0 up/down 启用/禁用网络接口：ifup/ifdown eth0 route 查看路由表：route –n 添加默认网关：route add default gw 192.168.1.1 删除默认网关：route del default gw 192.168.1.1 添加默认路由(下一跳)：route add –net 10.0.0.0 netmask 255.0.0.0 gw 192.168.30.254 添加默认路由(本地出口)：route add –net 10.0.0.0 netmask 255.0.0.0 dev eth0 添加主机路由(本地出口)：route add –host 11.22.22.3 dev eth0 添加主机路由(下一跳)：route add –host 1.2.3.4 gw 192.168.30.254 删除默认路由：route del –net 10.0.0.0 netmask 255.0.0.0 gw 192.168.30.254 删除默认路由：route del –net 10.0.0.0 netmask 255.0.0.0 dev eth0 curl响应 -o 下载文件并另存为 -O 下载文件 -c –cookie-jar FILE将服务器发送的cookie保存到文件中 curl -c cookie.txt -s https://www.linuxidc.com -I 只显示header信息 curl -s -I http://www.baidu.com -s –silent静默输出 -w 显示特定变量的信息【变量参考man curl】 curl -o /dev/null -s -w “%{http_code}” www.baidu.com 请求 -X 指定请求方法【默认get】 -d/–data 指定post请求数据 curl -X POST –data ‘{“message”: “01”, “pageIndex”: “1”}’ http://127.0.0.1:5000/python -H/–header 指定要发送的header信息 curl -H “Content-Type: application/json” -X POST –data ‘{“userID”:10001}’ http://localhost:8085/GetUserInfo -A 指定user-agent信息 curl -A “Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)” -o page.html https://www.linuxidc.com -b, –cookie STRING/FILE 指定发送请求时要发送的cookie文件或字符串 curl -b ‘a=1;b=2’ https://www.linuxidc.com -e, –referer指定上次访问的页面【可用于盗链】 curl -o test.jpg -e http://oldboy.blog.51cto.com/2561410/1009292 http://img1.51cto.com/attachment/201209/155625967.jpg -x 使用代理服务器 ncnetcat是一个用于TCP/UDP连接和监听的工具,nc是开源版本的netcat工具 常用选项 -l：开启监听模式 -p：nc使用的源端口 -s：发送数据使用的接口ip -n：不要使用DNS反向查询IP地址的域名 -u：使用udp协议 -w：设置超时时间 -v：设置详情输出 -z：扫描时不发送任何数据 主要功能监听和连接 服务端：nc -l 1234 udp服务端：nc -ul 2345 客户端(可用于测试服务端口是否开启)：nc 127.0.0.1 1234 数据传输文件传输 服务端：nc -l 1234 &gt; filename.out 客户端：nc host.example.com 1234 &lt; filename.in 文本传输 与web服务器通信：printf “GET / HTTP/1.0\r\n\r\n” | nc host.example.com 80 与snmp服务器通信： 123456789nc [-C] localhost 25 &lt;&lt; EOFHELO host.example.comMAIL FROM:&lt;user@host.example.com&gt;RCPT TO:&lt;user2@host.example.com&gt;DATABody of email..QUITEOF 端口扫描 范围扫描：nc -zv host.example.com 20-30 列表扫描：nc -zv host.example.com 80 20 22 wget非交互式网络下载器，wget支持https、http、ftp下载 选项 -O：另存为其他文件 -b：后台执行【查看下载进度：tail -f wget-log】 -c：支持断点续传 -i file：从文件中读取下载地址【一行一个】 –limit-rate： 限速【1M=限速1MB/s】 –spider：像spider一样只测试文件是否存在，而不是真正下载 –user-agent=agent-string：设置浏览器代理 –ftp-user/–ftp-password：ftp下载选项 –http-user/–http-password：http下载选项 –proxy-user=user/–proxy-password=password：proxy选项设置 范例 wget -b -c –limit-rate=300K https://mirrors.aliyun.com/docker-toolbox/linux/compose/1.10.0/docker-compose-Linux-x86_64 -O docker-compose.box iptables iptables是一个用于ipv4/ipv6包过滤和地址转换的管理工具 iptables语法主要由路由表、规则链、匹配规则、执行动作构成 iptables语法：iptables (-t 路由表) (规则操作 规则链) (功能参数) (匹配规则) (-j 执行动作) 表和链iptables包含4个表和5个链，路由表是对数据包的不同类型的操作，规则链是在处理流程中的不同时间点进行的操作 路由表：优先级：raw &gt; mangle &gt; nat &gt; filter filter：一般的主机过滤功能，默认表 nat：一般用于网络地址转换（nat） mangle：主要负责修改数据包中特殊的路由标记，如TTL、TOS、MARK等 raw，优先级最高，设置raw一般是为了不再让iptables做数据包的链接追踪处理，提高性能 规则链 PREROUTING：数据包进入路由表之前 INPUT：通过路由表后目的地为本机 FORWARD：通过路由表，目的地不是本机 OUTPUT：本计产生的数据包 POSTROUTING：发送到网卡接口前 规则操作 -A，–append chain rule-spec：在链的末尾添加规则 -D，–delete -D chain rule-spec：删除特定的规则 -D chain rulenum：删除特定编号的规则 -C，–check chain rule-spec：检查特定规则是否存在（与-D chain rule-spec处理逻辑相同） -I，–insert chain [rulenum] rule-spec：在链的指定规则编号前插入规则；如果没有指定规则编号，则在链的第一行插入规则 -R，–replace chain rulenum rule-spec：使用规则替换指定编号的规则 -L，–list [chain]：显示表下链的规则（不指定则显示所有链） -S，–list-rules [chain]：以和iptables-save一样的格式显示规则 -F，–flush [chain]：删除链中的所有规则 -Z，–zero [chain [rulenum]]：清空链中规则的数据包计数器 -P，–policy chain target：更改链的默认处理规则【ACCEPT、DROP等】 -N，–new-chain chain：添加用户自定义链 -X，–delete-chain [chain] ：删除用户自定义链（不能被引用）；如果未定义链名，则删除所有用户自定义链 -E，–rename-chain old-chain new-chain：重命名用户自定义的链 功能参数 -v，–verbose：展示详情输出 -n，–numeric：IP地址和端口以数字形式输出 -x，–exact：在使用-L选项时，显示数字计数器的精确值 –line-numbers：显示规则行号 –modprobe=command：当添加或插入规则时，加载必要的模块【targets、match extensions】 匹配规则[!]是对指定内容取反 [!] -p，–protocol protocol：只对特定协议(如tcp、udp、icmp)的数据包处理，默认为all [!] -s，–sorce address[/mask][,...]：匹配源地址，可以是网段或主机ip地址，–src标志是这个选项的别名 [!] -d, –destination address[/mask][,...]：匹配目标地址。–dst标志是这个选项的别名 [!]-i，–in-interface name：接收数据包的网络接口【仅适用于INPUT, FORWARD、PREROUTING链】 [!]-o，–out-interface name：将要发送数据包的网络接口【仅适用于FORWARD、OUTPUT、POSTROUTING链】 -j，–jump target：可以跳转到用户自定义的链处理；或直接使用内置处理规则【ACCEPT、DROP】处理数据包 -g，–got chain：转向到用户自定义的链处理 -m, –match match：匹配特定属性的扩展规则模块 扩展匹配规则 multiport：多端口匹配【这个模块可以一次性匹配多个源或目的端口，最多可以指定15个端口；地址范围(port:port)被当做是2个端口；只能跟在tcp、udp协议后。】 [!] --source-ports,--sports port[,port|,port:port]：源端口匹配 [!] --destination-ports,--dports port[,port|,port:port]：目的端口匹配 [!] --ports port[,port|,port:port]：端口匹配 范例：iptables -I INPUT -p udp -m multiport –dports 100,180 -j DROP state：网络连接状态匹配【如ftp】 –state 连接状态：NEW(新连接)、ESTABLISHED(已连接)、RELATED(正在连接或已连接)、INVALID(未知连接) 范例：iptables -A INPUT -m state –state ESTABLISHED,RELATED -j ACCEPT tcp：tcp协议匹配，在-p tcp指定后即可使用 [!] --source-port,--sport port[:port]：源端口匹配，只接受一个端口或端口范围 [!] --destination-port,--dport port[:port]：目的端口匹配 [!] --tcp-flags mask：tcp连接状态匹配 范例：iptables -A FORWARD -p tcp –tcp-flags SYN,ACK,FIN,RST SYN udp：udp协议匹配 [!] --source-port,--sport port[:port]：源端口匹配，只接受一个端口或端口范围 [!] --destination-port,--dport port[:port]：目的端口匹配 执行动作 ACCEPT：允许数据包通过 DROP：拒绝数据包通过 REJECT：向匹配的数据包发送一个错误响应，仅适用于INPUT, FORWARD、OUTPUT链 MASQUERADE：仅用于nat表的POSTROUTING链，仅用于出口为动态公网ip的nat连接 SNAT：修改数据包的源地址；仅适用于nat表的INPUT、POSTROUTING链；仅适用于tcp、udp协议 --to-source [ipaddr[-ipaddr]][:port[-port]]：转换为特定源地址 DNAT：修改数据包的目的地址；仅适用于nat表的 PREROUTING、OUTPUT链 --to-destination [ipaddr[-ipaddr]][:port[-port]]：转换为特定目的地址 范例filter与nat数据流 主机防火墙设置1234567891011iptables -Fiptables -Xiptables -Ziptables -A INPUT -s 192.168.100.0/24 -j ACCEPTiptables -A INPUT -i lo -j ACCEPTiptables -A INPUT -p tcp -m multiport --dports 3306,80 -j ACCEPTiptables -A INPUT -p icmp -j ACCEPTiptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPTiptables -P INPUT DROPiptables -P OUTPUT ACCEPTiptables -P FORWARD DROP 正向代理设置 代理局域网主机访问公网 123456789101112net.ipv4.ip_forward = 1sysctl -p# echo 1 &gt; /proc/sys/net/ipv4/ip_forwardiptables -P FORWARD ACCEPTiptables -F -t natiptables -X -t nat iptables -Z -t nat modprobe ipt_stat #开启iptables的状态记录模块modprobe ip_conntrack_ftp #开启iptables的ftp连接追踪模块modprobe ip_nat_ftp #开启iptables的ftp网络地址转换模块iptables -t nat -A POSTROUTING -s 192.168.100.0/24 -o eth1 -j MASQUERADE# iptables -t nat -A POSTROUTING -s 192.168.100.0/24 -o eth1 -j SNAT --to-source 192.168.1.50 反向代理设置 代理内网服务，以便公网可以访问 12iptables -t nat -A PREROUTING -i eth1 -p tcp --dport 80 -j DNAT --to-destination 192.168.100.2:80#iptables -t nat -A PREROUTING -d 192.168.1.50 -p tcp --dport 80 -j DNAT --to-destination 192.168.100.2:80 tcp-wrapper简介 tcp_wrapper是一个类似于iptables的实现访问控制工具；但是，iptables是工作在内核中的，所以只要是一个网络服务经由内核中的TCP/IP协议栈就能够受到netfilter的控制 tcp_wrapper是基于库调用来实现其功能的。这就意味着只有那些在开发时调用了tcp_wrapper相关库（这个库叫libwrap）的应用，tcp_wrapper的控制才能生效。 应用受控判断 编译方式：一个程序在开发时如果调用了某个接口，它在编译时会有两种编译方式 动态编译：表示基于动态链接库的方式使用库 静态编译：表示把调用的库文件直接编译进应用程序内部 应用是否支持tcp_wrapper，两种编译方式的判断如下 动态编译：使用ldd命令，显示出链接至libwrap，即表示支持tcp_wrapper功能；比如ssh服务：【ldd /usr/sbin/sshd】 静态编译：使用strings命令，显示结果中出现两个文件（hosts.allow和hosts.deny）表示支持tcp_wrapper 配置文件 /etc/hosts.allow：允许访问的设置 /etc/hosts.deny：禁止访问的设置 范例：【vsftpd:192.168.241.1】vsftpd服务不允许192.168.241.1访问 执行顺序：先检查hosts.allow，后检查hosts.deny【有相同条目时，allow生效】 配置语法语法：daemon_list：client_list ：[option_list] daemon_list：服务列表 服务的二进制文件名【应用程序是通过二进制文件链接至libwrap库文件来完成访问控制的】 多个服务间逗号分隔 client_list：客户端地址 ip地址 主机名： LOCAL 代表本机 ALL 代表所有程序，所有ip 网络地址 格式1：172.16.0.0/255.255.0.0 格式2：172.16.【最后那个点不能省略】 不能是： 172.16.0.0/16 option_list：可选参数列表 except：排除选项 范例要求：这个网络开放给172.16访问但是这个172.16.100.1不能访问 设置：【vsftpd:172.16. EXCEPT 172.16.100.1】 deny：表示拒绝，用于host.allow文件中，在允许的文件中实现拒绝的功能【vsftpd:192.168.241. :deny】 allow：表示允许，用于hosts.deny文件，实现allow的功能 spawn：额外启动其它应用程序，完成一部分的管理或其它功能 范例要求：本地开放了ftp服务，一旦有人访问了，默认策略【allow或deny】执行后，将其记录到日志中 设置：【vsftpd:ALL :spawn /bin/echo date login attemp from %c to %s,%d &gt;&gt; /var/log/vsftpd.deny.log】 参数注解：%c表示client ip,客户端地址，%s表示server ip，服务器端地址，%d为daomon name即访问的是服务器上的哪个守护进程；]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>curl</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本编辑器-vim]]></title>
    <url>%2F2019%2F07%2F15%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2F%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8-vim%2F</url>
    <content type="text"><![CDATA[简介学习方式vimtutor命令 主要文件 历史记录文件：~/.viminfo 配置文件：~/.vimrc 12345678910&quot;显示行号set nu&quot;tab长度为4个空格set ts=4&quot;把tab显示成空格set expandtab&quot;自动缩进set autoindent&quot;搜索高亮set hlsearch 命令行选项 -o 同时编辑多个文件【ctrl+w+↑↓切换文件】 +n 直接打开文件并定位光标到第n行 vim模式 普通模式：主要进行光标移动，或进行删除、复制、粘贴操作 编辑模式：对文本进行编辑 命令行模式：主要对普通模式进行输入输出操作 使用技巧多行注释与删除 ctrl+v进入块编辑模式 使用上下键选中行首 【大写i】插入#等字符进行注释或d键删除 Esc退出，wq保存 光标定位 普通模式下操作 光标任意移动：n(↑↓←→) 移动n个位置 向右移动n个字符位置：n space： 移动光标到行首：^、0、home 移动光标到行尾：$、end 移动光标到单词结束：e 移动光标到下个单词开始：w 移动光标到文件首行：gg（ngg/nG移动到第n行） 移动光标到文件尾行：G 多行选择：先按Shift + v后,使用上下键选中多行操作 区块选择 v：对光标以前的所有行的区块进行选择 【v :w filename】将区块选择内容保存到filename中 ctrl+v：对光标左上的区块进行选择 文本编辑 普通模式下操作；或普通模式使用i、o、a等进入编辑模式下操作(编辑模式使用Esc退回到普通模式) 单字符操作 x、delete：删除光标下字符 rx：替换当前光标字符为字符x 增加 i：光标前添加内容 I：当前行首添加内容 a：光标后添加内容 A：当前行尾添加内容 o：光标的下一行添加内容 O：光标的上一行添加内容 删除：d(delete) dw：删除内容到下一个单词开始 d2w：删除两个单词 de：删除内容到单词末尾 d$/d^：删除内容到行尾、行首 dd：删除当前行 2dd：删除2行 替换：c(change) ce：替换单词【删除原单词，并进入编辑模式】 c0、c$：替换光标至行首或行尾内容【删除原内容，并进入编辑模式】 复制：y(yank) yy：复制一行 5yy：复制5行 y$：复制到行尾内容 粘贴：p(paster)【将最近删除或复制的内容放入当前光标所在的下一行】 撤销操作：u(undo) 撤销最后一个命令的操作 多个u撤销最近n个操作 ctrl+r：撤销最近一次撤销的动作 U：恢复一行到修改前状态 命令行模式 普通模式使用【:、/、?】符号进入命令行模式(命令行模式下使用Esc退回到普通模式) 搜索 /word：普通模式下默认向后搜索文本 n、N：显示文本下一次【上一次】出现的位置 ?word：普通模式下默认向前搜索文本 替换 :s/old/new 将当前行第一次出现的old替换为new :s/old/new/g 将当前行出现的old都替换为new :n,ms/old/new/g 将n到m行出现的old都替换为new :%s/old/new/g 将当前文件出现的old都替换为new %s/old/new/gc 将当前文件出现的old都替换为new，每个替换都进行交互提示 输入输出 :w：保存(:w! 强制保存) :q：退出(:q! 强制退出) :wq：保存修改并退出(:wq! 强制保存退出) :w filename：保存当前文件到filename n,m w file2：将当前文件的n到m行保存为file2 :r filename：读入filename文件内容到光标的下一行 :r !command：读取命令行输出到光标的下一行 :e file2：跳出当前文件，另行编辑file2文件 :! command：执行shell或cmd命令 帮助与设置 :help：帮助信息 set nu/set nonu：设置行号 less查看文件内容，类似命令有more，但是less比more强大 space：换屏输出 ↑↓：换行输出 /string：向下搜索 ?string：向上搜索 n：下一个匹配字符串 N：上一个匹配字符串 q：退出查看模式]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>less</tag>
        <tag>more</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本处理语言-awk]]></title>
    <url>%2F2019%2F07%2F06%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2F%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E8%AF%AD%E8%A8%80-awk%2F</url>
    <content type="text"><![CDATA[介绍 awk是用于文本检索和处理的语言 awk程序是由一系列的pattern-action以及可选的函数定义组成 可以在命令行中输入短程序文本(通常使用单引号括起来以避免被shell解释)，也可以使用-f选项从文件中读取长的awk程序 读取的数据源可以是命令行的文件列表或标准输入 输入的数据被记录分隔符RS(RS默认为”\n“)切分为多条记录，每个记录都会与每个模式进行比较，如果匹配则执行{action}的程序文本 awk命令命令语法 awk 选项 -f awk程序文件 待处理的文本文件 awk 选项 awk程序文本 待处理的文本文件 命令选项 -f awk程序文件 -F 定义分隔符【也可使用变量FS】，可以同时定义多个分隔符 范例：ifconfig eth0|awk -F&#39;[ :]*&#39; &#39;NR==2{print $3}&#39;【同时使用任意多个空格和任意多个冒号作为分隔符】 -v var=val 定义变量【定义程序执行前的变量】 -e awk程序文本【可省略】 执行顺序 命令行-v指定的变量 BEGIN指定的规则 处理命令行下引用的每一个源文件【ARGV方式调用】 使用pattern匹配每一个record，匹配成功则执行actions 所有record处理完成后，执行END规则 awk程序 awk程序是由一系列的pattern { action }以及可选的函数定义组成 awk是面向行的语言，先是模式(pattern)，后是行为(action)，并且pattern和action是捆绑在一起的【模式控制的动作从紧挨的第一个花括号开始到第一个花括号结束】 pattern或action其中之一可能不存在，但不可能出现二者都缺失的情况；假如pattern缺失，则action应用于每一行记录；如果action缺失，则相当于action是{print}【即打印整行记录】 awk模式 BEGIN/END： BEGIN和END模式不对输入进行测试【也即不需要源文件也能使用BEGIN】，BEGIN在读取输入之前执行，END在所有输入都被处理完毕后执行 BEGIN模式通常被用来改变内建变量，如OFS，RS，FS等，也可以用于初始化自定义变量值，或打印输出标题 BEGIN和END模式必须有action部分 所有BEGIN模式的action部分会合并执行，END模式也是如此；但是BEGIN和END模式不与模式匹配中的表达式合并。 BEGINFILE/ENDFILE：BEGINFILE是在读取命令行的每个文件中的第一行记录之前执行的模式；相应的，ENDFILE是读取命令行的每个文件中最后一行记录之后执行的模式 模式匹配部分：由表达式(可以是记录、字段、内置变量、字符串、数字、正则表达式)和操作符构成 正则表达式 语法：expr ~ /r/ 含义：expr用来和正则表达式【和egrep一样的正则】进行匹配测试 说明：【/r/ { action }】和【$0 ~ /r/ { action }】都是相同的意思，都是用一行记录和正则进行匹配测试 条件表达式 范例：’NR&gt;=2&amp;&amp;NR&lt;=10{print $3}’【取2到10行中第3个字段中的内容】 关系表达式：使用操作符【&amp;&amp;、||、!、三元操作符、括号(改变连接顺序)，逗号(先后进行匹配测试)】连接多个表达式 awk执行 action语句和大多数程序语言一样，由控制语句、输入输入语句、赋值、操作符构成 循环体或action部分被大括号{...}分块，块内语句由分号或换行符分隔，块内最后一条语句不需要终止符 可以使用\来继续长语句；相反的，在逗号、左大括号、&amp;&amp;、do、else、if/while/for语句的右括号、自定义函数的右括号之后，可以在没有反斜杠的情况下断开语句 awk语法记录 记录通常由换行符分隔【也即一行内容为一个记录】，也可以由内置变量RS定义分隔符 只有单字符或正则表达式可以作为分隔符 如果RS设置空，则由空行(\n\n)作为记录分隔符；此时，换行符(\n)作为字段分隔符【FS】 字段 默认使用空格分隔记录为多个字段 使用FS定义字段分隔符，FS可以是单字符或正则表达式 如果设定FIELDWIDTHS，即每个字段相同宽度，则会覆盖FS设置 记录中的每个字段都可以使用$1,$2…$N进行引用，$0表示整个记录，不能使用负数进行字段引用 变量NF表示记录中的总字段数 引用不存在的字段将会产生空字符串 内置变量 ARGC：【count of arg】命令行参数数量【不包括选项和awk程序】 ARGIND：【index in ARGV of file being processed 】当前处理的文件在ARGV中的索引 ARGV：【arry of cmd arg】命令行参数数组 ARGV[0]为awk解释器 ARGV[1]…ARGV[ARGC-1]为待处理的文件 ENVIRON：环境变量数组【环境变量是由a父进程shell传递给awk程序的】 范例：awk &#39;BEGIN{print ENVIRON[&quot;HOME&quot;]}&#39; FIELDWIDTHS：固定宽度分隔字段 FILENAME：当前输入的文件名，在BEGIN阶段则是未定义 NR【number of record】：到目前为止的输入记录总数 FNR：【number record of current file】正在处理的记录在当前文件的行号 NR与FNR：由于awk可以一次处理多个文件，而FNR每打开一个文件都会重置为0，所以总是存在NR&gt;=FNR【在一个文件中NR和FNR相等】 范例(打印5到10行之间的内容)：awk ‘NR&gt;=5&amp;&amp;NR&lt;=10{print $0}’ access.log FS【field separator】：输入字段分隔符【默认空格】 OFS【output field separator】：输出字段分隔符【默认空格】 RS【record separator】：输入记录分隔符【默认换行符】 ORS【output record separator】：输出记录分隔符【默认换行符】 NF【number of field】：输入记录的字段总数 OFMT【output format】：数字输出格式，默认”%.6g” RT【record terminator】：记录终止符，awk将RT设置为与RS相匹配的字符或正则表达式匹配的文本 IGNORECASE：在正则表达式和字符串操作中关闭大小写敏感【当IGNORECASE内置变量的值为非0时，表示在进行字符串操作和处理正则表达式时关闭大小写敏感。】 数据类型 字符串常量 \n：换行符 \t：制表符 \\：反斜杠 字符串：由双引号包围 数字：在awk中变量无须定义即可使用，变量在赋值时即已经完成了定义。变量的类型可以是数字、字符串。根据使用的不同，未初始化变量的值为0或空白字符串” “，这主要取决于变量应用的上下文。 数组 删除数组成员：delete array[index] 删除数组：delete array 操作符 (…)：分组(但是awk分组功能不支持后向引用) $：字段或变量引用 ^：指数【也可以使用**，例如**=可以在赋值语句中使用】 + - * / % ++ --：算数运算符：加、减、乘、除、取余、递增、递减 |和|&amp;：用于getline、print、printf的的管道符 &lt; &gt; &lt;= &gt;= != ==：比较运算符 ~ !~：正则匹配，正则否定；只在符号的右侧使用常量，比如【$1 ~ ‘ceshi’】 in：在数组之中 &amp;&amp; || !：逻辑运算符：“与”、“或”、“非” ?:：三元运算符【第一个为真则执行第二个，否则执行第三个】 = += -= *= /= %= ^=：赋值语句（包含绝对赋值和带有其他操作符的赋值） 流程控制 if语句：if (condition) statement [ else statement ] 多个条件语句使用圆括号分组后使用逻辑操作符连接 多个执行语句使用分号分隔，整体使用花括号包围 循环语句while：while (condition) statement 循环语句do-while：do statement while (condition) 循环语句for：for (expr_st; expr_end; expr_incre) statement 数组循环for：for (var in array) statement 跳出循环体：break 跳出本次循环：continue 退出awk程序【但是不会跳过END模块】：exit [ expression ]{ statements } 多种选择switch： 12345switch (expression) &#123;case value|regex : statement...[ default: statement ]&#125; 输入输出输出重定向 使用shell的通用重定向符号“&gt;”完成awk的输出重定向 使用”&gt;”时，被打开的文件先被清空；文件会持续打开，直到文件被明确关闭(close)或awk程序结束 使用”&gt;&gt;”时，重定向的输出只是添加到文件末尾 输入重定向 awk对于输入重定向是通过getline函数完成的， getline可以从标准输入、管道、当前正在处理的文件之外的其他文件获取 语法 getline：从下一个输入记录中设置$0，同时设置NF, NR, FNR, RT. 对于模式匹配的记录直接跳过，直接处理相邻的下一个记录 getline &lt; file：从下一个文件记录中设置$0，设置NF，RT getline var：从下一个输入记录中设置变量，设置NR，FNR，RT getline var &lt; file：从下一个文件记录中设置变量，设置RT command| getline [var]：执行命令，将结果保存在$0或变量var中以及RT中 范例【命令输出保存为变量并打印】：awk &#39;BEGIN{&quot;date&quot;|getline d;print d}&#39; command|&amp; getline [var]：执行命令，同时将结果保存在$0或变量var中以及RT中 print：打印当前记录【即$0】到标准输出 print expr-list：打印表达式到标准输出 表达式之间以OFS分隔，输出记录以ORS定义的值结束 表达式可以时变量、数值、字符串【字符串使用双引号引用】、字符串常量【如\t：制表符 \n：换行符】 参数之间使用逗号分隔；没有分隔符时，参数就“黏”在一起 范例： 默认格式(%.6g)：awk &#39;BEGIN{a=1.23456789,print a}&#39; 自定义格式：awk &#39;BEGIN{OFMT=&quot;%.2f&quot;;a=1.23456789;print a}&#39; print expr-list &gt;file：打印表达式到文件【文件名使用双引号】 print … &gt;&gt; file：打印表达式到文件末尾 printf fmt, expr-list：格式化输出 范例： 显示日期的每一个字段：date|awk &#39;{for(i=1;i&lt;=NF;i++)printf(&quot;%s\n&quot;,$i)}&#39; 格式化数字：awk &#39;BEGIN{a=123.456;printf(&quot;a is %.2f\n&quot;, a)}&#39; printf fmt, expr-list &gt;file：格式化输出到文件 print … | command：输出写入管道 print … |&amp; command：打印输出并写入管道 next：停止处理当前的输入记录，读取下一个输入记录并使用awk程序的第一个模式处理；在到达输入数据的末尾时，awk执行END规则 对于第一个模式匹配的记录直接跳过，直接处理余下的全部记录 因此需要至少一个匹配模式，next位于第一个匹配模式之后，且由花括号包围 nextfile：停止处理当前的输入文件，读取的下一个记录来自下一个文件。FILENAME和ARGIND被更新，FNR设置为1，并使用awk程序的第一个模式处理；在到达输入数据的末尾时，awk执行END规则 close：关闭文件或管道 system(cmd-line)：执行命令并返回退出状态【不适用于非unix系统】 awk &#39;BEGIN{system(&quot;date&quot;)}&#39; fflush([file])：刷新所有输出文件或管道的buffer，如果文件丢失或为空则刷新所有输出文件或管道 特殊文件当从print或printf进行i/o重定向到文件，或使用getline从文件中进行i/o重定向时，awk程序可以从内部识别某些特殊的文件名。这些文件名允许通过继承自awk的父进程【一般为shell】来进行访问这些文件名也可以直接在命令行【即在shell】进行访问 -：标准输入 /dev/stdin：标准输入 /dev/stdout：标准输出 /dev/stderr：标准错误输出 内置函数字符串函数 gsub(regx, substr [, target_str]) ：在目标字符串中，每个与正则表达式匹配的子串都被替换，并返回替换的次数；如果目标字符串未提供则使用$0 范例：awk &#39;{gsub(&quot;:1&quot;,&quot;--&quot;);print}&#39; test.txt【将记录中的”:1”替换为”–”】 sub(regx, substr [, target_str])：只替换第一个匹配的字符串 index(str, substr)：返回子字符串在字符串中的索引位置，从1开始 范例：awk &#39;BEGIN{print index(&quot;1a2b3&quot;,&quot;2b&quot;)}&#39; test.txt【返回”2b”第一个字符在”1a2b3”中的索引位置】 length([str])：返回字符串的长度或数组个数 match(str, regx [, arry])：返回正则表达式在字符串中出现的位置，找不到则返回0 substr(str, index [, n])：字符串截取，从字符串中的第index个索引位置截取n个字符 tolower(str)：返回字符串的字母的小写形式 toupper(str)：返回字符串中字母的大写形式 split(str, arry [, regx [, seps] ])：使用正则表达式regx定义的分隔符将字符串str拆分成数组arry，如果regx未定义则使用FS 范例：awk &#39;BEGIN{split(&quot;1a 2b 3c&quot;,a)}END{for(i=0;i&lt;length(a);i++)print a[i]}&#39; test.txt awk的切分算法：用split函数将字符串切分为数组，用RS分隔符将文件切分为记录，用FS分隔符将记录切分为字段 strtonum(str)：字符串转化我数字 sprintf(fmt, expr-list)：使用指定格式输出表达式 格式化输出printf %c：单字符 %d, %i：十进制数（整数部分） %e, %E：[-]d.dddddde[+-]dd格式的浮点数【科学表示法】 %f, %F：[-]ddd.dddddd格式浮点数 %g, %G：取%e或%f中较短的内容，并抑制无意义0的输出 %o：无符号八进制数【整数】 %u：无符号十进制数【整数】 %s：字符串 %x, %X：无符号十六进制数【整数】，使用ABCDEF代替abcdef %%：单字符% count$：格式化字符串时指定位置参数 -：表达式应该在字段内左对齐 空格：对于数字转化，应该使用空格为正值添加前缀，使用减号为负值添加前缀 +：数字转化时，为宽度修饰符提供前缀符号 #：对数字系列的控制字符提供转化形式 0：前导0用于数字格式化的填充 width：定义输出宽度 .prec：定义输出精度控制 数学函数 int(expr)：截断为整数 rand()：返回0和1之间的随机数N【0 ≤ N &lt; 1】 srand([expr])：使用expr作为随机数生成器的新种子，如果未提供expr则使用时间作为种子 范例：awk &#39;BEGIN{srand();printf(&quot;%d\n&quot;, rand()*10)}&#39; 时间函数 systime()：返回当前时间到epoch(1970-01-01 00:00:00 UTC)之间的秒数【即timestamp】 mktime(datespec)：将datespec转换成和systime一样的时间戳（timestamp），datespec形式为YYYY MM DD HH MM SS[ DST] strftime([format [, timestamp[, utc-flag]]])：将timestamp格式化为指定格式的字符串输出 范例：awk &#39;BEGIN{print strftime(&quot;%Y%m%d&quot;, systime())}&#39; 类型函数isarray(x)：如果x是数组则返回为真 用户自定义函数 语法:function name(parameter list) { statements } 使用： 可以在pattern或action中调用函数 函数调用时，左括号需要紧跟函数名【但这不适用于内置函数】 可以在函数中使用return表达式来返回值，假如没有提供值则返回值显示为未定义 awk范例getline与next123456789101112131415161718# 源文本123002345671112# next用法示例awk &apos;/3/&#123;next&#125;&#123;print $0&#125;&apos; 1.txt：直接过滤掉包含3的记录# getline用法示例awk &apos;/3/&#123;getline;print $0&#125;&apos; 1.txt：对包含3的记录进行处理：读取下一行内容后直接打印awk &apos;/3/&#123;getline&#125;&#123;print $0&#125;&apos; 1.txt：此时和next用法一直：直接过滤掉包含3的记录 getline 循环获取命令输出并打印：awk &#39;BEGIN{while(&quot;ls&quot;|getline)print}&#39; getline交互式 1234567awk &apos;BEGIN&#123;print &quot;what is your name?&quot;;getline name &lt; &quot;/dev/pts/0&quot;&#125;\$1 ~ name&#123;print &quot;Found &quot; name &quot;on line&quot;, NR&#125;\END&#123;print&quot;See ya,&quot; name&#125;&apos; test.txt# BEGIN部分：打印标题【what is your name?】，从pts终端获取输入并赋值给name# pattern-action部分：如果文件中的某一行记录的第一个字段是name变量的值，则打印内容# END部分：打印name变量相关内容 应用范例 SQL执行统计【将java项目运行过程中的sql导出】：awk -F&#39;Preparing: &#39; &#39;/Preparing/{var=$2;sub(&quot; .*$&quot;,&quot;&quot;,var);print var}&#39; catalina.out-20190622 过滤包含“Preparing”的行【这样的行包含sql语句】 将第一步过滤的记录以“Preparing: ”分隔取第二个字段 删除【双空格及以后的内容】 TCP状态统计：【统计服务器443端口外网tcp各种连接状态及数量】 连接状态统计并排序：netstat -ant|awk -F &#39;[ :]+&#39; &#39;$1 !~ /^Act|^Pro/{if(($5==443)&amp;&amp;($6!=&quot;0.0.0.0&quot;))++count[$8]}END{for(i in count)print i,count[i]}&#39;|sort -nr -k2 排除Act和Pro开头的字头行 包含连接443端口的连接 排除来自0.0.0.0的连接 以tcp状态为作为自加数组变量，不同tcp状态共同构成数组 打印tcp状态及数量 以tcp状态的个数作为排序依据 连接总数【并发】：netstat -ant|awk -F &#39;[ :]+&#39; &#39;$1 !~ /^Act|^Pro/{if(($5==443)&amp;&amp;($6!=&quot;0.0.0.0&quot;))++count[$1]}END{print count[$1]}&#39; 选取每行都不变的信息作为自加变量，最终统计并发连接 WEB访问统计：【nginx日志中：第1个字段为访问者ip，第7个字段为访问的url【含get参数】，第10个字段为访问url响应体大小】 统计每天访问量最大的资源【get去除参数】TOP10:awk -F&#39;[ ?]&#39; &#39;{++url[$7]}END{for(i in url)print i,url[i]}&#39; access.log|sort -rn -k2|head -10 统计每天占用带宽最大的资源TOP10：awk &#39;{sub(&quot;?.*$&quot;,&quot;&quot;,$7);url[$7]+=$10}END{for(i in url)print i,url[i]}&#39; access.log|sort -rn -k2 sub(“?.*$”,””,$7)：get去除参数，获取真正的资源 url[$7]+=$10：对同一个资源，参数不同，获取的响应体大小也不一样；因此需要将相同资源每次返回的响应体大小累加 统计每天访问量最大的ip TOP10：awk &#39;{++ip[$1]}END{for(i in ip)print i,ip[i]}&#39; access.log|sort -rn -k2|head -10 shell脚本中的awk12read -p &quot;pls input a ip:&quot; ipegrep -v &quot;localhost|^$&quot; /etc/hosts|awk &apos;&#123;if($1==&quot;&apos;$ip&apos;&quot;)print $2&#125;&apos; 参考 centos下的gawk man文档 ubuntu下的mawk man文档]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux使用技巧]]></title>
    <url>%2F2019%2F07%2F02%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2Flinux%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[文件swap创建空文件 fallocate -l 4G /home/swapfile truncate -s 2G /swapfile dd if=/dev/zero of=/swapfile bs=4096 count=512k 格式化与挂载12345chmod 600 /home/swapfilemkswap /home/swapfileecho &quot;/home/swapfile none swap sw 0 0&quot; &gt;&gt; /etc/fstabswapon -afree -m ubuntu初始化 创建用户： useradd -s /bin/bash -mr -G sudo test 安装常用软件： sudo apt-get install vim ntp htop tree lrzsz sysv-rc-conf -y 时间和时区设置 12345service ntp startsysv-rc-conf ntp onntpdate -u time1.aliyun.comcp /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeecho &quot;Asia/Shanghai&quot; &gt; /etc/timezone 更改默认编辑器：update-alternatives –set editor /usr/bin/vim.basic 更改文件描述符大小 12echo &quot;* hard nofile 65536&quot; &gt;&gt; /etc/security/limits.confecho &quot;* soft nofile 65536&quot; &gt;&gt; /etc/security/limits.conf 批量删除小文件 建立空目录：mkdir /tmp/blank 使用rsync删除： rsync –delete-before -d /tmp/blank/ /var/spool/postfix/maildrop/ rsync解释：-d 只同步目录【不递归同步】 –delete-before 同步前删除相关文件 批量修改文件12touch &#123;a..g&#125;.htmlfor file in $(ls);do mv $file $&#123;file/html/HTML&#125;;done 判断变量是否为数字 grep过滤：grep -E -w &quot;[0-9]+&quot; expr相加：expr $a + 1 变量删除：${b//[0-9]/} 1+…+100求和 shell下for循环：for((i=0;i&lt;=100;i++));do ((sum+=i));done;echo $sum awk下for循环：awk 'BEGIN{{for(i=0;i]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>swap</tag>
        <tag>ubuntu</tag>
        <tag>全互联</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible之应用实践]]></title>
    <url>%2F2019%2F07%2F02%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%8E%E9%83%A8%E7%BD%B2%2Fansible%2Fansible%E4%B9%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[异步模式异步等待模式 ansible在客户端异步执行，在任务执行过程中，无论ssh连接是否中断都不影响任务执行 async：任务执行超时时间，如无此关键词，则任务以同步模式执行【ansible默认模式】 poll：任务轮询时间，大于0的正值，任务异步执行，但在任务出结果之前ansible在前台阻塞挂起 1234- name: test sleep command: /bin/sleep &#123;&#123; 41 | random(35, 1)&#125;&#125; async: 100 poll: 20 异步非等待模式 poll等于0，则任务不轮询结果 ansible在执行任务的过程中，把任务交给节点后即刻切换到下一个节点，不等待任务的执行结果。 1234- name: test sleep command: /bin/sleep &#123;&#123; 41 | random(35, 1)&#125;&#125; async: 100 poll: 0 查询非等待模式结果123456789101112- name: test sleep command: /bin/sleep &#123;&#123; 41 | random(35, 1)&#125;&#125; async: 100 poll: 0 register: sleep_status- name: check status async_status: jid: &quot;&#123;&#123; sleep_status.ansible_job_id &#125;&#125;&quot; register: job_result until: job_result.finished retries: 10 delay: 10 debugger调试 可以在任意具有name属性的区块设置，比如play、role、block、task debugger值： always：总是调用调试模块 never：从不调用 on_failed：仅在任务失败时调用调试模块 on_unreachable：当主机不可达时调用模块 on_skipped：任务跳过时调用模块 可用命令： p task：显示任务名称 p task.args：显示任务参数 p task_vars：显示任务变量 p host：显示任务操作主机 p result._result：显示任务执行结果 task_vars[key] = value：设置变量 task.args[key] = value：设置参数 r（edo）：重新运行任务 c（continue）：继续执行 q（uit） ：从debugger模式退出 错误处理忽略错误继续执行 默认行为：遇到错误会终止错误处以后task的执行 语法：ignore_errors：yes 定义位置：task 重置主机不可达错误 默认行为：当执行某任务时，主机不可达，会退出正在执行的任务进而退出整个play 设置后：重置主机不可达错误时，某个task的主机不可达不影响其他task的连接尝试 语法：ignore_unreachable: yes 定义位置：play 强制handler执行 默认行为：一个play中某个task的失败，会引起已经触发的handler不再执行 语法：force_handlers: True 定义位置：play、ansible.cfg或命令行（–force-handlers） 1234567891011force_handlers: truehandlers: - name: touch file command: touch /tmp/filetasks: - name: exe handlers command: touch /tmp/file1 notify: - touch file - name: touch failed command: touch /home/muk/ceshi 任何错误都退出 默认情况下：在多个主机执行任务时，在一个主机上遇到错误只造成此主机剩余任务不执行，不影响其他主机任务的执行【多个主机间的错误互不干扰】 设置后：任何主机的任何错误都会造成整个play的退出，不再执行。 语法：any_errors_fatal: true 定义位置：play 重定义失败状态 定义位置：task 语法：failed_when 含义：只有满足自定义的条件才算是失败状态 1234- name: test fail when command: touch /home/ceshi/12 register: result failed_when: &quot;&apos;No such&apos; in result.stderr&quot; 重定义变更状态 定义位置：task 语法：changed_when 含义只有满足自定义的条件才算是“变更”状态 使用block处理错误]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>异步</tag>
        <tag>debug</tag>
        <tag>错误处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux命令-查找替换]]></title>
    <url>%2F2019%2F06%2F30%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2Flinux%E5%91%BD%E4%BB%A4-%E6%9F%A5%E6%89%BE%E6%9B%BF%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[命令列表 sed grep find wc：统计字节数、字符数、单词数、行数 sort sort默认以空白(空格、制表符等)为分隔符，默认以第一个字段的第一个字符排序，其他参数如下 -u：删除重复的行 -f：忽略大小写 -b：忽略数据开始的空格部分 -r：反向排序【默认以字母从前往后排序】 -o：覆盖性输出【可直接覆盖源文档】 -n：按数字大小排序【默认从小到大】 -t：定义分隔符【只能使用单字符作为分隔符】 -k：指定开始和结束字段以及字段内的字符位置【与-t搭配使用】 find在指定的目录下搜索特定的文件，语法格式：find path option 选项参数 -maxdepth n 最大查找深度【0为目录本身；1为当前目录下，依次类推；此选项需紧跟查找路径之后】 -name 按照文件名查找文件【iname忽略大小写】 当name后使用通配符*时必须将匹配模式使用引号括起来或进行转义 find . -name ‘.c’ -print 或 $ find . -name \.c -print -size [±]n按大小匹配（大于、小于或等于n） find . -maxdepth 1 -size +5k -type c按照文件类型匹配（f、d、p、s、b、c、l） -mtime [±]n按文件最后修改时间【以天计数】 -mmin [±]n按文件最后修改时间【以分钟计数】 -o 用于多个条件表达式的”或者” -a 用于多个条件表达式的”同时” find / -type f -size +50k -a -size -55k 2&gt; /dev/null | xargs ls -lh | head -3 查找根目录下大于50k小于55k的文件 ! 逻辑取反 find / -type f -size +50k -a ! -user root 查找根目录下大于50k且不属于root的文件 应用范例name的使用 表达式：find . -name *.log -mtime +60 错误：paths must precede expression 原因：*在shell下会直接进行路径匹配 正确做法：find . -name ‘.c’ -print 或 $ find . -name \.c -print 与xargs的搭配find . -maxdepth 0 -type d -name “*8056” -mtime +119|xargs rm -rf {} grep 功能：显示匹配特定模式的行 语法 grep 选项 [-e] 模式匹配文本 待处理源文件 grep 选项 -f 模式匹配文件 待处理源文件 数据源：grep可以从标准输入或文件中读取数据 选项 -E：使用扩展的正则表达式进行模式解析【等同于egrep，grep默认支持基本的正则】 -F：关闭正则表达式功能，等同于fgrep 范例：grep -F &quot;.*18159&quot; hosts【匹配字符串.*18159】 -e pattern：可以多次定义pattern，从而进行多次匹配 -f FILE：从文件中获取pattern，pattern文件每行定义一个pattern -i：忽略大小写进行匹配 -v：反向匹配 -w：精确匹配单词（而不是目标的子集） -x：精确匹配行（行内容完全相同） 范例：grep -x test1 hosts【匹配行内容只有字符串”test1”内容的行】 -c：显示匹配的行数 –color=auto：对匹配的内容突出颜色显示 -l：显示匹配到内容的文件名【常用于多文件搜索】 -q：静默输出【不输出任何内容】 -s：屏蔽错误输出 -h：匹配到内容时，行首不显示文件名【单文件默认不显示】 -H：匹配到内容时，行首显示文件名【多文件默认显示】 -n：显示行号 -A n：显示每个匹配行及相邻的后n行内容 -B n：显示每个匹配行及相邻的前n行内容 -C m,n：显示每个匹配行相邻的前m、后n行内容 -r：递归读取目录下的文件，但不包含链接 -R：递归读取目录下的文件，包含链接 –exclude=GLOB：跳过指定模式(掩码方式匹配)的文件，掩码可以是* ? [..]，\可以引用字面意思的掩码和通配符 范例：grep -r newpass group_vars/ --exclude=test*【排除group_vars目录下test*文件】 –exclude-from=FILE：跳过模式匹配文件FILE【和exclude一样，使用掩码方式】中匹配到的文件 –exclude-dir=DIR：从递归搜索中跳过指定模式的目录 范例：grep git roles/ -R --exclude-dir={bigdata,web}【跳过roles目录下web、bigdata目录(忽略目录层级)】 –include=GLOB：仅搜索指定模式的文件【和exclude一样，使用掩码方式】 返回值 0：搜索到匹配的内容 1：没有搜索到匹配的内容 2：搜索时发生错误【可使用-qs屏蔽错误及静默输出】 sed简介 含义：用于文本过滤和替换的流编辑器【输入数据源可以是文件或管道】 原理：sed把当前处理的行存在临时缓冲区【模式空间pattern space】中，一旦sed完成对模式空间的处理，模式空间中的行就被送到屏幕输出；行被处理完毕后，被模式空间移除，程序读入下一行进行处理 语法：sed 命令选项 ‘脚本(行选择+操作命令)’ 待操作源文件 命令选项 -n 【–silent –quit】抑制模式空间(pattern space)自动输出，只显示匹配行的内容 -e 【–expression】script：添加命令将要执行的脚本文本【允许多次处理文本行】 范例：sed -e &#39;1,3d&#39; -e &#39;s/Hemenway/Jones/&#39; testfile【删除1到3行后，替换Hemenway为Jones】 -f 【–file】script-file：添加命令将要执行的脚本文件 -i[suffix] 【–in-place[=suffix]】：在模式空间中编辑文件， 如果提供suffix后缀，则会使用suffix后缀对文件备份后再进行编辑 -r【–regexp-extended】：在脚本中使用扩展的正则表达式 -u【-unbuffered】：从输入文件加载最少量的数据并更频繁地刷新输出缓冲区 sed脚本行选择 没有行定位信息表示对所有输入行进行处理 !用于地址【或地址范围】之后、命令之前，用于对不匹配的行进行操作 数字：仅匹配指定行号的内容【命令行-s选项会跨文件累加行号，此时不适用于行号匹配】 first~step：从first开始，每次显示第step行内容 范例：sed -n 1~2p ：从第一行开始，只显示奇数行内容 $：显示最后一行 范例：seq 10|sed -n ‘3,$p’【显示第3行到末尾行的内容】 /regexp/：匹配正则表达式匹配的行 \cregexpc：匹配正则表达式匹配的行：c可以是任意字符 以逗号分隔的2个地址【addr1,addr2】表示对2个地址之间的行进行处理 addr1,addr2 addr1会一直起作用，即使第addr2选择的行早于第1个 假如addr2是正则表达式，则不会对addr1匹配的行本身进行测试 addr1,+N：将匹配addr1及以后的N行 addr1,~N：将匹配addr1及以后到N的倍数的行 0,addr1：addr1只能使用正则表达式，表示从第一行开始到匹配行的内容 1,addr1：addr1可以是任意形式地址，表示从第一行开始到匹配行的内容 操作命令 { }：一个命令块，命令之间以分号分隔 s/regexp/replacement/：使用replacement内容替换正则表达式匹配的内容， regexp分组后，replacement语句可以使用\1..\9进行分组引用【sed -n &#39;/west/s/\(Charles\)/\1jingqi/p&#39; testfile】 默认只替换第一个出现的字符串，使用g标志可对行内进行全部替换【s/regexp/replacement/g】 s后面的字符一定是分隔搜索字符串和替换字符串的分隔符，默认为斜杠；但是在s命令使用的情况下可以改变。不论什么字符紧跟着s命令都认为是新的分隔符。这个技术在搜索含斜杠的模板时非常有用 范例：sed -n ‘/west/s/Charles/jingqi/p’ testfile 【过滤包含west的行后，将Charles替换为jingqi，最后显示该行内容】 &amp;：引用替换命令【s/regexp/replacement/】中正则匹配到的部分 范例：sed -n ‘/west/s/Charles/&amp;jingqi/p’ testfile 【将Charles替换为Charlesjingqi】 a\ text 在文本行之后的新行添加内容 i\ text 在文本行之前的新行添加内容 c\ text：使用文本内容替换文本行 d：删除模式空间内容，开始下一个循环 范例：seq 10|sed ‘3d’【删除第3行，其他行默认输出屏幕】 D：如果模式空间不包含换行符，则和d一样；如果包含换行符，则删除到第一个换行符之间的内容，然后启动循环而不读取新的内容。 p：打印当前模式空间内容 P：打印模式空间第一个换行符之前的内容 = 打印当前行号 l：显示当前行内容【包含隐藏内容，如换行符】 l width：显示当前行内容，以指定行宽度显示【超过宽度的行被截断为新行】 n/N：读取或追加下一行内容到模式空间 范例：sed -n &#39;/^north /{n;s/central/ceshi/p}&#39; testfile【定位到north 开始行的下一行，替换字符串后并显示】 h/H：复制或追加模式空间内容到暂存区 g/G：使用暂存区内容替换模式空间内容，或在模式空间后追加暂存区内容 r filename：将从filename文件读取的全部行内容追加到文本行之后 范例：sed &#39;/^north/r update.txt&#39; testfile【在以north开始的行后插入update.txt中的内容】 R filename：将从filename文件读取的一行内容追加到文本行之后，每次从filename中读取的行内容为上次读取行的下一行 w filename：将模式空间内容写入filename文件 范例：sed -n &#39;/north/w newfile&#39; testfile【将包含north的行写入newfile文件中，同时只显示包含north的行】 W filename：将模式空间的第一行内容写入filename文件 x：交换模式空间和暂存区内容 y/source/dest/：将目标中出现的字符替换为源中存在的字符【不能使用正则表达式】 q：立即退出sed脚本而不处理新行，但如果没有禁用自动打印功能，则会输出模式空间内容 范例：sed &#39;2q&#39; testfile【打印到第2行后退出脚本】 Q：立即退出sed脚本而不处理新行 范例 h与G：sed -e &#39;/^western/h&#39; -e &#39;$G;w newfile&#39; testfile 在第一个编辑模式中，将north开始的行从模式空间放入暂存区 在第二个编辑模式中，将暂存区中的内容追加到末尾行的模式空间，然后写入newfile中 sed中使用shell：里层使用双引号，外层使用单引号 sed -n &#39;/eastern/s/4.5/&#39;&quot;$(date +%F)&quot;&#39;/p&#39; testfile：将4.5替换为当前时间 sed -n &#39;/eastern/s/Savage/&#39;&quot;$USER&quot;&#39;/p&#39; testfile：将Savage替换为当前用户 获取eth0网卡地址： sed：ifconfig eth0|sed -n &#39;s/^.*addr:\(.*\)\sBcast.*$/\1/p&#39; awk：ifconfig eth0|awk -F &#39;[: ]+&#39; &#39;/inet/{print $4}&#39; 文本修改：将文本中的ver版本号替换为2.0.16，filename版本号替换为2.0.17_40 1234Data ver=&quot;2.0.16&quot; filenName=&quot;feng1_360_HD_2.0.15_39.apk&quot;Down ver=&quot;2.0.16&quot; filenName=&quot;feng2_360_HD_2.0.15_39.apk&quot;Data ver=&quot;2.0.14&quot; filenName=&quot;feng3_360_HD_2.0.14_38.apk&quot;Data ver=&quot;2.0.13&quot; filenName=&quot;feng4_360_HD_2.0.16_40.apk&quot; sed方法：sed -i-bak &#39;s/2.0..*\&quot; /2.0.16\&quot; /;s/HD_.*\./HD_2.0.17_40./&#39; 360test_apk.xml awk方法：awk &#39;{gsub(&quot;\&quot;2.0.[0-9][0-9]&quot;,&quot;\&quot;2.0.16&quot;);gsub(&quot;HD_2.0.1[0-9]_[0-9][0-9]&quot;, &quot;2.0.17_40&quot;);print}&#39; 360test_apk.xml 文本修改：将文本1修改为文本2 文本1：【修改前】 1234567&lt;html&gt;&lt;title&gt;Firest web&lt;/title&gt;&lt;body&gt;Hello the World&lt;body&gt;h1helloh1h2helloh2h3helloh3&lt;/html&gt; 文本2：【修改前】 1234567&lt;html&gt;&lt;title&gt;Firest web&lt;/title&gt;&lt;body&gt;Hello the World&lt;body&gt;&lt;h1&gt;hello&lt;/h1&gt;&lt;h2&gt;hello&lt;/h2&gt;&lt;h3&gt;hello&lt;/h3&gt;&lt;/html&gt; 执行命令：sed &#39;s/^\(h[123]\)/&lt;\1&gt;/;s#\(h[123]\)$#&lt;/\1&gt;#&#39; test.txt]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>find</tag>
        <tag>sort</tag>
        <tag>grep</tag>
        <tag>sed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[版本库管理-svn]]></title>
    <url>%2F2019%2F06%2F24%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E8%BE%85%E5%8A%A9%E5%BC%80%E5%8F%91%2F%E7%89%88%E6%9C%AC%E5%BA%93%E7%AE%A1%E7%90%86-svn%2F</url>
    <content type="text"><![CDATA[安装与部署基础配置 authz 1234[groups]member = xianing,chengle,liuzuowei[repos:/]@member = rw passwd 1234[users]xianing = svn1234chengle = svn1234liuzuowei = svn1234 svnserve.conf 12345[general]anon-access = noneauth-access = writepassword-db = passwdauthz-db = authz hooks设置123456789101112131415#!/bin/shexport LANG=&quot;en_US.UTF-8&quot;export LANGUAGE=&quot;en_US:en&quot;REPOS=&quot;$1&quot;REV=&quot;$2&quot;SVN_PATH=/usr/bin/svnWEB_PATH=/usr/share/nginx/htmlLOG_PATH=/tmp/svn_update.log#此行已注释#/usr/bin/svn update --username user --password password $WEB_PATH --no-auth-cacheecho &quot;\n\n\n##########开始提交 &quot; `date &quot;+%Y-%m-%d %H:%M:%S&quot;` &apos;##################&apos; &gt;&gt;$LOG_PATHecho `whoami`,$REPOS,$REV &gt;&gt; $LOG_PATH#注意将此行user和password改为你具体的user和passwordsudo $SVN_PATH update --username like --password svn1234 $WEB_PATH --no-auth-cache &gt;&gt; $LOG_PATHsudo chown -R www-data:www-data $WEB_PATH]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible之变量与模板]]></title>
    <url>%2F2019%2F06%2F20%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%8E%E9%83%A8%E7%BD%B2%2Fansible%2Fansible%E4%B9%8B%E5%8F%98%E9%87%8F%E4%B8%8E%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[变量变量使用注意 变量名，应该以字母开头，并且变量名中不含空格、逗点、中横线 变量内容，如果只包含字母、数字、下划线、中横线等普通字符，可以直接书写，无需使用引号 使用jinja2模块系统进行变量引用 对于字典变量，可以使用方括号或点方式引用，但是点方式可能会和python字典的属性或方法冲突 变量作用域 全局：由config、环境变量【environment】、命令行设置 play级别：每个play和包含的结构，变量条目【vars，vars_files，vars_prompt】，roles的defaults和vars host级别：直接关联主机的变量，比如inventory，include_vars，facts信息，任务执行产生的注册变量 特殊处理 模板语法（双大括号和大括号百分号）已插入转移符\特殊处理 当变量内容包含特殊字符（如&amp;#）时，需使用双引号包围变量内容； 当变量内容含有{\{等字符时，则需要使用“!unsafe“标志避免语法错误：un_safevar: !unsafe &#39;{\{in12var&#39; 避免模板变量被渲染（无论变量是否存在，都不对变量进行渲染）：{\% raw %\}{\{ test1 }\}{\% endraw %\} 锚点和引用 这是yaml语法特性 123456789101112vars: test1: &amp;defaults &apos;he&apos; #定义锚点 test2: - &apos;jing&apos; - &apos;qi&apos; - *defaults # 在列表中引用锚点 test3: &amp;pro name: &apos;yaning&apos; age: 30 test4: &lt;&lt;: *pro # 将test3的变量内容合并到test4中 age: 31 # 重新定义age变量 内置变量 保留变量 hostvars：主机变量 可以在当前主机访问其他主机变量 hostvars[&#39;bigdata&#39;][&#39;ansible_facts&#39;][&#39;eth0&#39;][&#39;ipv4&#39;][&#39;address&#39;] groups：所有组信息 group_names：当前主机所在组信息 inventory_hostname：inventory中定义的主机名 playbook_dir：playbook根目录 inventory_dir：inventory所在目录 facts变量：ansible_facts 连接类型变量 ansible_user：远程连接用户 ansible_ssh_pass：ssh连接密码 inventory中定义的变量inventory文件 主机变量： crm ansible_user=&#39;root&#39; ansible_ssh_pass=&#39;123456&#39; 组变量： 12[nginx:vars]key=9 inventory目录 与inventory同级或在其下的group_vars/host_vars目录 可以包含在playbook根目录下，也可以包含在inventory目录下，当两者同时存在时，playbook下的覆盖inventory下的 变量目录包含的变量文件是yaml格式的，且文件名没有后缀或是以’.yml’、’.yaml’、’.json’为后缀 ansible-playbook命令默认寻找当前playbook目录下的变量文件，但是其他ansible命令（比如ansible/ansible-console）则只查找inventory目录下的变量文件，除非使用–playbook-dir参数后才会查找playbook下的变量文件 多个地方定义的变量，优先级如下：host》childgroup》parentgroup》allgroup group_vars目录下定义组变量 组名文件表示组变量 all文件表示所有组的公共变量 host_vars目录下定义主机变量 主机名或ip名文件表示主机变量 playbook中定义的变量1234567891011121314151617vars: #直接定义变量 - key1: 8 # 定义长字符变量 - key5: | 123000 234111 345222vars_files: #使用变量文件 - var.ymlvars_prompt: #交互式输入变量 - name: &quot;key3&quot; #变量名 prompt: &quot;pls input key3 value:&quot; #交互式信息 default: &apos;None&apos; #默认值 private: yes #是否显示输入tasks: - name: debug info debug: msg=&quot;key1 is &#123;&#123; key1 &#125;&#125; key2 is &#123;&#123; key2 &#125;&#125; key3 is &#123;&#123; key3 &#125;&#125;&quot; roles中的变量 vars目录定义的变量不可被inventory级别定义的变量覆盖，但是play、命令行级别的可以覆盖 defaults目录定义的变量可以被inventory级别定义的变量覆盖 命令行下的变量 命令行下使用key=value传递的变量都是字符串形式，如果要传递其他类型变量【如：布尔、整数、浮点型、列表等】则需要使用json格式 范例：ansible-playbook -e “key1=7 key2=foo” -e “@var.yml @var1.json” test.yml facts中的变量facts是从远程操作系统收集的信息 facts变量获取 可以在playbook中使用变量ansible_facts获取 debug: var=ansible_facts 也可以使用setup模块获取 ansible执行过程中默认收集facts信息 ansible.cfg中配置项gathering设置默认行为 play中设置gather_facts改变默认行为 默认没有开启facts缓存【可以在ansible.cfg设置如下参数开启文件形式缓存】 fact_caching = jsonfile fact_caching_connection = /tmp fact_caching_timeout = 86400 facts变量引用 facts变量可以从缓存或开启收集功能后实时获取 可以在当前执行任务的主机中获取其他主机或组的facts变量信息，但是 需要在同一个play中已经和其他主机或组进行过通信，获取过facts信息 或者，在更高级别的play中有收集过其他主机或组的facts信息 也可以，开启facts缓存，当本地缓存有其他主机或组的facts信息时，则需受上述规则限制 注册变量 执行一个任务，并将任务返回值保留为一个变量以用于后续任务，此时的变量即是注册变量 注册变量只在产生之后、play运行结束之前有效，并且它只保留在内存中【而不像facts可以自定义保存位置】 12345- name: register variable shell: hostname register: info- name: use register debug: msg=&quot;This is &#123;&#123; info.stdout_lines[0] &#125;&#125;&quot; 变量冲突 变量合并 变量优先级 连接类型变量优先级【特定类型的链接设置优先于通用设置】：ansible_ssh_user》ansible_user》remote_user 主机与组的变量优先级：主机变量》组变量》父组变量 优先级简单表示【优先级从高到低】 命令行自定义变量 task 【tasks列表中定义的变量】 role 【roles列表中定义的变量】 play playbook inventory 过滤器 jinja2内置过滤器 ansible支持的过滤器 常用过滤器 名称 含义 int 字符串转整形 capitalize 首字母大写 default 设置默认值 random 取随机值 min/max 取最大最小值 replace 替换 regu_replace 正则替换 join 字符串拼接 json_query 从复杂json结构中获取值 from_json 从json文件获取变量 from_yaml 从yaml文件中获取变量 使用范例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657---- hosts: 127.0.0.1 gather_facts: False vars: filename: /etc/profile list: [1, 2, 3, 4, 5] one: &quot;1&quot; str: &quot;string&quot; domain_definition: domain: cluster: - name: &quot;cluster1&quot; - name: &quot;cluster2&quot; server: - name: &quot;server11&quot; cluster: &quot;cluster1&quot; port: &quot;8080&quot; - name: &quot;server12&quot; cluster: &quot;cluster1&quot; port: &quot;8090&quot; tasks: # 使用jmespath从复杂json结构中获取变量 - debug: var: item loop: &quot;&#123;&#123; domain_definition|json_query(&apos;domain.cluster[*].name&apos;)&#125;&#125;&quot; - name: use filter basename shell: echo &#123;&#123; filename|basename &#125;&#125; &gt;&gt; /tmp/shell11 - name: debug int capitalize filter debug: msg=&quot;The int value &#123;&#123; one|int &#125;&#125; the lower value is &#123;&#123; str|capitalize &#125;&#125;&quot; - name: debug default value filter debug: msg=&quot;The variable is &#123;&#123; ansible|default(&apos;ansible is not defined&apos;)&#125;&#125;&quot; # 当default第二个值为true，则会在变量计算出来为空或false时使用默认值 - debug: msg: &quot;var is &#123;&#123; lookup(&apos;env&apos;, &apos;USER1&apos;)|default(&apos;admin&apos;, true)&#125;&#125;&quot; - name: debug list max and min filter debug: msg=&quot;The list max value is &#123;&#123; list|max &#125;&#125; the min is &#123;&#123; list|min &#125;&#125;&quot; - name: debug join filter debug: msg=&quot;The join filter value is &#123;&#123; list|join(&apos;+&apos;) &#125;&#125;&quot; - name: debug random filter # 从1开始步长为10取随机值 debug: msg=&quot;the list random value is &#123;&#123; list|random &#125;&#125; generate a random value &#123;&#123; 1000|random(1, 10)&#125;&#125;&quot; - name: debug replace and regex_replace filter debug: msg=&quot;The replace value is &#123;&#123; str|replace(&apos;t&apos;, &apos;T&apos;)&#125;&#125;,\ The regex_replace value is &#123;&#123; str|regex_replace(&apos;.*str(.*)$&apos;, &apos;\\1&apos;)&#125;&#125;&quot; # 从json或yaml文件中读取变量 - name: cat test.json shell: cat test.json register: result_json - name: debug json info debug: msg: &quot;test2 var is &#123;&#123; (result_json.stdout|from_json)[&apos;test2&apos;]&#125;&#125;&quot; - name: cat test1.yml shell: cat test1.yml register: result_yml - name: debug yml info debug: msg: &quot;test1 var is &#123;&#123; (result_yml.stdout|from_yaml)[&apos;test1&apos;] &#125;&#125;&quot; lookup插件 lookup插件允许访问外部数据源 解析过程在控制端完成，和模板系统类似 file从文件中解析内容12345vars:- contents: &quot;&#123;&#123; lookup(&apos;file&apos;, &apos;/etc/hosts&apos;)&#125;&#125;&quot;tasks:- name: display network content debug: msg=&quot;network content is &#123;% for i in contents.split(&apos;\n&apos;) %&#125;&#123;&#123; i &#125;&#125;&#123;% endfor %&#125;&quot; template主要用于解析模板中的facts信息【被控主机】123456789lookup.j2：worker_processes &#123;&#123; ansible_processor_cores &#125;&#125;IPaddress &#123;&#123; ansible_eth0.ipv4.address &#125;&#125;test.yml：vars:- temp: &quot;&#123;&#123; lookup(&apos;template&apos;, &apos;lookup.j2&apos;)&#125;&#125;&quot;tasks:- name: display lookup content debug: msg=&quot;network content is &#123;% for i in temp.split(&apos;\n&apos;) %&#125;&#123;&#123; i &#125;&#125;&#123;% endfor %&#125;&quot; pipe解析命令行输出12345vars:- cmd: &quot;&#123;&#123; lookup(&apos;pipe&apos;, &apos;date +%s&apos;)&#125;&#125;&quot;tasks:- name: display lookup content debug: msg=&quot;&#123;&#123; cmd &#125;&#125;&quot; redis从redis中解析key值12345vars:- key: &quot;&#123;&#123; lookup(&apos;redis&apos;, &apos;he&apos;, host=&apos;127.0.0.1&apos;, port=6379)&#125;&#125;&quot;tasks:- name: display lookup content debug: msg=&quot;&#123;&#123; key &#125;&#125;&quot; csvfile从csv文件中解析内容1234# java1是第0列的值，同时作为key，去取第4列的值【从0开始索引】# 此时逗号作为分隔符【默认为tab（TAB或t）】- name: get value from csv debug: msg=&quot;java1 password is &#123;&#123; lookup(&apos;csvfile&apos;, &apos;java1 file=b.csv delimiter=, col=4&apos;)&#125;&#125;&quot; lookup与loop lookup一次解析的多个结果默认用逗号连接；loop循环默认用列表作为输入。 为了让lookup解析的结果可以使用loop循环输出，需要如下操作，以便将解析结果转为列表 在lookup中添加wantlist=True， 或使用query代替lookup 12345 - debug: # msg: &quot;&#123;&#123; lookup(&apos;inventory_hostnames&apos;, &apos;all&apos;, wantlist=True)&#125;&#125;&quot; msg: &quot;&#123;&#123; query(&apos;inventory_hostnames&apos;, &apos;all&apos;)&#125;&#125;&quot;# msg: &quot;&#123;&#123; item &#125;&#125;&quot;# loop: &quot;&#123;&#123; lookup(&apos;inventory_hostnames&apos;, &apos;all&apos;, wantlist=True) &#125;&#125;&quot; 循环 loop可以部分替代with_xxx功能 普通列表12345678910111213vars: - numbers: [&apos;one&apos;, &apos;two&apos;, &apos;three&apos;]- debug: msg=&apos;&#123;&#123; item &#125;&#125;&apos; # with_flattened: &apos;&#123;&#123; numbers &#125;&#125;&apos; loop: &apos;&#123;&#123; numbers|flatten &#125;&#125;&apos;- debug: msg=&quot;&#123;&#123; item &#125;&#125;&quot; # with_items: loop: - &apos;one&apos; - &apos;two&apos; - &apos;three&apos; hash列表12345- debug: msg=&quot;&#123;&#123; item.key &#125;&#125; is &#123;&#123; item.value &#125;&#125;&quot; # with_items: loop: - &#123;&apos;key&apos;: &apos;name&apos;, &apos;value&apos;: 1&#125; - &#123;&apos;key&apos;: &apos;nam2&apos;, &apos;value&apos;: 2&#125; 字典12345678910111213vars: - user: shencan: name: shencan shell: bash ruifengyun: name: ruifengyun shell: zsh- debug: msg=&apos;&#123;&#123; item.key &#125;&#125; value=&#123;&#123; item.value.name &#125;&#125; shell=&#123;&#123; item.value.shell&#125;&#125;&apos; #loop: &quot;&#123;&#123; user|dict2items &#125;&#125;&quot; with_dict: &quot;&#123;&#123; user &#125;&#125;&quot; 双循环1234- shell: &quot;echo &#123;&#123; item[0] &#125;&#125;*&#123;&#123; item[1] &#125;&#125;|bc&quot; with_nested: - [2, 3] - [3, 5, 7] 匹配文件1234- shell: echo 12 &gt; &#123;&#123; item &#125;&#125; with_fileglob: - &apos;./*.1&apos; - &apos;./*.2&apos; 条件判断when 一次性判断 when中直接使用变量名，不需要使用双大括号 多条件复杂逻辑关系可使用括号分组，如：【project_alias == “tomcat-crm” and (flag is changed or exe is defined)】 多个条件为and关系时可以使用列表形式 12345- name: touch file when os is ubuntu command: touch /tmp/ceshi when: - ansible_facts[&quot;os_family&quot;] == &quot;Debian&quot; - ansible_memory_mb.real.total &gt; 900 执行结果判断 successed failed changed skipped undefined【变量未定义】 12345678910111213- name: test result git: repo: https://github.com/simple0426/gitbook.git dest: /home/python/gitbook version: master run_once: true register: result- name: debug change debug: msg=&quot;change&quot; when: result is changed- name: debug undefined debug: msg=&quot;key12 is undefined&quot; when: key12 is undefined until多次尝试性判断 1234567# 每隔15s执行一次，共尝试3次；条件依然不满足时，task失败- name: ensure time is 201905241750 shell: date +%Y%m%d%H%M register: date until: date.stdout == &apos;201905241750&apos; retries: 3 delay: 15]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>变量</tag>
        <tag>lookup</tag>
        <tag>loop</tag>
        <tag>condition</tag>
        <tag>filter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志切割工具logrotate]]></title>
    <url>%2F2019%2F06%2F13%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2F%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E5%B7%A5%E5%85%B7logrotate%2F</url>
    <content type="text"><![CDATA[示例1234567891011121314151617/home/haproxy/log/*.log &#123;rotate 15dailydateextmissingoknotifemptycompressdelaycompresscopytruncatesize 50M# create 0640 user group# olddir oldlog# sharedscripts# postrotate# reload rsyslog &gt;/dev/null 2&gt;&amp;1 || true# endscript&#125; 介绍 功能 日志轮转 压缩 删除 默认在每天的定时任务【cron.daily】下执行，因此每天只会执行一次 只有当日志轮转参数基于日志大小并且多次运行logrotate，或者使用-f参数【logrotate -f】才会形成对日志的修改 可以在命令行使用任意多的配置文件或定义配置文件目录；具有相同功能的配置选项，后面的配置会覆盖前面的配置 命令参数 -f 强制日志轮转 -s 使用轮转状态文件，默认使用/var/lib/logrotate.status 默认轮转命令/usr/sbin/logrotate -s /var/lib/logrotate/logrotate.status /etc/logrotate.conf 配置选项 rotate count：日志轮转数量【保留的旧日志数量】 include：包含其他配置选项 包含在全局配置中，但不能包含在log配置中 compress：旧日志压缩，默认使用gzip delaycompress：延迟压缩功能 nocompress：不对旧日志进行压缩 copy：对当前日志文件创建一个副本，但不改变原来的日志文件【create选项会覆盖此功能】 nocopy：不复制日志 copytruncate：对当前日志建立一个副本后，清空原有日志文件【create选项会覆盖此功能】 在实时日志较大时会出现小部分丢失清空 适用于程序不能产生新日志文件的情况 nocopytruncate：在建立新副本后不清空原有日志 create mode owner group：设置新日志的属性 需要搭配postrotate脚本来通知程序产生新的日志文件 当任何的属性不设置时，都采用和原文件相同的属性 nodelaycompress：不延迟压缩日志 ifempty：日志为空也轮转 notifempty：日志为空不轮转 size：日志轮转大小，以字节为单位，可选单位【k、M、G】 missingok：日志不存在不报错 nomissingok：需要轮转的日志不存在时，报错 daily：按天轮转日志 weekly：按周轮转日志 monthly：按月轮转日志 yearly：按年轮转日志 dateext：以日期设置旧日志文件后缀【布尔类型】 nodateext：不用日期设置旧日志文件后缀 dateformat：设置旧日志文件后缀格式【默认-%Y%m%d】 olddir directory：旧日志被移动到一个单独的目录，可以是相对路径，也可以是绝对路径【但必须在同一个物理磁盘上】 noolddir：轮转日志在同级目录 postrotate/endscript：日志轮转之后执行的命令或脚本【/bin/sh】，这些指令只可能出现在日志文件定义中 可以向进程发送特殊信号【signal】触发程序产生新的日志文件【相当于使用了create选项】 prerotate/endscript：日志轮转之前执行的命令或脚本【/bin/sh】，这些指令只可能出现在日志文件定义中 sharedscripts：对于同一个log定义下的所有待轮转的日志文件，他们所需执行的pre或post脚本仅被执行一次； nosharedscripts：默认情况下，同一个log定义下每个待轮转的文件都会触发pre或post脚本的执行 应用实践12345678910111213141516171819202122232425262728# 全局设置compress # 使用双引号以处理特殊情况，比如文件名中的空格等# 对于使用同一轮转配置的多个文件# 可以在一行书写多个待轮转文件，空格分隔&quot;/var/log/httpd/access.log&quot; /var/log/httpd/error.log &#123; xxxxxx&#125;# 也可以一行写一个待轮转文件，书写多行/home/web/webhive/log/uwsgi/imgstore.log/home/web/webhive/log/uwsgi/shownail.log&#123; copytruncate daily dateext rotate 60 compress delaycompress missingok notifempty&#125;# 使用掩码进行文件名匹配/var/log/news/* &#123; xxxxxx&#125;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>logrotate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web基础知识]]></title>
    <url>%2F2019%2F06%2F11%2F%E9%80%9A%E7%94%A8%E6%8A%80%E8%83%BD%2Fweb%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[http浏览过程 用户提交域名 浏览器进行域名解析 浏览器使用本地缓存进行域名解析【刷新dns缓存：ipconfig/flushdns】 本地无缓存时使用本地dns服务器 本地dns无缓存时向授权dns服务器请求解析 有使用CDN时，进入CDN解析循环 访问模式BS模式即browser/server浏览器/服务器模式，是一种三层架构【页面显示、逻辑处理、数据库访问】， B/S架构中显示逻辑交给了web浏览器，事务处理放在webapp上，这样就避免了庞大的客户端，减少了客户端的压力，因为客户端包含的逻辑较少，因此也被称为瘦客户端 优点 无需安装客户端，有web浏览器就够了 BS架构无需升级多个客户端，升级服务器就行了 缺点 在跨浏览器上，需要测试人员进行各种测试 在速度和安全上需要花费巨大的设计成本，这是BS架构的最大问题 客户端服务器的交互式请求-相应模式，通常需要刷新页面，这并是不客户乐意做的（在Ajax实用化后此问题得到一定程度的缓解） CS模式C/S系统是一种典型的两层架构，期全称为Client/server，客户端服务端架构，客户端包含一个或多个在用户电脑上运行的程序，而服务端有两种，一种为数据库服务端，客户端通过数据库连接访问服务端的数据；另一种是socket服务器端，服务器程序通过socket与客户端程序通信。C/S架构为胖客户端，因为客户端需要实现绝大部分的业务逻辑和页面展示。这种架构中，通过与数据库交互（通常是sql或存储过程的实现）来达到持久化数据。 优点 C/S架构的页面和操作可以很丰富 服务器端和客户端可以更好的兼容 缺点 需要安装客户端，不利于向未知用户推广 维护成本高，发生一次升级，则所有客户端的程序都需要改变 网页技术静态网页程序在客户端浏览器解析，它是相对于动态网页而言，是指没有后台数据库、不含程序和可交互的网页。通俗来说就是编辑什么显示什么不会有任何变化。常见扩展名为：htm、html、xml、shtml、jpg(gif、png、bmp等所有图片)、js、css（样式），swf，avi，wmv，flv视频格式 特点 静态网页的每个页面都有一个固定的url，且网页url一般以.html、.htm、.shtml常见后缀，而且地址中不含有问号“？”或“&amp;”等特殊符号； 静态网页是实实在在保存在服务器上的文件，每个网页都是一个独立的文件 静态网页内容相对稳定，因此更容易被搜索引擎收录 静态网页没有数据库支持，维护更新不便 静态网页交互性差 网页程序在浏览器端解析，服务器直接返回数据，能够接受更多的并发 静态网页语言html，js，css，xml 动态网页以asp、aspx、php、jsp、do、cgi、perl为后缀，并且一般动态网页中含有标志性的“？”、“&amp;”等 特点 以数据库技术为基础 可以实现更多的功能，如用户登录、用户注册、在线调查、用户管理、订单管理等 动态网页大多并不是独立存在于服务器的网页文件，只有当用户请求时服务器才返回一个完整页面 动态网页中的“？”对搜索引擎的收录存在一定问题，搜索引擎一般不可能从一个网站的数据库中访问全部的网页，或者出于技术方面的考虑，所有蜘蛛一般不会去抓取网址中“？”后面的内容，一般采用动态网页的网站在进行搜索引擎推广时需要做一定的技术处理（伪静态）才能适应搜索引擎的抓取要求。 程序在服务端解析，服务端：php引擎，java容器（tomcat，resin，jboss、weblogic） 由于程序在服务端解析，因此会消耗大量的cpu和内存等资源，因此效率不如静态网页 伪静态网页 由于搜索引擎无法正确读取带参数的动态网页内容，多数网站采用动态生成静态页面的技术，消除动态网页中的参数，使搜索引擎收录更多的网页，达到优化的效果，伪静态实质依然是动态页面。 伪静态技术：通过某些技术（如rewrite规则），把网页的url重写，同时消除了动态网页中的参数，但是并不生成任何的页面，仅改变了地址路径，以达到搜索引擎收录的目的。 http报文 请求行 范例：GET /index.html HTTP/1.1 请求方法：GET、POST、HEAD、PUT、DELETE、OPTIONS、TRACE、CONNECT GET：当客户端从服务端读取文档时使用GET方法，使用GET方法时，请求参数和对应的值附加到URL后，利用一个问号（“？”）代表URL的结束与请求参数的开始，传递参数的最长为1024个字节 POST：当客户端向服务端提交的信息较多时使用POST方法，POST方法将参数和值封装在请求的数据中，以键值对的形式出现 请求头 请求头部由关键字/值对组成，每行一对。关键字与值使用英文冒号分割。请求头部通知服务器关于客户端请求的信息。 典型的请求头有： User-agent：产生请求的浏览器类型 Accept：客户端可识别的内容类型列表 Host：请求的主机名，允许多个域名同处一个ip地址，即为虚拟主机。 空行 最后一个请求头之后是一个空行，发送回车和换行符，通知服务器一下不再有请求头 对于一个完整的http请求来说，空行是必须的，否则服务器会认为本次请求的数据尚未完全发送到服务器，服务器会一直处于等待状态。 请求数据 请求数据不在GET方法中，而是在POST方法中 POST方法适用于需要客户填写表单的场合 与请求数据相关的最常用的请求头有Content-Type和Content-Length GET与POST GET是从服务器上获取数据，POST是向服务器传送数据 对于GET方式，服务端使用Request.QueryString获取变量的值；POST方式服务端使用Request.Form获取提交的数据 GET方式通过URL提交数据，数据在URL中可以看到，所以不安全；POST方式，数据放在html header中，较为安全。 GET方式提交的数据最多为1024字节，POST方式则没有限制。 http状态码 群组 状态码 含义 2系列【成功】 200 OK,服务器成功返回网页 3系列【重定向】 301 Moved Permanently（永久跳转）请求的网页已永久跳转到新位置 4系列【请求错误】 403 Forbidden（禁止访问）服务器拒绝请求 4系列 404 Not Found，服务器找不到请求的页面 5系列【服务器错误】 500 Internal Server Error(内部服务器错误) 5系列 502 Bad Gateway（坏的网关），一般是网关服务器请求后端服务时，后端服务没有按照http协议正确返回结果 5系列 503 Service Unavailable（服务不可用），可能因为超载或停机维护 5系列 504 Gateway Timeout（网关超时），一般是因为网关服务器请求后端服务时，后端服务没有在特定的时间内完成服务 名词注解 IP：独立的ip数，是网站流量分析的重要指标，0:00-24:00内相同ip被计算一次 PV【page view 访问量】：用户刷新一次被计算1次 UV【unique vistor独立访客】：访问网站的一个电脑客户端为一个访客 通过IP地址+其他特征信息定义 通过cookies分辨 URI标记一个网络资源 URL用地址标记一个网络资源 格式：scheme://host.domain:port/path/filename 范例：http://www.w3school.com.cn/html/html_url.asp web服务器 IIS：windows下常用web服务器 apache nginx tomcat]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>状态码</tag>
        <tag>http报文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx进阶学习]]></title>
    <url>%2F2019%2F06%2F11%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2Fweb%E6%9C%8D%E5%8A%A1%2Fnginx%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[参考文档淘宝nginx文档 proxy设置proxy相关变量 $remote_addr：客户端地址【距离服务器最近的客户端ip，有代理时为代理的ip】 $http_x_real_ip： 在没有特殊配置情况下，X-Real-IP请求头不会自动添加到请求头中； 这个请求头一般为代理服务器设置，形如：proxy_set_header X-Real-IP $remote_addr; 如果经过两次代理【客户端-》cdn-》waf-》nginx】，且都设置proxy_set_header X-Real-IP $remote_addr，则在nginx服务层获取的http_x_real_ip为cdn的ip地址 $http_x_forwarded_for： 在没有特殊配置情况下，X-Forwarded-For请求头不会自动添加到请求头中； 代理服务器中的设置：proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; $proxy_add_x_forwarded_for： 如果请求头中没有X-Forwarded-For则$proxy_add_x_forwarded_for为$remote_addr 代理服务器中的设置：proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 此变量是把请求头中的X-Forwarded-For与$remote_addr用逗号合起来，每经过一个反向代理就在请求头X-Forwarded-For后追加反向代理IP，形如：real client ip, proxy ip 1。。。proxy ip N upstream参数 upstream用于nginx代理多个相同功能的后端服务器，在nginx层实现对后端服务器的高可用和负载均衡 upstream在http区块下，与server同级 server语法： weight：服务器的权重，默认为1 max_fails：失败重试次数，默认为1，0为不重试 fail_timeout：与服务器通信的超时时间【此时认为服务器不可达】。默认为10s。 backup：标记作为备份服务器，当主服务器不可达时被启用 down：标记服务器永久不可用；可以和ip_hash指令一起用；当服务器被标记为down状态时，nginx和后端服务器已经建立的连接并不会被移除，只会阻止建立新的连接，因此可以用于nginx后端的软下线。 负载均衡算法 默认情况，请求通过权重轮询算法被分配给服务器 ip_hash用于将客户端请求基于客户端ip地址分发给后端服务器【一个客户端的所有请求只会发给一个后端服务器】；在ip_hash模式下，当一台服务器需要被临时移除，为了保持客户端ip地址的hash值，应当为此服务器标记down参数。 范例： 1234upstream server &#123; server 192.168.100.1 weight=1 max_fails=2 fail_timeout=30s; server 192.168.100.3 weight=1 max_fails=2 fail_timeout=30s; &#125; proxy参数设置12345678910111213# http, server, locationproxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_connect_timeout 60;proxy_send_timeout 60;proxy_read_timeout 60;proxy_buffering on;proxy_buffer_size 4k;proxy_buffers 4 32k;proxy_busy_buffers_size 64k;proxy_temp_file_write_size 64k; 12345678910111213141516171819202122232425proxy_redirect 是否对后端服务器的“Location”响应头和“Refresh”响应头进行该写,默认为default，即使用代理服务器的location替换后端服务器的location；off为关闭替换proxy_set_header 设置后，可以向后端服务器传递指定的header信息，默认的只有下面的header被定义 proxy_set_header Host $proxy_host; proxy_set_header Connection close;proxy_connect_timeout 表示与后端服务器连接的超时时间，即发起握手等候响应的超时时间；这个超时一般不可能大于75秒proxy_send_timeout 定义向后端服务器传输请求的超时。此超时是指相邻两次写操作之间的最长时间间隔，而不是整个请求传输完成的最长时间。如果后端服务器在超时时间段内没有接收到任何数据，连接将被关闭。 proxy_read_timeout 定义从后端服务器读取响应的超时。此超时是指相邻两次读操作之间的最长时间间隔，而不是整个响应传输完成的最长时间。如果后端服务器在超时时间段内没有传输任何数据，连接将被关闭。 proxy_buffering on; 代理的时候，开启或关闭缓冲后端服务器的响应。默认为on； 当开启缓冲时，nginx尽可能快地从被代理的服务器接收响应，再将它存入proxy_buffer_size和proxy_buffers指令设置的缓冲区中。如果响应无法整个纳入内存，那么其中一部分将存入磁盘上的临时文件。proxy_max_temp_file_size和proxy_temp_file_write_size指令可以控制临时文件的写入。 当关闭缓冲时，收到响应后，nginx立即将其同步传给客户端。nginx不会尝试从被代理的服务器读取整个请求，而是将proxy_buffer_size指令设定的大小作为一次读取的最大长度。 proxy_buffer_size 【该缓冲区大小默认等于proxy_buffers指令设置的一块缓冲区的大小，但它也可以被设置得更小】 nginx从被代理的服务器读取响应时，使用该缓冲区保存响应的开始部分，即header信息。proxy_buffers 【每块缓冲区默认等于一个内存页的大小。这个值是4K还是8K，取决于平台】 为每个连接设置缓冲区的数量为number，每块缓冲区的大小为size。这些缓冲区用于保存从被代理的服务器读取的响应。proxy_busy_buffers_size 【默认是proxy_buffer_size和proxy_buffers指令设置单块缓冲大小的两倍】 当开启缓冲响应的功能以后，在没有读到全部响应的情况下，写缓冲到达一定大小时，nginx一定会向客户端发送响应，直到缓冲小于此值。这条指令用来设置此值。 同时，剩余的缓冲区可以用于接收响应，如果需要，一部分内容将缓冲到临时文件。该大小proxy_temp_file_write_size 【默认值是proxy_buffer_size指令和proxy_buffers指令定义的每块缓冲区大小的两倍】 在开启缓冲后端服务器响应到临时文件的功能后，设置nginx每次写数据到临时文件的size(大小)限制。 proxy_max_temp_file_size 【默认值1024m，设置0时禁止响应写入临时文件】 打开响应缓冲以后，如果整个响应不能存放在proxy_buffer_size和proxy_buffers指令设置的缓冲区内，部分响应可以存放在临时文件中。 这条指令可以设置临时文件的最大容量。 proxy_set_header Host $host解析 Host的含义是表明请求的主机名 $http_host为请求头中的Host信息，可能为空 $host可以在多个地方取值，但主要为代理服务器端接受请求的域名【如外网域名】 $proxy_host主要为被代理的主机ip或域名【一般为内网域名或ip】 使用 12# locationproxy_pass http://server; realip设置123456789101112131415161718192021222324# 编译参数--with-http_realip_module# 参数位置：http, server, location# waf：set_real_ip_from 121.43.18.0/24;set_real_ip_from 120.25.115.0/24;set_real_ip_from 101.200.106.0/24;set_real_ip_from 120.55.177.0/24;set_real_ip_from 120.27.173.0/24;set_real_ip_from 120.55.107.0/24;set_real_ip_from 118.178.15.0/24;set_real_ip_from 123.57.117.0/24;set_real_ip_from 120.76.16.0/24;set_real_ip_from 182.92.253.32/27;set_real_ip_from 60.205.193.64/27;set_real_ip_from 60.205.193.96/27;set_real_ip_from 120.78.44.128/26;set_real_ip_from 118.178.15.224/27;# cdn：set_real_ip_from 140.205.127.0/25;set_real_ip_from 140.205.253.128/25;set_real_ip_from 139.196.128.128/25;set_real_ip_from 101.200.101.0/25;real_ip_header X-Forwarded-For;real_ip_recursive on; 123456set_real_ip_from 121.43.18.0/24; 设置代理服务器地址real_ip_header X-Forwarded-For; 设置读取真实ip的地址源headerreal_ip_recursive on; 使用realip算法递归获取真实ip proxy实验数据无代理模式 $remote_addr：114.242.249.63 $http_x_real_ip：- $http_x_forwarded_for：- $proxy_add_x_forwarded_for：114.242.249.63 cdn+waf模式客户端-》cdn-》waf-》nginx $proxy_add_x_forwarded_for：210.12.208.226; 101.200.101.36; 123.57.117.131 $http_x_forwarded_for：210.12.208.226; 101.200.101.36 $http_x_real_ip：101.200.101.36 $remote_addr：123.57.117.131 waf模式客户端-》waf-》nginx $proxy_add_x_forwarded_for：114.242.249.63; 123.57.117.131 $http_x_forwarded_for：114.242.249.63 $http_x_real_ip：114.242.249.63 $remote_addr：123.57.117.131 cdn模式客户端-》cdn-》nginx $proxy_add_x_forwarded_for：114.242.249.63; 101.200.101.42 $http_x_forwarded_for：114.242.249.63 $http_x_real_ip：- $remote_addr：101.200.101.42 在线升级nginx相关信号 可以通过向nginx主进程发送相关信号控制nginx TERM、INT：快速关闭nginx QUIT：优雅关闭nginx【待处理完请求才关闭】 HUP：变更配置文件时，新的worker进程使用新配置文件，老的worker使用旧配置文件 USR1：打开一个新的日志文件 USR2：升级nginx二进制文件【使用新的二进制文件启动进程】 WINCH：优雅关闭worker进程 编译新的二进制文件只需configure和make，不需要make install 二进制文件替换 备份旧的nginx二进制文件 复制新的nginx二进制文件：cp objs/nginx /usr/local/nginx/sbin/nginx 异常(提示文件被占用)：cp: cannot create regular file ‘/usr/local/nginx/sbin/nginx’: Text file busy 处理(强制覆盖)：cp -rfp objs/nginx /usr/local/nginx/sbin/nginx 配置文件语法检测nginx -t 给nginx发送信号 发送USR2信号使用新的二进制文件启动进程：sudo kill -USR2 4563 发送WINCH信号逐步停止旧的实例，让旧二进制文件启动的进程从容关闭：sudo kill -WINCH 4563 一段时间后，旧的工作进程处理了所有已连接的请求后退出，就仅由新的工作进程来处理输入的请求了 后续处理当新进程有问题时 发送 HUP 信号给旧的主进程 - 它将在不重载配置文件的情况下启动它的工作进程 发送 QUIT 信号给新的主进程，要求其从容关闭其工作进程 如果新主进程还没退出，发送 TERM 信号给新的主进程，迫使其退出 如果因为某些原因新的工作进程不能退出，向其发送 KILL 信号（9） 如果升级成功时发送 QUIT 信号给旧的主进程使其退出而只留下新的服务器运行 常用变量 $arg_PARAMETER： 这个变量值为GET请求中变量名PARAMETER参数的值。 $args：这个变量等于GET请求中的参数。例如，foo=123&amp;bar=blahblah;这个变量只可以被修改 $query_string 与$args相同 范例：foo=123&amp;bar=blahblah $uri：指的是请求的文件和路径，不包含”?”或者”#”之类的东西 范例：/docs/2.2/zh-cn/mod/mod_rewrite.html $request_uri：则指的是请求的整个字符串，包含了后面请求的东西 范例：/search?q=apache+rewrite $request：请求行信息【请求方法 请求url 使用的http协议】 $remote_user：通过基本授权【auth_basic】进行登录时的用户名 $time_local：处理请求时的系统时间 $status：返回给客户端的状态码 $body_bytes_sent：返回给客户端的数据大小 $http_referer：这个请求的referer信息【由哪个url跳转进来的请求】 $http_user_agent：客户端浏览器信息 $host 取用顺序： 请求行中的主机名 来自请求头中【Host】信息 与该请求所匹配的server name【nginx配置】。 apache变量 QUERY_STRING：get请求中的参数 范例：foo=123&amp;bar=blahblah REQUEST_URI：请求的资源信息【请求的文件和路径，不含查询字符串】 范例：/docs/2.2/zh-cn/mod/mod_rewrite.html rewrite指令语法 语法：rewrite regex replacement [flag]； 上下文：server，location，if 含义 如果指定的正则表达式能匹配URI，此URI将被replacement参数定义的字符串改写。 rewrite指令按其在配置文件中出现的顺序执行。 flag可以终止后续指令的执行。 如果replacement的字符串以“http://”或“https://”开头，nginx将结束执行过程，并返回给客户端一个重定向。 flag last 停止这一轮的rewrite指令，然后查找匹配改变后URI的新location break 停止这一轮的rewrite指令 redirect 在replacement字符串中为出现http://或https://开头时，返回302临时重定向 permanent 返回301永久重定向 范例网站改版 由于旧的url被搜索引擎收录，所以要实现：旧的url经过301跳转到新的url后，依然可以访问同一资源内容【网页内容一致】 12345678910111213location / &#123; if ($uri = &quot;/overviewSystem.html&quot;)&#123; rewrite .* &quot;/winTheTustomer.html&quot; permanent; &#125; root /data/font/www; index index.html index.htm;&#125;location /dynamic/ &#123; if ($uri = &quot;/dynamic/list/1.html&quot;)&#123; rewrite .* &quot;/articleList/dynamic.html&quot; permanent; &#125; rewrite ^/dynamic(.*)$ $1 permanent;&#125; 1231. 访问www.abc.com/overviewSystem.html重定向到www.abc.com/winTheTustomer.html2. 访问www.abc.com/dynamic/list/1.html重定向到www.abc.com/articleList/dynamic.html3. 访问www.abc.com/dynamic[url]重定向到www.abc.com[url] user_agent判断1234if ($http_user_agent ~ MSIE) &#123;rewrite ^(.*)$ /images/$1 break;&#125;if ($http_user_agent ~* &quot;android|iphone&quot;)&#123; proxy_pass http://192.168.100.3;&#125; 防盗链1234567location ~* \.(jpg|gif|png|swf|flv|wma|wmv|asf|mp3|mmf|zip|rar)$ &#123; valid_referers none blocked *.ixdba1.net ixdba1.net;if ($invalid_referer) &#123;rewrite ^/ http://www.ixdba.net/img/error.gif;&#125; valid_referers 定义需要处理防盗链的文件(如jpg等)，ixdba1.net表示这个请求可以正常访问上面指定的文件资源。if&#123;&#125;中的内容的意思是：如果地址不是上面指定的地址就跳转到通过rewrite指定的地址 首页301跳转12rewrite ^(.*)$ https://$host$1 permanent;【与下面return301效果相同】# return 301 https://$server_name$request_uri; 注意 如果replacement字符串包括新的请求参数，以往的请求参数会添加到新参数后面。如果不希望这样，在replacement字符串末尾加一个问号“？”，就可以避免，比如：rewrite ^/users/(.*)$ /show?user=$1? last; 如果正则表达式中包含字符“}”或者“;”，整个表达式应该被包含在单引号或双引号的引用中。 apache的rewrite转换为nginx的rewrite：Try use $uri or $request_uri instead $0 跨域设置12345678add_header Access-Control-Allow-Methods &apos;*&apos;; # 指定允许跨域的方法，*代表所有add_header Access-Control-Max-Age 3600; # 预检命令的缓存，如果不缓存每次会发送两次请求add_header Access-Control-Allow-Credentials &apos;true&apos;; # 带cookie请求需要加上这个字段，并设置为trueadd_header Access-Control-Allow-Origin $http_origin; # 表示允许这个域跨域调用（客户端发送请求的域名和端口） $http_origin动态获取请求客户端请求的域 不用*的原因是带cookie的请求不支持*号add_header Access-Control-Allow-Headers $http_access_control_request_headers; # 表示请求头的字段动态获取if ($request_method = &apos;OPTIONS&apos;)&#123; # OPTIONS预检命令，预检命令通过时才发送请求，检查请求的类型是不是预检命令【因为是判断url变量，所以此选项位于location下】 return 200;&#125; 与lua集成设置依赖软件下载 nginx luajit：Lua即时编译器 lua-cjson：lua语言cjson库 ngx_devel_kit：是一个拓展nginx服务器核心功能的模块，第三方模块开发可以基于它来快速实现。 lua-nginx-module：可在 Nginx 中嵌入 Lua 语言，让 Nginx 可以支持 Lua 强大的语法。 redis2-nginx-module：是一个支持 Redis 2.0 协议的 Nginx upstream 模块，它可以让 Nginx 以非阻塞方式直接防问远方的 Redis 服务，同时支持 TCP 协议和 Unix Domain Socket 模式，并且可以启用强大的 Redis 连接池功能。 set-misc-nginx-module：是标准的HttpRewriteModule指令的扩展，提供更多的功能，如URI转义与非转义、JSON引述，Hexadecimal、MD5、SHA1、Base32、Base64编码与解码、随机数等等 echo-nginx-module：是一个 Nginx 模块，提供直接在 Nginx 配置使用包括 “echo”, “sleep”, “time” 等指令。 lua语言环境安装 lujit安装： make &amp;&amp; make install cjson安装： 修改Makefile【LUA_INCLUDE_DIR = $(PREFIX)/include/luajit-2.0】 make &amp;&amp; make install 链接库文件 sudo ln -s /usr/local/lib/libluajit-5.1.so.2 /lib64/libluajit-5.1.so.2 sudo ldconfig nginx编译参数123--with-http_addition_module --add-module=../ngx_devel_kit --add-module=../lua-nginx-module \--add-module=../echo-nginx-module --add-module=../redis2-nginx-module \--add-module=../set-misc-nginx-module lua使用waf功能简介(config.lua)123456789101112131415161718192021222324252627config_waf_enable = &quot;on&quot; #是否开启配置config_log_dir = &quot;/tmp/waf_logs&quot; #日志记录地址config_rule_dir = &quot;/usr/local/nginx/conf/waf/rule-config&quot; #匹配规则所放地址config_white_url_check = &quot;on&quot; #是否开启url检测config_white_ip_check = &quot;on&quot; #是否开启IP白名单检测config_black_ip_check = &quot;on&quot; #是否开启ip黑名单检测config_url_check = &quot;on&quot; #是否开启url过滤config_url_args_check = &quot;on&quot; #是否开启参数检测config_user_agent_check = &quot;on&quot; #是否开启ua检测config_cookie_check = &quot;on&quot; #是否开启cookie检测config_cc_check = &quot;on&quot; #是否开启防cc攻击config_cc_rate = &quot;10/60&quot; #允许一个ip60秒内只能访问10次config_post_check = &quot;on&quot; #是否开启post检测config_waf_output = &quot;html&quot; #action一个html页面，也可以选择跳转config_waf_redirect_url = &quot;http://www.baidu.com&quot; config_output_html=[[ #下面是html的内容&lt;html&gt; &lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt; &lt;meta http-equiv=&quot;Content-Language&quot; content=&quot;zh-cn&quot; /&gt; &lt;title&gt;网站防火墙&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1 align=&quot;center&quot;&gt; # 您的行为已违反本网站相关规定，注意操作规范。详情请联微信公众号：chuck-blog。 &lt;/body&gt; &lt;/html&gt; ]] nginx设置1234567891011121314151617http &#123; map $http_x_forwarded_for $clientRealIp &#123; &quot;&quot; $remote_addr; ~^(?P&lt;firstAddr&gt;[0-9\.]+),?.*$ $firstAddr; &#125; lua_shared_dict limit 50m; #防cc使用字典，大小50M lua_package_path &quot;/home/zj-ops/nginx/conf/waf/?.lua&quot;; init_by_lua_file &quot;/home/zj-ops/nginx/conf/waf/init.lua&quot;; access_by_lua_file &quot;/home/zj-ops/nginx/conf/waf/access.lua&quot;; server &#123; location /lua &#123; echo &quot;Hello lua&quot;; &#125; location /lua_test &#123; content_by_lua &apos;ngx.say(&quot;Hello Lua! Simple.&quot;)&apos;; &#125; &#125; 功能测试 防sql注入测试：curl http://127.0.0.1/q.sql cc防护测试：ab -c 100 -n 100 http://127.0.0.1/ lua集成redislua-resty-redis提供一个lua语言版的redis API，使用socket（lua sock）和redis通信。 nginx配置1234567891011121314lua_package_path &quot;/home/zj-ops/nginx/conf/lua-resty-redis/lib/?.lua;&quot;; location =/content_by_lua_block &#123; default_type &apos;text/plain&apos;; content_by_lua_block &#123; ngx.say(&apos;Hello: content_by_lua_block&apos;) &#125; &#125; location /lua_redis_basic&#123; default_type &apos;text/html&apos;; lua_code_cache off; content_by_lua_file /home/zj-ops/nginx/conf/self_lua/test_redis_basic.lua; #access_by_lua_file /home/zj-ops/nginx/conf/self_lua/access_flow_control.lua; content_by_lua &apos;ngx.say(&quot;Hello Lua! Simple.&quot;)&apos;; &#125; redis功能测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556local function close_redis(redis_instance) if not redis_instance then return end local ok,err = redis_instance:close(); if not ok then ngx.say(&quot;close redis error : &quot;,err); endendlocal redis = require(&quot;resty.redis&quot;);--local redis = require &quot;redis&quot;-- 创建一个redis对象实例。在失败，返回nil和描述错误的字符串的情况下local redis_instance = redis:new();--设置后续操作的超时（以毫秒为单位）保护，包括connect方法redis_instance:set_timeout(1000)--建立连接local ip = &apos;127.0.0.1&apos;local port = 6379--尝试连接到redis服务器正在侦听的远程主机和端口local ok,err = redis_instance:connect(ip,port)if not ok then ngx.say(&quot;connect redis error : &quot;,err) return close_redis(redis_instance);end--Redis身份验证local auth,err = redis_instance:auth(&quot;foobared&quot;);if not auth then ngx.say(&quot;failed to authenticate : &quot;,err)end--调用API进行处理local resp,err = redis_instance:set(&quot;msg&quot;,&quot;hello world&quot;)if not resp then ngx.say(&quot;set msg error : &quot;,err) return close_redis(redis_instance)end--调用API获取数据 local resp, err = redis_instance:get(&quot;msg&quot;) if not resp then ngx.say(&quot;get msg error : &quot;, err) return close_redis(redis_instance) end --得到的数据为空处理 if resp == ngx.null then resp = &apos;this is not redis_data&apos; --比如默认值 end ngx.say(&quot;msg : &quot;, resp) close_redis(redis_instance)# 测试：http://127.0.0.1/lua_redis_basic 返回：【msg : hello world】说明redis可用 实现cc防护123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657-- access_by_lua_file &apos;/opt/ops/lua/access_limit.lua&apos;local function close_redis(red) if not red then return end --释放连接(连接池实现) local pool_max_idle_time = 10000 --毫秒 local pool_size = 100 --连接池大小 local ok, err = red:set_keepalive(pool_max_idle_time, pool_size) if not ok then ngx_log(ngx_ERR, &quot;set redis keepalive error : &quot;, err) endendlocal redis = require &quot;resty.redis&quot;local red = redis:new()red:set_timeout(1000)local ip = &quot;127.0.0.1&quot;local port = 6379local ok, err = red:connect(ip,port)local auth, err = red:auth(&quot;foobared&quot;)if not ok or not auth then return close_redis(red)endlocal clientIP = ngx.req.get_headers()[&quot;X-Real-IP&quot;]if clientIP == nil then clientIP = ngx.req.get_headers()[&quot;x_forwarded_for&quot;]endif clientIP == nil then clientIP = ngx.var.remote_addrendlocal incrKey = &quot;user:&quot;..clientIP..&quot;:freq&quot;local blockKey = &quot;user:&quot;..clientIP..&quot;:block&quot;local is_block,err = red:get(blockKey) -- check if ip is blockedif tonumber(is_block) == 1 then ngx.exit(ngx.HTTP_FORBIDDEN) return close_redis(red)endres, err = red:incr(incrKey)if res == 1 then res, err = red:expire(incrKey,1)end-- 1秒超过10次视为非法ip，进入黑名单if res &gt; 10 then res, err = red:set(blockKey,1) -- 每个黑名单ip封禁60秒 res, err = red:expire(blockKey,60)endclose_redis(red) 其他功能与参考 nginx限制连接模块-limit NGINX 结合 lua 动态修改upstream 模块代码：https://github.com/openresty/lua-upstream-nginx-module#set_peer_down Nginx+Tomcat+SSL 识别 https还是http 高并发之系统限流 Nginx + Lua + Redis 已安装成功(非openresty 方式安装) nginx + lua + redis 防刷和限流 nginx 不中断服务 平滑升级]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>rewrite</tag>
        <tag>nginx</tag>
        <tag>proxy</tag>
        <tag>lua</tag>
        <tag>waf</tag>
        <tag>升级</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx基础学习]]></title>
    <url>%2F2019%2F06%2F11%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2Fweb%E6%9C%8D%E5%8A%A1%2Fnginx%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[介绍淘宝nginx文档 特点 占用资源少 支持高并发 可以做代理服务器【类似squid、haproxy】 可以做缓存服务器【类似varnish】 安装下载http://nginx.org/en/download.html 依赖安装 ubuntu： apt-get install zlib1g-dev libpcre3 libpcre3-dev openssl libssl-dev -y centos：yum install pcre pcre-devel zlib zlib-devel openssl openssl-devel -y 编译12./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-pcre --with-http_ssl_module \--with-http_gzip_static_module --with-http_flv_module --with-http_realip_module --with-debug 支持查看nginx连接状态 支持正则表达式【比如map功能即为使用正则】 支持ssl功能 支持gzip压缩 支持flv视频流 支持通过realip模块定位最终客户端地址【客户端走多层代理访问最终服务时需要】 开启debug功能 安装make &amp;&amp; make install 命令参数 -?,-h : this help -v : show version and exit -V : show version and configure options then exit -t : test configuration and exit -T : test configuration, dump it and exit【显示配置文件详情】 -q : suppress non-error messages during configuration testing【检查配置文件语法时屏蔽非错误提示信息】 -s signal : send signal to a master process: stop, quit, reopen, reload stop：强制关闭主进程 quit：优雅关闭煮即成 reopen：打开新的日志文件写入 reload：重新加载配置文件 -p prefix : set prefix path (default: /usr/local/nginx/) -c filename : set configuration file (default: conf/nginx.conf) -g directives : set global directives out of configuration file【配置文件外设置全局命令，如：-g daemon on】 配置文件 全局设置123456789user nginx nginxworker_processes 4;worker_cpu_affinity 01 10 01 10;pid logs/nginx.pid;worker_rlimit_nofile 65535;events &#123; use epoll; worker_connections 65535;&#125; 123456789101112131415worker_processes 4; 指明了nginx要开启的进程数，据官方说法，一般开一个就够了，多开几个，可以减少机器io带来的影响。 一般为当前机器总cpu核心数的1到2倍worker_cpu_affinity 01 10 01 10; nginx默认是没有开启利用多核cpu的配置的。需要通过增加worker_cpu_affinity配置参数来充分利用多核cpu。 为每个进程开启一个cpu，1表示开启核心，0为关闭 2核2进程写法： worker_processes 2； worker_cpu_affinity 01 10; 2核4进程写法： worker_processes 4; worker_cpu_affinity 01 10 01 10;worker_rlimit_nofile 65535; 指定一个nginx进程可以打开的最多文件描述符数目，（需要使用命令“ulimit -n 65535”来设置。）worker_connections 65535; 用于定义Nginx每个进程的最大连接数 http设置12345678910111213141516171819202122232425http &#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;# map $http_x_forwarded_for $clientRealIp &#123;# &quot;&quot; $remote_addr;# ~^(?P&lt;firstAddr&gt;[0-9\.]+),?.*$ $firstAddr;# &#125; lua_shared_dict limit 50m; #防cc使用字典，大小50M lua_package_path &quot;/home/zj-web/nginx/conf/waf/?.lua&quot;; init_by_lua_file &quot;/home/zj-web/nginx/conf/waf/init.lua&quot;; access_by_lua_file &quot;/home/zj-web/nginx/conf/waf/access.lua&quot;; access_log logs/access.log main; error_log logs/error.log error; # tcp conf include tcp.conf; # gzip conf include gzip.conf; # site conf include site-available/*.conf; # realip conf include realip.conf;&#125; 12345678default_type application/octet-stream; 默认类型为二进制流，也就是当文件类型未定义时使用这种方式，例如：在没有配置PHP环境时，Nginx是不予解析的，此时，用浏览器访问PHP文件就会出现下载窗口。log_format: 日志格式access_log/error_log: 主日志信息【当location未定义时使用】lua*： 与lua脚本搭配构建WAF tcp设置1234567891011client_max_body_size 20m;client_header_buffer_size 32K;client_body_buffer_size 128k;large_client_header_buffers 4 32k;Sendfile on;tcp_nopush on;tcp_nodelay on;keepalive_timeout 60;client_header_timeout 10;client_body_timeout 10;send_timeout 10; 123456789101112131415161718192021client_max_body_size 20m; 用来设置允许客户端请求的最大的单个文件字节数client_header_buffer_size 32K; 用于指定来自客户端请求头的header buffer大小client_body_buffer_size 128k; 指定客户端请求主体缓冲区大小large_client_header_buffers 4 32k; 用来指定客户端请求中较大的消息头的缓存最大数量和大小sendfile on; 用于开启高效文件传输模式tcp_nopush on;tcp_nodelay on; 将tcp_nopush和tcp_nodelay两个指令设置为on用于防止网络阻塞keepalive_timeout 60; 设置客户端连接保持活动的超时时间。在超过这个时间之后，服务器会关闭该连接client_header_timeout 10; 设置客户端请求头读取超时时间。如果超过这个时间，客户端还没有发送任何数据，Nginx将返回Request time out（408）错误client_body_timeout 10; 设置客户端请求主体读取超时时间。如果超过这个时间，客户端还没有发送任何数据，Nginx将返回Request time out（408）错误，默认值是60send_timeout 10; 指定响应客户端的超时时间。这个超时仅限于两个连接活动之间的时间，如果超过这个时间，客户端没有任何活动，Nginx将会关闭连接。 gzip设置12345678910# 编译参数--with-http_gzip_static_modulegzip on;gzip_min_length 1k;gzip_proxied any;gzip_buffers 16 64k;gzip_http_version 1.1;gzip_disable &quot;MSIE [1-6].&quot;;gzip_comp_level 5;gzip_types text/plain application/x-javascript text/css application/xml application/json application/javascript image/jpeg image/gif image/png;gzip_vary on; 1234567gzip on; #开启gzip模块，实时压缩输出数据流gzip_min_length 1k; #设置允许压缩的下限阀值【大于1k的文件才进行压缩】gzip_buffers 4 16k; #申请4个大小16K的内存作为压缩结果流缓存gzip_http_version 1.1; #支持的http协议gzip_comp_level 5; #压缩级别gzip_types text/plain application/x-javascript text/css application/xml; #支持的压缩类型gzip_vary on; #可以根据客户端是否支持压缩自动调整压缩功能 ssl设置123456789# 编译参数--with-http_ssl_module# 文件路径为相对于nginx.conf的路径ssl on;ssl_certificate cert/214135355250268.pem;ssl_certificate_key cert/214135355250268.key;ssl_session_timeout 5m;ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;ssl_protocols TLSv1 TLSv1.1 TLSv1.2;ssl_prefer_server_ciphers on; 1234ssl自定义证书设置1.系统安装openssl及开发库2.使用openssl产生证书【pem格式】和私钥【pem格式】openssl req -x509 -nodes -newkey rsa:2048 -keyout nginx.key -out nginx.crt auth与status12345678910111213# 编译参数：--with-http_stub_status_moduleserver &#123; listen 80; server_name 0.0.0.0; location /status &#123; stub_status on; #开启模块功能 access_log off; #关闭访问日志 allow 127.0.0.1; #只允许127 访问 deny all; auth_basic &quot;status for nginx&quot;; #验证登陆时的标题 auth_basic_user_file htpasswd; #使用授权文件htpasswd &#125;&#125; 12345auth_basic是Nginx的一种认证机制。auth_basic_user_file用来指定认证的密码文件，由于Nginx的auth_basic认证采用的是与Apache兼容的密码文件，因此需要用Apache的htpasswd命令来生成密码文件，例如要添加一个webadmin用户，可以使用下面方式生成密码文件：htpasswd -c htpasswd webadmin此命令会在当前目录生产一个文件htpasswd，其中用户名webadmin websocket支持 nginx1.3.13之后，nginx内置支持websocket代理 123456location /chat/ &#123; proxy_pass http://backend; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;;&#125; server配置配置123456789101112131415161718192021222324252627282930313233343536server &#123; listen 80; server_name pre-zj-static.zj-hf.cn; return 301 https://$server_name$request_uri;&#125;server &#123; listen 443; server_name pre-zj-static.zj-hf.cn; include ssl.conf; error_page 403 /error/403.jpg; error_page 404 /error/4041.html; error_page 500 502 503 504 /error/50x.jpg; location /error/ &#123; internal; root html; &#125; location / &#123; error_log logs/vue-html.error.log info; root wechat/vue; add_header Cache-Control &apos;no-store&apos;; index index.html index.htm; try_files $uri $uri/ /index.html =404; &#125; location ~\.html &#123; error_log logs/jq-html.error.log info; root wechat/jq; add_header Cache-Control &apos;no-store&apos;; allow all; &#125; location ~* ^.+pdf.+\.(bcmap|css|json|js|properties|txt|html|swf|wav|png|jpg|woff|ttf)$ &#123; error_log logs/vue-assetst.error.log info; root wechat/jq; access_log off; expires 30d; &#125;&#125; 配置详解 listen 80 default_server; 用于指定虚拟主机的服务端口，default_server可以在多个虚拟主机之间设置默认的虚拟主机。 server_name www.abc.org abc.com; 用来指定IP地址或者域名，多个域名之间用空格分开,不含www的域名也可直接设置，如abc.com return 301 https://$server_name$request_uri; 向客户端返回相应的状态码以及url root 虚拟主机根目录，【定义的根目录与conf、sbin同级】 示例： 12345location /request_path/image/ &#123; root /local_path/image/;&#125;当客户端请求 /request_path/image/cat.png 的时候， Nginx把请求映射为/local_path/image/request_path/image/cat.png alias： 对请求的路径做替换转换 示例 12345location /request_path/image/ &#123; alias /local_path/image/;&#125;当客户端请求 /request_path/image/cat.png 的时候， Nginx把请求映射为/local_path/image/cat.png add_header 重写发送给客户端的响应头【response】 allow all 对匹配的location作访问限制【allow或deny】 可使用的匹配规则为：允许部分，拒绝所有；拒绝部分，允许所有。 access_log off; 关闭访问日志 expires 30d; 设置静态文件缓存时间 try_files $uri $uri/ /index.html =404; 当location的程序不能处理请求时的处理方式【可以处理404等异常】 按照指定的顺序检查文件或目录【名字末尾加反斜线】是否存在 如果找不到任何文件，将按最后一个参数指定的uri进行内部跳转。 最后一个参数可以是一个命名的location或状态码【404】等 internal 只能由内部url调用，外部访问则404 error_page 403 /error/403.jpg; 定义错误页面，位于server内 错误页面大小必须大于512字节，否则会被浏览器的默认错误页面替代 location优先级语法定义12location [ = | ~ | ~* | ^~ ] uri &#123; ... &#125;location @name &#123; ... &#125; = 精确匹配，如果找到匹配=好的内容，立即停止搜索，并立即处理请求（优先级最高） ~ 表示执行一个正则匹配，区分大小写 ~* 表示执行一个正则匹配，不区分大小写 ^~ 只匹配字符串，不匹配正则表达式,一般用来匹配目录 @ 指定一个命名的location，一般只用于内部重定向请求【try_files、error_page】 location示例12345678910111213141516171819202122232425location指令：#NO.1 location / &#123; return 500; &#125;#NO.2 location /a/ &#123; return 403; &#125;#NO.3 location ^~ /a/ &#123; return 403; &#125;#NO.4 location /a/1.jpg &#123; return 402; &#125;#NO.5 location ~* \.jpg$ &#123; return 401; &#125;#NO.6 location = /a/1.jpg &#123; return 400; &#125; 123456优先级：1）优先匹配#NO.6 “=”优先级最高2）再次匹配#NO.5 正则表达式匹配3）再次匹配#NO.4 完整匹配4）再次匹配#NO.3 部分包含的被匹配【NO.2与NO.3效果相同】5）最后匹配#NO.1 所有的访问都被匹配]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>htpasswd</tag>
        <tag>location</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat配置与优化]]></title>
    <url>%2F2019%2F06%2F06%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2Fweb%E6%9C%8D%E5%8A%A1%2Ftomcat%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[JAVA程序java程序 java程序设计语言 java api【库函数】 java class文件 jvm：java虚拟机【字节码运行环境】 JRE：java运行时环境，只能运行class文件； JDK：java开发环境，可将java程序编译为class文件； servlet Servlet类文件放到WEB-INF\classes目录下。 Servlet（小服务程序）是一个与协议无关的、跨平台的Web组件，它基于Java技术开发，由Servlet容器所管理。和运行在客户端浏览器中的Applet（小应用程序）相似，Servlet运行在服务器端。Servlet采用“请求—响应”模式提供Web服务，交互式地浏览和修改数据，生成动态Web内容。Servlet是平台独立的Java类，即按照Servlet规范编写的Java类，所以具有Java语言的所有优点，如良好的可移植性及安全性等。Servlet被编译为平台中立的字节码，可以被动态地加载到支持Java技术的Web服务器中运行，就如同Applet对客户端一样，区别在于Servlet运行并不需要图形用户界面。Java Servlet具有如下优点： Servlet可以和其他资源（数据库、文件、Applet和Java应用程序等）交互，把生成的响应内容返回给客户端。如果需要，还可以保存“请求—响应”过程中的信息。 服务器采用Servlet可以完全授权对本地资源的访问，Servlet自身也会控制外部 用户的访问数量及访问性质。 Servlet可以从本地硬盘，或者通过网络从远端硬盘来激活。 通过Servlet Tag技术（注：即HTML中标签），可以在HTML页面中动态调用Servlet。 Servlet可以是其他服务的客户端程序。 通过链接技术，一个Servlet可以调用另一个或一系列Servlet来成为它的客户端。 Servlet API与协议无关。 jsp是由Sun Microsystems公司倡导，在传统的网页HTML文件(.htm,.html)中插入Java程序段(Scriptlet)和JSP标记(tag)，从而形成JSP文件(*.jsp)。 用JSP开发的Web应用是跨平台的，既能在Linux下运行，也能在其他操作系统上运行。相应的ASP是微软公司倡导的。ASP是Active Server Page的缩写，意为“动态服务器页面”。ASP是微软公司开发的代替CGI脚本程序的一种应用，它可以与数据库和其它程序进行交互，是一种简单、方便的编程工具。ASP的网页文件的格式是 .asp。 jsp 要先翻译成servlet才能执行。JSP文件第一次执行时，要先由Tomcat将其转化为Servlet文件，然后编译，所以速度会慢一些，但后继执行时速度会很快；比如 test.jsp 要变成 test_jsp.java 然后编译成 test_jsp.class。而 test_jsp.java 本身就是一个servlet。所以 jsp只是servlet的一个变种，方便书写html内容才出现的。 war在建立WAR文件之前，需要建立正确的Web应用程序的目录层次结构： 建立WEB-INF子目录，并在该目录下建立classes与lib两个子目录。 将Servlet类文件放到WEB-INF\classes目录下，将Web应用程序所使用Java类库文件（即JAR文件）放到WEB-INF\lib目录下。 建立web.xml文件，放到WEB-INF目录下。 根据Web应用程序的需求，将JSP页面或静态HTML页面放到上下文根路径下或其子目录下。 如果有需要，建立META-INF目录 要注意的是，虽然WAR文件和JAR文件的文件格式是一样的，并且都是使用jar命令来创建，但就其应用来说，WAR文件和JAR文件是有根本区别的。JAR文件的目的是把类和相关的资源封装到压缩的归档文件中，而对于WAR文件来说，一个WAR文件代表了一个Web应用程序，它可以包含Servlet、HTML页面、Java类、图像文件，以及组成Web应用程序的其他资源，而不仅仅是类的归档文件。 tomcat与传统桌面应用程序不同，Tomcat中的应用程序是一个WAR（Web Archive）文件，它是许多文件构成的一个压缩包，包中的文件按照一定目录结构来组织，不同目录中的文件也具有不同的功能。部署应用程序时，只需要把WAR文件放到Tomcat的webapp目录下，Tomcat会自动检测和解压该文件。Tomcat既是一个Servlet容器，又是一个独立运行的服务器，像IIS、Apache等Web服务器一样，具有处理HTML页面的功能。但它处理静态HTML文件的能力并不是太强，所以一般都是把它当作JSP/Servlet引擎，通过适配器（Adapter）与其他Web服务器软件（如Apache）配合使用。此外，Tomcat还可与其他一些软件集成起来实现更多功能，例如，与JBoss集成起来开发EJB、与OpenJMS集成起来开发JMS应用、与Cocoon（Apache的另外一个项目）集成起来开发基于XML的应用等。 tomcat目录主要目录 bin：存放启动和关闭tomcat脚本 conf：存放配置文件【server.xml、web.xml、logging.properties】 lib：存放tomcat运行所需的库文件【jar】 logs：存放tomcat运行时产生的日志 webapps：tomcat的主要web程序发布目录 work：存放jsp编译后产生的class文件 脚本设置 catalina.sh变量设置；官方建议在bin目录下单独建立setenv.sh文件设置变量 CATALINA_OUT：设置标准输出和错误输出，默认$CATALINA_BASE/logs/catalina.out CATALINA_OPTS：运行start、run、debug命令时的选项，但不被stop进程使用 JAVA_HOME：设置jdk路径 JAVA_OPTS：java运行时的选项，包含所有命令，当然也包含stop进程 CATALINA_PID：设置进程pid，pid在强制停止【kill】进程时使用 脚本使用 catalina.sh是控制tomcat启停的核心脚本 startup/shutdown脚本都是调用catalina.sh的 catalina.sh可选参数 run：控制台运行tomcat start：后台运行tomcat【在另一个窗口运行tomcat】 stop [n]：关闭tomcat -force：强制关闭tomcat【无法正常关闭时使用kill命令杀死进程】 configtest：对server.xml进行语法检查 server.xml配置1234567891011&lt;Server&gt; &lt;Service&gt; &lt;Connector/&gt; &lt;Engine&gt; &lt;Host&gt; &lt;Context&gt; &lt;/Context&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; Server一个server代表整个catalina servlet容器： port：指定Tomcat服务器监听shutdown命令的端口 shutdown：指定终止tomcat服务器运行时，发给tomcat服务器shutdown监听端口的字符串 Serviceservice是一个集合，它包含一个engine以及一个或多个connector组成 Connector一个connector将在某个端口监听客户请求，并把请求交给engine处理，同时从engine获取响应返回给客户端 http连接器：监听来自客户端的http请求； port：接受http请求的端口 redirectPort：如果端口不支持ssl时，将请求转发 connectionTimeout：请求超时时间【以毫秒计，默认20s，设置-1关闭超时】 maxHttpHeaderSize：请求和响应的http头部大小，以字节计数，【默认8192即8KB】 acceptCount：指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理【默认100】 maxConnections：任何时间都可以接收和处理的请求总数，超过此阈值但不超过acceptCount的请求依然可以接收【默认值10000】 minSpareThreads：tomcat保持的最小线程数【默认为10】 maxThreads：tomcat可以创建的最大线程数【默认200】 SSLEnabled：是否开启ssl【默认False】 ajp连接器： 监听来自Webserver(apache)的servlet/jsp代理请求； Engine是一个service下的请求处理功能组件，可以包含多个虚拟主机(Host) defaultHost指定缺省的请求处理主机名，它至少与其中一个host元素的name属性值是一样 Host一个虚拟主机匹配一个域名，它可以包含多个应用(Context) name：主机名 appBase：应用程序基本目录，可以指定绝对路径，也可以指定相对于CATALINA_HOME的相对路径 这个目录下面的子目录自动被当成应用被部署 这个目录下边的war文件自动被解压并作为应用部署 unpackWARs：如果设置为true，则tomcat会自动解压war文件，否则直接运行war文件 autoDeploy：设置为true时，当tomcat处于运行状态时，能够监测appBase下的文件，如果有新的wweb加入的话，会自动发布这个web应用 Context一个应用程序对应一个Context，一个web程序由一个或多个servlet组成 docBase：【只有在应用不在appBase下才需要设置】应用程序的路径或者是war文件的路径 path：表示此web应用的url前缀 reloadable：如果设置为true，则tomcat会自动检测应用程序的WEB-INF/lib和WEB-INF/classes目录下class文件变化，自动重载新的应用程序，这样可以在不重启tomcat情况下改变应用程序 Value可以在（Engine, Host, or Context）级别设置不同功能的阈值，以下以设定访问日志为例 className=”org.apache.catalina.valves.AccessLogValve”：访问日志类名 directory=”logs”：日志存储目录 prefix=”localhost_access_log” ：日志文件前缀 suffix=”.txt”：日志文件后缀 pattern=”[%{yyyy-MM-dd HH:mm:ss}t] &quot;%r&quot; %S &quot;%{postdata}r&quot; %s %{Referer}i [%{User-Agent}i] %T %b”：日志格式 日志配置 server.xml：配置访问日志【Value属性】 需要在logrotate中配置日志轮询 logging.properties：配置tomcat自身日志、console输出 可以将1catalina、2localhost、3manager、4host-manager内容全部注释或将其prefix设置为同一个文件 log4j.properties：项目自定义日志 位置：项目WEB-INF/classes下 JVM调优按照存储数据的内容，将内存分配为堆区(heap)和非堆区(non-heap) 堆区：通过new的方式创建的对象(类实例)占用的内存空间，mv的垃圾回收机制可以回收堆区占用的内存，调优参数如下 -Xms n：设置初始java堆【JVM】大小 默认，JVM初始大小是物理内存的1/64， 最小是8MB -Xmx n：设置最大java堆【JVM】大小 默认，JVM最大大小是物理内存的1/4 【server模式下】最大值是32GB【此时内存大于等于128GB】 【client模式下】最大值是256MB【大于等于1GB都被当做1GB处理】 非堆区：代码、常量、外部访问(文件访问占用的资源流)等，调优参数如下+ -XX:MaxMetaspaceSize=n：设置metaspace的最大大小 + 【-XX:PermSize和-XX:MaxPermSize】在java8中已被遗弃 更多参考 java性能调优书籍：《Java Performance: The Definitive Guide》 jvm设置]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible之命令行]]></title>
    <url>%2F2019%2F05%2F29%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%8E%E9%83%A8%E7%BD%B2%2Fansible%2Fansible%E4%B9%8B%E5%91%BD%E4%BB%A4%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[ansible在一个或一组主机下运行单个任务 语法 语法：ansible 《pattern》 -m 《module_name》 -a 《arguments》 other_options 默认的模块名为command 示例：ansible 10.150.20.209 -u db -m apt -a “pkg=dos2unix state=latest” -b –become-method sudo -k -K 注意：在执行任务时，应该特别注意shell引用规则(即单双引号的使用规则)，避免变量在被传递给ansible前被本地shell捕获 主机资源匹配 all或*匹配所有主机 以逗号分隔多个主机或组：ansible bigdata,crm -m ping 使用*也可以进行主机或组名的部分匹配：ansible test* -m ping 使用切片功能，在组内从上往下进行主机匹配：webservers[0:2] 使用正则进行匹配(必须以~开头)：~(web|db).*.example.com 使用-l/–limit参数【ansible/ansible-playbook】进一步说明需要执行任务的主机 常用参数 –ask-vault-pass： 提示输入加密面 –become-method： 权限变更的方式【su或sudo】 –become-user： 权限变更时使用的用户 –list-hosts： 输出符合要求的主机列表 –playbook-dir 指定playbok的根目录，这样就可以在命令行下使用playbook的roles、group_vars等特性 –private-key，–key-file –scp-extra-args： scp选项参数 –sftp-extra-args ： sftp选项参数 –ssh-common-args：指定传给scp/sftp/ssh的一般参数 –ssh-extra-args： 只传给ssh的参数 –syntax-check： 检测语法 –vault-id –vault-password-file：加密密码的文本文件 –version： 显示程序版本、配置文件位置、模块搜索路径、模块文件位置、可执行文件位置 -B/–background ： 异步运行模式，运行超过X秒后失败 -C/–check： 不实际执行任务，但是显示执行后可能发生的变化 -D/–diff： 与-C搭配使用，显示当使用files和templates模块时，变化前后的区别 -K/–ask-become-pass：权限变更时交互式输入密码 -M/–module-path： 以冒号分隔的自定义模块路径【默认~/.ansible/plugins/modules:/usr/share/ansible/plugins/modules】 -P/–poll： 和-B搭配使用，设置轮询时间间隔【默认15，0为永不轮询】 -t/–timeout： 设置连接超时时间【默认10】 -a/–args： 模块参数 -b/–become： 设置将要进行权限变更 -c/–connection 连接类型，比如：ssh/local/docker等 -e/–extra-vars : 设置自定义变量【key=value形式或yaml、json文件（文件名称前添加@）】 -f/–forks： 设置并行进程数【默认为5】 -h/–help： 帮助信息 -i/–inventory： 设置资源文件位置或以逗号分隔的主机列表 -k/–ask-pass： 远程连接时交互式输入密码 -l/–limit 限定执行任务的主机资源【以逗号分隔或以@开头引用文件】 -m/–module-name：将要执行的模块名称 -o/–one-line： 简化输出为一行 -t/–tree： 将输出记录到此目录 -u/–user： 远程连接用户 -v/–verbose： 详细输出模式（-vvv输出更多，-vvvv将开启连接调试） 范例1：异步模式123456789101112[hjq@localhost ~]$ ansible python -B 300 -P 0 -m yum -a &quot;name=libselinux-python state=latest&quot; python | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;pkg_mgr&quot;: &quot;yum&quot; &#125;, &quot;ansible_job_id&quot;: &quot;759078551843.27281&quot;, &quot;changed&quot;: true, &quot;finished&quot;: 0, &quot;results_file&quot;: &quot;/root/.ansible_async/759078551843.27281&quot;, &quot;started&quot;: 1&#125;[hjq@localhost ~]$ ansible python -m async_status -a &quot;jid=759078551843.27281&quot; 范例2：新建用户 产生随机密码 使用openssl：echo pass|openssl passwd -1 -stdin ubuntu下mkpasswd：echo pass|mkpasswd --method=sha-512 --stdin 新建用户 密码必须hash：ansible python -m user -e &quot;pass=Muke#123&quot; -a &#39;name=muker password=&quot;{\{ pass|password_hash(&quot;sha512&quot;) }\}&quot;&#39; -b 用户sudo配置 ansible python -m lineinfile -a &quot;dest=/etc/sudoers state=present line=&#39;muker ALL=(ALL) NOPASSWD: ALL&#39; validate=&#39;visudo -cf %s&#39;&quot; ansible python -m lineinfile -a &#39;dest=/etc/sudoers state=present line=&quot;Defaults:muker !requiretty&quot; validate=&quot;visudo -cf %s&quot;&#39; 秘钥登录 ansible python -m authorized_key -a &quot;user=muker key=&#39;{\{ lookup(&#39;file&#39;, lookup(&#39;env&#39;, &#39;HOME&#39;) + &#39;/.ssh/id_rsa.pub&#39;) }\}&#39; state=present&quot; -u muker -K ansible-console 交互式使用ansible 常用参数 cd 切换主机或组 list 显示当前的主机或组 forks 设置临时并发数 module XXX 使用模块 help module 查看模块用法 become yes/no 进入/离开sudo模式 范例12hjq@all (2)[f:5]$ cd opshjq@ops (1)[f:5]$ copy src=ansible.cfg dest=~/ ansible-doc插件文档工具语法：ansible-doc [-l|-F|-s] [options] [-t ] [plugin] -l 查看插件列表及相关简单描述信息 -F 查看插件列表及相关的源码位置【隐含-l参数】 -s 查看插件的参数信息 ansible-doc -s -t lookup csvfile -t 设置插件类型，默认为模块，可选插件如下 cache callback connection inventory lookup shell module strategy vars ansible-config配置查看工具 ansible-config dump –only-changed：查看ansible.cfg中的自定义配置【非默认配置】 ansible-config view：查看当前配置文件ansible.cfg ansible-inventory资源查看工具语法：–list [–export] [–yaml]|–graph [–vars]|–host[–yaml] –list：显示所有主机信息 –export ：与–list搭配使用，优化显示信息 –host：显示特定主机信息 -y/–yaml：以yaml显示输出【默认json格式】 与list和host搭配使用 –graph：以图表形式显示所有主机信息 –vars：在图表中显示变量信息 ansible-vault 是用于加密结构化数据[json或yaml格式]文件的命令 可以通过include_vars或vars_files加载group_vars或host_vars下的资源变量文件 也可以是ansible-playbook命令下使用-e参数加载的变量文件 语法：ansible-vault [create|decrypt|edit|encrypt|rekey|view] [options] [vaultfile.yml] 命令选项 create 创建加密文件 edit 编辑加密文件 encrypt 加密文件 decrypt 解密文件 view 查看加密文件内容 rekey 变更加密密码 命令参数 –ask-vault-pass：【默认选项】要求输入加密密码 –vault-password-file：提供密码文件 使用方式 命令ansible或ansible-playbook –ask-vault-pass 交互式出入加密密码 –vault-password-file=xx 提供加密密码文件 范例： ansible 127.0.0.1 -e “@vars.yml” -m debug -a “msg=“ –ask-vault-pass ansible-playbook test.yml –vault-password-file=password.txt ansible-playbook运行playbook的工具 –flush-cache：清除每一台主机的facts缓存信息 –force-handlers：即使任务失败也执行handlers –syntax-check：对playbook进行语法检查 –start-at-task：从指定任务处继续执行playbook -t/–tags xxx：执行指定标签任务 –step：每执行一个任务都要进行确认 –list-hosts：查看所有主机 –list-tags：查看所有标签 –list-tasks：查看所有任务 –skip-tags：跳过标签执行其他任务 -C/–check： 不实际执行任务，但是显示执行后可能发生的变化 playbook关键词用法：check_mode：yes -D/–diff：与-C搭配使用，显示当使用files和templates模块时，变化前后的区别 ansible-galaxy管理共享仓库中的ansible角色，默认的共享仓库是https://galaxy.ansible.com. info：查询已经安装的或在共享仓库中的角色详细信息 search：从共享仓库搜索角色【全名搜索】 list：查看本地已经安装的角色【全名搜索】 remove：移除本地角色 install：安装一个角色 -f 强制覆盖已存在的角色 –force-with-deps：强制覆盖已存在的角色和依赖信息 ansible-pull从版本库中拉取playbook并在本地执行 命令参数ansible-pull -o -C master -U https://github.com/simple0426/ansible_test.git -i hosts –purge -o 只有代码库有变更时拉取代码并执行 –purge 执行ansible完成后删除代码 与-o参数有冲突 默认会将playbook项目拉取至~/.ansible/pull/《hostname》|local目录下 -C 使用指定分支代码 -i 强制使用项目中的hosts -U 指定playbook的仓库地址【必选项】 仓库目录ansible_test/├── hosts├── local.yml├── ops.yml└── simple.yml hosts12[localhost]127.0.0.1 hosts中只能定义本机，即127.0.0.1 当系统没hosts或未设置时默认使用项目中的hosts 当系统有hosts设置时，只会读取127.0.0.1设置，此时需要在命令行使用【-i hosts】参数强制读取项目中的hosts playbook123456---- hosts: localhost gather_facts: no tasks: - name: touch file command: touch /tmp/ceshi3 playbook中的hosts只能为本机，即127.0.0.1或其别名 程序会通过python接口读取系统的主机名或其缩略形式 ansible-pull会在项目中查找与主机名同名的playbook执行【如ops.yml、simple.yml】 如果未找到主机名相关的playbook，则会在项目中找local.yml这个playbook后执行 最后，如果找不到local.yml则报错退出 使用 可以在项目中的local.yml中定义每个主机都要执行的操作 在项目的《hostname》.yml中定义个别主机需要执行的操作 也可以使用不同分支控制不同主机执行不同操作 可以使用crontab来定义每个主机定期执行的playbook 番外：FQDN FQDN=主机名+域名 设置主机名 命令行：hostname xxxx 文件/etc/hostname：xxx 文件/etc/hosts：127.0.0.1 xxx 设置FQDN【以便于python等程序通过接口获取】 删除hosts中默认的”127.0.0.1 localhost localhost.localdomain”等选项 hosts中添加”127.0.0.1 xxx localhost” 如果hosts的127.0.0.1行内存在诸如”localhost.localdomain”以逗号分隔的选项，则FQDN依然为”localhost.localdomain”]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>ansible-config</tag>
        <tag>ansible-console</tag>
        <tag>ansible-doc</tag>
        <tag>ansible-inventory</tag>
        <tag>ansible-playbook</tag>
        <tag>ansible-galaxy</tag>
        <tag>ansible-vault</tag>
        <tag>ansible-pull</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible之playbook学习]]></title>
    <url>%2F2019%2F05%2F25%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%8E%E9%83%A8%E7%BD%B2%2Fansible%2Fansible%E4%B9%8Bplaybook%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[playbook简介playbook是以目录文件结构的形式组织ansible语法，用以实现复杂功能，它的主要概念如下： module：实现功能的基本组成单元，类似程序代码 它应该是幂等效果，即多次执行和一次执行具有同样的效果 task：执行module，用以实现特定功能，类似运行代码后的进程 role：是由task、handler、var等组成以实现特定功能，它还可能包含模块、插件等其他功能组件 play：是将一些主机(inventory)和一些role或task进行映射、绑定，以达到在这些主机上实现特定功能 playbook：playbook是多个play的集合，以达到在多主机进行多功能的部署 block：一般用于task的逻辑分组以及在play中进行错误处理 handlers：事件触发器，当远程系统发生变化时执行的触发器【即特定task】 playbook功能 管理配置文件 远程部署服务 多层架构下的滚动更新 将操作委派给其他主机 在部署等操作过程中和监控系统、负载均衡系统交互 block范例task逻辑分组123456789101112131415161718---- hosts: 127.0.0.1 debugger: on_skipped tasks: - name: display memory and cpu load block: - name: display memory shell: free -m register: mem - debug: msg=&quot;&#123;&#123; mem.stdout &#125;&#125;&quot; - name: display cpu load shell: uptime register: uptime - debug: msg=&quot;&#123;&#123; uptime.stdout &#125;&#125;&quot; when: ansible_facts[&apos;distribution&apos;] == &apos;Ubuntu&apos; become: yes - name: touch file command: touch /tmp/test play中错误处理类似python中的try/expect/finally123456789101112131415161718---- hosts: 127.0.0.1 tasks: - name: Handler the error block: # 标记可能出现异常的区块 - debug: msg=&apos;I execute normally&apos; - name: I force a failure command: /bin/false - debug: msg=&quot;I never execute&quot;# ignore_errors: yes # ignore与rescue功能互斥 rescue: # 出现异常时的处理 - debug: msg=&apos;I caught an error&apos; - name: &apos;force an error in rescue&apos; command: /bin/false - debug: msg=&apos;I alse never executes&apos; always: # 无论是否出现异常都执行的任务 - name: other tasks command: uptime handlers语法 不支持在notify和handlers的name中使用变量 在handers中定义listen选项，既可以作为handler的名称被notify使用，也可以将多个handler分组以便notify使用 一个触发器仅被执行一次，即使在一个play中声明多次 在一个play中，多个触发器共同在task列表执行完成后执行 触发器的运行顺序根据handlers中的定义顺序执行，和notify的使用顺序无关 pre_tasks/tasks/post_tasks中的触发器在相应部分的末尾被触发 不能触发位于include中触发器，但可以使用import中包含的触发器 task语法 name：task名称，以描述这个task的具体任务；可以在name中使用已经定义过的变量 action：task定义旧形式 task定义新形式：【module：options】 task定义旧形式：【action：module options】 module：执行的模块；如果模块中的参数过长，可以在末尾留出空格并以缩进形式开启新行 notify：在任务执行完成后激活触发器的执行； run_once：在一组主机中仅执行一次【即仅在一组主机的第一个主机上执行，但是执行结果可以应用到所有主机】 delegate_facts：True 从主机或主机组之外的其他主机收集facts信息【一般和delegate_to搭配使用】 delegate_to：在主机或主机组的task中定义其他主机要执行的任务 1234本地操作实现shell：free -mrun_once：truedelegate_to:localhost play语法 name：play名称 hosts：将要执行任务的主机，以逗号分隔多个主机或多个组 remote_user：远程连接用户 remote_user、ansible_user【ansible_ssh_user】、命令行下的-u参数 三者具有相同功能都是用于ssh远程连接时设置用户 remote_user主要在ansible.cfg、play中设置 ansible_user主要在inventory中设置 order：设置执行任务的主机顺序 默认inventory，即以inventory中定义的顺序执行任务 gather_facts：是否收集操作系统信息 vars：定义的变量 tasks：执行任务列表 pre_tasks/post_tasks：tasks之前或之后执行的任务列表 roles：角色列表 handlers：触发器列表；实际也是任务列表，和普通的任务没什么不同 any_errors_fatal: True：对于一个任务，只有所有主机都执行成功才认为是成功，才能执行下一个任务；否则认定为失败，失败则playbook立即停止运行并退出 serial：指定在主机组或主机列表中执行任务时，同时有几台主机在执行任务，此功能主要用于灰度发布 可以是数字或数字列表 可以是百分比或百分比列表 也可以是数字和百分比的混合12345678910- hosts: 172.17.134.58,172.17.134.63 gather_facts: no vars: &#123; haproxy: 172.17.134.53, end_sec: 10 &#125; serial: 1 tasks: - include: files/deploy/double_srv.yml tags: [&apos;service_user&apos;] vars: &#123; project: service_user, project_port: 8050, start_sec: 30 &#125;# 由于serial为1，同时只有一台主机在执行任务，循环2次执行完此任务；# 若serial为2，则同时会有2台主机执行任务，一次循环即可执行完 公共语法play或task中都可以使用的语法 environment：在task和play中设置环境变量 environment: PATH: /home//open_api: tags：在play、roles、task级别设置标签，以便只执行特定标签任务 play级别 123- name: deploy java hosts: 172.17.12.14 tags: [&apos;java&apos;] role级别 12roles: - &#123; role: interface_app, tags: [&apos;interface_app&apos;]&#125; task级别 123- name: debug info debug: &quot;msg=&#123;&#123; ansible_env.PATH &#125;&#125;&quot; tags: [&apos;path&apos;] include：包含另一个play或task 此功能已被拆分为include_xxx和import_xxx两类模块，未来可能被遗弃：https://docs.ansible.com/ansible/latest/modules/include_module.html#include-module 包含play：与hosts同级的另一个play 包含task：task列表 123456789---- hosts: ops vars: - key: 8 tasks: - name: debug info debug: msg=&quot;The &#123;&#123; inventory_hostname &#125;&#125; Value is &#123;&#123; key &#125;&#125;&quot; - include: task.yml- include: play2.yml 与when搭配使用 12- include: service_base.yml when: change|changed and project == &apos;service_base&apos; 动态导入与静态导入 include_x：为动态导入，即在运行时遇到该任务点时才执行导入操作 include_role：加载并执行一个role include_tasks：动态包含任务列表 import_x：为静态导入，即在ansible整体解析时执行导入操作 import_playbook：导入playbook import_role：导入role到一个play中 import_tasks：导入task列表 当使用tags或when时 对于import，task选项(options)将会被复制进子task中 对于include，task选项(options)只会影响自身，不会影响子task include_x使用限制 被包含的tags或tasks不会出现在命令行下–list-tags或–list-tasks中 主play中的notify不会触发include包含的handler 不能使用–start-at-task从include包含的task处执行 import_x使用限制 循环时只能使用include而不是import inventory中的变量不能用于目标文件名或角色名 wait_for：在继续其他任务时，等待一个状态成立 12345678910111213# 指定的时间后【delay】，检测某台主机的某个端口是否还有tcp连接【drained】，最多等待300s，在300s内， # 如果为drained状态则继续执行其他任务，但是exclude_hosts中包含的主机【列表】与所操作的主机连接排除在外- name: wait &#123;&#123; project &#125;&#125; port drain wait_for: host: &apos;&#123;&#123; inventory_hostname &#125;&#125;&apos; port: &apos;&#123;&#123; project_port &#125;&#125;&apos; state: drained timeout: 300 delay: &apos;&#123;&#123; end_sec &#125;&#125;&apos; exclude_hosts: &apos;&#123;&#123; micro_srv &#125;&#125;&apos;# 在指定时间后检测端口是否开启- name: wait &#123;&#123; project &#125;&#125; port up wait_for: host=&apos;&#123;&#123; inventory_hostname &#125;&#125;&apos; port=&apos;&#123;&#123; project_port &#125;&#125;&apos; state=started delay=&apos;&#123;&#123; start_sec &#125;&#125;&apos; roles目录 roles以包含规定目录名的语法来构成 每个规定的目录名下必须包含main.yml文件 123456789roles/ 角色主目录 common/ common角色目录 files/ 文件目录 templates/ 模板目录 tasks/ 任务列表目录 handlers/ handler目录 vars/ 不可被inventory定义覆盖的变量目录 defaults/ 可被inventory定义覆盖的变量目录 meta/ meta中定义角色依赖关系 playbook目录通用设置12345678910site.yml 主playbook入口webservers.yml 特殊任务playbook入口hosts 自定义inventorygroup_vars/ 组变量 all dbservershost_vars/ 主机变量 host1 host2roles 多环境设置 在区分环境时【比如开发、测试、生产、预上线、生产】，只需将jinventory及相关变量放置到同级目录即可 执行范例：ansible-playbook -i environments/pre/hosts site-pre.yml -t interface_campaign 12345678910111213141516171819202122232425262728293031323334353637# 主目录结构├── ansible.cfg├── environments│ ├── pre│ └── prod├── files│ ├── conf│ ├── keyfile│ ├── pre│ └── prod├── readme.md├── roles│ ├── common│ ├── project_java│ ├── project_python│ ├── python_web├── site-pre.yml├── site-prod.yml└── tasks ├── ChPass_DenyRoot_AddKey.yml └── UseRoot_AddUser.yml# environment目录结构├── pre│ ├── group_vars│ │ └── all│ ├── hosts│ └── host_vars│ ├── 172.17.134.53│ └── 172.17.134.63└── prod ├── group_vars │ └── all ├── hosts └── host_vars ├── 172.17.12.10 └── 172.17.8.18]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>playbook</tag>
        <tag>include</tag>
        <tag>多环境</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible之基础学习]]></title>
    <url>%2F2019%2F05%2F17%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%8E%E9%83%A8%E7%BD%B2%2Fansible%2Fansible%E4%B9%8B%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[简介ansible是用于远程系统管理、软件部署的工具，类似工具有fabric、puppet 软件特性 基于当前的架构理解，使用简单的语言描述操作过程（playbook编写） 操作的可重用性及操作过程的可追溯性（playbook的可读性、roles的可重用性） 任何操作都是基于状态的描述（模块的幂等特性），只需保证目标对象最终要达到的状态，而不管目标对象的当前状态 基于openssh进行安全通信，无需额外的端口，无需客户端 管理各种基础设置，比如裸机(cobbler)、操作系统、虚拟化(vagrant)、容器(docker)、云、网络、存储等 内置功能丰富的模块，同时拥有强大的社区（galaxy） 管理软件迭代过程中使用的多个阶段环境（比如dev/test/stage/prod，通过多inventory实现） 可以实现服务的滚动更新（percentage）和不停机更新 实现操作 安装软件【yum、apt】 服务启停控制【service】 文件修改【lineinfile】 文件上传与下载【copy、fetch】 执行命令【command】 软件安装安装要求控制端 当前版本(2.8)要求控制端的python版本 python2（2.7） python3（3.5以上） 控制端不支持在windows上安装 可以在RHEL/CentOS/Debian/Ubuntu/macOS/BSDs等linux主机安装 被控端 python版本要求 python2（2.6或以上） python3（3.5或以上） 安装命令 yum：yum install ansible apt： 1234sudo apt updatesudo apt install software-properties-commonsudo apt-add-repository --yes --update ppa:ansible/ansiblesudo apt install ansible pip：pip install ansible 其他安装参考 注意事项 假如远端主机开启selinux，如果需要使用copy/file/template模块，则需要先安装libselinux-python软件 被控端，ansible默认使用的python解释器位置为/usr/bin/python，可以使用ansible_python_interpreter设置 ansible有个原生模块“raw”不需要使用python解释器，可以使用它初始化安装python：ansible myhost –become -m raw -a “yum install -y python2” pip或源码安装的ansilbe默认没有配置文件ansible.cfg 设置ansible 主要为设置ansible.cfg文件 配置文件ansible.cfg中定义了ansible执行时的参数配置 可以使用环境变量或命令行参数进行部分选项设置，多种选项的优先级是：命令行》环境变量》配置文件 配置文件默认加载顺序： 环境变量ANSIBLE_CONFIG 当前目录下的ansible.cfg【但是当前目录权限为其他人可写时，则拒绝加载】 用户主目录下的.ansible.cfg 系统目录/etc/ansible/ansible.cfg 常用参数 参数 含义 inventory 资源清单 library 模块位置【冒号分隔多个位置】 forks 几个进程在工作【默认5个】 host_key_checking 如果远端主机第一次被链接是否执行秘钥检查【设置为False】 timeout ssh连接超时 log_path 日志路径 sudo_user sudo用户 remote_port ssh连接端口 ssh_args 额外的ssh连接参数【可用于跳板机配置】 scp_if_ssh 如果有跳板机，则需设置为True retry_files_enabled 关闭因playbook无法执行而产生的retry文件 deprecation_warnings = False 关闭警告信息 stdout_callback 定义屏幕输出格式为yaml(json格式输出遇到换行时不直观) 范例1234567891011[defaults]inventory = ./hostsremote_port = 22host_key_checking = Falsestdout_callback = yamlcallback_whitelist = timercommand_warnings = Falsefact_caching = jsonfilefact_caching_connection=/tmpfact_caching_timeout = 86400retry_files_enabled = False 设置inventoryinventory即执行任务的主机资源列表，默认指的是/etc/ansible/hosts文件 引用inventory 默认使用/etc/ansible/hosts或ansible.cfg中定义的hosts 动态的获取主机资源，比如 使用脚本，动态获取主机资源 通过插件，从云上获取主机资源 主机资源文件可以是多种格式的，默认是ini，也可以是yaml 查看ansible支持的主机资源类型：ansible-doc -t inventory –list 多种主机资源聚合时 可以在命令行中多次使用-i参数指定 也可以建立一个目录，在目录下定义多个主机资源文件 定义inventory 可以在inventory中定义主机变量和组变量【一般只设置连接类型的内置变量，常用参数如下：】 ansible_user：ansible连接远程主机使用的ssh用户 ansible_host：远程连接主机 ansible_port：远程连接使用的端口 ansible_password：远程连接面 ansible_connecttion：定义hosts的连接方式【值为local时为执行本地操作】 一个主机可以被包含在多个组中，一个组也可以包含另一个组 当主机名或ip中包含连续的字母或数字时，可以使用正则形式，比如 www[a-f].example.com 192.168.0.1[0-9] 默认的组是all【包含所有主机】和ungrouped【包含未分组的主机】 当控制端与远程主机没有使用标准的22端口通信时， 如果使用的是paramiko进行连接【比如centos6/RHEL6】,则不会读取ssh配置文件中的端口信息 当使用openssh进行连接时，则会使用ssh配置文件中的端口信息 所以当使用非标准端口进行通信时，应该在inventory中明确指明使用的端口，例如： 后缀形式：badwolf.example.com:5309 变量形式：jumper ansible_port=5555 ansible_host=192.0.2.50 1234567crm ansible_user=&apos;root&apos; ansible_ssh_pass=&apos;123456&apos; 定义主机和主机变量[docker] 定义docker组192.168.99.10[2:9][docker:vars] 定义docker组变量ansible_ssh_pass=&quot;123&quot;[newserver:children] newserver组包含webservers组webservers 远程连接设置 ansible默认使用原生openssh用于远程连接，并将开启ControlPersist 功能 由于RHEL6和centos6的openssh版本过老无法使用ControlPersist 功能，在这些系统上将会使用paramiko来替代openssh用于远程连接 有时会出现个别设备不支持sftp，这时候就需要使用scp来替代【比如使用跳板机】 密码方式登录在inventory文件中设置ansible_user和ansible_password参数 秘钥方式登录 先使用密码方式，建立秘钥后取消密码选项 产生秘钥：ssh-keygen -t rsa -P “” -f ./bastion 传送公钥：ansible ops -m copy -a “src=keyfiles/bastion.pub dest=~/.ssh/authorized_keys mode=0600” 跳板机设置实现目标ansible可以通过跳板机管理远程内网服务器 实现原理 通过ssh的代理转发功能实现本地使用远程主机内网ip登录远程服务器， 本案例中使用证书登录，即ansible主机与跳板机(bastion)、跳板机与目标服务器(internal)之间均使用证书登录 操作步骤产生秘钥 ssh-keygen -t rsa -P “” -f ./bastion ssh-keygen -t rsa -P “” -f ./internal 传送公钥 公钥放置在某用户主目录下，则以后必须使用相应的用户登录，此例中ansible主机使用muker登录跳板机，跳板机使用muker登录目标主机 ansible ops -m copy -a “src=keyfiles/bastion.pub dest=~/.ssh/authorized_keys mode=0600” ansible 1.1.1.1【下例中172.16.0.205主机的公网ip】 -m copy -a “src=keyfiles/internal.pub dest=~/.ssh/authorized_keys mode=0600” 设置sshd(可选) 设置ssh服务只允许证书登录 123# /etc/ssh/sshd_confPermitRootLogin noPasswordAuthentication no ssh配置 ssh发起连接时，默认使用~/.ssh/config配置，可使用-F参数强制使用指定配置文件 本地私钥权限必须为0600 config文件配置 12345678910111213Host ops User muker #连接跳板机使用的用户名 HostName 47.99.78.151 #跳板机ip ProxyCommand none BatchMode yes #跳板机模式 IdentityFile ~/keyfiles/bastion #本地连跳板机时使用的私钥 StrictHostKeyChecking no #首次登录时禁止秘钥检查Host 172.16.0.* # 目标主机网络 ServerAliveInterval 60 TCPKeepAlive yes ProxyCommand ssh -qaY -i ~/keyfiles/bastion muker@ops &apos;nc -w 14400 %h %p&apos; # ssh代理转发 IdentityFile ~/keyfiles/internal #跳板机使用私钥internal连接目标主机 StrictHostKeyChecking no ssh登录测试 登录跳板机： ssh -F keyfiles/config ops 登录目标内网主机：ssh -F keyfiles/config muker@172.16.0.205 ansible配置 ansible.cfg 123[ssh_connection]ssh_args = -C -o ControlMaster=auto -F keyfiles/configscp_if_ssh = True #文件复制操作强制使用scp模式 hosts 12ops ansible_user=&apos;muker&apos;172.16.0.205 ansible_user=&apos;muker&apos; ansible测试 ping测试 ansible ops -m ping ansible 172.16.0.205 -m ping 常用模块 ping：测试主机连通性 setup：用于获取操作系统信息 ansible 127.0.0.1 -m setup -a “filter=ansible_os*” command/shell：执行命令【command为命令行下默认模块】 creates：当文件存在时，module所在task不执行【可用于实现幂等性】 template：模板系统，可以复制包含变量名的文件 validate：检查由实参渲染的模板文件语法是否正常，如nginx配置文件、sudo文件1234- name: write the nginx config file template: src=nginx2.conf dest=/etc/nginx/nginx.conf validate=&apos;nginx -t -c %s&apos; notify: - restart nginx file：创建、删除文件或目录 state：directory、absent yum/apt：软件包管理 service：服务管理 user：用户管理 git：git操作 copy：复制文件和目录 缺点：当复制的目录有多级或目录内的文件数据过多时，传输效率异常低下 优点：可以备份（backup），可以检测配置文件的有效性（validate） archive：打包文件和目录 缺点：不会复制空目录或空文件【比如python包文件__init__.py即可以是空文件】 synchronize：使用rsync模块同步文件和目录 优点：传输效率高 缺点： 必须使用ansible.cfg中的ssh配置选项 不能备份、不能检测配置文件有效性 不能解析hosts文件中的变量 haproxy：控制haproxy服务 haproxy版本：1.5【增加后端服务器drain状态（软下线）】 haproxy依赖：安装socat，并在haproxy.cnf中配置：stats socket /var/run/haproxy.sock mode 600 level admin12345678# 此配置主要将后端的某台服务器软下线【不接受新连接，已经建立的连接正常处理并关闭】- name: disable &#123;&#123; project &#125;&#125; in haproxy haproxy: state=drain backend=&apos;&#123;&#123; project &#125;&#125;&apos; host=&apos;&#123;&#123; inventory_hostname &#125;&#125;&apos; socket=/var/run/haproxy.sock # 上线某个后端的某台主机并等待，保障此后端主机可用- name: enable &#123;&#123; project &#125;&#125; in haproxy haproxy: state=enabled backend=&apos;&#123;&#123; project &#125;&#125;&apos; host=&apos;&#123;&#123; inventory_hostname &#125;&#125;&apos; socket=/var/run/haproxy.sock wait=yes delegate_to: &apos;&#123;&#123; haproxy &#125;&#125;&apos; become: yes fetch：从远程主机拉取文件到本地 dest：保存为本地文件或保存在本地目录【必须以斜线结尾】 flat：设置为yes时，和copy一样的行为；当为no时，则保存在本地的dest/&lt;remote_hostname&gt;/&lt;absolute_path&gt;下 src：远程主机上的文件 validate_checksum：是否在传输完成后进行校验 范例：ansible test1 -m fetch -a “src=~/vendor/redis-4.0.14.tar.gz dest=files/ flat=yes” blockinfile：插入、更新、删除多行文本内容 group/owner/mode：属主属组权限等 backup：备份文件 block：在标记处将要插入的文本；如果选项缺失或是空字符串，则和state=present一样都是删除内容 path：文件路径 create：文件不存在则新创建 validate：文件语法检查 state：present为添加或更新，absent为删除 marker：替换内容的前后注释信息，默认：”# {mark} ANSIBLE MANAGED BLOCK” insertafter：在指定标记后插入内容 ‘EOF’表示文件末尾 regex表示一般正则表达式，如果匹配不到则使用EOF insertbefore：在指定标记钱插入内容 ‘BOF’表示文件开始 regex表示一般正则表达式，如果匹配不到则使用EOF 1234567891011121314# 修改mavne仓库为阿里云- name: add aliyun repo blockinfile: path: /usr/local/apache-maven-3.6.0/conf/settings.xml marker: &quot;&lt;!-- &#123;mark&#125; ANSIBLE MANAGED BLOCK --&gt;&quot; backup: yes insertafter: &quot;&lt;mirrors&gt;&quot; block: | &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt;]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible.cfg</tag>
        <tag>ssh</tag>
        <tag>inventory</tag>
        <tag>hosts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[angular运行环境]]></title>
    <url>%2F2019%2F05%2F15%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2Fweb%E6%9C%8D%E5%8A%A1%2Fangular%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[使用淘宝npm库npm install -registry=https://registry.npm.taobao.org 安装nodejs下载地址：https://nodejs.org/en/download/ node为免安装，解压后bin目录有node和npm，只需将bin目录添加到系统PATH下即可 安装Angularjsangular是用typescript编写的，所以先安装typescript，再安装angularjs-cli npm install -g typescript typings npm install -g @angular/cli build项目 首先进入项目目录：npm install ng build –prod –output-hashing=none 错误 npm install报错：Error: EACCES: permission denied, mkdir ‘/root/web/CRM-Website-ABKE/node_modules/wd/build’ 原因：如果npm是在root账户下执行的话，它会将uid改成当前账户，或者uid的值从user配置文件中获取，而默认情况下uid的值为nobody。所以在root账户下运行npm install时需要将unsafe-perm选项加上。 解决npm install -registry=https://registry.npm.taobao.org –unsafe-perm=true ng build报错: JavaScript heap out of memory 原因：项目build时需要的内存不足 解决：export NODE_OPTIONS=–max_old_space_size=4096]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>angular</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows常用命令]]></title>
    <url>%2F2019%2F05%2F15%2F%E9%80%9A%E7%94%A8%E6%8A%80%E8%83%BD%2Fwindows%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[启停windows服务 停止：net stop gitblit 启动：net start gitblit sleep实现发起30个ping包耗时30s：ping -n 30 127.0.0.1 &gt; null grep实现 findstr netstat -ant|findstr :80$ 进程命令 进程列表：tasklist /? 关闭进程：taskkill /? 关闭nginx：taskkill /F /IM nginx.exe &gt; nul 变量设置 设置变量：set key=value 删除变量（空值）：set key= 查看变量值：set key]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows常用工具]]></title>
    <url>%2F2019%2F05%2F11%2F%E9%80%9A%E7%94%A8%E6%8A%80%E8%83%BD%2Fwindows%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[软件列表办公类 beyondCompare：文本比较工具 git：windows下git工具（一般作为windows下的linux命令行使用） pycharm：python集成开发工具 sublimeText3：文本编辑工具 xmind8：思维导图工具 secureCRT：linux系统远程连接工具 Postman：接口调试工具 navicat：数据库连接工具 DockerToolbox：windows下docker使用环境 （默认安装）Oracle VM VirtualBox：虚拟化工具 （默认安装）Git MSYS-git UNIX tools：windows下linux命令行工具 shadowsocks：FQ工具 wireshark：网络包分析工具 生活类 快播/QQ影音 印象笔记 windows便签 迅雷下载极速版 uiso：镜像制作工具 驱动精灵万能网卡版 teamviewer：远程协作工具 office DiskGenius：硬盘分区工具 DriverStoreExplorer：驱动卸载工具 百度网盘 firefox/chrome QQ浏览器： qq登录 书签同步 网站账号云同步 git下载地址https://git-scm.com/download/win 配置在环境变量PATH中添加路径【C:\Git\bin；C:\Git\usr\bin】以方便适用其中的linux命令 pycharm设置py文件默认头部信息【file and code templates】 1234567#!/usr/bin/env python3# -*- coding: utf-8 -*-# @Time : $&#123;DATE&#125; $&#123;TIME&#125;# @Author : simple0426# @Email : istyle.simple@gmail.com# @File : $&#123;NAME&#125;.py# @Software: $&#123;PRODUCT_NAME&#125; sublimetext3安装packagecontrol 安装地址：http://packagecontrol.cn/installation#st3 执行命令：通过 ctrl+` 或 View &gt; Show Console打开控制台，将Python代码粘贴到控制台，回车。 1import urllib.request,os,hashlib; h = &apos;6f4c264a24d933ce70df5dedcf1dcaee&apos; + &apos;ebe013ee18cced0ef93d5f746d80ef60&apos;; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( &apos;http://packagecontrol.cn/&apos; + pf.replace(&apos; &apos;, &apos;%20&apos;)).read(); dh = hashlib.sha256(by).hexdigest(); print(&apos;Error validating download (got %s instead of %s), please try manual install&apos; % (dh, h)) if dh != h else open(os.path.join( ipp, pf), &apos;wb&apos; ).write(by) 添加或修改PackageControl的channels【PackageControl-SettingsUser】： 1&quot;channels&quot;: [ &quot;http://packagecontrol.cn/channel_v3.json&quot; ] 插件安装 ctrl+shift+p &gt;&gt; install package &gt;&gt; xxxx Pretty JSON按Ctrl+Alt+J就可格式化json数据 Table Editor 通过Ctrl+Shift+P-&gt;Table Editor: Enable for current view开启 先输入标题行,如|id|name|age|，回车后在第二行输入|-后，按tab键就将进入table编辑模式 表格必须与前面输入的文字之间有空行，否则表格会被当成普通文字渲染 Markdown Editing 设置：package setting–&gt;markdown editing–&gt;GFM setings User 12345&#123; "draw_centered": false, //去除文字整体居中 "color_scheme": "Packages/MarkdownEditing/MarkdownEditor-Dark.tmTheme", //主题与sublime保持一致 "line_numbers": true, //显示行号&#125; 在全局设置中忽略默认的markdown 12345"ignored_packages":[ "Markdown", "Vintage"], Markdown preview 按键绑定的设置： 123[ &#123; &quot;keys&quot;: [&quot;ctrl+m&quot;], &quot;command&quot;: &quot;markdown_preview&quot;, &quot;args&quot;: &#123;&quot;target&quot;: &quot;browser&quot;, &quot;parser&quot;:&quot;markdown&quot;&#125; &#125;] 全局配置123456789101112131415161718192021222324&#123; &quot;color_scheme&quot;: &quot;Packages/Color Scheme - Default/Monokai.tmTheme&quot;, &quot;expand_tabs_on_save&quot;: true, &quot;font_face&quot;: &quot;微软雅黑&quot;, &quot;font_size&quot;: 12, &quot;ignored_packages&quot;: [ &quot;Vintage&quot; ], &quot;pep8_ignore&quot;: [ &quot;E123&quot;, &quot;E128&quot;, &quot;E301&quot;, &quot;E302&quot;, &quot;E309&quot;, &quot;E401&quot;, &quot;E305&quot; ], &quot;tab_size&quot;: 4, &quot;theme&quot;: &quot;Default.sublime-theme&quot;, &quot;translate_tabs_to_spaces&quot;: true, &quot;update_check&quot;: false&#125;]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>beyondCompare</tag>
        <tag>pycharm</tag>
        <tag>sublimeText</tag>
        <tag>xmind</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache下rewrite使用]]></title>
    <url>%2F2019%2F05%2F07%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2Fweb%E6%9C%8D%E5%8A%A1%2Fapache%E4%B8%8Brewrite%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[功能 rewrite url实现URL的跳转和隐藏真实地址，基于perl语言的正则表达式规范 主要用途：拟静态、拟目录、域名跳转、防盗链 开启功能 去除httpd.conf文件中”#LoadModule rewrite_module modules/mod_rewrite.so”前面的”#”号; RewriteEngine on 配置 基于整个apache的配置，即httpd.conf 基于虚拟主机的配置，即virtual host指令 基于目录的配置，即directory指令和 目录下的.htaccess文件 htaccess文件 .htaccess只有在用户访问目录时加载 子目录和父目录的htaccess文件处于同等地位，默认不会继承父作用域规则 默认情况下，mod_rewrite在合并属于同一上下文内容时会覆盖规则。 htaccess开启rewrite功能 RewriteEngine On Options FollowSymLinks RewriteBase / 【从根开始改写url】 语法 设定符合条件的url：RewriteCond TestString CondPattern 该写符合条件的url：RewriteRule Pattern Substitution [flags] RewriteCondTestString&lt;要匹配的服务器变量&gt; + &lt;正则匹配条件&gt; CondPattern 额外的标志位 ‘nocase|NC’ (no case) 忽略大小写 ‘ornext|OR’ (or next condition) 更改多个RewriteCond为逻辑“或”(默认为“与”) ‘novary|NV’ (no vary) RewriteRulePattern request_uri(不包含hostname、port、query_string的部分) pattern在( VirtualHost)中指代request_uri pattern在(Directory and .htaccess)中则指request_uri排除当前目录后的部分 Substitution file-system-path：在virtualhost中配置的规则被当做文件系统路径 URL-path：request_uri absolute URL：使用R标志重定向到一个新的url -(dash)：保持url不变 flags NC：忽略大小写 R[=code]：url重定向 C：如果本条rule匹配则传递给下一条规则，如果本条不匹配则以后的rule都跳过 L：本条rule为最后一条规则，之后的rule都不再应用 QSA：在原始URL后追加查询字符串 F：返回403给客户端 范例虚拟主机建立多个网站 只添加根目录htaccess文件，既能子域名访问网站，也可以通过首域名+同名目录访问网站 每添加一个域名及相应的同名目录，都需要在根目录和同名目录添加相关配置 阿里云虚拟主机页面上的301配置只能实现首页【域名级别】的301跳转，要实现域名间的全站跳转必须使用下方的配置 根目录htaccess12345678910111213141516&lt;IfModule mod_rewrite.c&gt;RewriteEngine OnRewriteBase /# auroraabrasive.com全站301跳转www.auroraabrasive.comRewriteCond %&#123;HTTP_HOST&#125; ^auroraabrasive.com$ [NC] RewriteRule ^(.*)$ http://www.auroraabrasive.com/$1 [R=301,L]# 首域名+目录访问 或 子域名访问网站RewriteCond %&#123;HTTP_HOST&#125; ^www\.auroraabrasive\.com$ [NC] RewriteCond %&#123;REQUEST_URI&#125; !^/auroraabrasive/ RewriteRule ^(.*)$ auroraabrasive/$1?Rewrite [L,QSA]&lt;/IfModule&gt;# 部分注解1. 如果请求的header信息中host为www.auroraabrasive.com2. 如果请求的request_uri中不是以auroraabrasive开头的(斜杠为分界符)3. 重写url-path为 auroraabrasive/%&#123;URI&#125;?Rewrite 子目录htaccess12345678910111213141516171819&lt;IfModule mod_rewrite.c&gt;RewriteEngine OnRewriteBase /# 只允许指定的域名访问RewriteCond %&#123;HTTP_HOST&#125; !^www\.auroraabrasive\.com$ [NC] RewriteRule (.*) http://www.auroraabrasive.com/$1 [L,R=301]# 同名目录访问RewriteCond %&#123;REQUEST_URI&#125; ^\/auroraabrasive\/ [NC]RewriteCond %&#123;QUERY_STRING&#125; !^(.*)?Rewrite RewriteRule ^(.*)$ /%&#123;REQUEST_URI&#125;/%&#123;REQUEST_URI&#125;/$1?Rewrite [L,QSA] &lt;/IfModule&gt;# 部分注解1. 如果请求的header信息中host不是www.auroraabrasive.com2. 重定向url为http://www.auroraabrasive.com/%&#123;URI&#125;，并且不再匹配其他规则3. 如果请求的%&#123;REQUEST_URI&#125;是以auroraabrasive开头的4. 如果请求的query_string不是以任意字符串开头后紧跟Rewrite5. 改写url-path为/%&#123;REQUEST_URI&#125;/%&#123;REQUEST_URI&#125;/%&#123;URI&#125;?Rewrite(由于rewritecond中使用了REQUEST_URI变量，此时url-path为全路径匹配，包含了本级目录auroraabrasive)]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>apache</tag>
        <tag>rewrite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件系统监控inotify]]></title>
    <url>%2F2019%2F05%2F05%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7inotify%2F</url>
    <content type="text"><![CDATA[简介inotify是一个细粒度的异步文件监控系统，可以监控文件发生的一切变化，如： 访问属性 读写属性 权限属性 删除 移动 inotify-tools是linux下使用inotify接口的简单实现 安装内核检查ls -l /proc/sys/fs/inotify/ 安装 【centos】：yum install inotify-tools -y 【ubuntu】：apt install inotify-tools -y 安装检查安装完成后会得到两个命令:inotifywait和inotifywatch inotify事件 事件 详解 access 访问或读取 modify 内容变更 attrib 属性变更 close 文件或目录关闭 open 文件或目录打开 move 文件或目录移动 create 新建文件或目录 delete 文件或目录删除 inotifywatch统计文件和目录发生的变化 参数 -z –zero 输出表格的行和列，即使元素为空 –exclude 正则匹配需要排除的文件，大小写敏感 –excludei 正则匹配需要排除的文件，大小写忽略 -r –recursie 监控一个目录下的所有子目录 -t –timeout 设置超时时间 -e –event &lt;event1&gt;监控指定的事件，多个事件之间逗号分隔 -a|–ascending &lt;event&gt; 升序统计指定事件 -d|–descending &lt;event&gt; 降序统计指定事件 范例inotifywatch -v -e access -e modify -t 60 -r /home inotifywait等待文件或目录发生的变化 参数 -m|–monitor 接收一个事件而不退出，无限执行下去。默认接受一个事件后退出 -d|–daemon 和-m一样，但是在后台执行，同时必须指定–outfile选项，包含–syslog -o|–outfile &lt;file&gt; 输出事件到文件 -s|–syslog 输出错误到系统日志 -r –recursie 监控一个目录下的所有子目录 -q|–quiet 不输出详细信息（指定2次时，除了致命错误，不会输出任何信息) –exclude 正则匹配需要排除的文件，大小写敏感 –excludei 正则匹配需要排除的文件，大小写忽略 -t –timeout 接收一个事件前的超时退出时间，0为永不超时；但是接收一个事件后会退出 -e –event &lt;event1&gt;监控指定的事件，多个事件之间逗号分隔 -c|–csv 输出csv格式 –timefmt &lt;fmt&gt; 指定时间格式 –timefmt ‘%y-%m-%d %H:%M’ –format &lt;fmt&gt; 指定输出信息格式 –format ‘%T %f %e’ %w 发生事件的目录 %f 发生事件的文件 %e 发生的事件 %T timefmt定义的时间格式 范例 监控事件：inotifywait -mrq -e ‘create,delete,close_write,attrib,moved_to’ –timefmt ‘%Y-%m-%d %H:%M’ –format ‘%T %f %e’ /tmp/ 排除特定的目录和文件不予监控：inotifywait -mrq --exclude &quot;.*\.py|test.*/\..*&quot; -e &quot;open,access,modify&quot; python_scripts/【此例为排除python_scripts下的py文件和test**目录下的隐藏文件】 12342018-05-21 19:53 xiaoke.txt CREATE 2018-05-21 19:53 xiaoke.txt ATTRIB 2018-05-21 19:53 xiaoke.txt CLOSE_WRITE,CLOSE 2018-05-21 19:54 xiaoke.txt DELETE rsync+inotify可实现单向的目录或文件的实时同步 使用步骤 安装并配置rsync【daemon模式服务端与客户端设置】 安装inotify 编写实时同步脚本 12345678910#!/bin/bashsrc=/oldboydst=oldboyuser=backup_userhost=192.168.1.1inotifywait -mrq --timefmt &apos;%d/%m/%y %H:%M&apos; --format &apos;%T %w%f%e&apos; -e modify,delete,create,attrib $src \| while read files do cd $src &amp;&amp; rsync -arzu -R --delete --timeout=100 --password-file=/etc/rsyncd.pass ./ $user@$host::$dst done 将同步脚本放入后台执行【nohup cmd &amp;或supervisor方式】 使用注意 rsync的客户端和服务端的密码文件内容不同 服务端含用户名和密码 客户端只有密码 服务端和客户端的密码文件权限相似 属主只能是运行用户 权限只能是0600 rsync-daemon端要关闭防火墙和selinux 若要同步目录的内容一定要进入目录后再进行同步，否则会将客户端的目录作为服务端模块下的子目录进行同步]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>inotify</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发之中间件学习]]></title>
    <url>%2F2018%2F06%2F30%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fdjango%E5%BC%80%E5%8F%91%2Fdjango%E5%BC%80%E5%8F%91%E4%B9%8B%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[cookie简单介绍 保存在浏览器端的键值对 cookie依附在请求头或响应头中出现 向网站发送请求时，会自动携带网站的cookie信息 缺点 明文传输，容易被劫持和篡改 不能用于存储敏感信息 客户端存储，因此cookie可能被拒绝 使用方法 查看cookie：request.COOKIES、request.COOKIES[‘id’] 设置cookie：request.set_cookie 测试客户端是否可以存储cookie：request.test_cookie_worked cookie参数：set_cookie(self, key, value=&#39;&#39;, max_age=None, expires=None, path=&#39;/&#39;,domain=None, secure=False, httponly=False) 参数 默认值 含义 max_age None cookie有效期，单位s expires None 指定时间点cookie过期 path / 只在某个url下cookie有效 domain None 只在某个域有效 secure False 为True时只在https下有效 httponly False 只在http下有效 应用范例12345678def test_cookie(request): if request.COOKIES and &apos;id&apos; in request.COOKIES: return HttpResponse(&apos;hello %s&apos; % request.COOKIES[&apos;id&apos;]) else: ip = request.META[&apos;REMOTE_ADDR&apos;] response = HttpResponse(&apos;hello world&apos;) response.set_cookie(&apos;id&apos;, ip, max_age=10) return response session简单介绍 视图的第一个参数request包含session属性，它是一个字典对象 它是基于cookie实现 检测客户端cookie是否可用：request.session.test_cookie_worked() 设置测试cookie：request.session.set_test_cookie() 删除测试的cookie：request.session.delete_test_cookie() 用户登录时，django产生随机字符串作为session的key，将用户设置的session的key/value对进过“加工”后作为session的value在数据库中存储；同时设置一个cookie键值对，key为“sessionid”，value为session的key返回给客户端存储 当用户再次登陆时，服务端从cookie中取出sessionid的值作为session的key，根据key在数据库中取出session的value，从而可以验证用户是否已登录 使用方法开启session 项目settings.py 123456INSTALLED_APPS = [ &apos;django.contrib.sessions&apos;,]MIDDLEWARE = [ &apos;django.contrib.sessions.middleware.SessionMiddleware&apos;,] session配置 默认配置 django.conf.global_settings中有默认设置，可在settings中覆盖 默认使用数据库存储123456789SESSION_ENGINE = &apos;django.contrib.sessions.backends.db&apos; # 引擎（默认）SESSION_COOKIE_NAME ＝ &quot;sessionid&quot; # Session的cookie保存在浏览器上时的key，即：sessionid＝随机字符串（默认）SESSION_COOKIE_PATH ＝ &quot;/&quot; # Session的cookie保存的路径（默认）SESSION_COOKIE_DOMAIN = None # Session的cookie保存的域名（默认）SESSION_COOKIE_SECURE = False # 是否Https传输cookie（默认）SESSION_COOKIE_HTTPONLY = True # 是否Session的cookie只支持http传输（默认）SESSION_COOKIE_AGE = 1209600 # Session的cookie失效日期（2周）（默认）SESSION_EXPIRE_AT_BROWSER_CLOSE = False # 是否关闭浏览器使得Session过期（默认）SESSION_SAVE_EVERY_REQUEST = False # 是否每次请求都保存Session，默认修改之后才保存（默认） 其他存储方式 使用redis存储[django-redis-sessions] 1234SESSION_REDIS_DB = 5SESSION_REDIS_HOST = 127.0.0.1SESSION_REDIS_PORT = 6379SESSION_ENGINE = &apos;redis_sessions.session&apos; 使用cache系统存储 12SESSION_ENGINES= &quot;django.contrib.sessions.backends.cache&quot;SESSION_CACHE_ALIAS = &quot;default&quot; 其他存储方式 应用范例1234567891011121314151617181920212223242526272829303132333435363738def auth(func): def wrapper(request, *args, **kwargs): if request.session.get(&apos;username&apos;): obj = func(request, *args, **kwargs) return obj else: return redirect(&apos;login.html&apos;) return wrapper@authdef ok(request): user = request.session.get(&apos;username&apos;) return render(request, &apos;ok.html&apos;, context=&#123;&apos;user&apos;:user&#125;)@csrf_exemptdef login(request): if request.session.get(&apos;username&apos;): return redirect(&apos;ok.html&apos;) if request.method == &apos;POST&apos;: if request.session.test_cookie_worked(): request.session.delete_test_cookie() user = request.POST.get(&apos;user&apos;) pwd = md5.encrypt(request.POST.get(&apos;passwd&apos;)) obj = UserInfo.objects.filter(username=user, password=pwd).first() if obj: request.session[&apos;username&apos;] = user return redirect(&apos;ok.html&apos;) else: return render(request, &apos;login.html&apos;, &#123;&apos;msg&apos;: &apos;用户名或密码错误&apos;&#125;) else: return HttpResponse(&apos;请开启cookie&apos;) request.session.set_test_cookie() return render(request, &apos;login.html&apos;)@authdef logout(request): del request.session[&apos;username&apos;] return redirect(&apos;login.html&apos;) 扩展csrf装饰器 导入：from django.views.decorators.csrf import csrf_exempt, csrf_protect csrf_exempt：被装饰的函数不使用csrf【csrf中间件开启时，全站使用csrf验证】 csrf_protect：被装饰的函数使用csrf【csrf中间件屏蔽时，全站禁用csrf验证】 查看session存储内容12345678from django.contrib.sessions.models import Sessionsession = Session.objects.get(session_key=&apos;90nv2o99bykw3qtqotrlt947c2pnx75f&apos;)# 解码session内容session.get_decoded()# 查看session过期时间session.expire_date# 查看session内容session.session_data 中间件 中间件1 中间件2 请求处理流程 socket 中间件1的request 中间件2的request url路由 中间件1的view 中间件2的view 视图函数 中间件2的response 中间件1的response socket 常用方法 process_request process_request默认返回None，此时其他流程可以继续执行 如果返回非None，则请求只到此中间件即停止并返回请求 process_response process_view：和process_request一样从前往后执行，默认返回None process_exception process_template_response 范例1234567891011121314151617181920212223from django.utils.deprecation import MiddlewareMixinfrom django.shortcuts import render, HttpResponseclass M1(MiddlewareMixin): def process_request(self, request): print(&apos;M1.process_request&apos;) # return HttpResponse(&apos;gun&apos;) def process_view(self, request, callback, callback_args, call_kwargs): print(&apos;M1.process_view&apos;, callback) def process_response(self, request, response): print(&apos;M1.process_response&apos;) return response def process_exception(self, request, exception): print(&apos;M2.process_exception&apos;) return HttpResponse(&apos;内部错误&apos;)class M2(MiddlewareMixin): def process_request(self, request): print(&apos;M2.process_request&apos;) def process_view(self, request, callback, callback_args, call_kwargs): print(&apos;M2.process_view&apos;, callback) def process_response(self, request, response): print(&apos;M2.process_response&apos;) return response 缓存缓存位置 开发调试：dummy 内存：locmem 默认选项：django.core.cache.backends.locmem.LocMemCache 文件：filebased 数据库：db 创建缓存表：python manage.py createcachetable memcached：memcached redis【pip install django-redis】 123456789101112131415# settings设置CACHES = &#123;&quot;default&quot;: &#123; &quot;BACKEND&quot;: &quot;django_redis.cache.RedisCache&quot;, # 引擎 &quot;LOCATION&quot;: &quot;redis://192.168.10.10:6379/0&quot;, # 缓存位置 &apos;TIMEOUT&apos;: 300, # 缓存超时，None永不过期，0立即过期 &quot;OPTIONS&quot;: &#123; &apos;MAX_ENTRIES&apos;: 1000, # 最大缓存个数 &quot;CLIENT_CLASS&quot;: &quot;django_redis.client.DefaultClient&quot;, # 默认使用纯python编写的解析器，HiredisParser为c语言编写的解析器可提高性能10倍 # 安装hiredis：pip install hiredis # &quot;PARSER_CLASS&quot;: &quot;redis.connection.HiredisParser&quot;, &#125;, &#125;,&#125; 缓存级别 全局模式【中间件】 ‘django.middleware.cache.UpdateCacheMiddleware’【位于所有中间件之前】 ‘django.middleware.cache.FetchFromCacheMiddleware’【位于所有中间件之后】 视图函数【cache_page装饰器】 12345from django.views.decorators.cache import cache_page @cache_page(60 * 5) #括号内为时间以秒计算def test(request): now = datetime.datetime.now() return HttpResponse(now) 模板变量【cache标签】 1234# 5是缓存时间，&apos;ceshi&apos;是缓存key&#123;% cache 5 &apos;ceshi&apos; %&#125; &#123;&#123; now1 &#125;&#125;&#123;% endcache %&#125; 信号 主要功能为：当识别到请求处理流程中的某一行为时，触发自定义动作 可以保存在项目同名app下__init__.py文件中 1234567891011121314# 请求到来前，请求结束后触发from django.core.signals import request_finished, request_started, got_request_exception# 对象保存前后触发from django.db.models.signals import pre_delete, pre_init, pre_save, pre_migratefrom django.db.models.signals import post_delete, post_init, post_migrate, post_save# 多对多关系表变更触发from django.db.models.signals import m2m_changed, class_prepared# 创建数据库连接时触发from django.db.backends.signals import connection_createddef callback(sender, **kwargs): print(&apos;request is comming!&apos;) print(sender, kwargs)request_started.connect(callback)]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>cookie</tag>
        <tag>session</tag>
        <tag>缓存</tag>
        <tag>中间件</tag>
        <tag>信号</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发之views学习]]></title>
    <url>%2F2018%2F06%2F29%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fdjango%E5%BC%80%E5%8F%91%2Fdjango%E5%BC%80%E5%8F%91%E4%B9%8Bviews%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[request内容请求路径 request.path：除域名以外的请求路径，以斜杠开头 request.get_host()：主机名（比如通常所说的域名） request.get_full_path()：请求路径，可能包含查询字符串 request.is_secure()：请求方法是否是https，是则返回True 请求内容 request.method：请求方法 request.GET：对收到的get请求进行数据【来自form或url中的查询串】解析，它是一个类字典对象 request.POST：对收到的post请求进行数据【来自html中的form】解析，他是一个类字典对象 仅当Content-Type：application/x-www-form-urlencoded request.body：请求体内容 get请求体为空 post请求体范例：b&#39;csrfmiddlewaretoken=SP3GO7LEfUb0QqWwE4Rq0r0W&amp;user=he&amp;passwd=12&#39; request.Meta：它是一个python字典，包含了本次请求的所有header信息，可以通过get请求获得【防止异常退出】 HTTP_REFERER，进站前链接网页，如果有的话。 HTTP_USER_AGENT，用户浏览器的user-agent字符串，如果有的话。 REMOTE_ADDR 客户端IP 类视图简单介绍 使用类方式实现通用视图，和使用函数方式相比，类能更方便的实现继承和mixins 类视图在URLconf中的实现： 调用类的as_view方法，比如url(r&#39;^login&#39;, views.LoginView.as_view()) 接受request并实例化，返回实例的dispatch方法 实例的dispatch方法根据请求的类型返回同名的处理函数 类视图在增加功能时【比如授权登录】，可以采取两种方式： 类的多重继承方式 装饰器方式 当类视图使用装饰器时，必须使用django内置的装饰器方法【比如method_decorator】 在类视图使用csrf装饰器时，必须在dispatch方法前使用 类视图装饰器可以放在类前【必须指明要装饰的具体函数名称】，也可以放在类下的方法前 应用范例基础功能类1234567class BaseView(View): def dispatch(self, request, *args, **kwargs): if request.session.get(&apos;username&apos;): response = super(BaseView, self).dispatch(request, *args, **kwargs) return response else: return redirect(&apos;login.html&apos;) 基础功能装饰器12345678def auth(func): def wrapper(request, *args, **kwargs): if request.session.get(&apos;username&apos;): obj = func(request, *args, **kwargs) return obj else: return redirect(&apos;login.html&apos;) return wrapper 主功能组件12345678910111213141516171819202122232425262728293031from django.utils.decorators import method_decoratorclass LoginView(View): @method_decorator(csrf_exempt) def dispatch(self, request, *args, **kwargs): response = super(LoginView, self).dispatch(request, *args, **kwargs) return response def get(self, request, *args, **kwargs): return render(request, &apos;login.html&apos;) def post(self, request, *args, **kwargs): user = request.POST.get(&apos;user&apos;) pwd= md5.encrypt(request.POST.get(&apos;passwd&apos;)) obj = UserInfo.objects.filter(username=user, password=pwd).first() if obj: request.session[&apos;username&apos;] = user return redirect(&apos;ok.html&apos;) return render(request, &apos;login.html&apos;, &#123;&apos;msg&apos;: &apos;用户或密码错误&apos;&#125;)# class OkView(BaseView, View): # 可以使用类的多重继承凡是增加功能【比如登录授权】@method_decorator(auth, name=&apos;get&apos;)# 在类前使用装饰器必须指明要装饰的具体函数名称，比如get、post等class OkView(View): def get(self,request,*args, **kwargs): return render(request, &apos;ok.html&apos;, &#123;&apos;user&apos;: request.session[&apos;username&apos;]&#125;)# class LogoutView(BaseView, View):class LogoutView(View): # 装饰器也可放在类下的方法前 @method_decorator(auth) def get(self, request, *args, **kwargs): del request.session[&apos;username&apos;] return redirect(&apos;login.html&apos;) Form表单 自动生成html标签，并对字段进行校验 表单框架最主要的用法是：为HTML下每一个将要处理的表单定义一个Form类 Form对象表单要素 字段类型 CharField：文本框 DateField：日期选择 DecimalField：数字 MultipleChoiceField：多选框 ChoiceField：单选框 FileField：文件选择框 字段参数 label：标签显示内容 required：是否必选 initial：初始值 min_length/max_length：最大最小长度 error_messages：错误提示 widget：插件 choices：可选项【choice相关字段类型】 validators：简单的验证规则 常用插件 TextInput：默认插件 RadioSelect：单选插件 CheckboxSelectMultiple：多选插件 Textarea：多行文本框 PasswordInput：密码类型输入框 使用范例123456789101112131415161718192021222324252627282930313233class BookForm(Form): def __init__(self, *args, **kwargs): super(BookForm, self).__init__(*args, **kwargs) # 初始化时从数据库获取信息 self.fields[&apos;authors&apos;].choices = Author.objects.values_list(&apos;id&apos;, &apos;name&apos;) self.fields[&apos;publisher&apos;].choices = Publisher.objects.values_list(&apos;id&apos;, &apos;name&apos;) title = fields.CharField( required=True, label=&apos;书名&apos;, widget=widgets.Input( attrs= &#123;&apos;class&apos;: &apos;c1&apos;, &apos;style&apos;: &apos;color: red&apos;&#125;, ) ) publication_date = fields.DateField( required=True, label=&apos;出版日期&apos;, widget=widgets.SelectDateWidget( years=range(2018, 1970, -1), ) ) price = fields.DecimalField( required=True, label=&apos;价格&apos; ) authors = fields.MultipleChoiceField( label=&apos;作者&apos;, choices=[], ) publisher = fields.ChoiceField( label=&apos;出版社&apos;, choices=[], ) Form规则验证使用方法 位置 使用方法 验证级别 是否有返回值 优先级 类字段下的validators参数 1. RegexValidator对象【只支持正则判断】 2. 自定义函数 【支持逻辑判断，错误时抛出异常】 字段级别 有错误时抛出异常 在默认规则前生效 类下的clean_字段 类下的clean_字段【支持逻辑判断和与数据库联动】 字段级别 返回字段信息，同时有错误抛出异常 在默认规则后生效 类下的clean方法 类下的clean方法 表单级别多字段 返回表单数据，同时有错误抛出异常 在默认规则后生效 使用范例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364from django.core.exceptions import ValidationErrorfrom django.core.validators import RegexValidatordef validate_username(msg): if &apos;test&apos; in msg: raise ValidationError(&apos;关键词不能包含test&apos;)class UserForm(Form): username = fields.CharField( min_length=6, max_length=20, required=True, error_messages=&#123; &quot;required&quot;: &apos;用户名不能为空&apos;, &#125;, validators=[RegexValidator(r&apos;^(\D)&apos;, &apos;不能数字开头&apos;), validate_username] ) password = fields.CharField( required=True, error_messages=&#123; &quot;required&quot;: &apos;密码不能为空&apos;, &#125;, widget=widgets.PasswordInput(render_value=True), ) password_confirm = fields.CharField( required=True, error_messages=&#123; &quot;required&quot;: &apos;密码不能为空&apos;, &#125;, widget=widgets.PasswordInput(render_value=True), ) email = fields.EmailField( required=True, error_messages=&#123; &quot;required&quot;: &apos;邮箱不能为空&apos;, &quot;invalid&quot;: &apos;邮箱格式错误&apos;, &#125;, ) user_type = fields.ChoiceField( required=True, choices=((&apos;1&apos;, u&apos;普通用户&apos;), (&apos;2&apos;, u&apos;超级用户&apos;)), ) # 字段级别验证 def clean_username(self): username = self.cleaned_data[&apos;username&apos;] if not re.match(r&apos;^(\D)&apos;, username): raise ValidationError(&apos;不能数字开头&apos;) if &apos;test&apos; in username: raise ValidationError(&apos;关键词不能包含test&apos;) return username # 表单级别多字段验证 def clean(self): # 调用父类初始化 cleaned_data = super().clean() # get方法避免取空值 password = cleaned_data.get(&apos;password&apos;) password_confirm = cleaned_data.get(&apos;password_confirm&apos;) if password == password_confirm: return self.cleaned_data else: # 可以将表单验证结果绑定在特定字段 self.add_error(&apos;password_confirm&apos;, ValidationError(&apos;密码输入不一致&apos;)) return self.cleaned_data Form对象实例化使用要点 初始化：data = UserForm(initial=xxx) 实例化：data = UserForm(data=request.POST) 调用验证规则：data.is_valid() 获取校验后的数据：data.cleaned_data 返回的错误信息：data.errors/data.errors.字段.字段错误索引 使用范例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950def book_admin(request, book_id=None): # 图书信息变更 if request.method == &apos;POST&apos;: data = BookForm(data=request.POST) if data.is_valid(): data = data.cleaned_data # 设置书籍出版社【一对多关系】 data[&apos;publisher&apos;] = Publisher.objects.get(id=data[&apos;publisher&apos;]) # 获取作者id列表 authors_id_list = data.pop(&apos;authors&apos;) # 获取作者对象列表 authors_list = Author.objects.filter(id__in=authors_id_list) # 编辑图书 if book_id is not None and Book.objects.filter(id=int(book_id)).exists(): query = Book.objects.filter(id=int(book_id)) # 更新其他信息 query.update(**data) # 更新作者信息 book_obj = query.first() book_obj.authors.clear() book_obj.authors.add(*authors_list) return HttpResponseRedirect(&apos;book_admin_%s&apos; % book_id) # 添加书籍 else: # 添加书籍 new_book = Book.objects.create(**data) # 书籍对象处添加作者【多对多关系】 new_book.authors.add(*authors_list) book_id = str(new_book.id) return HttpResponseRedirect(&apos;book_admin_%s&apos; % book_id) # 显示书籍 elif book_id is not None: book_obj = Book.objects.filter(id=int(book_id)).first() if book_obj: authors_list = book_obj.authors.values_list(&apos;id&apos;) authors_id_list = list(zip(*authors_list))[0] book_info = &#123; &apos;title&apos;: book_obj.title, &apos;publication_date&apos;: book_obj.publication_date, &apos;price&apos;: book_obj.price, &apos;authors&apos;: authors_id_list, &apos;publisher&apos;: book_obj.publisher.id &#125; data = BookForm(initial=book_info) else: return HttpResponseRedirect(&apos;book_admin&apos;) # 默认显示空表格 else: data = BookForm() return render(request, &apos;book_admin.html&apos;, &#123;&apos;form&apos;: data&#125;) HTML渲染使用要点 &lt;form method=&quot;post&quot; novalidate&gt;：novalidate关闭浏览器验证 form.as_p：循环模式下生产p标签，由于标签格式固定不利于css渲染 form.username：获取表单字段 form.errors.username.0：获取表单字段的错误信息 错误提示 表单内容较多时 此时表单验证使用前台提交(url跳转)方式【验证时页面刷新】 由于页面刷新，所以可以在页面中内置错误变量，刷新后显示错误 表单内容较少时 如场景：模态对话框，此时表单验证使用ajax方式【验证时页面无刷新】 验证成功时，前台处理url跳转 由于页面无刷新，页面内的错误变量无法被渲染，所以此时需要使用DOM新建错误标签后显示 ajax范例1234567891011121314151617181920212223242526272829303132&lt;form&gt; &#123;% csrf_token %&#125; &lt;p&gt;书名：&#123;&#123; form.title &#125;&#125; &lt;/p&gt; &lt;p&gt;出版日期：&#123;&#123; form.publication_date &#125;&#125;&lt;/p&gt; &lt;p&gt;价格：&#123;&#123; form.price &#125;&#125;&lt;/p&gt; &lt;p&gt;作者: &#123;&#123; form.authors &#125;&#125; &lt;/p&gt; &lt;p&gt;出版社：&#123;&#123; form.publisher &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;input type=&quot;button&quot; value=&quot;提交&quot; class=&quot;submit&quot;&gt;&lt;/p&gt;&lt;/form&gt;&lt;script&gt; $(&apos;.submit&apos;).click(function () &#123; $.ajax(&#123; url: &apos;book_ajax&apos;, type: &apos;POST&apos;, data: $(&quot;form&quot;).serialize(), dataType: &quot;json&quot;, success:function (data) &#123; if(data.status)&#123; // ajax处理页面跳转 location.href = &apos;book_admin_3&apos;; &#125;else&#123; $.each(data.Error, function (k, v) &#123; var tag = document.createElement(&apos;span&apos;); tag.innerHTML = v[0]; tag.className = &apos;error&apos;; $(&apos;input[name=&quot;&apos;+k+&apos;&quot;]&apos;).after(tag); &#125;) &#125; &#125; &#125;) &#125;)&lt;/script&gt; 1234567891011121314def book_ajax(request): if request.method == &apos;POST&apos;: response = &#123;&apos;status&apos;: True, &apos;Error&apos;: None&#125; data = BookForm(request.POST) if data.is_valid(): data = data.cleaned_data # ajax跳转在前台处理，此处redirect无用 else: response[&apos;status&apos;] = False response[&apos;Error&apos;] = data.errors return HttpResponse(json.dumps(response)) else: data = BookForm() return render(request, &apos;book_ajax.html&apos;, &#123;&apos;form&apos;: data&#125;)]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>CBV</tag>
        <tag>Form</tag>
        <tag>request</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发之models学习]]></title>
    <url>%2F2018%2F06%2F14%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fdjango%E5%BC%80%E5%8F%91%2Fdjango%E5%BC%80%E5%8F%91%E4%B9%8Bmodels%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[ORM介绍ORM介绍 Object Relational Mapping(对象关系映射)：是一种程序技术，用于实现面向对象编程语言里不同类型系统的数据之间进行转换。 在django中主要实现方式为：在modles文件中定义类，通过映射关系和相关命令转换为对数据库中对应的对象进行操作。 django中的映射关系 程序 数据库 类名 表名 属性 字段名 类实例化对象 数据记录 ORM功能 创建数据表 操作数据 前置配置 创建数据库，设置相应的用户和权限 安装python连接数据库的引擎【如连接mysql的pymysql】 在settings文件中配置数据库相关选项 创建数据表数据库建模 作者（Author）和作者详情（AuthorDetail）为一对一关系（OneToOneField） 出版社（Publisher）和书籍（Book）为一对多关系（ForeignKey） 书籍（Book）和作者（Author）为多对多关系（ManyToManyField） 表结构范例 modles.py文件 12345678910111213141516171819202122232425262728293031323334353637class Publisher(models.Model): name = models.CharField(max_length=30, verbose_name=&apos;名称&apos;) address = models.CharField(&quot;地址&quot;, max_length=50) city = models.CharField(&quot;城市&quot;, max_length=60) state_province = models.CharField(max_length=30) country = models.CharField(max_length=50) website = models.URLField() class Meta: verbose_name = &apos;出版商&apos; verbose_name_plural = verbose_name def __str__(self): return self.nameclass Author(models.Model): name = models.CharField(max_length=30) def __str__(self): return self.nameclass AuthorDetail(models.Model): sex = models.BooleanField(max_length=1, choices=((0, &apos;男&apos;), (1, &apos;女&apos;))) email = models.EmailField() address = models.CharField(max_length=50) birthday = models.DateField() author = models.OneToOneField(Author)class Book(models.Model): title = models.CharField(max_length=100) authors = models.ManyToManyField(Author) publisher = models.ForeignKey(Publisher) publication_date = models.DateField() price = models.DecimalField(max_digits=5, decimal_places=2, default=10) def __str__(self): return self.title 数据库建表 创建执行SQL的脚本：python manage.py makemigrations 查看建表SQL语句：python manage.py sqlmigrate app01 0001 执行建表SQL脚本：python manage.py migrate 数据操作增加基础操作方式 create方法： Author.objects.create(name=&#39;he&#39;) save方法 12author = Author(name=&apos;jing&apos;)author.save() 一对多关系操作方式 含有外键的表 获取外键字段对象【出版社】 pub_obj=Publisher(name=&#39;河大出版社&#39;,address=&#39;保定&#39;,city=&#39;保定&#39;,state_province=&#39;河北&#39;,country=&#39;China&#39;,website=&#39;http://www.hbu.com&#39;) 在添加数据时绑定外键字段 Book.objects.create(title=&#39;php&#39;, publication_date=&#39;2017-7-7&#39;, price=99, publisher=pub_obj) 多对多关系操作方式 实质为关系表数据增加 正向操作 以外键所在表为操作对象，例如book 获取作者对象：author = Author.objects.filter(id__gt=1) 获取书籍对象：book = Book.objects.get(id=1) 在书籍处添加作者【一本书多个作者】：book.authors.add(*author) 删除作者：book.authors.remove(*author) 反向操作 从外键所映射的主键所在的表为操作对象，例如author 获取书籍对象：book1 = Book.objects.filter(id__gt=1) 获取作者对象：author1 = Author.objects.get(id=2) 作者处添加书籍【一个作者有多本书】：author1.book_set.add(*book1) 删除书籍：author1.book_set.remove(*book1) 删除 Modle对象删除：Author.objects.get(id=1).delete() Queryset对象删除：Author.objects.filter(id=1).delete() 修改 update方法 只能用于queryset对象【比如filter、all的结果】 update方法只对变更的属性赋值，效率较高Author.objects.filter(id=1).update(name=&#39;yang&#39;) save方法 对modle对象进行操作【比如get的结果】 save方法会对所有属性重新赋值，效率较低123author = Author.objects.get(id=2)author.name = &apos;meng&apos;author.save() 查询查询类API filter：获取所有匹配的queryset对象 all：获取所有的queryset对象 get：获取指定条件的modle对象【没有或多于1个时则报错】 过滤型API value：获取由指定字段组成的queryset对象 Book.objects.filter(price__gt=12).values(&#39;price&#39;) exclude：排除指定条件的数据 Book.objects.all().exclude(title=&#39;java&#39;) count：返回指定条件的结果数量 [](切片)：返回指定数量的结果 Book.objects.all().order_by(&#39;title&#39;)[:2] first/last：返回结果集中的第一条或最后一条数据 exists：判断返回的结果中是否有数据【True或False】 order_by：根据指定字段对结果排序 字段名前加减号【-】为反向排序，字段可以有多个 reverse：反向排序 distinct：结果去重 下划线语法条件查询 contains：包含指定字符串的数据【icontains不区分大小写】 Book.objects.filter(title__contains=&#39;php&#39;) regex：正则查询【iregex不区分大小写】 Book.objects.filter(title__regex=&#39;^p&#39;) lt/gt：数值比较 Author.objects.filter(id__gt=1) range/in：范围与区间查询 Author.objects.filter(id__in=[1, 3]) Author.objects.filter(id__range=[1, 3]) 跨表使用 正向查询【从外键所在的表查询主键所在表中的数据，跨表时使用表内的外键字段名】 Book.objects.filter(title__icontains=&#39;php&#39;).values(&#39;publisher__name&#39;) 反向查询【从主键所在的表查询外键所在表中的数据，跨表时使用另一个表的表名】 Publisher.objects.filter(id=1).values(&#39;book__title&#39;) 聚合和分组 from django.db.models import Avg, Sum aggregate：对返回的结果进行聚合运算【平均值，最大值，最小值】 Book.objects.all().aggregate(avg=Avg(&#39;price&#39;)) annotate：对返回的结果的每一个分组分别进行聚合运算 Book.objects.values(&#39;authors__name&#39;).annotate(Sum(&#39;price&#39;)) F和Q查询 from django.db.models import F, Q F查询：保存中间状态值 Book.objects.all().update(price=F(&#39;price&#39;) + 10) Q查询：根据&amp;|~【与或非】逻辑组合查询条件 Book.objects.filter(Q(id__gt=1)&amp;Q(title=&#39;python&#39;)) admin site主要功能是：在web页面操作Django ORM 前置条件 settings中默认配置【INSTALLED_APPS和MIDDLEWARE_CLASSES】 urls中保持默认配置【存在admin路由】 数据库中存在django相关表 后台汉化 ‘django.middleware.locale.LocaleMiddleware’【SessionMiddleware之后添加】 新建用户python manage.py createsuperuser 注册模块显示逻辑 list_display：可显示的字段 list_display_links：可点击编辑的字段 search_fields：可搜索字段 list_filter：在字段列表右侧显示可用于过滤的字段 date_hierarchy：在字段列表上方显示日期过滤参数 ordering：默认排序方式【优先级左右依次降低】 filter_horizontal：设置多对多字段使用水平的可选控件 raw_id_fields：设置外键使用可搜索的文本框形式而非列表【降低列表加载带来的系统开销】 actions：执行函数功能 范例123456789101112131415161718from app01.models import *class BookAdmin(admin.ModelAdmin): list_display = [&apos;title&apos;, &apos;price&apos;, &apos;publisher&apos;, &apos;publication_date&apos;] list_display_links = [&apos;title&apos;] search_fields = [&apos;title&apos;, &apos;publisher&apos;] list_filter = [&apos;publication_date&apos;] date_hierarchy = &apos;publication_date&apos; ordering = [&apos;-publication_date&apos;] filter_horizontal = [&apos;authors&apos;] raw_id_fields = [&apos;publisher&apos;] def func(self, request, queryset): print(self, request, queryset) print(request.POST.getlist(&apos;_selected_action&apos;)) func.short_description = &apos;显示结果&apos; actions = [func,]admin.site.register(Book, BookAdmin)admin.site.register(Author) 登录后台http://localhost/admin 多数据库联用settings设置123456789101112131415161718# 数据库设置DATABASES = &#123; # default为默认数据库，具有特殊含义 &apos;default&apos;: &#123; &apos;NAME&apos;: &apos;app_data&apos;, &apos;ENGINE&apos;: &apos;django.db.backends.postgresql_psycopg2&apos;, &apos;USER&apos;: &apos;postgres_user&apos;, &apos;PASSWORD&apos;: &apos;s3krit&apos; &#125;, &apos;users&apos;: &#123; &apos;NAME&apos;: &apos;user_data&apos;, &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;USER&apos;: &apos;mysql_user&apos;, &apos;PASSWORD&apos;: &apos;priv4te&apos; &#125;&#125;# 数据库路由设置[类名]DATABASE_ROUTERS = [&apos;utils.dbroute.DBRouter&apos;] 路由设置123456789101112131415161718192021222324252627282930class DBRouter: # 指定读数据库路由 def db_for_read(self, model, **hints): app_label = model._meta.app_label if app_label in (&apos;order&apos;, &apos;payment&apos;): return &apos;order&apos; if app_label in (&apos;xcass_passport&apos;, &apos;store_manage&apos;): return &apos;xcass&apos; return &apos;default&apos; # 指定写数据库路由 def db_for_write(self, model, **hints): app_label = model._meta.app_label if app_label in (&apos;order&apos;, &apos;payment&apos;): return &apos;order&apos; if app_label in (&apos;xcass_passport&apos;, &apos;store_manage&apos;): return &apos;xcass&apos; return &apos;default&apos; # 如果obj1 和obj2 之间应该允许关联则返回True，如果应该防止关联则返回False， # 如果路由无法判断则返回None def allow_relation(self, obj1, obj2, **hints): if obj1._meta.app_label == obj2._meta.app_label: return True # 定义迁移操作是否允许在别名为db的数据库上运行。如果操作应该运行则返回True， # 如果不应该运行则返回False，如果路由无法判断则返回None def allow_migrate(self, db, app_label, model_name=None, **hints): if app_label in (&apos;order&apos;, &apos;payment&apos;): return db == &apos;order&apos; if app_label in (&apos;xcass_passport&apos;, &apos;store_manage&apos;): return db == &apos;xcass&apos; return db == &apos;default&apos; 数据对象操作 queryset对象：Book.objects.using(‘default’).all() Models对象 12author = Author(first_name=&apos;yashuai&apos;, last_name=&apos;gao&apos;)author.save(using=&apos;default&apos;) 数据导入导出 数据同步【建表】：python manage.py migrate –database=test 数据导出：python manage.py dumpdata app1 –database=db1 &gt; app1_fixture.json 数据导入：python manage.py loaddata app1_fixture.json –database=db1]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>models</tag>
        <tag>ORM</tag>
        <tag>admin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发之templates学习]]></title>
    <url>%2F2018%2F06%2F13%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fdjango%E5%BC%80%E5%8F%91%2Fdjango%E5%BC%80%E5%8F%91%E4%B9%8Btemplates%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[约定为避免模板二次渲染，特在变量{{ }}和流程控制{% %}中添加短横线屏蔽，替换结果如下： {{ }} 替换为{-{ }-} {% %}替换为{-% %-} 介绍介绍含有模板【例如jinja2模板】语法的html文件即是模板文件 主要语法 变量：{-{ }-} 流程控制(标签)：{-% %-} 注释：{# #} 运算符 == 等于 != 不等于 &gt; &gt;= 大于等于 &lt; &lt;= 小于等于 使用范例1234567from django.template import Template, Context#建立模板对象t = Template(&quot;my name is &#123;-&#123; name &#125;-&#125;&quot;) #建立参数对象c = Context(&#123;&quot;name&quot;: &quot;jingqi&quot;&#125;) #使用Template的render方法将Context对象传入t.render(c) 变量属性与方法 在django模板系统中处理复杂数据结构使用（.）字符 根据对象的key或索引获取对象的value 调用对象的方法【方法不能加括号，不能加参数】 获取对象的属性 过滤器变量可以通过过滤器进行结果显示变更的操作，例如设置变量的默认值：{-{ test|default:&#39;空值&#39; }-} 特殊变量forloop forloop变量只能在循环中得到，当模板解析器到达endfor时forloop就消失了 forloop.counter：表示循环的次数，从1开始计数 forloop.counter0：表示循环的次数，从0开始计数 forloop.revcounter：反向循环计数，末尾是1 forloop.revcounter0：反向循环计数，末尾是0 forloop.first：如果是循环的第一个元素 forloop.last：如果是循环的最后一个元素 流程控制if判断 if可以接受and、or、not测试同一变量，但不允许同一个标签内同时出现and和or，但可以多次出现and或or等同一逻辑 1234567&#123;-% if test &gt; 2 %-&#125; &lt;p&gt;大于2&lt;/p&gt;&#123;-% elif test == 2 %-&#125; &lt;p&gt;等于2&lt;/p&gt;&#123;-% else %-&#125; &lt;p&gt;小于2&lt;/p&gt;&#123;-% endif %-&#125; for循环 列表迭代 12345&#123;-% for item in test %-&#125; &lt;p&gt;&#123;-&#123; item &#125;-&#125;&lt;/p&gt;&#123;-% empty %-&#125; &lt;p&gt;列表为空&lt;/p&gt;&#123;-% endfor %-&#125; 字典迭代 12345&#123;-% for key,value in test.items %-&#125;&lt;p&gt; &#123;-&#123; key &#125;-&#125;:&#123;-&#123; value &#125;-&#125;&lt;/p&gt;&#123;-% endfor %-&#125; 其他标签 csrf_token：{-% csrf_token %-} 用于防治csrf跨站攻击验证；其实这里会生成一个input标签，和其他表单标签一起提交给后台 url引用：&lt;form action=&quot;{-% url &quot;bieming&quot;%-}&quot; &gt; 在html中引用urls.py中配置的url路径 with别名设置：{-% with total=fhjsaldfhjsdfhlasdfhljsdal %-} {-{ total }-} {-% endwith %-} verbatim禁止渲染：{-% verbatim %-}{-{ ceshi }-}{-% endverbatim %-} 安全转义 为了避免非法输入造成安全威胁，django模板系统对html开启自动转义 转义字符 &lt;自动转义为&amp;lt &gt;自动转义为&amp;gt &#39;自动转义为&amp;#39 &quot;自动转义为&amp;quot &amp;自动转义为&amp;amp 转义范例 单变量关闭自动转义 123tm = Template(&apos;my name is &#123;&#123; name|safe &#125;&#125;&apos;)con = Context(&#123;&apos;name&apos;: &apos;&lt;b&gt;&apos;&#125;)tm.render(con) 模块级别关闭自动转义 123&#123;% autoescape off %&#125;Hello &#123;&#123; name &#125;&#125;&#123;% endautoescape %&#125; 自定义标签和过滤器创建 在已经注册过的app下新建templatetags包 在templatetags包下编写python文件 使用注意 filter对变量进行处理，可以在if和for中使用 simple_tag为自定义流程标签，不能在if和for中使用 使用范例python文件12345678910111213from django import templateregister = template.Library()# name为给过滤器添加别名@register.filter(name=&apos;percent&apos;)def percent_decimal(value): value = float(str(value)) value = round(value, 3) value = value * 100 return str(value) + &apos;%&apos;# 自定义标签@register.simple_tagdef add_sum(v1, v2): return v1 + v2 html文件1234&lt;!--在html文件顶部使用load加载标签文件名--&gt;&#123;-% load MyTag %-&#125;Your input is &#123;-&#123; value|percent &#125;-&#125;.&lt;p&gt;output is &#123;-% add_sum v1 v2 %-&#125;&lt;/p&gt; 静态文件设置在编写模板时，引入一些现成的库文件【如bootstrap，jquery】，此时需要做一些额外的配置，相关设置如下： 在settings中设置公有静态目录 将库文件放入设置的静态目录中 使用【load staticfiles】标签导入相关语法 使用标签语法【static “url”】导入相关库文件 模板继承基础模板设置 每个block必须是唯一的 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&#123;-% load staticfiles %-&#125;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;&#123;-% block title %-&#125;title&#123;-% endblock %-&#125;&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;&#123;-% static &quot;bootstrap-3.3.7-dist/css/bootstrap.css&quot; %-&#125;&quot;&gt; &lt;script src=&quot;&#123;-% static &quot;jquery-3.1.1.js&quot; %-&#125;&quot;&gt;&lt;/script&gt; &lt;script src=&quot;&#123;-% static &quot;bootstrap-3.3.7-dist/js/bootstrap.js&quot; %-&#125;&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&#123;-% block content %-&#125;你好&#123;-% endblock %-&#125;&#123;-% block footer %-&#125;测试&#123;-% endblock %-&#125;&lt;/body&gt;&lt;/html&gt; 子模板设置当需要继承基础模板时，使用extends关键词导入基础模板，且extends必须位于文件首行 123456789101112131415161718192021&#123;-% extends &quot;base.html&quot; %-&#125;&#123;-% load Mytag %-&#125;&#123;-% block content %-&#125;&lt;p&gt;output is&#123;-% add_sum v1 v2 %-&#125;&lt;/p&gt;&lt;div class=&quot;container&quot;&gt; &lt;table class=&quot;table table-bordered&quot;&gt; &lt;tr&gt; &lt;th&gt;1&lt;/th&gt; &lt;th&gt;2&lt;/th&gt; &lt;th&gt;3&lt;/th&gt; &lt;th&gt;4&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;a&lt;/td&gt; &lt;td&gt;b&lt;/td&gt; &lt;td&gt;c&lt;/td&gt; &lt;td&gt;d&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/div&gt;&#123;-% endblock %-&#125;]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>templates</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发之基本设置]]></title>
    <url>%2F2018%2F06%2F12%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fdjango%E5%BC%80%E5%8F%91%2Fdjango%E5%BC%80%E5%8F%91%E4%B9%8B%E5%9F%BA%E6%9C%AC%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[MTV模型MTV即是通用的web开发模型MVC在django中的实现， 此外django中还有一个URLconf。 M【models】：建立和操作数据库 T【templates】：建立和渲染html V【views】：连接models和templates，进行逻辑操作 URLconf：匹配相关的url请求，交于后端的views处理 项目创建 创建project：django-admin startproject webapp 创建app：python manage.py startapp books 项目目录简介： webapp：项目的根目录 webapp：项目的默认app【主要用于项目各种配置】 settings.py：项目的主配置文件 urls.py：项目的主url配置入口 manage.py：项目的命令行工具入口 books：项目下books app目录 models.py：books app的模型文件 views.py：books app的视图文件 命令行 语法：python manage.py [CMD] 可选子命令 命令[CMD] 含义 runserver 0.0.0.0:80 运行django内建的web服务器[默认8000端口] makemigrations 根据models生成表结构 sqlmigrate 查看用于建表的语句 migrate 将表结构写入数据库 dumpdata books &gt; books.json 导出books的数据【不加app默认导出所有app数据】 flush 清空数据库 loaddata books.json 导入books数据【不需要设置app】 shell 进入django项目终端环境 dbshell 根据settings设置进入相应数据库 collectstatic 把静态文件收集到 STATIC_ROOT 目录 check 检验数据模型（models）有效性 settings设置 DEBUG = True：开启调试模式 ALLOWED_HOSTS = [‘*’]：当DEBUG=False时，此值必须设置 INSTALLED_APPS：此处可以让django自动在app下的templates子目录中查找模板文件，在static子目录中查找静态文件 BASE_DIR：项目根目录 模板目录设置 TEMPLATES：设置模板目录 &#39;DIRS&#39;: [os.path.join(BASE_DIR, &#39;templates&#39;).replace(&#39;\\&#39;, &#39;/&#39;),],：设置公有模板目录 &#39;APP_DIRS&#39;: True,：开启app私有的模板目录 静态目录设置 STATIC_URL = ‘/static/‘：使用STATIC_ROOT中的静态文件时使用的url前缀 STATICFILES_DIRS = (os.path.join(BASE_DIR, “statics”),)：设置app公有的静态目录 STATIC_ROOT = os.path.join(BASE_DIR,’static_root’) ：这个目录配置只在运行collectstaitc时才会用到 数据库设置1234567891011121314151617# 安装数据库引擎pip install pymysql# pip install psycopg2# 使用pymysql作为mysql数据库引擎import pymysqlpymysql.install_as_MySQLdb()DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, # &apos;ENGINE&apos;: &apos;django.db.backends.postgresql_psycopg2&apos;, &apos;NAME&apos;: &apos;mysite&apos;, &apos;HOST&apos;: &apos;127.0.0.1&apos;, &apos;PORT&apos;: &apos;3306&apos;, &apos;USER&apos;: &apos;root&apos;, &apos;PASSWORD&apos;: &apos;123456&apos;, &#125;&#125; 邮件设置12345678910DEFAULT_FROM_EMAIL = &apos;zabbix@abc.com&apos;EMAIL_BACKEND = &apos;django.core.mail.backends.smtp.EmailBackend&apos;EMAIL_HOST = &apos;smtp.exmail.qq.com&apos;EMAIL_HOST_USER = &apos;zabbix@abc.com&apos;EMAIL_HOST_PASSWORD = &apos;******&apos;EMAIL_PORT = 587EMAIL_USE_TLS = True#django邮件发送from django.core.mail import send_mailsend_mail(subject, body, from_address, list_to_address) 日志设置 在进行ORM操作时，在日志中还原为原始SQL 1234567891011121314151617LOGGING = &#123; &apos;version&apos;: 1, &apos;disable_existing_loggers&apos;: False, &apos;handlers&apos;: &#123; &apos;console&apos;:&#123; &apos;level&apos;:&apos;DEBUG&apos;, &apos;class&apos;:&apos;logging.StreamHandler&apos;, &#125;, &#125;, &apos;loggers&apos;: &#123; &apos;django.db.backends&apos;: &#123; &apos;handlers&apos;: [&apos;console&apos;], &apos;propagate&apos;: True, &apos;level&apos;:&apos;DEBUG&apos;, &#125;, &#125;&#125; URLconf语法url(url正则匹配，views视图函数，参数，别名) url正则匹配不分组url 此时按位置将参数传递给视图函数 12345678# urls.pyurls.py： url(r&apos;^time/plus/(\d)/$&apos;, hours_ahead),views.py def hours_ahead(request, offset): now = datetime.now() new_date = now + timedelta(hours=int(offset)) return HttpResponse(str(new_date)) 分组url 此时按关键词方式将参数传递给视图函数 12345urls.py： url(r&apos;^image/getimage/(?P&lt;file_id&gt;\w+)_(?P&lt;image_width&gt;\d+)_(?P&lt;image_height&gt;\d+)&apos;, imgview.get_image, name=&apos;get_image&apos;)views.py： def get_image(request, file_id, image_width, image_height): pass 参数设置123456urls.py： url(r&apos;^foo/$&apos;, views.foobar_view, &#123;&apos;template_name&apos;: &apos;template1.html&apos;&#125;),views.py： def foobar_view(request, template_name): m_list = MyModel.objects.filter(is_new=True) return render_to_response(template_name, &#123;&apos;m_list&apos;: m_list&#125;) views参数优先级 URLconf设置的参数 正则匹配捕获的参数【命名分组》无名分组】 参数默认值 别名设置views中使用123456789101112urls.py url(r&apos;^calc/(\d+)/(\d+)/$&apos;, calc, name=&apos;calc&apos;), url(r&apos;^add/(?P&lt;v1&gt;\d+)/(?P&lt;v2&gt;\d+)/$&apos;, calc2, name=&apos;add&apos;),views.py def calc(request, v1, v2): return HttpResponseRedirect(reverse(&apos;add&apos;, args=(v1, v2))) def calc2(request, v1, v2): result = int(v1) + int(v2) return HttpResponse(str(result))解释：1）访问calc时重定向url2）reverse组合要跳转的url，第一个参数为视图名称【非视图函数名称】，args、kwargs为捕获或设置的参数 template中使用1234urls.py： url(r&apos;^register&apos;, views.index, name=&apos;reg&apos;)html： &lt;form action=&quot;&#123;% url &quot;reg&quot; %&#125;&quot;&gt; 路由分发123456urls.py： url(r&apos;^time/&apos;, include(&apos;contact.urls&apos;)),contact.urls.py： url(r&apos;^(?P&lt;year&gt;\d&#123;4&#125;)/(?P&lt;month&gt;\d&#123;1,2&#125;)/(?P&lt;day&gt;\d&#123;1,2&#125;)/&apos;, views.current_datetime),eg： http://127.0.0.1:8000/time/2014/12/1/ 主URLconf使用include关键词包含子URLconf 主URLconf捕获url的第一部分time，子URLconf对time之后的部分进行匹配 当使用include时，主URLconf捕获的命名参数和手动设置的参数将传递给子URLconf的每一行 Pycharm中运行django 创建django项目 设置django项目使用的语言解释器【使用virtualenv】 设置位置：file -》settings -》project simplesite-》project Interpreter 设置django项目的框架配置 设置位置：file -》settings -》languages &amp; frameworks -》django 开启django支持：enable django support 设置django项目根目录：django project root 设置django项目配置：settings 设置server运行配置 设置位置：run -》Edit Configuration 添加一个django server 设置django server名称 设置django server使用的端口]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>URLconf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web开发之jquery学习]]></title>
    <url>%2F2018%2F06%2F08%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fweb%E5%BC%80%E5%8F%91%2Fweb%E5%BC%80%E5%8F%91%E4%B9%8Bjquery%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[介绍 jquery是一个快速、简洁的JavaScript框架， 它封装了JavaScript是常用的功能模块，提供了一种简便的JavaScript设计模式，优化HTML文档操作、事件处理、动画设计和Ajax交互 下载地址 语法 语法：$(selector).action() 导入方式：&lt;script type=&quot;text/javascript&quot; src=&quot;jquery-3.1.1.js&quot;&gt;&lt;/script&gt; echo循环无标签对象的循环1234var lis = [11, 22, 33];$.each(lis, function (index, val) &#123; console.log(index, val);&#125;) 有标签对象的循环12345$(&quot;li&quot;).each(function(index, el) &#123; if ($(this).text() == &apos;22&apos;) &#123; $(this).css(&apos;color&apos;, &apos;red&apos;); &#125; &#125;); 节点查找 jquery支持链式操作 1234$(&apos;.title&apos;).click(function(event) &#123; //jquery支持链式操作 $(this).next().removeClass(&apos;hide&apos;).parent().siblings().children(&apos;.con&apos;).addClass(&apos;hide&apos;);&#125;); 基本查找 标签选择器：$(&quot;tag&quot;) ID选择器：$(&quot;#id&quot;) 类选择器：$(&quot;.class&quot;) 自定义属性选择器：$(&#39;[egon=&quot;ceshi1&quot;]&#39;) $(&#39;[egon]&#39;) 导航查找 需先通过基本选择器确定一个基点 $(&quot;.box2&quot;).sibling()：所有兄弟标签 $(&quot;.box2&quot;).next()：下一个兄弟 $(&quot;.box2&quot;).nextAll()：下面所有兄弟 $(&quot;.box2&quot;).nextUntil(&#39;.p3&#39;)：下面直到.p3标签的所有兄弟 $(&quot;.box2&quot;).prev()：前面兄弟 $(&quot;.box2&quot;).prevAll()：前面所有兄弟 $(&quot;.box2&quot;).prevUntil(&quot;.p3&quot;)：前面直到.p3标签的所有兄弟 $(&quot;.box2&quot;).children(&#39;p&#39;)：寻找子标签 $(&quot;.box2&quot;).find(&#39;p&#39;)：寻找后代标签 $(&quot;.box2&quot;).parent()：查找父标签 混合查找 逻辑“或”连接：$(&quot;.class,#id,div&quot;) 子代选择：$(&quot;.outer&gt;p&quot;) 后代选择：$(&quot;.outer p&quot;) 向下的兄弟选择：$(&quot;.box1~p&quot;) 向下的毗邻选择（紧挨）：$(&quot;.box1+p&quot;) 筛选器 $(&quot;ul li&quot;).eq(2)：索引为2的li $(&quot;ul li:lt(2)&quot;)：索引小于2的li $(&quot;ul li:odd&quot;)：索引为奇数的li $(&quot;ul li:even&quot;)：索引为偶数的li 节点事件页面载入 等同于window.load 123$(function (argument) &#123; alert(&apos;123&apos;)&#125;) 事件绑定 给已存在的标签绑定事件 与js区别：事件没有on关键词 js：js标签对象.on事件=函数 jquery：js标签对象.事件(函数) 1234567891011//js方式var ele = document.getElementsByClassName(&quot;box2&quot;)[0]ele.onclick = function () &#123; alert(&apos;123&apos;)&#125;//jquery方式$(&quot;.box2&quot;).click( function () &#123; alert(&quot;123&quot;) &#125;) 事件委派 无论子标签是否存在 父标签委派事件给子标签 语法：父标签.on(事件，子标签，函数) 123$(&quot;.box1&quot;).on(&quot;click&quot;, &apos;p&apos;, function () &#123; alert(345);&#125;) 节点修改属性与值 添加类属性：$(“.box1”).addClass(“aa”) 移除类属性：$(“.box1”).removeClass(“aa”) 设置或获取自有属性：$(“.box1”).prop(“id”) 移除自有属性：$(“.box1”).removeProp(“id”) 设置或获取自定义属性：$(“.box1”).attr(“age”, 18) 移除自定义属性：$(“.box1”).removeAttr(“sex”) 设置或获取标签html：$(&quot;.box2&quot;).html(&#39;&lt;label&gt;yes&lt;/label&gt;&#39;) 设置或获取标签文本：$(&quot;.box2&quot;).text(&#39;ceshi&#39;) 清空标签内容：$(“.aaa”).empty() 获取input标签的value值：$(“input”).val() css操作 设置标签的css：$(“.box1”).css({“color”:”gold”, “background-color”:”green”}) 显示效果 隐藏标签：$(“.box2”).hide() 显示标签：$(“.box2”).show() 标签显示隐藏切换：$(“.box”).toggle() 滑入：$(“”).slideUp() 滑出：$(“”).slideDown() 滑入滑出切换：$(“”).slideToggle() 淡入：$(“”).fadeIn() 淡出：$(“”).fadeOut() 淡入淡出切换：$(“”).fadeToggle() 123456789101112//显隐切换$(&quot;button&quot;).click( function () &#123; if($(this).text() == &apos;hide&apos;)&#123; $(&quot;p&quot;).hide(); &#125;else if($(this).text() == &apos;show&apos;)&#123; $(&quot;p&quot;).show(); &#125;else &#123; $(&quot;p&quot;).toggle(); &#125; &#125;) 节点增删创建节点 创建：var $ele1 = $(&quot;&lt;p&gt;&quot;) 克隆：var $ele1 = $(“.aaa”).clone() 添加节点 父节点末尾添加：$(“div”).append($ele1) 父节点开始添加：$(“div”).prepend($ele1) 指定节点之后添加：$(“.aaa”).after($ele1) 指定节点之前添加：$(“.aaa”).before($ele1) 删除节点 操作自身 $(“.aaa”).remove() 替换节点 操作自身 $(“.aaa”).replaceWith($ele1) 12345678910//添加标签【克隆】$(&quot;.add&quot;).click(function (event) &#123; var $outer=$(this).parent().clone(); $outer.children(&apos;button&apos;).text(&apos;删除&apos;).attr(&apos;class&apos;, &apos;remove&apos;); $(&quot;body&quot;).append($outer);&#125;);//删除标签【事件委派】$(&quot;body&quot;).on(&quot;click&quot;, &quot;.remove&quot;, function (event) &#123; $(this).parent().remove();&#125;); json介绍 JSON（JavaScript Object Notation）：js对象标记；它使用JavaScript语法来描述数据对象，但是它仍独立于语言和平台。 json是存储和交换文本的语法。类似XML，但是比XML更小、更快，更易解析。 json文本的MIME类型是”application/json” 语法 数据在名称/值对中，值可以是 字符串【在双引号中】 数值【整数和浮点数】 布尔值【true和false】 对象 数组 null 数据由逗号分隔 花括号保存对象 方括号保存数据 使用 json对象转换为json字符串（stringify）：console.log(JSON.stringify({“name”: “xiaofang”})) json字符串转换为json对象（parse）：console.log(JSON.parse(‘{“name”: “hejingqi”}’)) ajax简介 AJAX（Asynchronous JavaScript And XML）：异步JavaScript和XML 异步向服务端发送数据 浏览器局部刷新 语法：$.ajax({key1: value1}) 参数 url：ajax向后端提交数据的url type：提交数据的方式（默认get） data：向服务端传送的数据 contentType：发送给服务端时的内容编码MIME类型(默认application/x-www-form-urlencoded) dataType：客户端希望从服务端接受的数据类型【xml、html、json、text等】 success：当后端处理成功时，前端的处理方式 traditional：（true/false） 当要传输的数据为多维数组时使用 error：后端错误时的处理方式 complete：后端处理完成时的处理方式 statusCode：根据后端处理结果的返回码进行处理 范例 js实现 123456789101112131415161718192021&lt;script&gt; $(&quot;#username&quot;).blur(function () &#123; var $user = $(this).val(); //csrf设置 $.ajaxSetup(&#123; data: &#123;csrfmiddlewaretoken: &apos;&#123;&#123; csrf_token &#125;&#125;&apos;&#125; &#125;); if($user.trim().length != 0) &#123; $.ajax(&#123; url: &quot;checkuser&quot;, type: &quot;POST&quot;, //data: &#123;username: $user&#125;, //ajax的serialize方法序列化表单数据 data: $(&quot;form&quot;).serialize(), success: function (data) &#123; console.log(data) &#125; &#125;) &#125; else &#123;console.log(&apos;user is empty&apos;)&#125;; &#125;)&lt;/script&gt; python实现 123456def checkuser(request): username = request.POST.get(&apos;username&apos;) if username == &apos;he&apos;: return HttpResponse(&quot;user is exist&quot;) else: return HttpResponse(&apos;user not exists&apos;) 注意当数据传输使用json格式时，由于django的csrf中间件默认使用“application/x-www-form-urlencoded”格式获取csrftoken值，此时由于格式不匹配，造成后端无法正确获取csrftoken值从而造成csrf Forbidden错误，目前暂未解决，建议使用默认数据格式传输。]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>json</tag>
        <tag>jquery</tag>
        <tag>ajax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web开发之js学习]]></title>
    <url>%2F2018%2F06%2F06%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fweb%E5%BC%80%E5%8F%91%2Fweb%E5%BC%80%E5%8F%91%E4%B9%8Bjs%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[引入方式head标签下导入js文件 1&lt;script type=&quot;text/javascript&quot; src=&quot;test.js&quot;&gt;&lt;/script&gt; 组成部分 ECMAScript：js语法规范 变量定义 基本数据类型 数据对象（引用数据类型） 运算符 流程控制 BOM对象（浏览器对象模型）：整合js和浏览器 DOM对象（文档对象模型）：整合js、css、html ECMAScript变量定义 变量声明使用关键词var，如果不用var，则声明的是全局变量 变量名区分大小写，首字符可以是：美元$、下划线、字符，余下的字符可以是：字符、数字、下划线、美元$ 基本数据类型类型 字符串 数值 布尔值：true或false null：空值 undefined：只声明，未赋值 特例NaN属于数字类型，是在字符串转换为数字失败时返回的 123var a = &apos;test&apos;b = +aconsole.log(b) 运算符 算术运算符：+ - * / % ++ – 比较运算符：&gt; &gt;= &lt; &lt;= != == === !== 由于js是弱类型语言，在进行数据比较前默认会进行类型转换 当比较对象中存在数字类型时，会把其他数据转换为数字后进行比较 ==在代码内部可以先进行数据类型转换再进行比较，如console.log(2==”2”) ===在代码内部不能进行数据类型转换后进行比较，如console.log(2===”2”) 当比较对象中存在字符串时，会把其他数据转换为字符串进行比较 逻辑运算符：&amp;&amp; || ！ 赋值运算符：= += -= *= /= ++i 先加1再赋值 i++ 先赋值再加1 字符串运算符：+ 连接，两边操作数有一个或两个是字符串就做连接运算 流程控制if-else 没有elif 12345if( 5 &gt; 4)&#123; console.log(&apos;ok&apos;)&#125;else &#123; console.log(&apos;not&apos;)&#125; switch-case123456var y = 5switch (y) &#123; case 5:console.log(&apos;5&apos;);break; case 2:console.log(&apos;2&apos;);break; default:console.log(&apos;未知数&apos;);break;&#125; for条件循环12345Things = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;]// 初始表达式；条件表达式；自增或自减for (var i = Things.length - 1;i &gt;= 0;i--)&#123; console.log(Things[i])&#125; for遍历循环1234Things = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;]for(item in Things)&#123; console.log(Things[item])&#125; while循环12345var i = 0while (i &lt; 10)&#123; console.log(i) i++&#125; 异常处理try-catch12345678910try&#123; //可能出现异常的代码 y=+x&#125;catch (e)&#123; // 对异常的处理 console.log(e)&#125;finally &#123; // 无论是否异常都执行的代码 alert(&apos;nothing&apos;)&#125; 异常处理throw直接抛出异常：throw Error(‘ceshi’) 数据对象 对象 说明 Number 数字对象 String 字符串对象 Boolean 布尔对象 Array 数组对象 Match 数学对象 Date 日期对象 Object 自定义对象 Error 错误对象 Function 函数对象 RegExp 正则表达式对象 Global 全局对象 字符串对象 toUpperCase() 转换为大小 length 长度 toLowerCase() 转换为小写 trim() 去除两侧空白 charAt(2) 指定索引位置字符 indexOf(‘bc’) 指定字符串出现时首字符索引位置 lastIndexOf(‘bc’) 指定字符串最后一次出现的首字符索引位置 match(regexp) 返回匹配字符串组成的数组 search(regexp) 返回匹配字符串首字符索引位置 substring(n, m) 取索引n到m之间的字符串 substr(n, m)从索引n开始取m个字符 slice(n, m) 取索引n到m之间的字符串 replace(‘bc’, ‘12’)将字符串内的第一次出现’bc’替换成’12’ split(‘ ‘, 3) 使用空格切割字符串,最多返回3个分割后的元素 concat(‘12’) 字符串末尾追加字符串’12’ 数组对象 join(‘#’) 使用’#’链接数组元素拼接成字符串 concat(4, 5) 在数组内追加元素 sort() 排序【默认以字符的ASCII码排序】 reverse() 倒序输出 slice(2, 4) 切片操作（包含开始不包含结束，索引可以为负数） splice(1, 2, ‘c’) 参数1为开始操作的索引，参数2为删除的元素个数，参数3为为替换或插入的元素 push() 在末尾追加元素 pop() 弹出末尾元素 unshift() 在开头添加元素 shift() 弹出开头元素 toString() 转换为字符串输出 数字的排序12345function Insort (a, b) &#123; return a - b;&#125;var arry = [11, 2, 13]console.log(arry.sort(Insort)) 日期对象 Date()有参数时为创建时间对象，无参数时为获取当前时间 getFullYear() 获取指定的时间属性(此处为年) toLocaleString() 将时间对象转换为本地格式的字符串 数学对象 Math.random() 获取0~1之间的随机数 Math.round(n) 通过四舍五入将n转换为整数 函数对象 定义和调用：由于js是整体加载完才会执行，所以函数定义和调用的前后顺序无关 参数个数：func_name.length arguments对象：可以接受任意个参数并组成数组 12345678function addnum () &#123; var sum = 0; for (var i = 0; i &lt; arguments.length; i++) &#123; sum+=arguments[i] &#125; return sum&#125;alert(addnum(1, 2, 3, 6)) 匿名函数 12345alert( function (x, y) &#123; return x + y &#125;(4, 5)) BOM对象介绍windows对象：一个html文档对应一个windows对象 方法 alert(‘123’) 弹出含有确认按钮的提示框 confirm(‘确认’) 弹出含有确认和取消按钮的提示框，可以接收用户的点击信息（true或false） prompt(‘请输入数字：’) 弹出可以输入的提示框，可以接收用户的输入信息 open(url,,’浏览器设置’) 打开一个新的浏览器窗口 close() 关闭浏览器窗口 setTimeout(close_win, 5000) 在指定的毫秒数之后执行函数或表达式 clearTimeout(ID) 清除设置的一次性任务 setInterval(getinfo, 1000) 设置每隔多少毫秒执行函数或表达式 clearInterval(ID) 清除设置的周期性任务 范例一次性任务123456new_window = open(&apos;http://www.baidu.com&apos;, &apos;&apos;, &apos;width=1000,height=500&apos;)function close_win () &#123; new_window.close();&#125;id = setTimeout(close_win, 5000)clearTimeout(id) 周期性任务 html 1234&lt;form action=&quot;&quot;&gt; &lt;input type=&quot;text&quot; onclick=&quot;start()&quot; id=&quot;time&quot;&gt; &lt;input type=&quot;button&quot; onclick=&quot;stop()&quot; value=&quot;停止&quot;&gt;&lt;/form&gt; javascript 123456789101112131415161718function getinfo() &#123; var text = document.getElementById(&apos;time&apos;) var date = new Date().toLocaleString(); text.value = date&#125;var ID = undefinedfunction start() &#123; if (ID == undefined)&#123; getinfo(); ID = setInterval(getinfo, 1000); &#125;&#125;function stop() &#123; if (ID != undefined)&#123; clearInterval(ID); ID = undefined; &#125;&#125; DOM对象介绍 一个html就是一个DOM对象 document对象（整个html） element对象（标签元素） text对象（文本内容） attribute对象（标签属性） 注释对象（标签注释） 节点查找由于正文标签只有在全部加载后才能进行查找，所以所有涉及到标签查找的js必须位于body标签的末尾 直接查找 document.getElementById()：通过ID属性查找 document.getElementsByTagName()：通过标签名查找 document.getElementsByName()：通过name属性查找 document.getElementsByClassName()：通过class属性查找 导航查找 需要先通过直接查找确定一个基点如：var ele = document.getElementsByClassName(“box2_div”)[0]; ele.parentElement 父节点标签 ele.children 所有子节点标签 ele.firstElementChild 第一个子节点标签 ele.lastElementChild 最后一个子节点标签 ele.nextElementSibling 下一个兄弟节点标签 ele.previousElementSibling 上一个兄弟节点标签 节点增删创建节点123var tag = document.createElement(&apos;input&apos;)tag.type = &apos;text&apos;tag.innerText = &apos;aa&apos; 添加子节点 在标签内末尾添加子节点：ele.append(tag) 在标签内指定子标签前添加子节点：ele.insertBefore(tag, ele1) 删除子节点ele.removeChild(ele1) 替换子节点ele.replaceChild(new_node, old_node) 节点修改节点文本操作 设置文本：tag.innerText 设置为html：tag.innerHTML 节点类操作 类名：ele.className、ele.classList 添加类：ele.classList.add(‘he’) 删除类：ele.classList.remove(‘yuan’) 节点属性操作 获取属性值：ele.getAttribute(‘age’) 设置属性值：ele.setAttribute(‘sex’, ‘nv’) 删除属性值：ele.removeAttribute(‘age’) 节点事件使用方法 在标签中设置相应事件，并调用相关函数 1&lt;input type=&quot;button&quot; onclick=&quot;stop()&quot; value=&quot;停止&quot;&gt; 在js文件中查找相关标签并触发相关事件 123456var ele = document.getElementById(&apos;bb&apos;)ele.onclick = function () &#123; alert(&apos;ok&apos;); //this指代当前标签 console.log(this);&#125; 事件方法 onlick：鼠标单击 ondbclick：鼠标双击 onfocus：元素获取焦点【input标签】 onblur：元素失去焦点【input标签】 123456789var ele = document.getElementById(&apos;aa&apos;)ele.onfocus = function (argument) &#123; this.value = &apos;&apos;&#125;ele.onblur = function (argument) &#123; if(!this.value.trim())&#123; this.value = &apos;ceshi&apos; &#125;&#125; onchange：当域的内容被改变（如下拉框） 1234var ele = document.getElementById(&apos;age&apos;);ele.onchange = function () &#123; confirm(&apos;确定？&apos;)&#125; onkeydown 当某个键被按下 123456789ele.onkeydown=function (event) &#123; // 兼容设置 event=event||window.event; // asicc码 var keynum=event.keyCode; // asicc转字符 var keychar=String.fromCharCode(keynum); console.log(keychar);&#125; onkeypress：当某个键被按下并松开 onkeyup：当某个键被松开 onload：一个页面或一张图像完成加载 123456789var ele= document.getElementsByTagName(&apos;body&apos;)[0]ele.onload=function () &#123; alert(&apos;ok&apos;)&#125;//window.onload事件中可以定义整个窗口加载完执行的动作，//从而可以在head标签下的script中定义html中的标签事件window.onload=function (argument) &#123; /* body... */&#125; onmousedown：鼠标按钮被按下 onmousemove：鼠标移动 onmouseover：鼠标移动到某个元素上 onmouseout：鼠标从某个元素离开 onmouseleave：鼠标从元素离开 onselect：文本被选中 onsubmit：确认按钮被点击（只能用于form元素） 123456789101112131415var ele = document.getElementsByTagName(&apos;form&apos;)[0]ele.onsubmit=function (event) &#123; if(this.firstElementChild.value == &apos;test&apos;)&#123; console.log(&apos;请不要测试！&apos;); event.preventDefault(); &#125;&#125;//阻止默认事件方式1ele.onsubmit=function (argument) &#123; return false;&#125;//阻止默认事件方式2ele.onsubmit=function (event) &#123; event.preventDefault(); &#125; event.stopPropagation 阻止事件扩散 12345ele2.onclick=function (event) &#123; alert(456); //阻止事件从子元素扩展到父元素 event.stopPropagation();&#125;]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>javascrip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web开发之css学习]]></title>
    <url>%2F2018%2F06%2F04%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fweb%E5%BC%80%E5%8F%91%2Fweb%E5%BC%80%E5%8F%91%E4%B9%8Bcss%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[语法1234567选择器selector &#123; 属性：值； property: value; property1: value1; property2: value2&#125; 引入方式行内式 定义：在标签的style属性中设置 范例：&lt;p style=&quot;color: chartreuse;font-size: 12px&quot;&gt;hello world&lt;/p&gt; 嵌入式 定义：在head标签下的style标签内引入 范例： 123456&lt;style&gt; p&#123; color: chartreuse; font-size: 14px; &#125;&lt;/style&gt; 链接式 定义：在head标签下使用link引入css文件 范例：&lt;link rel=&quot;stylesheet&quot; href=&quot;test.css&quot;&gt; 选择器分类标签选择器12345p&#123; font-size: 14px; color: #cf9aff; background-color: #8dff84;&#125; ID选择器 每个标签有唯一的id属性 1234#aa&#123; color: aqua; font-size: 29px;&#125; 类选择器 多个标签可以有相同的class属性，一个标签也可以有多个class属性 123.ceshi&#123; background-color: wheat;&#125; 自定义属性选择器123456[item]&#123; background-color: wheat&#125;[item=&quot;2&quot;]&#123; background-color: red&#125; 混合选择器逻辑“或” 逗号分隔 123h4,.xxx,#p2&#123; background-color: wheat;&#125; 逻辑“与” 标签名在前 123456div.xxx&#123; background-color: green&#125;p#p2&#123; background-color: green&#125; 后代选择 使用空格分隔基础选择器，示例：为.outer的所有后代p选择器 123.outer p&#123; background-color: wheat&#125; 子选择 使用大于号分隔基础选择器，示例：为.outer的所有子p选择器 123.outer &gt;p&#123; background-color: wheat&#125; 优先级默认权重 标签选择器：1 class选择器：10 id选择器：100 内嵌在属性中的选择器：1000 特权【!import】:高于一切 范例：div{background-color: blue!important;} 同权覆盖优先级相同时，排在后边的属性覆盖前面的。 属性设置文本属性在未定义时，子类标签的文本类型的属性可以继承父类标签 12345678910div&#123; /*字体大小*/ font-size: 30px; /*字体颜色*/ color: red; /*使标签内的文本或图像左右居中*/ text-align: center; /*设置行高的同时即设置了文本上下居中*/ line-height: 500px;&#125; 背景和边框属性123456789101112131415161718.ceshi1&#123; height: 400px; /*块标签的宽占浏览器宽度的百分比*/ width: 100%; /*padding 填充 此区块的内容区块外扩（四周）大小*/ padding: 50px; /*margin 页边距； 此区块与其他区块的间距， 第一个为上下间距，第二个为左右间距（auto自动居中【需要搭配width实现居中】）*/ margin: 20px auto; /*边框：厚度 实线 红色*/ border: 2px solid red; /*背景色*/ background-color: wheat; /*背景图片：填充方式 上下左右居中*/ background: url(&quot;http://724.169pp.net/bizhi/2017/025/1.jpg&quot;) no-repeat center;&#125; display属性 不显示：display：none 块级别标签转内联标签：display：inline 内联标签转块级别标签：display：block 既有内联标签又有块级别标签功能：display：inline-block 1234label&#123; background-color: wheat; display: inline-block;&#125; float和clear 正常文档流的区块占用一行的位置，相互之间上下排版 float文档流的多个float区块在一行排版，但不占用一行位置 当float区块有内容时，它会占用相邻正常文档流的内容空间，从而让正常文档流内容可以“环绕”漂浮文档流内容排版 clear清除浮动，假设上一个或左或右浮动的标签为正常文档流，占用一行位置，从而使自己另起新行排版 float可以对block和line进行操作，对line进行操作类似转为block，可以设置宽和高 1234567891011121314span&#123; background-color: green; font-size: 20px; height: 50px; width: 50px; float: left;&#125;.div2&#123; clear: left; float: right; width: 130px; height: 140px; background-color: blue;&#125; 定位positionfixed 绝对定位 123456789101112.guding&#123; width: 80px; height: 40px; background-color: gray; font-size: 15px; color: blue; text-align: center; line-height: 40px; position: fixed; bottom: 20px; right: 10px;&#125; relative 相对定位，直接写则为相对自身原位置的定位 123456789.zhuti&#123; width: 100%; line-height: 500px; background-color: wheat; text-align: center; position: relative; top: 200px; left: 200px;&#125; absolute 绝对定位，absolute根据前代的一个准确定位取得当前定位；一般用法：在父代标签中设置相对定位relative，在子代中设置绝对定位absolute，则此时的定位为相对父代的定位 123456789101112131415161718* &#123; margin: 0;&#125;.box&#123; height: 200px; width: 80%; border: 2px solid red; position: relative;&#125;.zhuti&#123; text-align: center; line-height: 100px; width: 50%; border: 1px solid gold; position: absolute; right: 50px; bottom: 50px;&#125; 链接属性 又称anchor伪类 12345678910111213141516171819202122hover 徘徊，萦绕/*链接默认颜色*/a:link&#123; color: green;&#125;/*链接被激活时的颜色*/a:active&#123; color: red;&#125;/*链接被访问过时的颜色*/a:visited&#123; color: blue;&#125;/*链接样式：去除a标签下划线*/a&#123; text-decoration: none;&#125;/*鼠标悬浮在链接上时的颜色*//*在 CSS 定义中，:hover 必须位于 :link 和 :visited 之后（如果存在的话），这样样式才能生效。*/a:hover&#123; color: white;&#125; before与after12345678/*在标签的开始（before）或结束（after）位置添加子标签*/p:after&#123; /*标签内容*/ content: &quot;aa&quot;; color: red; /*标签设置为块标签*/ display: block;&#125; 其他属性 列表属性：ul{list-style: none;} 图片属性 123456/*对齐的四线：底线、基线、中线、顶线*/img&#123; /*图片与文本的中线对齐*/ /*vertical-align: middle;*/ vertical-align: -100px;&#125; 范例 正常文档流中，子元素可以填充父元素的宽高 漂浮文档流中，子元素不会填充父元素的宽高 范例：此标签【类clear】添加一个块级子标签，并且块标签前后清除浮动，使此标签变成标准文档流，占用一行 12345&lt;div class=&quot;box clear&quot;&gt; &lt;div class=&quot;div1&quot;&gt;&lt;/div&gt; &lt;div class=&quot;div2&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;footer&quot;&gt;test&lt;/div&gt; 123456789101112131415161718192021222324.box&#123; border: 1px solid red;&#125;.clear:after&#123; clear: both; content: &quot;&quot;; display: block;&#125;.div1&#123; width: 150px; height: 150px; float: left; background-color: gold;&#125;.div2&#123; width: 150px; height: 150px; float: left; background-color: green;&#125;.footer&#123; height: 200px; border: 3px solid yellow;&#125;]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web开发之html学习]]></title>
    <url>%2F2018%2F06%2F03%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fweb%E5%BC%80%E5%8F%91%2Fweb%E5%BC%80%E5%8F%91%E4%B9%8Bhtml%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[范例12345678&lt;html&gt; html文档的开始和结束标签&lt;head&gt; 文档头部&lt;title&gt; 网页标题&lt;/title&gt; &lt;/head&gt;&lt;body&gt; 网页内容&lt;/body&gt;&lt;/html&gt; 标签格式标签语法 语法：&lt;标签名 属性名=”属性值” 属性名=”属性值”&gt;&lt;/标签名&gt; 范例：&lt;a href=&quot;&quot;&gt;&lt;/a&gt; 标签分类 闭合标签：有开始和结束的标志，如：&lt;title&gt;test&lt;/title&gt; 自闭和标签：只有开始的标志，如：&lt;meta charset=&quot;utf-8&quot;&gt;|&lt;img src=&quot;&quot;&gt; 块级别标签：显示效果为独占一行，如&lt;h1&gt;&lt;/h1&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt; 内联标签：显示效果取决于内容长度，如&lt;label&gt;&lt;/label&gt;&lt;span&gt;&lt;/span&gt;&lt;img src=&quot;&quot;&gt; 助记：span = 跨度 嵌套原则 块级别标签可以嵌套快级别标签和内联标签 内联标签只能嵌套内联标签 head标签123456789101112131415161718&lt;head&gt; &lt;!--搜索引擎搜索网页使用的关键词--&gt; &lt;meta name=&quot;keywords&quot; content=&quot;it测试&quot;&gt; &lt;!--搜索引擎对网页内容的简单介绍--&gt; &lt;meta name=&quot;description&quot; content=&quot;it测试&quot;&gt; &lt;!--网页解码方式--&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;!--网页标题前的图标--&gt; &lt;link rel=&quot;icon&quot; href=&quot;heart.png&quot;&gt; &lt;!--网页使用的css文件--&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;&quot;&gt; &lt;!--网页使用的js文件--&gt; &lt;script type=&quot;text/javascript&quot;&gt;&lt;/script&gt; &lt;!--网页标题--&gt; &lt;title&gt;我的未来&lt;/title&gt; &lt;!--直接在html中定义css样式--&gt; &lt;style&gt;&lt;/style&gt;&lt;/head&gt; body标签一般标签12345678910&lt;h1&gt;一级标题&lt;/h1&gt;&lt;h2&gt;二级标题&lt;/h2&gt;&lt;p&gt;段落1&lt;/p&gt;# p = paragraph 段落&lt;p&gt;段落2&lt;/p&gt;&lt;br&gt;换行&lt;hr&gt;分割线&lt;b&gt;加粗&lt;/b&gt;&lt;strong&gt;加粗&lt;/strong&gt;&lt;i&gt;斜体&lt;/i&gt; CSS类标签123&lt;div style=&quot;&quot;&gt;自定义块级别标签&lt;/div&gt;&lt;span&gt;自定义内联标签&lt;/span&gt;&lt;label&gt;自定义内联标签&lt;/label&gt; 资源标签 图片引用： 123alt = alternate 备用的&lt;img src=&quot;http://blog.unforget.cn/2018/04/18/TCP%E8%BF%9E%E6%8E%A5/tcp%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5.png&quot; height=&quot;200px&quot; width=&quot;110px&quot; alt=&quot;无资源显示&quot; title=&quot;tcp连接&quot;&gt; 超链接：&lt;a href=&quot;http://www.baidu.com&quot; target=&quot;_blank&quot;&gt;点击地址&lt;/a&gt; target=”_blank” 跳转时新打开一个窗口 列表标签无序列表123456# ul = unordered list&lt;ul&gt; &lt;li&gt;111&lt;/li&gt; &lt;li&gt;222&lt;/li&gt; &lt;li&gt;333&lt;/li&gt;&lt;/ul&gt; 有序列表123456# ol = ordered list&lt;ol&gt; &lt;li&gt;aaa&lt;/li&gt; &lt;li&gt;bbb&lt;/li&gt; &lt;li&gt;ccc&lt;/li&gt;&lt;/ol&gt; 自定义列表1234567# dl = define list&lt;dl&gt; &lt;dt&gt;列表名称&lt;/dt&gt; &lt;dd&gt;列表项1&lt;/dd&gt; &lt;dd&gt;列表项2&lt;/dd&gt; &lt;dd&gt;列表项3&lt;/dd&gt;&lt;/dl&gt; 表格标签12345678910111213141516171819202122232425262728# padding 填充&lt;!--cellpading内容到内边框的距离--&gt;&lt;!--cellspacing内边框到外边框的距离--&gt;&lt;!--border有边框--&gt;&lt;table border=&quot;1&quot; cellpadding=&quot;5px&quot; cellspacing=&quot;10px&quot;&gt;&lt;!--tr = table row 表格的行--&gt; &lt;tr&gt; &lt;!--th为头部信息--&gt; &lt;th&gt;id&lt;/th&gt; &lt;th&gt;name&lt;/th&gt; &lt;th&gt;age&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;!--td为数据信息，colspan横跨多少列--&gt; &lt;td colspan=&quot;2&quot;&gt;1&lt;/td&gt; &lt;td&gt;27&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;!--rowspan横跨多少行--&gt; &lt;td rowspan=&quot;2&quot;&gt;2&lt;/td&gt; &lt;td&gt;jing&lt;/td&gt; &lt;td&gt;25&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;qi&lt;/td&gt; &lt;td&gt;23&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; 表单标签 action：处理请求的地址 method：请求使用的方法 范例：&lt;form action=&quot;http://www.baidu.com&quot; method=&quot;get&quot;&gt;&lt;/form&gt; text文本输入框 123456&lt;p&gt; &lt;!--label的for和input的id使用同一值，则鼠标点击提示信息即可直接输入--&gt; &lt;label for=&quot;user&quot;&gt;姓名&lt;/label&gt; &lt;!--name为向后端传递的变量名，id则确定标签的唯一性--&gt; &lt;input type=&quot;text&quot; name=&quot;username&quot; id=&quot;user&quot;&gt;&lt;/p&gt; password密码输入框 1234&lt;p&gt; &lt;label for=&quot;pass&quot;&gt;密码&lt;/label&gt; &lt;input type=&quot;password&quot; name=&quot;pwd&quot; id=&quot;pass&quot;&gt;&lt;/p&gt; checkbox复选框【多选】 12345&lt;p&gt; 爱好： &lt;input type=&quot;checkbox&quot; name=&quot;hobby&quot; value=&quot;football&quot;&gt;足球 &lt;input type=&quot;checkbox&quot; name=&quot;hobby&quot; value=&quot;basketball&quot;&gt;篮球&lt;/p&gt; radio复选框【单选】 12345&lt;p&gt; 性别： &lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;1&quot; checked&gt;男 &lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;2&quot;&gt;女&lt;/p&gt; submit表单提交 1&lt;input type=&quot;submit&quot; value=&quot;表单提交&quot;&gt; button触发动作的按钮 1&lt;input type=&quot;button&quot; value=&quot;按钮&quot;&gt; reset恢复默认值 1&lt;input type=&quot;reset&quot; value=&quot;恢复默认&quot;&gt; file 上传文件：form表单需要加上属性enctype=”multipart/form-data” method=”post” enctype = encode type 编码方式 12345&lt;form action=&quot;http://www.baidu.com&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt;&lt;p&gt; &lt;input type=&quot;file&quot;&gt;&lt;/p&gt;&lt;/form&gt; select下拉选择 size：下拉框一次显示的选项个数 multiple：允许多选 selected：默认选项 123456&lt;select name=&quot;province&quot; size=&quot;2&quot; multiple&gt; &lt;option value=&quot;beijing&quot;&gt;北京&lt;/option&gt; &lt;option value=&quot;henan&quot; selected&gt;河南&lt;/option&gt; &lt;option value=&quot;hubei&quot;&gt;湖北&lt;/option&gt; &lt;option value=&quot;shanxi&quot;&gt;山西&lt;/option&gt;&lt;/select&gt; textarea多行文本框 1234&lt;p&gt; 个人简介 &lt;textarea name=&quot;&quot; id=&quot;&quot; cols=&quot;30&quot; rows=&quot;10&quot;&gt;&lt;/textarea&gt;&lt;/p&gt; 参考 html特殊标签 html学习参考]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[守护进程工具supervisor]]></title>
    <url>%2F2018%2F05%2F30%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2F%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B%E5%B7%A5%E5%85%B7supervisor%2F</url>
    <content type="text"><![CDATA[介绍supervisor用于管理非daemon进程 安装 可使用系统安装apt-get install supervisor 可使用python安装：pip install supervisor 配置文件 更多配置说明请参考 123456789101112131415161718192021[inet_http_server] ;web管理界面设置port=0.0.0.0:9001 username=user password=123456 [program:logstash] ;管理单个进程的配置;设置需要守护的进程，此进程必须是前台执行command=/home/zj-ops/logstash-5.1.1/bin/logstash -f /home/zj-ops/logstash-5.1.1/config/logstash-test.conf;主要用于启动时间过长的进程startsec=10;是否随supervisor一起启动autostart=true;异常退出后是否自动重启autorestart=true;运行进程的用户user=zj-ops;设置环境变量environment=JAVA_HOME=/usr/local/jdk1.8.0_121;日志配置，配合supervisor日志用于调试进程是否运行redirect_stderr=Truestdout_logfile=/tmp/mgt_operation.logstderr_logfile=/tmp/mgt_operation.log 配置范例12345678[program:mgt_user]command=/home/&#123;&#123; ansible_ssh_user &#125;&#125;/tomcat8/bin/catalina.sh runenvironment=JAVA_HOME=&quot;/usr/local/jdk1.8.0_121&quot;startsec=100directory=/home/&#123;&#123; ansible_ssh_user &#125;&#125;autostart=trueautorestart=trueuser=&#123;&#123; ansible_ssh_user &#125;&#125; 命令行管理 start、restart、stop都不会载入最新的配置文件。 start xxx 启动某个进程 stop xxx 停止某个进程 status xxx 查看进程状态 restart xxx 重启某个进程 tail xxx 查看进程的日志 reload 载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程 update 根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启。 web管理123port=0.0.0.0:9001 username=user password=123456]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python环境管理]]></title>
    <url>%2F2018%2F05%2F30%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[virtualenv创建一个隔离的python运行环境 安装pip3 install virtualenv 创建独立环境 –no-site-packages 不复制系统已存在的软件包 -p指定解释器，否则使用默认解释器 virtualenv -p /usr/bin/python3 venv 进入虚拟环境source venv/bin/activate 退出虚拟环境deactive pippython包管理工具 安装 更新系统软件库：apt-get update 安装python-pip：apt-get install python-pip 升级python-pip：pip install pip –upgrade 使用easy_install替换pip为最新版本：easy_install pip 使用 install：安装：pip install xxx [-f requirements.txt] uninstall：卸载 list：安装包显示 freeze：安装包显示与导出：pip freeze &gt;requirements.txt search：软件包在线搜索 软件源设置 文件位置：~/.pip/pip.conf 1234[global]index-url = https://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.com]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>virtualenv</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类unix终端显示控制]]></title>
    <url>%2F2018%2F05%2F28%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2F%E7%B1%BBunix%E7%BB%88%E7%AB%AF%E6%98%BE%E7%A4%BA%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[ANSI转义序列 参考 通常我们可以使用echo命令加-e选项输出各种颜色的文本，例如：echo -e “\033[31mRed Text\033[0m”，可以输出红色的字体“Red Text”。其中：”\033[31m”和”\033[0m”是ANSI转义序列（ANSI escape code/sequence），它控制文本输出的格式、颜色等，大多数的类unix终端仿真器都能够解释ANSI转义序列。 颜色控制格式 CSI n1 [;n2 [;…]] m 其中CSI全称为“控制序列引导器”（Control Sequence Introducer/Initiator），也就是上述示例中的”\033[“（其中\033是你键盘左上角Esc键对应的ascii码（八进制））；n1、n2等表示SGR参数（下面会列出一些常用的SGR参数），用于控制颜色、粗体、斜体、闪烁等文本输出格式；m表示转义序列结束。 常用SRG参数 编码 说明 0 关闭所有格式 1 粗体或高亮 2 模糊 3 斜体 4 下划线 5 闪烁（慢） 6 闪烁（快） 7 交换前景背景色 8 隐藏 30-37 前景色（30+x） 40-47 背景色（40+x） 颜色表 颜色值 颜色 0 黑 1 红 2 绿 3 黄 4 蓝 5 紫 6 青 7 白 光标控制格式 格式 含义 \33[K 清除从光标到行尾的内容 \33[?25l 隐藏光标 \33[?25h 显示光标 范例1234567891011121314import timefor i in range(1, 10): # 隐藏光标 print('\x1b[?25l', end='') # 将光标移到行首位置，并清除光标到行尾的内容 #print('\r\x1b[K', end='') print('\x1b[K', end='') # 打印内容后换行 #print('*'*i, end='\n', flush=True) print('*'*i, end='', flush=True) time.sleep(0.5)# 显示光标print('\x1b[?25h')time.sleep(1)]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>颜色</tag>
        <tag>光标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql表结构与数据操作]]></title>
    <url>%2F2018%2F05%2F14%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmysql%E8%A1%A8%E7%BB%93%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[库操作 查看存在的库：show databases; 建数据库：create database olgboy_utf8 default character set utf8 collate utf8_general_ci; 不存在再建立：create database if not exists oldboy_default; 进入数据库：use db1 删除数据库： drop database db1; 存在才删除：drop database if exists test1; 数据类型数字 tinyint：1字节 无符号：(0，255) 有符号：(-128，127) smallint：2字节 无符号：(0，65 535) 有符号：(-32 768，32 767) int：4字节 无符号：(0，4 294 967 295) 有符号：(-2 147 483 648，2 147 483 647) bigint：8字节 float：4字节 double：8字节 decimal【精确的小数】 字符串 char：定长存储，最长255 varchar：不定长存储，最长65535 text：存储文本，最长(2**16-1)65535 mediumtext：最长（2**24-1） longtext：最长4GB（2**32-1） 时间 date【日期】：1000-01-01/9999-12-31 time【时间】：’-838:59:59’/‘838:59:59’ datetime【日期 时间】：1000-01-01 00:00:00/9999-12-31 23:59:59 year：1901/2155 timestamp【时间戳、4字节存储】：开始时间0表示1970-01-01 00:00:00，结束时间是第 2147483647 秒【北京时间 2038-1-19 11:14:07（格林尼治时间 2038年1月19日 凌晨 03:14:07）】 新建表范例1234567891011121314CREATE TABLE subject_comment_manager ( subject_comment_manager_id bigint(12) NOT NULL auto_increment COMMENT &apos;主键&apos;, subject_type tinyint(2) NOT NULL COMMENT &apos;素材类型&apos;, subject_primary_key varchar(255) NOT NULL COMMENT &apos;素材的主键（词条是名称，文章是iden，组图是id，视频是MD5）&apos;, subject_title varchar(255) NOT NULL COMMENT &apos;素材的名称&apos;, edit_user_nick varchar(64) default NULL COMMENT &apos;修改人&apos;, edit_user_time timestamp NULL default NULL COMMENT &apos;修改时间&apos;, edit_comment varchar(255) default NULL COMMENT &apos;修改的理由&apos;, state tinyint(1) NOT NULL default &apos;1&apos; COMMENT &apos;0代表关闭，1代表正常&apos;, PRIMARY KEY (subject_comment_manager_id), KEY IDX_PRIMARYKEY (subject_primary_key(32)), KEY IDX_SUBJECT_TITLE (subject_title(32)), KEY index_nick_type (edit_user_nick(32),subject_type)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 123456create table tb1( id int not null auto_increment primary key, name char(20), age int default 18, gender char(1) )engine=innodb default charset=&apos;utf8&apos; comment=&apos;跟进表（基于客户、联系人、询盘）&apos;; 字段 字段名 数据类型 是否为空 是否为主键 是否有默认值 是否自增 外键约束 - 数字/字符串/时间 【not】null primary key default 【xxx】 auto_increment constraint 自增 关键字：auto_increment 限制：一个表只能有一个自增列 主键 约束：不能为空，不能重复 索引：对字段建立索引可以加速查找 外键 约束：只能是某个表中已经存在的字段 语法：constraint 约束名称 foreign key(本表字段名) references 外表(外表字段名) 批量建表 使用like语法创建结构一样的表：create table tb_name1 like tb_name2 12345678910import pymysqltb_list = [&apos;c_fu&apos;, &apos;c_fu_file&apos;, &apos;e_email&apos;, &apos;e_email_body&apos;, &apos;e_email_file&apos;, &apos;e_email_to&apos;, &apos;e_email_track&apos;, &apos;f_mem_upload&apos;]conn = pymysql.connect(host=&apos;127.0.0.1&apos;, user=&apos;user&apos;, password=&apos;pass_str&apos;, database=&apos;crm_big3&apos;, charset=&apos;utf8&apos;)for index in range(2001, 2003): for table in tb_list: cursor = conn.cursor(cursor=pymysql.cursors.Cursor) cursor.execute(&apos;create table %s_%s like %s_2000&apos; % (table, index, table)) cursor.close()conn.close() 修改表表名修改alter table 表名 rename 新表名; 字段类型修改 修改字段类型：alter table 表名 modify 列名 列类型; 修改字段名及字段类型：alter table 表名 change 列名 新列名 列类型; 增加字段 增加字段到其他字段末尾【默认】：alter table 表名 add 列名 列类型 添加字段为第一个字段：alter table 表名 add 列名 列类型 FIRST 在指定的字段后添加字段：alter table 表名 add 列名 列类型 AFTER col_name 删除字段alter table 表名 drop 列名; 默认值 设置字段默认值：ALTER TABLE tbl_name ALTER col_name SET DEFAULT literal 删除字段默认值：ALTER TABLE tbl_name ALTER col_name DROP DEFAULT 删除表 删除空表：drop table tb1; 删除表数据：delete from tb1; 自增列会继续之前的ID 清空表：truncate table tb1; 物理删除，速度快，重新计算ID 查看表 查看存在的表：show tables; 表结构：desc tb_name; 建表语句：show create table tb_name; 多表范例一对多关系123456789101112create table department( id int not null auto_increment primary key, title char(20) );create table userinfo( id int not null auto_increment primary key, name char(20), age int default 18, gender char(1), department_id int, constraint user_depar foreign key (department_id) references department(id) )engine=innodb default charset=&apos;utf8&apos;; 多对多关系123456789101112131415create table boy( id int not null auto_increment primary key, name char(32) )engine=innodb default charset=&apos;utf8&apos;;create table girl( id int not null auto_increment primary key, name char(32) )engine=innodb default charset=&apos;utf8&apos;;create table b2g( id int not null auto_increment primary key, bid int, gid int, constraint to_boy foreign key (bid) references boy(id), constraint to_girl foreign key (gid) references girl(id) )engine=innodb default charset=&apos;utf8&apos;; 数据操作增加 单行数据：insert into tb1(name,age,gender) values(‘hejingqi’,30,’0’); 多行数据：insert into tb1(name,age,gender) values(‘yuanshuo’, 24, ‘1’),(‘yangxiaomeng’, 29, ‘1’); 删除 精确删除：delete from tb1 where name=’hejingqi’; 修改 单字段修改：update tb1 set age=18 where id=1; 多字段修改：update tb1 set id=2,age=30 where name=’yangxiaomeng’; 数据查询排序（order by） 从大到小：select * from score order by number desc; 从小到大：select * from score order by number asc; 限定数量（limit） 输出前2行：select * from score limit 2; 从第1个之后取2个：select * from score limit 1,2; 模糊匹配（like） 单字符匹配（_）：select * from class where caption like ‘_三一班’; 多字符匹配（%）:select * from class where caption like ‘三%’; 左右连表（join） INNER JOIN即为JOIN，只保留2个表均有的数据 LEFT JOIN以左边的表为主输出数据 12345678SELECT student.sname AS &apos;姓名&apos;, # &apos;指明表和列&apos; class.caption AS &apos;班级&apos;FROM student #查的主表LEFT JOIN class ON student.class_id = class.cid;# LEFT JOIN要连接的表# ON 2个表的桥接 1234567SELECT student.snameFROM studentLEFT JOIN score ON score.student_id = student.sidLEFT JOIN cource ON score.course_id = cource.cid # 多表关联WHERE cource.cname = &apos;体育&apos;; # 连表之后条件过滤 分组（group by） 先分组，再过滤 123456789SELECT class.caption as &apos;班级&apos;, count(class_id) as &apos;数量&apos; #对重复数据的聚合处理：count|max|min|avgFROM studentLEFT JOIN class ON class.cid = student.class_idGROUP BY # 分组依据 student.class_idHAVING count(class_id) &gt; 1; #先分组，然后对分组进行二次过滤 先过滤，再分组 123456789SELECT class.caption as &apos;班级&apos;, count(class_id) as &apos;数量&apos; #对重复数据的聚合处理FROM studentLEFT JOIN class ON class.cid = student.class_idWHERE class_id &gt; 1 #先使用条件过滤再进行分组GROUP BY # 分组依据 student.class_id; 上下连表（union）12select sid,sname from student union select tid,tname from teacher; 其他用法 结果无重复的查询（distinct ）：select distinct 列名 from 表名 where 条件； 拼接查询结果（concat）：select concat (id, name, score) as info from tt2; 别名设置（as） 聚合函数：count、sum、max、min、avg 操作符 逻辑操作 or and in not between 。。。and。。。 比较操作 &gt; &gt;= &lt; &lt;= = 索引介绍 一般对select查询的where条件列建立索引 可以对多个字段、一个字段、一个字段的前n个字符建立索引 由于复合索引的前缀特性，索引内的字段顺序很重要【一般将常用的列放在前边】 不应当建立索引的情况 频繁更新的字段【数据插入时，也需要更新索引，这会降低更新操作性能】 数据量小的表，或字段内容较少的字段（如性别、旗标） 字段值为空【此时，查询不走索引】 字段为主键【主键创建时默认会创建索引】 管理 建立索引： create table test1(id int not null,name char(20),sex char(3),primary key(id),index k_name(name(2))); alter table test add index index_name(column1,column2…); create index index_name on test(name); 删除索引 alter table test DROP INDEX index_name drop index index_Sage on student; 查询是否有索引：show crate table tb_name 查询是否使用索引：explain select * 。。。 存储过程 批量建表的范例 12345678910111213141516delimiter // -- 定义分界符drop procedure if exists create_batch_table; -- 删除已经存在的存储过程create procedure create_batch_table() -- 创建存储过程begin -- 开始存储过程declare i int; -- 定义变量类型set i = 2001; -- 设置变量while i &lt; 2005 do -- 循环开始 set @create=CONCAT(&apos;create table c_fu_&apos;, i , &apos; like c_fu_2000;&apos;); -- 定义创建表的语句 select @create; -- 显示建表语句 prepare tmt from @create; -- 预编译sql语句 execute tmt; -- 执行sql语句 deallocate prepare tmt; -- 收回sql游标cursor set i = i + 1; -- 循环自增end while; -- 循环结束end // -- 结束存储过程call create_batch_table(); -- 调用存储过程 python使用 pymysql模块 123456789101112131415161718192021import pymysqlconn = pymysql.connect(host=&apos;127.0.0.1&apos;, user=&apos;kingold&apos;, password=&apos;zjht098_kingold&apos;, database=&apos;db1&apos;, charset=&apos;utf8&apos;)cursor = conn.cursor(cursor=pymysql.cursors.DictCursor)# 查询cursor.execute(&apos;select name,age,gender from tb1&apos;)# 取所有结果res1 = cursor.fetchall()# 取一个结果res2 = cursor.fetchone()# 取指定数目结果res3 = cursor.fetchmany(2)# 插入cursor.execute(&apos;insert into tb1(name, age, gender) values(%s, %s, %s)&apos;, (&apos;hejingqi&apos;, 30, &apos;0&apos;))# 删除cursor.execute(&apos;delete from tb1 where name=%s&apos;, (&apos;yangxiaomeng&apos;))cursor.close()# 增删改数据时提交变更conn.commit()conn.close()]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>索引</tag>
        <tag>存储过程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python正则表达式]]></title>
    <url>%2F2018%2F05%2F13%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[语法介绍python re模块使用的是PCER(Perl Compatible Regular Expression)，即：Perl 兼容的正则表达式【可参考linux系统man pcre文档】。我们平时使用的就是这种正则表达式， 各种编程语言如 Java、Python、C#、JavaScript 实现的就是这种正则表达式。 元字符 表示法 含义 注意事项 . 匹配除换行符（\n）之外的任意字符 - \ 转义字符 - […] 一个字符集范围内的任意字符 第一个字符为[^]表示取反 预定义字符 可用于字符集[…] 表示法 含义 注意事项 \w 任意字母数字下划线 - \W 非字母数字下划线 - \d 数字 - \D 非数字 - \s 空白字符 - \S 非空白字符 - 数量词 可用于字符或分组()之后 表示法 含义 注意事项 * 匹配前一个字符0或多次 *?非贪婪模式 + 匹配前一个字符1或多次 +?非贪婪模式 ? 匹配前一个字符0或1次 ??非贪婪模式 {m} 匹配前一个字符m次 - {m,n} 匹配前一个字符m到n次 1. 省略m则0到n次，省略n则m到多次 2. {m,n}?非贪婪模式 边界匹配 表示法 含义 注意事项 ^ 匹配字符串开头 - $ 匹配字符串结尾 - 分组 表示法 含义 注意事项 1【竖线】 匹配左边或右边 没有括号时，范围是整个正则 （…） 分组 从左到右依次编号 \n 分组引用 - (?p&lt;name&gt;...) 命名分组 - (?p=name) 引用命名分组 - 不分组构造 表示法 含义 范例 (?:…) (…)的不分组表示 re.match(‘(?:abc){2}’, ‘abcabc’) (?iLmsux) iLmsux的每个字符代表一个匹配模式只能用在正则表达式的开头，可选多个用来替代整体模式的flag re.match(‘(?i)abc’, ‘AbC’) (?#…) #后的内容为注释 re.match(‘ab(?#ceshi)cd’, ‘abcd’) (?=…) 之后的字符串匹配表达式才能成功匹配 re.match(‘abc(?=ef)’, ‘abcef’) 后面是ef的abc (?!…) 之后的字符串不匹配表达式才能成功匹配 re.match(‘abc(?!ef)’, ‘abce’)后面不是ef的abc (?&lt;=…) 之前的字符串匹配表达式才能成功匹配【使用search】 re.search(‘(?&lt;=ab)cd’, ‘abcd’)前面是ab的cd (?&lt;!...) 之前的字符串不匹配表达式才能成功匹配【使用search】 re.search(&#39;(?&lt;!ab)cd&#39;, &#39;qacd&#39;)前面不是ab的cd (?(id/name)pattern) 如果编号为id或别名为name的组匹配到字符，则此分组应用同时需要匹配到pattern re.match(‘(\d)ab(?(1)\d)’, ‘1ab1’) 分组(\d)和表达式之后的分组(?(1)\d)必须同时匹配【1代表第一个分组】 应用re模块 search：在字符串中进行匹配测试 findall：在字符串中进行匹配测试，并返回所有匹配的字符串 match：从字符串开始进行匹配测试，re.match(&#39;\s+&#39;, &#39; &#39;) compile：预编译 12user_account = re.compile(r'[\w\.\-]+@([\w\.\-]+)\.[a-z]+$|^0(\d)&#123;2,3&#125;(\d)&#123;8&#125;$|^1(\d)&#123;10&#125;$')user_account.match('jingqi.he@zj-inv.cn') split：字符串切分，re.split(r’[\s\,]+’, ‘a b, c d’) sub：替换，re.sub(r’\slove\s’, ‘ hate ‘, ‘i love you’) 经典范例1234re.compile( r'(^|\s)(' + OPTIONS_REGEX + r')=(?P&lt;quote&gt;[\'"])?(.*?)(?(quote)(?&lt;!\\)(?P=quote))((?&lt;!\\)(?=\s)|$)') 表达式 含义 (^/\s) 以竖线开头或空格 (?P&lt;quote&gt;[\&#39;&quot;]) 单或双引号为一个分组 (?(quote)(?&lt;!\\)(?P=quote)) 如果前面的单或双引号匹配到，则在上述任意字符串之后必须同时匹配一个相同的单或双引号，并且保证此引号之前没有转义符 ((?&lt;!\\)(?=\s)/$) 直接以上述匹配结束或是上述匹配之后是空格，并且保证空格之前没有转义符]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
        <tag>PCRE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python文件操作]]></title>
    <url>%2F2018%2F05%2F11%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[open函数with使用 上下文管理 可以一次打开多个文件进行操作 不用自己处理文件关闭操作 123with open('test.txt', encoding='utf-8') as f1,open('b.txt', mode='w', encoding='utf-8') as f2: print(f1.read()) f2.write('ok') 读操作 文本编辑器（vim、sublime、记事本等）和python解释器（如open函数）,默认使用系统的编码方式保存和打开文件,如windows的gbk，linux的utf-8;当然也可以指定这俩种方式下的编码方式。 文件的默认操作模式：mode=’r’ 文件对象的读方法 read：一次读取整个文件，或指定字节数 readline：一次读取一行 readlines：将读取的整个文件保存为列表输出 写操作 文件操作模式：mode=’w’[覆盖写]和mode=’a’[追加写] 文件对象的写方法 write：一次写入整个内容 writelines：将列表或元组写入文件【自己处理换行】 1234shuzi = list(range(0,10))kexie = [str(n) + '\n' for n in shuzi]with open('shuzi.txt', mode='w', encoding='utf-8') as f: f.writelines(kexie) 文件打开模式 r+ 读写 w+ 写读 a+ 追加读 b 以bytes形式读取【默认str】 123# 复制的实现with open('a.png', mode='wb') as w, open('test.png', mode='rb') as r: w.write(r.read()) 文件对象操作 seek 移动光标；参数1为偏移量，参数2为起始位置 起始位置0表示数据流的开始【默认】：可以在str或bytes下使用；偏移量必须大于等于0。 起始位置1表示当前光标位置：在str模式下，偏移量只能为0；在bytes模式下，偏移量可正可负。 起始位置2表示数据流的末尾：在str模式下，偏移量只能为0；在bytes模式下，偏移量通常是负数。 tell 显示当前光标位置 范例 模拟tailf 12345678import timewith open('shuzi.txt', encoding='utf-8') as f: f.seek(0, 2) while True: line = f.read().strip() if line: print(line) time.sleep(0.5) 模拟文件修改 123456789import oswith open('shuzi.txt', 'r') as f1, open('shuzi.txt.tmp', 'w') as f2: lines = f1.readlines() for line in lines: if line.startswith('ce'): line = 'aa\n' f2.write(line)os.remove('shuzi.txt')os.rename('shuzi.txt.tmp', 'shuzi.txt') json与序列化把变量从内存中取出变成可存储或传输的过程 pickle12345678import pickled = dict(name='Bob', age=20, score=88)# 序列化（写）with open('./dump.txt', 'wb') as f: pickle.dump(d, f)# 反序列化（读）with open('./dump.txt', 'rb') as f: print(pickle.load(f)) json json表示的对象就是标准的javascript语言的对象。 json不仅是标准格式，并且比XML更快，而且可以直接在web页面中读取，非常方便； json和python json类型 python类型 {} dict [] list “string” ‘str’或u’unicode’ 123.45 int或float true/flase True/False null None 序列化 dump生成一个类文件对象 dumps生成一个字符串 12345import jsond = dict(name='Bob', age=20, score=88)with open('./1.json', 'w') as f: # json.dump(d, f, indent=4) f.write(json.dumps(d, indent=4)) 反序列化 load 解析类文件对象 loads 解析json格式字符串 123with open('./1.json', 'r') as f: # print(json.load(f)) print(json.loads(f.read())) 非标准类型123456789101112import jsonfrom json.encoder import JSONEncoderfrom datetime import datetime# https://docs.python.org/3/library/json.html?highlight=json#module-jsonclass CustJSONEncoder(JSONEncoder): def default(self, obj): if isinstance(obj, datetime): return obj.strftime('%Y-%m-%d %H:%M:%S') return json.JSONEncoder.default(self, obj)now = datetime.now()res = json.dumps(now, cls=CustJSONEncoder)print(res) xml解析语法123456789# 导入try: import xml.etree.cElementTree as ETexcept ImportError: import xml.etree.ElementTree as ET# 创建解析器tree = ET.parse('repositories.xml')# 获取根节点root = tree.getroot() 查找1234567891011121314# 遍历子元素for child in root: print(child.tag, child.text, child.attrib)# 遍历后代元素# 查看标签名称、文本、属性内容for ele in root.iter(): print(ele.tag, ele.text, ele.attrib)# findall使用xpath查找子元素下所有特定标签【默认查找当前标签下的子元素】code = root.findall('connection//code')# find使用xpath查找子元素下第一个特定标签【默认查找当前标签下的子元素】server = root.find('connection/server') 变更123456789101112131415# 创建节点nei = ET.Element('nei')nei.text = 'hi'nei.attrib['name'] = 'ceshi'# 变更节点par = root.find('connection/attributes')for child in par: if child.find('code').text == 'IS_CLUSTERED': # 添加节点【父节点末尾添加】 child.append(nei) # 修改节点相关值 child.find('attribute').text = 'true' # 删除相关节点【父节点删除子节点】 par.remove(child)tree.write('res1.xml') ini解析语法12345import configparser# 创建解析器config = configparser.ConfigParser()# 读取ini文件config.read('12.txt') 查找1234567# 查看所有块标题print(config.sections())# 查看特定标题下的所有keyprint(config.options('persistent_connection'))# 获取指定标题下key的值print(config.get('defaults', 'log_path'))print(config.getint('persistent_connection', 'connect_timeout')) 变更12345678910# 添加块config.add_section('aa')# 添加或修改块的keyconfig.set('aa', 'name', 'jingqi')config.write(open('12.txt', 'w'))# 删除块config.remove_section('aa')# 删除块的keyconfig.remove_option('persistent_connection', 'connect_timeout')config.write(open('34.txt', 'w'))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>open</tag>
        <tag>json</tag>
        <tag>xml</tag>
        <tag>ini</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python函数]]></title>
    <url>%2F2018%2F05%2F09%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[函数定义名称空间 内置名称空间：python解释器自带的名字所在的空间 全局名称空间：文件级别定义的名字所在的空间 局部名称空间：函数级别定义的名字所在的空间 作用域 全局作用域：内置名称空间、全局名称空间 查看全局作用域的名字：globals 局部作用域：局部名称空间 查看局部作用域的名字：locals 名字查找顺序：局部名称空间》全局名称空间》内置名称空间 定义 空函数pass 空函数可以作为占位符，在某部分代码没想好之前，可以先让函数运行起来 函数定义阶段只检查语法定义错误 定义函数时，需要确定函数名和参数个数；如有必要，可以先对参数的数据类型做检查。 返回值 函数可使用return随时返回值 没有return语句时，默认返回None 当返回多个值时，以元组形式组成 多个值的解包：a, b, c, d, e = t 只取某些值【下划线占位】： a, _, b, _, c = t 只取首尾的值：x, *_, y = t 参数 位置参数必须在关键词参数之前 位置参数 是必选参数 按位置赋值 123def foo(x, y): return x / yprint(foo(4, 2)) 关键词参数 以key-value形式赋值 范例：print(foo(y=4, x=2)) 默认参数 默认参数在非默认参数之后 默认参数只在定义时赋值一次 默认参数需要定义为不可变类型 范例： 错误使用范例 123456789def add_end(L=[]):L.append('END')return L# print(add_end([1,2,3]))print(add_end())print(add_end())# 输出['END']['END', 'END'] 正确使用 12345678def add_end(L=None):if L is None: L = []L.append('END')return L# print(add_end([1,2,3]))print(add_end())print(add_end()) 对比解释： python函数在定义的时候，默认参数L的值就被计算出来，即[],因为默认参数L也是一个变量，它指向对象[] 每次调用该函数，如果改变了L的内容，则下次调用时，默认参数的内容就变了，不再是定义时的[]的了。 所以定义默认参数要牢记一点：默认参数必须指向不变对象！ 可变长参数*args *会把溢出的按位置定义的实参都接收，并以元组的形式赋值给args 123456def foo(*args): total = 0 for i in args: total+=i return totalprint(foo(1,2,3)) 在list或tuple前面加一个*号，把list或tuple的元素变成可变参数传进去 1234def foo(*args): print(args)li = ['a', 'b', 'c']foo(*li) 可变长参数**kwargs**会把溢出的按关键词定义的实参都接收，并以字典的形式赋值给kwargs 1234def test_kw(**kwargs): print(kwargs)dic = &#123;'a': 1, 'b': 2&#125;test_kw(**dic) 命名关键字参数 *后为命名关键字参数，必须传值，且以关键字形式赋值 参数搭配使用及顺序：位置参数/默认参数/*,命名关键字参数 123def foo(x, y=1, *, z): print(x, y, z)foo(2, z=3) 参数顺序 严格的顺序：位置参数、默认参数、可变长参数args，[\，命名关键字参数]，可变长参数**kwargs 一般使用：位置参数、默认参数、可变长参数*args、可变长参数**kwargs 123def bar(a, b='x', *args, **kwargs): print(a, b, args, kwargs)bar(1,2,3,4, x='a', y='g') 内置函数递归函数语法特点 递归函数的优点是定义简单，逻辑清晰。理论上所有递归函数都可以写成循环的方式。但循环的逻辑不如递归清晰 使用递归函数需要防止栈溢出。在计算机中，函数调用是通过栈【stack】这种数据结构实现的，每当进入一个函数调用，栈就会增加一层栈帧。每当函数返回，栈就会减少一层栈帧。由于栈的大小不是无限的，所以递归调用的次数过多就会导致栈溢出。 尾递归可以解决递归栈溢出，但由于python解释器没有对尾递归做优化，依然会存在栈溢出，只要保证函数嵌套不超过100一般就没问题。 范例（汉诺塔）把圆盘从下面开始按大小顺序重新摆放到另一根柱子上。并且规定，在小圆盘上不能放大圆盘，在三根柱子之间一次只能移动一个圆盘。 12345678def hanoi(n,x,y,z): if n==1: print(x,'--&gt;',z) else: hanoi(n-1,x,z,y) #将前n-1个盘子从x移动到y上 hanoi(1,x,y,z) #将最底下的最后一个盘子从x移动到z上 hanoi(n-1,y,x,z) #将y上的n-1个盘子移动到z上hanoi(5,'x','y','z') lambda语法 语法：lambda 参数：表达式 匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果 范例12f = lambda x, y: x if y &gt; x else yprint(f(3, 2)) map语法 map函数接收两个参数，一个是函数，一个是迭代器 map将传入的函数依次作用到序列的每个元素，并把结果作为新的迭代器返回 范例12result = map(lambda x:x*x, [1, 3, 5])print(list(result)) reduce语法 在python3中，reduce函数已经被从全局名字空间中移除了，它被放置在functools模块里，用的话需要先引入 reduce函数接收两个参数，一个是函数且必需有两个参数，一个是迭代器 reduce会把相邻的两个元素使用函数处理后，再把处理的结果和相邻的元素进行处理，以此类推。 123from functools import reduceresult = reduce(lambda x,y: x + y, range(1, 10))print(result): 范例将数字字符串转换为数字 12345678from functools import reducedef str2int(s): def char2num(s): return dict(zip('0123456789', range(0,10)))[s] def fn(x, y): return 10 * x + y return reduce(fn, map(char2num, s))print(str2int('123')) filter语法 filter也接收一个函数和一个迭代器。 和map不同的是，filter把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素 1234def is_odd(n): return n % 2 == 1result = list(filter(is_odd, [1,2,3,6]))print(result) 范例 质数：在大于1的自然数中，除了1和它本身之外不再有其他因数 删除1-100内的质数 利用filter函数，只显示有返回值的函数结果【是质数，不返回；不是质数则返回】 单个数除以比它小但大于2的数，如果余数为0说明不是质数，直接返回。 1234567def not_prime(n): flag = False for i in range(2, n): if n % i == 0: flag = True return flagprint(list(filter(not_prime, range(1, 101)))) sorted 第一个参数接收可迭代的序列 list的sort属性只可用于list类型 key为只接收一个参数的函数，以此定义排序依据 reverse为是否逆序排列 结果：生成新序列的副本 list的sort属性变更list生成新列表 12student_tuple = (('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10))print(sorted(student_tuple, key=lambda student:student[2])) 闭包 定义在函数内部的函数，它包含对外部作用域而非全局作用域的引用，该内部函数就是闭包函数 一个闭包就是你调用了函数A，这个函数A返回了一个函数B给你，这个返回的函数B就是闭包；调用函数A传递的参数就是自由变量 1234567def funcA(): x = 1 def funcB(): print(x) #可以引用外部作用域的变量x return funcBf = funcA()f() 1234567from urllib.request import urlopendef index(url): def get(): return urlopen(url).read() return getres = index('https://blog.unforget.cn')print(res().decode('utf-8')) 装饰器作用符合开闭原则：对源代码修改封闭，对功能扩展开放 语法 多个装饰器，从上往下依次执行，从下往上依次装饰 写法 使用decorator 不使用decorator 单个Decorator，不带参数 @decdef method(args):&emsp;pass def method(args):&emsp;passmethod = dec(method) 多个Decorator，不带参数 @dec_a@dec_b@dec_cdef method(args):&emsp;pass def method(args):&emsp;passmethod = dec_a(dec_b(dec_c(method))) 单个Decorator，带参数 @dec(params)def method(args):&emsp;pass def method(args):&emsp;passmethod = dec(params)(method) 多个Decorator，带参数 @dec_a(params1)@dec_b(params2)@dec_c(params3)def method(args):&emsp;pass def method(args):&emsp;passmethod = dec_a(params1)(dec_b(params2)(dec_c(params3)(method))) 范例无参装饰器12345678910111213141516171819202122import time, functoolsdef timmer(func): # 添加此装饰器后可保持原函数属性不变 @functools.wraps(func) def wrapper(*args, **kwargs): start_time = time.time() func(*args, **kwargs) #index() end_time = time.time() print('run time is %s' % (end_time - start_time)) return wrapper@timmer #timmer(index)def index(): time.sleep(3) print('welcome!')@timmerdef index1(args): time.sleep(3) print('%s' % args)index()index1('test') 有参装饰器12345678910111213import timedef log(text): def decorator(func): def wrapper(*args, **kwargs): print('%s %s' % (text, func.__name__)) return func(*args, **kwargs) return wrapper return decorator@log('execute')def now(): print(time.time())now()print(now.__name__) 装饰器的叠加123456789101112131415161718192021222324def decorator_a(func): print('Get in decorator_a') def inner_a(*args, **kwargs): print('Get in inner_a') return func(*args, **kwargs) return inner_adef decorator_b(func): print('Get in decorator_b') def inner_b(*args, **kwargs): print('Get in inner_b') return func(*args, **kwargs) return inner_b@decorator_a@decorator_bdef f(x): print('Get in f') return x * 2# 函数定义阶段，decorator_b将f作为参数，取得“Get in decorator_b”# decorator_a把decorator_b作为参数，取得"Get in decorator_a"f(1)# 函数调用阶段，执行等同于decorator_a(decorator_b(f(1))),# 依次执行decorator_a，decorator_b，f,取得“Get in inner_a”、“ Get in inner_b”“Get in f”]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python流程控制]]></title>
    <url>%2F2018%2F05%2F08%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[流程语句if-else123456789name = input('input names:').strip()if name == 'oldboy': print('superadmin')elif name == 'alex': print('admin')elif name == 'jingqi': print('man')else: print('other') while 当条件为真时永远执行 范例：1-2+3-4…+99 123456789result = 0i = 1while i &lt; 100: if i % 2 == 0: result = result - i else: result = result + i i = i + 1print(result) break 跳出循环体，不再执行循环 break只能跳出单层循环，跳出多层循环需要在内循环设置变量，在外层循环捕捉变量再次跳出 范例：3次登陆失败则退出 12345678910i = 0while i &lt; 3: user = input('input user:').strip() password = input('input password:').strip() if user == 'alex' and password == 'newb': print('welcome') break else: print('输入错误') i += 1 continue 退出本次循环，继续下次循环 continue只能跳出单层循环的本次循环 范例：1到10的循环，遇到5不执行任何操作 123456for i in range(1, 10): if i == 5: continue else: print(i) print('ok') for-else|while-else 在循环体内没有break语句、没有return语句、或者没有异常都会正常执行else一次 范例 正常执行else 1234for i in range(1, 4): print(i)else: print('everything is ok') 不执行else 1234567for i in range(1, 4): if i == 3: break else: print(i)else: print('everything is ok') 异常处理try-except 语法 12345678try： 需要捕获的异常源码部分except 期望捕获的异常类型： 捕获异常类型后执行的操作else： 未捕获异常执行的操作finally： 无论上述代码执行结果都会执行此部分代码 需要注意的是，它不但捕获该类型错误，还把其子类也”一网打尽” 如果错误没有被捕获，它就一直往上抛，最后被解释器捕获，打印一个错误信息，然后程序退出 常见的错误类型和继承关系 范例 12345678910111213try: print('try...') # a = 5 + 'a' r = 10 /0except ZeroDivisionError as e: print('except:', e)except BaseException as b: print('except:', b)else: print('No error!')finally: print('finally')print('END') raise 更改抛出的错误类型【单写raise原样抛出】 12345try: result = 10/0except ZeroDivisionError as e: # raise ValueError('Error!') raise 抛出自定义错误 123456789class FooError(ValueError): passdef foo(s): n = int(s) if n == 0: raise FooError('invalid value:%s' % s) print(10/n)foo('0') assert如果第一个条件为假时，抛出第二个语句 123456def foo(s): n = int(s) # n!=0为假时，抛出后边的断言 assert n !=0, 'n is zero' print(10/n)foo('0')]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>流程控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python数据类型]]></title>
    <url>%2F2018%2F05%2F07%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[数据类型基本数据类型 整数 小数 小数之所以称为浮点数，是因为按照科学计数法的表示时，小数点的位置是可变的 对于很大或很小的浮点数，就必须用科学计数法表示，把10用e替代，1.23x10^9就是1.23e9 字符串 使用\转义特殊字符如\t 使用r’’表示内部字符串不转义 使用三引号显示多行内容 布尔值 数字中的0为False，其他均为True 空字符串为False，其他均为True 空值：None python数据类型 列表 字典 元组 集合 变量和常量 常量：通常用全部大写的变量名表示常量 变量名 包含字母、数字、下划线 不能以数字开头 不能包含内置关键字 命名必须有实际意义 通常将下划线作为变量名字符串的连接符 运算符 数字运算符 符号 含义 用法 + 加法 a = 1 + 2 - 减法 c = 2 -1 * 乘法 d = 2 * 4 / 除法 e = 6/3 // 地板除 b = 5//2 % 取余 h = 5%2 ** 平方 g = 3**2 比较运算符：==、!=、&gt;=、&lt;= 逻辑运算符：not 、and、or 成员判断：in、not in 变与不变 可变对象，比如list，对list进行操作，list内部的内容会发生变化 不可变对象，比如str、tuple，调用对象自身的任意方法也不会改变对象自身的内容；相反，这些方法会创建新的对象并返回。 list和dict对比 list dict 插入和查找的时间随着元素的增加而增加 插入和查找速度极快，不会随着key的增加而增加 占用内存较少 占用大量内存，内存浪费比较严重 列表方法 append：追加单个元素 extend：在列表中添加可迭代对象的多个元素（比如：列表中添加列表） 列表拼接【类同字符串拼接】 c = L + L2 1234L = ['1', '2', '3', '2']L2 = ('4', 'a')L.append('a')L.extend(L2) clean：清空列表 count：返回元素出现的次数 index：返回元素第一次出现的索引位置 remove：删除第一次出现的元素 del L[1]：删除指定索引位置的值 pop：删除指定位置（索引）元素并返回【默认最后一个】 insert：指定索引位置插入元素 sort：排序 reverse：反向排序 索引和切片切片始终创建新列表，不会改变原有列表 1234L = list(range(10))print(L[:3])print(L[-2:])print(L[::4]) 列表推导式使用其他列表创建新的列表的方式 123L = ['a', 'B', 5, 'C', 'd']s = [s.lower() for s in L if isinstance(s, str)]print(s) 迭代函数 range：返回一个可迭代的range对象 12for i in range(1,5): print(i) enumerate：接受一个可迭代对象，返回一个枚举类型对象；当使用for循环时，每次返回一对数，第一个[默认]是从0开始的计数， 第二个为可迭代对象的元素 123list_1 = [1, 3, 4]for k, v in enumerate(list_1): print(k, v) 范例 列表去重【保持列表元素位置不变】 1234567list_1 = [1, 3, 5, 1, 7, 4]list_2 = []for i in list_1: if i not in list_2: list_2.append(i)print(list_2) 元组 元组是不可变数据类型[子元素不可变] 元组的指向固定，但元组的元素内容是可变的[孙元素可变] 变与不变 123tuple_2 = (1, 3, [&apos;x&apos;, &apos;y&apos;])tuple_2[2][0] = &apos;A&apos;print(tuple_2) 单元素元组 因为括号()既可以表示tuple，又可以表示数学公式中的小括号，这就产生了歧义，因此，Python规定，这种情况下，按小括号进行计算 1234tup = (1)type(tup)tup1 = (1,)type(tup1) 索引和切片 123a = (1, 3 , 4, 2)a[1]a[2:] 字典 字典的键值对都是无序的，字典的存储顺序和放入顺序无关 字典的key必须是不可变对象 内存中的key以hash值的方式存储，而只有不可变对象才可hash 12345678a = &#123;(1, 2): 'a', 'a': 'c'&#125;# True和1等效 False和0等效 会相互覆盖b = &#123; True: 'a', 1: 'c', 12: 'd'&#125;print(a, b) 字典构造 dict函数（列表或元组中构造） 123list_1 = [('hejingqi', 26), ('xiaofang', 27)]dict_1 = dict(list_1)dict_2 = dict(hejingqi=25, xiaofang=27, zhaoying=24) 字典推导式 12dict_1 = &#123;x: x*2 for x in range(3)&#125;print(dict_1) 方法 update：更新或插入kv 12a = &#123;'a': 1&#125;a.update(&#123;'b': 2&#125;) clear：字典内容清空 del a[‘a’]：删除元素 get：取值【不存在不报错】 123v = dic.get('c', 'Not')v1 = dic['a']print(v, v1) pop：删除并取值 popitem：随机删除kv对 1234v = dic.pop('b')k, v1 = dic.popitem()print(v)print(k, v1) setdefault：设置默认值【不存在时使用】 123dic.setdefault('c', 111)dic['c'] = 3print(dic['c']) fromkeys：用于创建一个新字典，以序列seq中元素作为字典的键，value为字典所有键对应的初始值【没有则为None】 123456new_dic = dict.fromkeys(['k1', 'k2', 'k3'], [345])# 赋值操作新开辟一个内存空间# new_dic['k1'] = 12# 因为k1,k2,k3对应同一块内存空间，列表操作为对原空间进行操作new_dic['k1'].append(12)print(new_dic) keys：获取key列表【类似选项values、items】 1234567dict_1 = &#123; 'hejingqi': 30, 'yuanshuo': 24, 'yangxiaomeng': 29&#125;for k, v in dict_1.items(): print(k, v) 集合 没有重复值的列表，没有value的字典 集合会自动排序和去重 集合的数学运算 1234567a = set('abracadabra')b = set('alacazam')# print(a, b)print(a - b)print(a | b)print(a &amp; b)print(a ^ b) 集合推导式 12a = &#123;x for x in 'adfaseasdfe' if x not in 'abc'&#125;print(a) 方法 add：添加元素 discard：删除集合元素【没有不报错】 remove：删除集合元素【没有则报错】 clear：清空集合内容 del set_1：删除集合 update：更新集合内容 使用列表、元组、字典、集合等联合数据类型更新已经存在的集合 123a = &#123;'x', 'y', 'z'&#125;b = ['1', '2']a.update(b)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python类]]></title>
    <url>%2F2018%2F05%2F07%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[概念面向对象 面向过程：面向过程的程序设计把计算机程序视为一系列的命令集合，即一组函数的顺序执行 面向对象：面向对象的程序设计把计算机程序视为一组对象的集合，而每个对象都可以接收并处理其他对象发送的消息，程序的执行即为一系列消息在各个对象之间的传递 在python中一切皆为对象，对象包括数据（属性）和操作数据的函数（方法） object是一个基类或元类，在python2中继承object为新式类，否则为经典类；python3中默认都是新式类（无论是否明写object） 类的三大特性：数据封装、继承、多态 封装 类的属性和方法可以共用一套数据【例如下例中echo方法中可以调用age属性的值】 在python中，以双下划线开头同时以双下划线结尾的是特殊变量，可以直接访问 以下划线开头的是私有变量：单下划线开头的变量在导入类时会被忽略，双下划线是类的私有变量 123456789class test: def __init__(self, name, age): self.name = name self.age = age def echo(self): print(&apos;my age is %s&apos; % self.age)person1 = test(&apos;he&apos;, 27)person1.echo() 多态 是指由继承而产生的相关的不同类，这些类的实例对象会对同一消息作出不同的响应 例如：狗和鸡都有“叫”这一方法，但是调用狗的“叫”，狗会吠叫；调用鸡的“叫”，鸡则会啼叫。 继承12345678910class Animal(): def run(self): print(&apos;Animal is running&apos;)class Dog(Animal): def run(self): print(&quot;Dog is running&quot;)# 当子类和父类都存在相同的run()方法时，我们说，子类的run()覆盖了父类的run()，在代码运行的时候，总是会调用子类的run()。dog = Dog()dog.run() 多重继承在进行主线继承的同时，需要“混入”额外的功能，这可以通过多重继承来实现，这种设计模式即为Mixin 123456789101112class Animal(object): passclass Mammal(Animal): passclass Runnable(object): def run(self): print(&quot;Running&quot;)class Dog(Mammal, Runnable): pass MRO MRO即method resolution order，主要用于在多重继承时判断方法的调用路径（来自哪个类） 在新式类中，查找一个要调用的函数或属性时，采用广度优先原则。范例如下： 1234567891011121314class D(object): def foo(self): print(&quot;class D&quot;)class B(D): passclass C(D): def foo(self): print(&quot;class C&quot;)class A(B, C): passf = A()f.foo()输出： class C Super【只能用于新式类】从运行结果上看，普通继承和super继承是一样的。但是其实他们的内部运行机制不一样，这一点在多重继承时体现得很明显。在super机制里可以保证公共父类仅被执行一次，至于执行顺序，则是按照MRO进行。 1234567891011121314class C(object): def __init__(self): print(&quot;Enter C&quot;) print(&apos;Leave C&apos;)class B(C): def __init__(self): print(&quot;enter B&quot;) super(B, self).__init__() print(&quot;leave B&quot;)b = B()# 注解：super(B, self).__init__()【python2中写法】等同于super().__init__()调用父类进行初始化【__init__为父类方法】self指代类的实例 开闭原则 对功能组件扩展开放、对源代码修改封闭 开闭原则是面向对象设计中“可复用设计”的基石 鸭子类型 鸭子类型是动态类型的一种风格。在这种风格中，一个对象的有效语义不是由继承自特定的类或实现特定的接口来决定，而是由当前的方法和属性的集合决定 鸭子类型通常得益于不测试方法和函数中参数的类型，而是依赖文档、清晰的代码和测试来保证正确使用 Python的“file-like object“就是一种鸭子类型。对真正的文件对象，它有一个read()方法，返回其内容。但是，许多对象只要有read()方法，都被视为“file-like object“。许多函数接收的参数就是“file-like object“，你不一定要传入真正的文件对象，完全可以传入任何实现了read()方法的对象。 属性12345678class chinese(object): country = &apos;china&apos; def __init__(self, name, age): self.name = name self.age = age def talk(self): print(&apos;%s is chinese&apos; % self.name) 类属性 在类中定义的变量,上例中country即为类属性 既可以在类中，也可以在实例中调用 property将类的方法变为属性 12345678910111213141516171819202122class Student(): # 返回属性值 @property def score(self): return self._score # 设置属性值 @score.setter def score(self, value): if not isinstance(value, int): raise ValueError(&apos;score必须是整型&apos;) if value &lt; 0 or value &gt; 100: raise ValueError(&apos;socre必须在0和100之间&apos;) self._score = value # 删除属性值 @score.deleter def score(self): del self._score # raise PermissionErrors = Student()s.score = 60del s.scoreprint(s.score) 动态属性12345678910111213141516class person(): # 限制给实例添加的属性 __slots__ = (&apos;name&apos;, &apos;age&apos;, &apos;score&apos;) def __init__(self, name, age): self.name = name self.age = age def print_info(self): print(&apos;%s:%s&apos; % (self.name, self.age))p = person(&apos;he&apos;, 18)# 1）使用setattr添加属性【getattr获取/hasattr判断/delattr删除】# setattr(p, &apos;height&apos;, 16)# 2）直接添加属性p.score = 32p.print_info() 方法实例方法 在类中定义的函数，默认为实例方法 与实例进行绑定，函数的第一个参数是self，用于指代实例本身 第一个参数如果不是self，则第一个参数会被当成self，最终解释器会报参数个数错误 类实例化之后才能调用此方法 类方法 使用classmethod装饰器 与类进行绑定，函数的第一个参数是cls 类和实例均可以直接调用 12345class test: @classmethod def tell(cls): print(&apos;ok&apos;)test.tell() 静态方法 使用staticmethod装饰器 不与实例或类进行绑定（所以不需要第一个参数是self或cls） 类和实例均可以直接调用 12345class test: @staticmethod def tell(x, y): print(x, y)test.tell(3, 5) 方法范例1234567891011121314151617181920212223242526272829import settingsimport timeimport hashlibclass Mysql(): # 类实例化时绑定主机和端口 def __init__(self, host, port): self.__id = self.create_id() self.__host = host self.__port = port def select(self): print(&apos;%s is selecting...&apos; % self.__id) # 当类不实例化时，定义从配置文件中读取参数 @classmethod def from_conf(cls): return cls(settings.HOST, settings.PORT) # 定义一个与类或实例无关的工具包 @staticmethod def create_id(): id = hashlib.md5(str(time.clock()).encode(&apos;utf-8&apos;)) return id.hexdigest()con1 = Mysql(&apos;127.0.0.1&apos;, 3306)con4 = Mysql.from_conf()con1.select()con4.select() 内置方法12345678910111213141516171819202122232425262728class Foo: def __init__(self, name, age): self.__name = name self.__age = age def __del__(self): print(&apos;del---&apos;) def __str__(self): return &apos;name:%s age:%s&apos; % (self.__name, self.__age) def __setitem__(self, key, value): print(&apos;setitem&apos;) self.__dict__[key] = value def __getitem__(self, item): print(&apos;getitem&apos;) return self.__dict__[item] def __delitem__(self, key): print(&apos;delitem&apos;) self.__dict__.pop(key)test1 = Foo(&apos;he&apos;, 18)test1[&apos;score&apos;] = 35print(test1[&apos;score&apos;])del test1[&apos;score&apos;]print(test1) __dict__ 包含类的名称空间【包含属性和方法的集合】 __init__ 通过__init__方法可以给实例绑定属性，而类的其他函数则给实例绑定方法 它是一个特殊的函数，在类实例化时首先执行，并且此函数不能有返回值 self指代实例本身 __new__待续，参考见 __str__ 打印实例对象时触发此方法的执行 此方法只能返回字符串 PS：在命令行直接显示变量，调用的是__repr__方法 __del__ 当实例对象被解释器回收或主动删除实例对象时触发此方法执行 __setitem__ 以字典形式设置（获取、删除）类的属性时触发方法的执行 这3种方法【setitem、getitem、delitem】和【setattr、getattr、delattr】函数具有相同功能 __setattr__ 以属性形式设置或删除类的属性 123456789101112131415161718class Foo: def __init__(self, name, age): self.__name = name self.__age = age def __setattr__(self, key, value): print(&apos;setattr&apos;) self.__dict__[key] = value def __delattr__(self, item): print(&apos;delattr&apos;) del self.__dict__[item]test1 = Foo(&apos;he&apos;, 18)test1.score = 35print(test1.score)del test1.scoreprint(test1.score) __getattr__ 只有在没有找到属性的情况下，才调用getattr,已有的属性，比如name，不会在getattr中查找 123456789101112131415161718import datetimeclass Open: def __init__(self, filepath, mode=&apos;r&apos;, encoding=&apos;utf-8&apos;): self.filepath = filepath self.mode = mode self.encoding = encoding self.f = open(self.filepath, mode=self.mode, encoding=self.encoding) def write(self, msg): msg = str(datetime.datetime.now()) + &apos;\t&apos; + msg return self.f.write(msg) def __getattr__(self, item): return getattr(self.f, item)obj = Open(&apos;a.txt&apos;, &apos;w&apos;)obj.write(&apos;111\n&apos;)obj.write(&apos;222\n&apos;)obj.close() 以上为重写open的write方法，每次写操作均添加时间 对于其他方法由于没有重写，使用getattr直接获取内置open函数对应文件对象的属性和方法 __iter__|__next__ 如果一个类实现了iter和next方法，那么他就实现了迭代器协议，它就是一个迭代器 如下的类实现了迭代器协议【因此就可以被用于for…in循环】 for循环通过next方法获取循环的下一个值，直到遇到StopIteration错误时退出循环 1234567891011121314class Foo: def __init__(self): self.a, self.b = 0, 1 def __iter__(self): return self def __next__(self): self.a, self.b = self.b, self.a + self.b if self.a &gt; 1000: raise StopIteration() return self.afor n in Foo(): print(n) __enter__|__exit__ enter和exit用于上下文管理（with） enter方法用于入口的处理，直接返回对象本身，当使用as后实现f=self.f效果 exit方法用于出口的处理，exc_type为异常类型，exc_value异常的值，exc_tb为异常的追踪 exit方法必须返回True以保证with代码块的异常不会影响其他代码的执行 123456789101112131415161718192021222324class Open: def __init__(self, filepath, mode=&apos;r&apos;, encoding=&apos;utf-8&apos;): self.filepath = filepath self.mode = mode self.encoding = encoding self.f = open(self.filepath, mode=self.mode, encoding=self.encoding) def __enter__(self): print(&apos;__enter__&apos;) return self def __exit__(self, exc_type, exc_val, exc_tb): print(&apos;__exit__&apos;) print(exc_type) print(exc_val) print(exc_tb) self.f.close() return True def __getattr__(self, item): return getattr(self.f, item)with Open(&apos;c.txt&apos;, &apos;w&apos;) as f: #f=self.f 1/0 f.write(&apos;abc\n&apos;)print(&apos;ok&apos;) __call__ 任何类，只要定义了call方法，就可以直接对类的实例进行调用 对实例进行调用就好比对一个函数进行调用，所以你完全可以把实例对象当成函数 因为任何自定义类都是元类type的实例，而可以直接调用自定义类就是因为元类有call方法 12345678class Student: def __init__(self, name): self.name = name def __call__(self, *args, **kwargs): print(&apos;my name is %s.&apos; % self.name)s = Student(&apos;Michael&apos;)s() 元类 元类是类的类，是用来创建类【对象】的 函数type实际上是一个元类。type就是python在背后用来创建所有类【包括自身】的元类。 str是用来创建字符串对象的类，int时用来创建整数对象的类，而type就是用来创建类对象的类 python中所有的东西都是对象，包括整数、字符串、函数、类，他们都是由一个类【元类】创建的 创建类 使用type创建类和直接写class完全一样，因为python解释器遇到class定义时，仅仅是扫描class定义的语法，然后调用type创建class 语法：type(name, bases, dict) -&gt; a new type class的名称，字符串形式 继承的父类集合，由于python支持多重继承，所以此处为元组形式 包含的属性或方法的字典 修改类元类很复杂，对于非常简单的类可以不通过元类对类进行修改，可以通过其他两种两种技术实现 Monkey patching class decorators exec函数 读取字符串中的python代码并执行 表达式：exec(object[, globals[, locals]]) 参数1：python代码形式字符串对象 参数2：语句执行的全局作用域【下例：复用已存在的globals获取全局变量字典】 参数3：语句执行的本地作用域【下例：将函数的执行结果使用字典接收】 type与class对比 使用type 1234567891011121314class_name = &apos;chinese&apos;class_base = (object,)class_body = &quot;&quot;&quot;def __init__(self, name): self.name = namedef print_info(self): print(self.name)&quot;&quot;&quot;class_dict = &#123;&#125;exec(class_body, globals(), class_dict)chinese = type(class_name, class_base, class_dict)p = chinese(&apos;he&apos;)p.print_info() 使用class 123456class chinese: def __init__(self, name): self.name = name def print_info(self): print(self.name) 元类扩展阅读 python中type和object关系 使用元类实现自定义ORM框架 瞎驴讲解元类]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>class</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python数据类型之字符串]]></title>
    <url>%2F2018%2F05%2F02%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B9%8B%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[字符串方法 isdecimal/isdigit/isnumberic：判断是否为数字型字符串 1234v1 = a.isdecimal() #2v2 = a.isdigit() #2 ②v3 = a.isnumeric() #2 ② 二/贰print(v1, v2, v3) istitle：判断首字母是否大写 isidentifier：变量名有效性判断 123n = 'temp'v = n.isidentifier()print(v) capitalize：使字符串首字母大写 upper/lower：字符串变大小写 startswith/endswith：判断是否以某字符开头或结束 123s = 'abcd's.startswith('a')s.endswith('d') strip：移除空白或字符串 123456m = ' abc 'm.lstrip() #移除左侧空白m.rstrip()m.strip() #移除两端空白n = 'abc'n.strip('c') #移除字符c split：切割 splitlines：按行分割 12a = 'a|123|3'a.split('|') #默认以空格分割，只能是单字符分隔符 replace：替换 123n = 'ab12c'n.replace('a', '3') #替换所有字符n.replace('a', '3', 1) #只替换第一个字符 center：字符串居中 123st = 'oldboy'v = st.center(10, '#')print(v) encode：编码 123name = '测试'print(name.encode('utf-8'))print(name.encode('gbk')) format：字符串格式化【关键字(key=value)方式传递值】 format_map：字符串格式化【字典({key: value})方式传递值】 1234ori = 'my name is &#123;name&#125;, my age is &#123;age&#125;'# new = ori.format(name='he', age=12)new = ori.format_map(&#123;'name': 'he', 'age': 12&#125;)print(new) join：join可以拼接任意数量的字符串，调用此方法的字符串将被插入多个字符串之间形成一个新的字符串 123456a = '0'd = ['1', '2', '3']c = 'xyz'e = a.join(d)h = a.join(c)print(e, h) 子串判断1234if a in b: #如果a在b中 print(a)if a is b: #如果a和b相等 print('ok') 索引和切片12a = "abcd"print(a[1], a[::2]) # 取第2个元素；从第一次元素开始，每隔一个取一个元素。 字符串格式化占位符 %d 十进制整数(decimal) %s 字符串(string) %f 浮点数(float) %x 十六进制数(hex) %o 八进制数(octal) 百分号方式1print('my name is %s,my age is %d' % ('he', 29)) format方式 字符串索引方式 &#39;my name is {name}, my age is {age}&#39;.format(name=&#39;he&#39;, age=29) 数字索引方式 &#39;my name is {1}, my age is {0}&#39;.format(29, &#39;he&#39;) 数字格式化小数一般处理round(3.16, 1) #保留一位小数，按四舍五入处理 数字的格式化处理 填充符号 对其方式 符号 宽度 精度 数据类型 任意字符 &gt;&lt;=^ +- 任意数字 任意数字 占位符 1234"&#123;:*&gt;+10.3f&#125;".format(34)"&#123;:0=+10.3f&#125;".format(34)'&#123;a&#125;\'long format is &#123;a:0=+10.2f&#125;'.format(a=34)"The number &#123;1&#125; in hex is:&#123;1:#x&#125;, the number &#123;0&#125; in oct is &#123;0:#o&#125;".format(45, 4746) 元组格式化123tup = ('xiaomeng', 'jingqi')print('list is %s' % (tup,))'list is &#123;&#125;'.format(tup)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>格式化</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[部署工具fabric]]></title>
    <url>%2F2018%2F04%2F20%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2F%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7fabric%2F</url>
    <content type="text"><![CDATA[命令行选项 -l 显示任务名称 -f 指定fab入口文件，默认为fabfile.py -H 指定目标主机，多台主机以逗号分隔【当fab文件中只定义排除的主机列表时有效】 -x 排除指定主机【当fab文件中定义主机列表时有效，且列表形式必须一致，比如主机名，ip或同时包含用户名】 -u 目标主机用户名 -p 目标主机密码 -I 打开连接目标主机时的交互式提示 -P 以异步并行方式运行多主机任务，默认为串行运行 -R 指定role（角色），以角色名区分不同业务组设备 –skip-bad-hosts 跳过不可达主机 -t 设置目标主机连接超时时间（秒） -T 设置远程主机命令执行超时时间（秒） -w 当命令执行失败，发出警告，而非默认中止任务。 –set=KEY=VALUE,… 以逗号分隔设置环境变量 -z 设置并行执行时的进程数量 env设置 env.hosts 定义目标主机列表，可以是ip或主机名 此时可以只定义主机列表，形如：[‘172.17.20.12’, ‘172.17.20.13’]，此时所有主机将使用已定义好的用户名和密码连接目标主机 当各主机的用户名不同时，在hosts里定义用户名，形如：[&#39;zj-ops@172.17.20.12‘, &#39;zj-ops@172.17.20.13‘] env.exclude_hosts 排除指定主机 env.user 定义目标主机用户名 仅限于所有主机使用相同用户名 当没有定义user变量，同时hosts里也没有user选项时，将设置user为本地用户 env.password 定义目标主机密码 仅限于所有主机使用相同密码 当没有定义password变量，同时passwords里没有定义密码时，将出现交互式的密码输入提示 env.passwords 定义目标主机密码组 passwords变量中的key中user、host、port必须同时设置，否则将依然提示输入密码 范例：env.passwords = {&#39;user1@172.17.20.12:22’: ‘123’, &#39;user2@172.17.20.13:22’: ‘456’, &#39;zj-ops@2.2.2.2:22’: ‘abc’} env.gateway 定义网关设备【堡垒机、跳板机】， 网关设备的认证信息在passwords变量中定义 当堡垒机的用户名与应用主机不同时，应当在此添加，如：env.gateway = &#39;zj-ops@2.2.2.2‘ env.roledefs 将主机分组 定义：env.roledefs = {‘test1’: [&#39;zj-ops@1.1.1.1‘], ‘test2’: [&#39;zj-web@1.1.1.2‘], ‘test3’: [&#39;zj-ops@1.1.1.1‘, &#39;zj-web@1.1.1.2‘]} 使用：使用roles装饰器，表明仅某个主机组执行此任务，例如：@roles(‘test1’) 常用API命令 with 上下文管理，与python的with类似 导入：from fabric.context_managers import * run 运行远程命令 cd 远程切换目录 local 运行本地命令 lcd 本地切换目录 sudo 使用sudo执行远程命令 put 上传本地文件至远程主机 get 下载远程文件到本地主机 prompt 获得用户输入信息，如：prompt(‘please input user password:’) 导入：from fabric.contrib.console import confirm, prompt confirm 获得提示信息确认，如：confirm(‘Test failed,Continue[Y/N]?’) 导入：from fabric.contrib.console import confirm, prompt yellow|green|red 输出带颜色字体 导入：from fabric.colors import * 装饰器 @task 定义任务可以通过命令行【fab -l】看到 @runs_once 定义任务仅运行一次 @roles(‘test1’, ‘test2’) 定义任务仅被主机组执行 @hosts(&#39;zj-ops@172.17.20.12‘) 定义任务仅被此主机执行 @parallel 在多个主机并行执行任务【默认串行】 范例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185#!/usr/bin/python3# -*- coding: utf-8 -*-# @Time : 2018/4/16 17:08# @Author : simple0426# @Email : istyle.simple@gmail.com# @File : fabfile.py# @Software: PyCharm# @desc : 功能如下# 1.查看系统信息# 2.部署nginx代码# 3.回滚nginx代码# 4.更新nginx配置【更新成功后自动重启，更新失败自动回滚配置】# 5.查看nginx日志【分主机分项目】# 6.登陆nginx主机【分主机】from fabric.api import *from fabric.context_managers import *from fabric.contrib.console import promptfrom fabric.colors import *import os, shutilimport jsonenv.hosts = ['zj-ops@1.1.1.1', 'zj-web@1.1.1.2']env.gateway = 'zj-ops@2.2.2.2'env.passwords = &#123; 'zj-ops@1.1.1.1:22': '1213456', 'zj-web@1.1.1.2:22': '1213456', 'zj-ops@2.2.2.2:22': '1213456',&#125;env.roledefs = &#123; 'web1': ['zj-ops@1.1.1.1'], 'web2': ['zj-web@1.1.1.2'], 'webserver': ['zj-ops@1.1.1.1', 'zj-web@1.1.1.2']&#125;project_dict = &#123; 'fop': &#123;'name': 'fop', 'log': 'fop.abc.cn.log'&#125;, 'kop': &#123;'name': 'kop', 'log': 'kop.abc.cn.log'&#125;, 'check': &#123;'name': 'cloud-h5', 'log': 'check.fff.cn.log'&#125;, 'open': &#123;'name': 'cloud', 'log': 'open.fff.cn.log'&#125;, 'www': &#123;'name': 'kingold-web', 'log': 'www.fff.cn.log'&#125;,&#125;@task@paralleldef df(): '''查看所有主机的磁盘信息''' print yellow(run('df -h'))@task@roles('web1')def free(): '''只用于查看web1的内存''' run('free -m')@task@hosts('zj-web@1.1.1.2')def uptime(): '''只用于查看1.1.1.2的负载信息''' print green(run('uptime'))def delete_files(filename): '''如果文件或目录存在则删除''' dest_file = os.path.join(os.path.expanduser('~'), 'deploy', filename) if os.path.exists(dest_file) and os.path.isdir(dest_file): shutil.rmtree(dest_file) elif os.path.exists(dest_file) and os.path.isfile(dest_file): os.remove(dest_file) else: pass@runs_oncedef tar_code(): '''本地代码打包''' project = prompt('请输入要部署的项目:').strip() print yellow('本地代码打包') if project not in project_dict.keys(): abort('请输入正确的项目名称') project_name = project_dict[project]['name'] delete_files(project_name) delete_files('%s.tar.gz' % project_name) with lcd('~/deploy'): local('git clone git@10.10.10.164:kingold_app/%s.git' % project_name, capture=True) local('tar czf %s.tar.gz %s' % (project_name, project_name), capture=True) return projectdef backup_code(project): '''远程备份代码''' print yellow('远程备份代码') if project not in project_dict.keys(): abort('请输入正确的项目名称') project_name = project_dict[project]['name'] with cd('~/nginx'): with settings(warn_only=True): result = run('rsync -az --delete %s/ %s.bak/' % (project_name, project_name), quiet=True) if result.succeeded: print green('代码备份成功')def push_code(project): """上传代码【传输压缩包】""" print yellow('本地上传代码') if project not in project_dict.keys(): abort('请输入正确的项目名称') project_name = project_dict[project]['name'] result = put('~/deploy/%s.tar.gz' % project_name, '~/nginx/%s.tar.gz' % project_name) if result.failed: abort("上传代码失败！") else: with cd('~/nginx'): run('tar xzf %s.tar.gz' % project_name, quiet=True) print green('代码部署成功')@taskdef updateconf(): '''更新配置文件目录''' # 备份 with cd('nginx'): run('rsync -az --delete conf/ conf.bak/') # 上传 result = put('~/deploy/conf', '~/nginx') with settings(warn_only=True) and cd('nginx'): if result.failed: # 回滚 run('rsync -az --delete conf.bak/ conf/') abort('上传失败') else: res_conf = sudo('~/nginx/sbin/nginx -t', quiet=True) # 配置文件有效，重启nginx if res_conf.succeeded: nginx_count = run('ps aux|grep nginx|grep -v grep|wc -l') if nginx_count.stdout == '0': sudo('~/nginx/sbin/nginx') print green('nginx启动成功') else: sudo('~/nginx/sbin/nginx -s reload') print green('nginx重启成功') else: # 配置文件无效，回滚配置 run('rsync -az --delete conf.bak/ conf/') print red(res_conf.stdout)@taskdef rollback(): '''服务回滚''' project = prompt('请输入要回滚的项目:').strip() print yellow('代码回滚') if project not in project_dict.keys(): abort('请输入正确的项目名称') project_name = project_dict[project]['name'] with settings(warn_only=True): result = run('rsync -az --delete %s.bak/ %s/' % (project_name, project_name), quiet=True) if result.succeeded: print green('代码回滚成功')@taskdef deploy(): '''服务部署''' project = tar_code() backup_code(project) push_code(project)@task@runs_oncedef host(): '''设置登陆主机''' print green(json.dumps(env.hosts, indent=4)) host = prompt('请输入要登陆的主机') env.exclude_hosts.extend(env.hosts) for hostname in env.hosts: if host in hostname: env.exclude_hosts.remove(hostname)@taskdef login(): '''远程登陆[需设置登陆主机]''' open_shell()@taskdef log(): '''查看日志[需设置登陆主机]''' print green(json.dumps(project_dict.keys())) project = prompt('请输入要部署的项目:').strip() project_log = project_dict[project]['log'] with cd('~/nginx/logs'): run('tail -10f %s' % project_log) QAQ 安装：pip install fabric 参考]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>fabric</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP连接]]></title>
    <url>%2F2018%2F04%2F18%2F%E9%80%9A%E7%94%A8%E6%8A%80%E8%83%BD%2FTCP%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[建立连接 三次握手 释放连接 四次挥手 状态迁移客户端状态迁移 CLOSED 连接关闭 SYN_SENT 主动发送连接请求【SYN】，等待确认 ESTABLISHED socket已经处于链接状态，可以进行数据交互 一般认为一个established就是一个服务的并发连接 FIN_WAIT1 要求关闭连接【FIN】，但请求未被确认 FIN_WAIT2 要求关闭连接的请求被确认【ACK】 此时为半连接，可以接收数据单不能发送数据 TIME_WAIT 收到关闭半连接的请求【FIN】，发送确认信息【ACK】 超时【2MSL(maximum segment lifetime)数据包最大生存时间】后连接被释放 CLOSED 连接关闭 服务端状态迁移 CLOSED 连接关闭 LISTEN 监听状态，等待连接请求 SYN_RECVD 被动收到连接请求后，发送确认信息【ACK】，状态改变 ESTABLISHED socket已经处于链接状态，可以进行数据交互 CLOSE_WAIT 收到关闭连接的请求【FIN】，发送确认信息【ACK】 LAST_ACK 要求关闭半连接【FIN】，但请求未被确认 CLOSED 收到连接关闭的确认信息【ACK】，连接关闭 CLOSING状态 原因：两端同时要求关闭连接 已发出关闭请求【FIN】，但未收到对此的确认信息 同时，收到对端的关闭请求【FIN】，发出确认信息【ACK】 邻接状态 FIN_WAIT1 要求关闭连接【FIN】，但请求未被确认 CLOSING 同时发出关闭连接请求【ACK】，但未收到确认信息 TIME_WAIT 收到发送关闭连接的确认信息【ACK】 有限状态机 TCP参数 tcp_syn_retries：对于一个新建连接，内核要发送多少个 SYN 连接请求才决定放弃。不应该大于255，默认值是5，对应于180秒左右时间。(对于大负载而物理通信良好的网络而言,这个值偏高,可修改为2.这个值仅仅是针对对外的连接） tcp_retries1：放弃回应一个TCP连接请求前﹐需要进行多少次重试。默认值是3 tcp_synack_retries：对于远端的连接请求SYN，内核会发送SYN ＋ ACK数据报，以确认收到上一个 SYN连接请求包。这是所谓的三次握手( threeway handshake)机制的第二个步骤。这里决定内核在放弃连接之前所送出的 SYN+ACK 数目。不应该大于255，默认值是5，对应于180秒左右时间。(可以根据上面的 tcp_syn_retries 来决定这个值) tcp_syncookies：当出现syn等候队列出现溢出时象对方发送syncookies。目的是为了防止syn flood攻击。 tcp_max_syn_backlog：对于那些依然还未获得客户端确认的连接请求﹐需要保存在队列中最大数目。对于超过 128Mb 内存的系统﹐默认值是 1024 ﹐低于 128Mb 的则为 128。如果服务器经常出现过载﹐可以尝试增加这个数字。 tcp_abort_on_overflow：当守护进程太忙而不能接受新的连接，就向对方发送reset消息，默认值是false。这意味着当溢出的原因是因为一个偶然的猝发，那么连接将恢复状态。只有在你确信守护进程真的不能完成连接请求时才打开该选项，该选项会影响客户的使用。(对待已经满载的sendmail,apache这类服务的时候,这个可以很快让客户端终止连接,可以给予服务程序处理已有连接的缓冲机会,所以很多防火墙上推荐打开它) tcp_max_tw_buckets：系 统在同时所处理的最大 timewait sockets 数目。如果超过此数的话﹐time-wait socket 会被立即砍除并且显示警告信息。之所以要设定这个限制﹐纯粹为了抵御那些简单的 DoS 攻击﹐(事实上做NAT的时候最好可以适当地增加该值) tcp_tw_recycle：打开快速 TIME-WAIT sockets 回收。(做NAT的时候，建议打开它) tcp_tw_reuse：该文件表示是否允许重新应用处于TIME-WAIT状态的socket用于新的TCP连接(这个对快速重启动某些服务,而启动后提示端口已经被使用的情形非常有帮助) tcp_timestamps：Timestamps 用在其它一些东西中﹐可以防范那些伪造的 sequence 号码。 tcp_max_orphans：系统所能处理不属于任何进程的TCP sockets最大数量。假如超过这个数量﹐那么不属于任何进程的连接会被立即reset，并同时显示警告信息。之所以要设定这个限制﹐纯粹为了抵御那些简单的 DoS 攻击﹐ tcp_fin_timeout ：对于本端断开的socket连接，TCP保持在FIN-WAIT-2状态的时间。对方可能会断开连接或一直不结束连接或不可预料的进程死亡。默认值为 60 秒。 tcp_keepalive_time：当keepalive打开的情况下，TCP发送keepalive消息的频率。默认值是7200(2小时) tcp_keepalive_probes：TCP发送keepalive探测以确定该连接已经断开的次数。默认值是9 tcp_keepalive_intvl：探测消息发送的频率，乘以tcp_keepalive_probes就得到对于从开始探测以来没有响应的连接杀除的时间。默认值为75秒，也就是没有活动的连接将在大约11分钟以后将被丢弃。(对于普通应用来说,这个值有一些偏大,可以根据需要改小.特别是web类服务器需要改小该值,15是个比较合适的值) 常见问题 SYN超时或syn攻击防御 tcp_syncookies tcp_synack_retries tcp_max_syn_backlog tcp_abort_on_overflow TIME_WAIT处理 TIME_WAIT快速回收 tcp_tw_recycle tcp_timestamps TIME_WAIT重用 tcp_tw_reuse tcp_timestamps tcp_max_tw_buckets：控制并发的TIME_WAIT数量 参考 tcp_syn_retries等参数详解 浅析TCP协议中的疑难杂症]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-入门基础]]></title>
    <url>%2F2018%2F04%2F03%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fkubernetes%2Fkubernetes-%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[容器平台分层架构 基础设施(openstack)：虚拟机、网络、存储、数据库、公有云 容器引擎：docker 容器编排：kubernetes PaaS层：为开发、测试、运维提供统一的平台服务 访问和工具层：web控制台、CICD、监控、日志 官方文档使用 概念 任务：具体的任务 教程：有状态应用案例、无状态应用案例、CICD pipeline 参考：API、kubectl、k8s组件二进制命令 核心功能 自动装箱：构建于容器技术之上，基于资源依赖和其他约束性自动完成程序部署；通过调度机制，提升节点资源利用率 自我修复：支持容器故障后自动重启，节点故障后重新调度容器 水平扩展：支持通过命令、UI或HPA方式完成扩容、缩容等弹性伸缩 服务发现、负载均衡：通过使用DNS插件为系统内置服务发现功能，它为每个service配置DNS名称；而service通过iptables或ipvs内建了负载均衡机制 应用的发布、回滚：支持自动滚动更新，保证服务可用性；在出现故障时，支持回滚操作 秘钥和配置管理：通过ConfigMap实现配置管理，使用secret保证数据安全性 存储编排：支持pod对象按需挂载不同类型的存储系统，例如：本地存储(hostpath)、云存储(oss)、网络存储(glusterfs) 批量执行任务 概念术语name和namespace name是资源对象的标识，作用域为namespace namespace：用于限定资源的作用域 用于集群内部的逻辑隔离（资源对象名称隔离） 不能隔离不同名称空间的pod间通信，这是网络策略(network policy)的功能 默认名称空间为default label和selector label：用于资源分类的key-value对，用来过滤和选择资源 selector：根据标签(label)选择和过滤资源的一种机制 Pod 具有相同namespace的一组容器的集合体 是k8s中最小任务调度单元 一个pod里的所有容器共享资源【volumes/网络】 pod控制器 pod控制器是工作负载类控制器，用于部署和管理pod对象 工作负载类控制器包括：ReplicationController、ReplicaSet、Deployment、Statefulset、job等 Service 建立在pod对象之上的资源抽象，通过标签选择器选定一组pod，并为这组pod对象定义一个统一且固定的访问入口【集群ip或DNS名称】 实现方式 ClusterIP NodePort LoadBalancer ExternalName 架构和功能组件 master组件 etcd：分布式配置存储服务，保存资源的定义和状态；它不属于kubernetes集群本身 apiserver：是kubernetes系统的入口，封装了对资源对象的增删改查操作，以restful接口的形式提供给外部和内部使用。它维护的rest对象持久化到etcd中 scheduler：负责集群资源调度，根据预定的调度策略将pod调度到相应的机器上 controller-manager：确保各资源的当前状态(status)可以匹配用户期望的状态(spec)；实现此功能的操作有：故障检测、自动扩展、滚动更新等；实现此功能的控制器有：各类pod控制器，endpoint控制器、ServiceAccount控制器、node控制器等 node组件 kublet： 从apiserver接收关于pod对象的配置信息，并确保他们处于期望的状态 在APIServer注册当前节点，并汇报当前节点的资源使用情况 通过存储插件、网络插件，管理Volume(CVI)和网络(CNI)。 kube-proxy：按需为service对象生成相应的iptables或ipvs规则，从而将访问service的流量转发到相应的pod对象 container runtime(容器运行环境)：负责镜像管理以及容器的真正运行(CRI)，比如docker 核心附件 DNS组件(CoreDNS):为集群提供服务注册和服务发现的动态名称解析服务 UI组件(Kubernetes-dashboard):为集群提供web页面管理功能 监控组件：收集容器和节点的状态信息 早期使用heapster 现在使用metrics server+prometheus IngressController：在service之上，为集群提供7层代理；实现项目:nginx、traefik 集群部署方式 minikube方式：官方 二进制手动方式 kubeadm工具部署 集群运行模式 独立组件【二进制安装方式】：系统组件直接以守护进程方式运行在节点上 静态pod模式【kubeadm默认方式】，除了kubelet和docker之外其他组件(etcd/api/scheduler/controller-manager)都以静态pod方式运行在master主机上 自托管模式(self-hosted)【可通过kubeadm由静态pod转换而来】：类似静态pod方式，除了kubelet和docker之外其他组件都是集群上的pod对象，但这些pod受控于daemonset控制器 minikube软件安装 下载安装minikube minikube是类似于vagrant的工具，需要借助本地虚拟化的支持（hyper-v、virtualbox） 下载安装kubectl 注意事项 minikube命令和minikube项目存储位置(MINIKUBE_HOME，也即.minikube的上级目录)应该在同一分区上(例如都在c盘或d盘),否则minikube启动会找不到minikube的iso文件 默认项目存储位置(MINIKUBE_HOME)在用户家目录(如C:\Users\simple)，可以设置MINIKUBE_HOME变量改变 项目启动时会下载minikube的iso文件、kubectl、kubelet、kubeadm等组件，它们都是从境外下载的，为了快速下载，应该在23点之后进行首次下载并缓存 集群管理 启动命令：minikube start --image-mirror-country=cn --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers --registry-mirror=https://2x97hcl1.mirror.aliyuncs.com --iso-url=https://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/iso/minikube-v1.7.3.iso start其他配置选项 --cpus=2：为minikube虚拟机配置的cpu数量 --disk-size=20000mb：为minikube虚拟机配置的磁盘大小 --memory=2000mb：为minikube虚拟机分配的内存 --kubernetes-version=v1.16.2：minikube使用的kubernetes版本 停止命令：minikube stop web界面使用：minikube dashboard 集群信息查看：kubectl config view、kubectl cluster-info 应用管理 部署：kubectl apply -f https://k8s.io/examples/application/deployment.yaml 升级镜像：kubectl apply -f https://k8s.io/examples/application/deployment-update.yaml 扩容：kubectl apply -f https://k8s.io/examples/application/deployment-scale.yaml 集群运维 kubect get node：查看节点状态 kubectl get --watch deployments：持续查看deployments信息 kubectl describe deployment：显示deployments详情 kubectl delete deployment nginx-deployment：删除deployment 最佳实践集群部署硬件要求 环境 节点类型 配置 实验环境 master/node 2C/2G+ 测试环境 master 2C/4G/40G - node 4C/8G/40G 生产环境 master 4C/8G/100G - node 8C/64G/500G 使用限额12345在 v1.18 版本中， Kubernetes 支持的最大节点数为 5000。更具体地说，我们支持满足以下所有条件的配置：节点数不超过 5000Pod 总数不超过 150000容器总数不超过 300000每个节点的 pod 数量不超过 100]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker镜像仓库-harbor]]></title>
    <url>%2F2018%2F03%2F20%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2Fdocker%2Fdocker%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93-harbor%2F</url>
    <content type="text"><![CDATA[harbor介绍 镜像的存储harbor使用的是官方的docker registry服务去完成；至于registry是用本地存储或者s3都是可以的，harbor的功能是在此之上提供用户权限管理、镜像复制等功能 harbor镜像的复制是通过docker registry 的API去拷贝 安装 安装前置条件 docker-engine 17.06.0-ce+ or higher docker-compose 1.18.0 or higher 下载离线安装包 参数配置(harbor.yml) hostname: 对外发布的主机名 harbor_admin_password：web管理界面的密码【默认：admin/Harbor12345】 database：本地数据库密码 password: root123 data_volume: 镜像等数据的存储位置，默认/data log.location：日志位置，默认/var/log/harbor hostname配置要点 当配置hostname为内网地址时，虽然登陆地址可以通过地址映射使用外网地址；但是认证时，服务端回传客户端的认证地址，依然是内网地址造成无法登陆认证。 当配置hostname为外网地址时，由于外网带宽限制，内网服务器不能高速的进行镜像传输 当配置hostname为域名时，采用dns分离解析，内网dns解析使用自定义dns并解析为内网地址，外网dns解析使用公网dns并解析为公网ip。 harbor安装 包装命令：sudo ./install.sh web访问：http://ip:80 https设置 使用公有证书或自签名证书 harbor.yml中设置 hostname：设置域名或ip地址 certificate、private_key：设置证书和秘钥的路径 重新部署harbor 关闭服务：docker-compose down 重新部署：./install.sh 客户端设置 如果使用公有证书，客户端无需设置 如果使用自签名证书，将ca根证书放入如下位置：/etc/docker/certs.d/myregistry:5000/ca.crt myregistry为harbor主机的ip地址或域名，如果使用非443端口则要添加端口信息 ca.crt为根证书且名称必须是这样 重启docker服务 harbor服务控制容器控制 docker-compose up -d 创建和启动容器【后台】 docker-compose down 停止和删除容器 docker-compose start 启动容器及服务 docker-compose stop 停止容器及服务 容器介绍 harbor-core：配置管理中心 harbor-db：pg数据库 harbor-jobservice：负责镜像复制 harbor-log：记录操作日志 harbor-portal：web管理页面和API nginx：前端代理，负责前端页面和镜像上传、下载转发 redis：会话 registryctl：镜像存储 harbor管理用户管理 项目中的角色： 访客(guest)：对项目只读 开发者(developer)：对项目有读写权限 维护者(master)：高于开发者的权限，同时拥有权限：扫描镜像、查看复制任务、删除镜像 项目管理员（projectadmin）：用户新建项目时，默认具有的权限；项目管理员可以添加或删除项目成员 系统级别角色 系统管理员（sysadmin）：具有最高权限 匿名用户（anonymous）：未登录的用户；默认，只能对公开项目有读权限 客户端使用 【http模式】客户端添加不安全的私有镜像库地址(/etc/docker/daemon.json)：insecure-registries 添加客户端认证：docker login -u username -p password reg.mydomain.com 上传镜像 docker tag SOURCE_IMAGE[:TAG] harbor.zj-hf.cn/mytest/IMAGE[:TAG] docker push harbor.zj-hf.cn/mytest/IMAGE[:TAG] 下载镜像 docker login docker pull harbor.zj-hf.cn/mytest/registry:latest 删除镜像 web界面删除镜像 设置垃圾清理（Garbage Collection）：删除文件系统上的数据]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>harbor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python网络编程之socket]]></title>
    <url>%2F2018%2F03%2F12%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%B9%8Bsocket%2F</url>
    <content type="text"><![CDATA[数据流处理服务端 绑定端口 监听端口【udp无】 接受tcp连接【udp无】 处理连接 接收客户端数据 处理数据 向客户端返回数据 关闭连接【udp无】 客户端 建立连接【udp无】 发送数据 接收数据 关闭连接【udp无】 tcp编程服务端12345678910111213141516171819202122232425262728293031from socket import *import time, threading# 建立sockets = socket(AF_INET, SOCK_STREAM)# 绑定端口s.bind(('127.0.0.1', 9999))# 监听端口s.listen(5)print('等待连接。。。')# 处理连接def tcplink(sock, addr): print('从%s:%s接受新连接' % addr) # 连接建立时首先向客户端发送信息 sock.send('Welcome!'.encode('utf-8')) while True: # 接受数据 data = sock.recv(1024) time.sleep(1) # 如果数据为空或收到exit关键字子则不再接受数据 if not data or data.decode('utf-8') == 'exit': break sock.send(('你好,%s' % data.decode('utf-8')).encode('utf-8')) # 关闭连接 sock.close() print('来自%s:%s的连接已经关闭' % addr)while True: sock, addr = s.accept() t = threading.Thread(target=tcplink, args=(sock, addr)) t.start() 客户端1234567891011from socket import *s = socket(AF_INET, SOCK_STREAM)s.connect(('127.0.0.1', 9999))print(s.recv(1024).decode('utf-8'))for data in ['Michael', 'Tracy', 'Sarah']: s.send(data.encode('utf-8')) print(s.recv(1024).decode('utf-8'))s.send('exit'.encode('utf-8'))s.close() udp编程服务端12345678from socket import *s = socket(AF_INET, SOCK_DGRAM)s.bind(('127.0.0.1', 9999))print('在udp端口9999开启服务')while True: data, addr = s.recvfrom(1024) print('从%s:%s接受新连接' % addr) s.sendto(('你好,%s' % data.decode('utf-8')).encode('utf-8'), addr) 客户端123456from socket import *s = socket(AF_INET, SOCK_DGRAM)for data in ['Michael', 'Tracy', 'Sarah']: s.sendto(data.encode('utf-8'), ('127.0.0.1', 9999)) print(s.recv(1024).decode('utf-8'))s.close() socketserver编程 SocketServer模块简化了编写网络服务程序的任务。同时SocketServer模块也 是Python标准库中很多服务器框架的基础。 socketserver中包含了两种类， 一种为服务类（server class），它提供了许多方法：像绑定，监听，运行…… （也就是建立连接的过程） 一种为请求处理类（request handle class），则专注于如何处理用户所发送的数据（也就是事务逻辑）。 范例【服务端】 12345678910111213141516import socketserverimport timeclass Myhandler(socketserver.BaseRequestHandler): # 数据处理 def handle(self): # while True: res = self.request.recv(1024) if res: msg = res.decode('utf-8') print('client:%s msg:%s' % (self.client_address, res))if __name__ == '__main__': # 连接循环 s = socketserver.ThreadingTCPServer(('127.0.0.1', 9999), Myhandler) s.serve_forever() 粘包与分包 参考 粘包 简单描述：发送方发送两个字符串”hello”+”world”，接收方却一次性接收到了”helloworld”。 产生原因：有时候，TCP为了提高网络的利用率，会使用一个叫做Nagle的算法。该算法是指，发送端即使有要发送的数据，如果很少的话，会延迟发送。如果应用层给TCP传送数据很快的话，就会把两个应用层数据包“粘”在一起，TCP最后只发一个TCP数据包给接收端。 分包 简单描述：发送方发送字符串”helloworld”，接收方却接收到了两个字符串”hello”和”world”。 产生原因：由于MTU和MSS的长度限制 范例思路解读【粘包处理】 设置数据的属性信息比如版本、md5、长度为报头信息 【发送】将报头信息的长度发送给接收方【struct】 struct用于python【str，int】和c【struct】之间的数据类型转换 此处struct将要发送的【数据长度】打包成固定长度的bytes对象发送给接收方 【接收方】接收固定长度的数据【struct】，解析出报头长度 【发送】发送报头信息 【接收方】根据报头长度接收报头信息 【发送】发送数据 【接收方】根据报头信息接收数据信息 模拟远程执行命令服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152from socket import *import threadingimport subprocessimport structimport hashlibimport jsons = socket(AF_INET, SOCK_STREAM)s.bind(('0.0.0.0', 9999))s.listen(5)print('端口正在监听。。。')def tcplink(sock, addr): while True: try: data = sock.recv(1024) print(data.decode('utf-8')) res = subprocess.Popen(data.decode('utf-8'), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) res_err = res.stderr.read() res_std = res.stdout.read() if res_err: cmd_out = res_err elif not res_std: cmd_out = 'ok'.encode('utf-8') else: cmd_out = res_std head = &#123; 'ver': '1', 'md5': hashlib.md5(cmd_out).hexdigest(), 'lenth': len(cmd_out) &#125; head_json = json.dumps(head) head_bytes = head_json.encode('utf-8') print(head_bytes) # 发送报头长度 sock.send(struct.pack('i', len(head_bytes))) # 发送发送报头 sock.send(head_bytes) # 发送数据 sock.send(cmd_out) except Exception: break sock.close() print('来自%s:%s的连接已关闭' % addr)if __name__ == '__main__': while True: sock, addr = s.accept() print('已接受来自%s:%s的连接' % addr) t = threading.Thread(target=tcplink, args=(sock, addr)) t.start() 模拟远程执行命令客户端123456789101112131415161718192021222324252627282930313233from socket import *import structimport jsont = socket(AF_INET, SOCK_STREAM)t.connect(('10.10.10.100', 9999))while True: cmd = input('&gt;&gt;&gt;').strip() if not cmd: continue elif cmd == 'exit': break else: t.send(cmd.encode('utf-8')) # 接收报头长度 head_info = t.recv(4) head_len = struct.unpack('i', head_info)[0] # 接收报头 head_bytes = t.recv(head_len) head_json = head_bytes.decode('utf-8') head_dict = json.loads(head_json) data_len = head_dict['lenth'] print(head_dict) # 接收数据 data_buffers = bytes() recv_size = 0 while recv_size &lt; data_len: recv_data = t.recv(1024) data_buffers+=recv_data recv_size+=len(recv_data) print(data_buffers.decode('utf-8'))t.close()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>socket</tag>
        <tag>粘包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python网络编程之进程]]></title>
    <url>%2F2018%2F03%2F02%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[进程与线程概念 进程是资源集合，至少包含一个线程；线程是程序运行的最小单位 一个进程的多个线程共享内存空间 无论多进程或多线程，数量增加到一定程度，任务开销就会急剧上升，效率就会下降 计算密集型任务，更多使用cpu，注重代码的执行效率，更适合使用C语言开发；而如web应用等io密集型【磁盘和网络】，瓶颈不在cpu和内存，所以适合使用python这样代码少的语言提高开发效率 利用操作系统对异步io的支持，可以用单进程单线程来执行多任务，这种模型即为事件驱动模型，对应到python即为协程 要实现多任务，通常采用master-worker模式，master负责分配任务，worker负责执行任务 优缺点 - 优点 缺点 应用范例 多进程 稳定性高,一个进程的崩溃不会影响到其他进程 创建进程的开销大,Unix下fork还好,windows下特别明显 Apache默认采用进程模型 多线程 通常线程模式比进程模式执行快,windows下iis就采用多线程模式 但是由于多线程共享内存,一个线程的崩溃会导致整个进程的崩溃 现在apache和iis都出现了多进程多线程混合模式,在保证稳定性的同时提高效率 进程Process方法 Process.name：查看子进程名称 Process.pid：子进程pid Process.is_alive()：进程是否存活 Process.terminate()：终止进程 Process.daemon：当主进程结束时子进程也跟着结束，子进程的daemon属性必须先于start设置 Process.start：开启子进程 Process.join：父进程等待子进程结束【当不设置join时，父进程不等待子进程结束】 1234567891011121314151617181920212223242526272829from multiprocessing import Processimport os, random, timedef run_proc(name): print('子进程 %s(%s)开始' % (name, os.getpid())) time.sleep(random.randint(3, 6)) print('子进程 %s(%s)结束' % (name, os.getpid()))if __name__ == '__main__': print('父进程%s开始' % os.getpid()) # Process产生用于执行函数的子进程 p1 = Process(target=run_proc, args=('test1',)) p2 = Process(target=run_proc, args=('test2',)) # 开启子进程,此时p1与p2并行执行 p1.start() p2.start() # 等待子进程结束 p1.join() p2.join() print('父进程%s结束' % os.getpid())# 假如程序为如下顺序，则p1与p2串行执行# 子程序1p1.start()p1.join() # 子程序2p2.start()p2.join() 进程池Pool方法12345678910111213141516171819202122from multiprocessing import Poolimport os, time, randomdef long_time_task(name): print('运行任务 %s(%s)' % (name, os.getpid())) start = time.time() time.sleep(random.random() * 10) end = time.time() print('任务 %s 运行 %0.2f seconds' % (name, (end - start)))if __name__ == '__main__': print('主进程 %s 开始' % os.getpid()) # Pool默认产生和cpu核数相等的子进程 p = Pool(5) for i in range(5): # apply_async用于产生并行子进程，一个进程结束又会有新的进程进入，维持进程总数不变 p.apply_async(long_time_task, args=(i,)) # 关闭进程池 p.close() # 主进程阻塞，等待子进程的退出， join方法要在close或terminate之后使用。 p.join() print('主进程 %s 结束' % os.getpid()) Pool方法回调12345678910111213141516171819# 进程池开启n个进程，每个进程获取一个随机值并取这个随机值的平方from multiprocessing import Poolimport randomdef random_int(n): res = random.randint(1, 2*n) print('res is %s' % res) return resdef square(n): print(n**2)if __name__ == '__main__': p = Pool(3) for i in range(1, 6): print('i is %d' % i) p.apply_async(random_int, args=(i,), callback=square) p.close() p.join() 线程 任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程 多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改 为了保证一个变量不被多个线程同时修改，可以在一个线程执行前加锁，执行完后释放锁，然后其他线程再执行操作【 由于锁只有一个，无论多少线程，同一时刻最多只有一个线程持有该锁，所以，不会造成修改的冲突】 GIL【global iterpretor lock】 Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL 全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。 多线程同步由于CPython的python解释器在单线程模式下执行，所以导致python的多线程在很多的时候并不能很好地发挥多核cpu的资源。大部分情况都推荐使用多进程【多个Python进程有各自独立的GIL锁，互不影响。】。python的多线程的同步与其他语言基本相同，主要包含： Lock&amp;RLock ：用来确保多线程多共享资源的访问。 Semaphore： 用来确保一定资源多线程访问时的上限，例如资源池 Event：是最简单的线程间通信的方式，一个线程可以发送信号，其他的线程接收到信号后执行操作。 Lock&amp;RLock Lock对象的状态可以为locked和unlocked，使用acquire()设置为locked状态；使用release()设置为unlocked状态。 如果当前的状态为unlocked，则acquire()会将状态改为locked然后立即返回。当状态为locked的时候，acquire()将被阻塞直到另一个线程中调用release()来将状态改为unlocked，然后acquire()才可以再次将状态置为locked。 Lock.acquire(blocking=True, timeout=-1),blocking参数表示是否阻塞当前线程等待，timeout表示阻塞时的等待时间 。如果成功地获得lock，则acquire()函数返回True，否则返回False，timeout超时时如果还没有获得lock仍然返回False。 Rlock在acquire状态时，依然可以再次acquire，只要acquire与release成对出现即可，可以递归使用 RLock与Lock的区别是：RLock中除了状态locked和unlocked外还记录了当前lock的owner和递归层数 范例Lock【确保只有一个线程可以访问共享资源】 12345678910111213141516171819202122232425262728import time, threading, randombalance = 0lock = threading.Lock()def change_it(n): global balance balance = balance + n print(balance) balance = balance - n print(balance) time.sleep(random.random() * 2)def run_thread(n): for i in range(10): lock.acquire() try: change_it(n) finally: lock.release()t1 = threading.Thread(target=run_thread, args=(5,))t2 = threading.Thread(target=run_thread, args=(8,))t1.start()t2.start()t1.join()t2.join()print('final balance is %d' % balance) 范例RLock 1234567891011121314151617181920212223242526import threading, timelock1 = threading.RLock()x = 0def increase_5(lock, loop): global x for i in range(0, loop): lock.acquire() x += 5 print('increase x is %d' % x) lock.release()def decrease_4(lock, loop): global x for i in range(0, loop): lock.acquire() increase_5(lock, loop) x -= 4 print('decrease x is %d' % x) lock.release()t1 = threading.Thread(target=decrease_4, args=(lock1, 4))t1.start()t1.join()print('x is %d' % x) Semaphore Semaphore管理一个内置的计数器，每当调用acquire()时内置计数器-1；调用release() 时内置计数器+1。 计数器不能小于0；当计数器为0时，acquire()将阻塞线程直到其他线程调用release()。 范例【同时只有2个线程可以获得semaphore,即可以限制最大连接数为2】 1234567891011121314import threading, timesemaphore = threading.Semaphore(2)def func(name): if semaphore.acquire(): print( '%s get semaphore' % name) time.sleep(2) semaphore.release() print('%s release semaphore' % name)for i in range(4): t1 = threading.Thread(target=func, args=(i,)) t1.start() Event Event内部包含了一个标志位，初始的时候为false。 可以使用使用set()来将其设置为true，或者使用clear()将其重新设置为false。 可以使用is_set()来检查标志位的状态 wait(timeout=None)，用来阻塞当前线程，直到event的内部标志位被设置为true或者timeout超时。 范例【线程间相互通信】 12345678910111213141516171819202122232425import threading, timeevent = threading.Event()def mysql_status(e): print('mysql is starting') time.sleep(5) e.set() print('mysql is ready...')def mysql_conn(e): while True: if e.is_set(): print('%s connected to mysql' % threading.current_thread().getName()) break else: e.wait(2) print('%s connecting to mysql' % threading.current_thread().getName())t1 = threading.Thread(target=mysql_status, args=(event,))t2 = threading.Thread(target=mysql_conn, args=(event,))t3 = threading.Thread(target=mysql_conn, args=(event,))t1.start()t2.start()t3.start() 线程隔离Local 全局变量local_school是一个threadlocal对象，每个线程都可以对它的student属性操作，而互不影响 threadlocal常用于为每个线程绑定一个数据库连接、http请求、用户身份信息等 1234567891011121314import threadinglocal_school = threading.local()def process_thread(name): local_school.student = name print('Hello, %s (in %s)' % (local_school.student, threading.current_thread().name))t1 = threading.Thread(target=process_thread, args=('Alice',), name='Thread-A')t2 = threading.Thread(target=process_thread, args=('Bob',), name='Thread-B')t1.start()t2.start()t1.join()t2.join() 协程 对于多线程应用，cpu通过切片的方式来切换线程间的执行，线程切换需要耗时【保存上下文】 协程则只使用一个线程，在一个线程中规定某个代码块的执行顺序 生成器实现 生产者和消费者在同一进程中的使用范例 123456789101112131415161718192021222324252627282930313233343536import timedef consumer(): r = '' while True: n = yield r if not n: return print('[消费者] 正在消费 %s...' % n) time.sleep(1) r = '200 OK'def produce(c): next(c) n = 0 while n &lt; 5: n = n + 1 print('[生产者] 正在生产 %s...' % n) r = c.send(n) print('[生产者] 消费返回：%s' % r) c.close()if __name__ == '__main__': c = consumer() produce(c)# 范例详解生产者中：n = 1生产1消费者中：向yield传值1后，n为1消费1消费者返回r 为‘200 ok’生产者中：接受消费者的返回值r为‘200 ok’ gevent实现 gevent是第三方库，通过greenlet实现协程 当一个greenlet遇到IO操作时，比如访问网络，就会自动切换到其他的greenlet，等待IO操作完成，再在适当的时候切换回来继续执行 由于IO操作非常耗时，经常处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO 由于gevent是基于IO切换的协程，所以最神奇的是，我们编写的Web App代码，不需要引入gevent的包，也不需要改任何代码，仅仅在部署的时候，用一个支持gevent的WSGI服务器，立刻就获得了数倍的性能提升。 12345678910# 创建一个协程对象g1，spawn括号内第一个参数是函数名，如eat，后面可以有多个参数，可以是位置实参或关键字实参，都是传给函数eat的g1=gevent.spawn(func,1,,2,3,x=4,y=5)g2=gevent.spawn(func2)# 等待g1结束g1.join() # 等待g2结束g2.join() # 或者上述两步合作一步：gevent.joinall([g1,g2])# 拿到func1的返回值g1.value gevent范例 基本使用 12345678910111213141516171819202122232425262728293031from gevent import monkey;monkey.patch_all()import geventimport timedef eat(name): print('%s eat 1' % name) # 模拟IO阻塞 ''' 在gevent模块里面要用gevent.sleep(2)表示等待的时间 然而我们经常用time.sleep()用习惯了，那么有些人就想着 可以用time.sleep()，那么也不是不可以。要想用，就得在 最上面导入from gevent import monkey;monkey.patch_all()这句话 如果不导入直接用time.sleep()，就实现不了单线程并发的效果了 ''' time.sleep(2) print('%s eat 2' % name) return 'eat'def play(name): print('%s play 1' % name) time.sleep(1) print('%s play 2' % name) return 'play'start = time.time()g1 = gevent.spawn(eat, 'egon')g2 = gevent.spawn(play, 'alex')gevent.joinall([g1, g2])print('主', time.time() - start)print(g1.value)print(g2.value) 爬虫的使用 12345678910111213141516import timedef get_page(url): print('get :%s' % url) response = requests.get(url) if response.status_code == 200: print('%d bytes received from:%s' % (len(response.text), url))start = time.time()gevent.joinall([ gevent.spawn(get_page, 'http://www.baidu.com'), gevent.spawn(get_page, 'https://www.yahoo.com'), gevent.spawn(get_page, 'https://github.com'),])stop = time.time()print('run time is %s' % (stop - start)) 参考 多线程同步]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>IPC</tag>
        <tag>进程</tag>
        <tag>线程</tag>
        <tag>协程</tag>
        <tag>gevent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python函数之迭代器]]></title>
    <url>%2F2018%2F03%2F02%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython%E5%87%BD%E6%95%B0%E4%B9%8B%E8%BF%AD%E4%BB%A3%E5%99%A8%2F</url>
    <content type="text"><![CDATA[迭代概念 迭代：重复的过程称为迭代，每次重复即是一次迭代，但是每次重复的结果都是下一次重复的初始值 可迭代：每个含有iter()方法的数据类型都是可迭代的，都可以使用for循环获取对象中的每一个元素 for循环：先执行对象的iter方法得到一个迭代器对象，再执行迭代器对象的next方法从而得到对象的元素 123456789a = ['a', 'b', 'c']# i = a.__iter__()i = iter(a) #iter方法获取列表的迭代器对象print(i)while True: try: print(next(i)) #next方法获取迭代器的下一个值 except StopIteration: break 可迭代对象12345from collections import Iterable, Iteratorprint(isinstance([], Iterable))print(isinstance((), Iterable))print(isinstance(&#123;&#125;, Iterable))print(isinstance('', Iterable)) 相关函数 zip:[拉链函数] 接受一系列的可迭代对象作为参数【至少2个】，返回由可迭代对象元素组成的元组；可用于双循环或多循环的取值 1234names = ['hejingqi', 'hanjianfang', 'xiaofangfang']ages = [27, 26, 27]for name, age in zip(names, ages): print(name, age) enumerate 接收一个可迭代对象和索引初始值，返回由索引和元素组成的元组；可用于序列的取值 123456from collections import Iterable, Iteratorl = list(range(5))i = enumerate(l)print(isinstance(i, Iterator))for k, v in enumerate(l, 10): print(k, v) 迭代器概念 既含有__iter__()方法，又含有__next__()方法的对象 执行对象的__iter__()方法得到的结果仍然是他本身 优缺点 惰性计算：它仅在迭代至当前元素时才计算该元素的值，在此之前和之后都可以不存在，也就是不需要在遍历之前准备好迭代过程的所有元素，所以适合遍历那些有无穷个元素的集合【比如自然数】 优点 提供了一种不依赖下标的迭代方式 就迭代器本身来说，更节省内存 缺点 无法获取迭代器对象的长度 不如序列类型取值灵活，是一次性的，只能往后取值，不能往前退 生成器概念 调用生成器函数返回一个生成器（和迭代器类似，返回自身） 自动实现了迭代器的功能（相当于为函数封装好iter和next方法） 语法上与函数相似，只是将return替换成了yield；但是return只能返回一次值，函数就终止了；而yield能返回多次值，每次返回都会将函数暂停，下次调用会从上一次暂停的位置继续执行 定义 生成器表达式 类似列表推导式(简单理解为元组推导式) 12g = (x*x for x in range(10))print(g) 生成器函数（使用yield返回的函数） 1234567891011def foo(): print('first') yield 1 print('second') yield 2 print('third') yield 3g = foo() #函数的执行，得到一个生成器【同时也是一个迭代器】print(g)next(g) #使用迭代器的next方法获取对象的元素（此处为执行函数，遇yield第一次返回）print(next(g)) #执行函数，并打印返回值 send方法send定义 生成器必须在执行一次next【也即yield一次，产生一个断点】才能接受send发送的值 send是调用生成器的方法，在断点恢复同时向yield传递值，在下次yield处暂停 next也是调用生成器的方法，但是不向yield传值，此时yield值为空 send范例1234567891011121314151617181920212223242526def echo(value=None): while 1: value = (yield value) print("The value is", value) if value: value = value + 1g = echo(1)print(next(g))print(g.send(2))print(g.send(5))print(next(g))# 输出1The value is 23The value is 56The value is NoneNone# 步骤详解定义生成器时value为1，返回value【1】value重新赋值等于2【The value is 2】，value重新计算等于3，返回value【3】value重新赋值等于5【The value is 5】，value重新计算等于6，返回value【6】next调用，向yield中传递空值，value为空【The value is None】，value重新计算为空，返回空值【None】 send范例详解 参考：http://codingpy.com/article/python-generator-notes-by-kissg/ 上述代码既有yield value的形式，又有value = yield形式，看起来有点复杂。但以yield分离代码进行解读，就不太难了。第一次调用next()方法，执行到yield value表达式，保存上下文环境暂停返回1。第二次调用send(value)方法，从value = yield开始，打印，再次遇到yield value暂停返回。后续的调用send(value)或next()都不外如是。 在一次next()(非首次)或send(value)调用过程中，实际上存在2个yield，一个作为恢复点的yield与一个作为暂停点的yield。因此，也就有2个yield表达式。send(value)方法是将值传给恢复点yield;调用next()表达式的值时，其恢复点yield的值总是为None，而将暂停点的yield表达式的值返回。 使用范例 范例1：模拟tail -f a.txt|grep ‘python’ 123456789101112131415import timedef tail(filepath): with open(filepath, encoding='utf-8') as f: f.seek(0, 2) while True: line = f.readline().strip() if line: yield line else: time.sleep(0.2)def grep(pattern, lines): for line in lines: if pattern in line: print(line)grep('python', tail('a.txt')) 范例2：获取斐波那契数前n个值 斐波那契数:除第一第二个数之外，其他每个数都由前俩个数相加得到结果 123456789def fib(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1g = fib(3)for i in g: print(i)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>迭代器</tag>
        <tag>生成器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程间通信]]></title>
    <url>%2F2018%2F02%2F28%2Fweb%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%2F%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%2F%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[进程间通信what进程间的通讯IPC (Inter-process communication))：指至少两个进程或线程间传送数据或信号的一些技术或方法。 why 数据传输：一个进程需要将它的数据发送给另一个进程，发送的数据量在一个字节到几M字节之间 共享数据：多个进程想要操作共享数据，一个进程对共享数据的修改，别的进程应该立刻看到。 通知事件：一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。 资源共享：多个进程之间共享同样的资源。为了作到这一点，需要内核提供锁和同步机制。 进程控制：有些进程希望完全控制另一个进程的执行（如Debug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。 基于相对位置的分类 本地过程调用(LPC)LPC用在多任务操作系统中，使得同时运行的任务能互相会话。这些任务共享内存空间使任务同步和互相发送信息。 远程过程调用(RPC)RPC类似于LPC，只是在网上工作。RPC开始是出现在Sun微系统公司和HP公司的运行UNIX操作系统的计算机中。 how 管道(pipe)：管道可用于具有亲缘关系的进程间的通信，是一种半双工的方式，数据只能单向流动，允许一个进程和另一个与它有共同祖先的进程之间进行通信。 命名管道(named pipe)：命名管道克服了管道没有名字的限制，同时除了具有管道的功能外（也是半双工），它还允许无亲缘关系进程间的通信。命名管道在文件系统中有对应的文件名。命名管道通过命令mkfifo或系统调用mkfifo来创建。 信号(signal)：信号是比较复杂的通信方式，用于通知接收进程有某种事件发生了，除了进程间通信外，进程还可以发送信号给进程本身；linux除了支持Unix早期信号语义函数sigal外，还支持语义符合Posix.1标准的信号函数sigaction（实际上，该函数是基于BSD的，BSD为了实现可靠信号机制，又能够统一对外接口，用sigaction函数重新实现了signal函数）。 信号量（semaphore）：主要作为进程间以及同一进程不同线程之间的同步手段。 共享内存：使得多个进程可以访问同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。 内存映射：内存映射允许任何多个进程间通信，每一个使用该机制的进程通过把一个共享的文件映射到自己的进程地址空间来实现它。 消息队列：消息队列是消息的链接表，包括Posix消息队列和system V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点 套接字（Socket）：更为一般的进程间通信机制，可用于不同机器之间的进程间通信。起初是由Unix系统的BSD分支开发出来的，但现在一般可以移植到其它类Unix系统上：Linux和System V的变种都支持套接字。 消息队列消息传递与传统的应用程序交互的区别：实时性。Message Queue不适合实时性要求比较高的场景，因为Message Queue通过异步的方式与server端进行交互，不用担心server端的长时间处理过程。 概念 消息：两个计算机（或进程）之间传递的数据单位，例如字符串、文本等 消息队列（queue、message queue）：消息的容器；用于在消息传递的过程中保存消息的容器，充当消息源和目标之间的中间桥梁。队列的主要目的就在于提供路由保证消息的传递。 消息中间件：利用高效可靠的消息传递机制进行平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息排队模型，可以在分布式环境下扩展进程间的通信。 消息中间件对于消息中间件，常见的角色大致也就有Producer（生产者）、Consumer（消费者）、Broker（中转角色）；主要实现以下几个功能： 优先级(Message Priority)：Producer把消息发送给Broker来存储，那么我们就可以在消息队列中对我们的消息来进行排序，实现不同的优先级。从而满足我们复杂的业务需求。 消息排序(Message Order)，有的消息的处理是需要按照一定的顺序进行处理的，比如用户的创建订单、订单付款、订单完成。那么对于消费者也需要按照这个流程来消费，否则就没有意义了。 过滤器(Message Filter)：在消息队列中，也可以对我们的消息进行过滤，比如按照消息类型等条件来过滤 持久化存储(Message Persistence)：消息的持久化，防止了系统挂掉后，仍然能够从之前备份中恢复出来。持久化方式有以下几种： 持久化到数据库，比如MySQL 持久化到KV存储，比如Redis 文件形式持久化 丢弃策略：我们知道Broker是用来存储需要处理的消息，如果消息过多，导致Buffer满了，这时候就会采取一定的策略来丢弃已有的消息。 事务的支持：正如上面所谈到的订单的操作，因此消息中间件中也会提供对分布式事务的支持。 定时消息：在实际应用中，有时也会需要定时消费的功能，因此中间件中，也会对消息进行排序，然后实现定时发送或者消费消息的业务需求。 消息重试：考虑一下这个问题，如果消息消费失败后，怎么办，是等待处理这个消息呢？还是让消费者再次消费一次呢？通常情况下，采取后者的形式，因为大多数情况下，消费失败的原因在于该消息本身的原因，如果再次消费这个消息的话，还是会出现失败的情况，因此通常采取再次发送消息的方式。 回溯消费：什么是回溯消费呢？对于已经消费成功的消息，是不是在Broker中就丢弃该消息呢？显而易见是不可能的，因此需要中间件对该功能支持，支持已经消费的信息进行时间段内的存储，等待某一刻内该消息会被重新消费的可能。 python范例共享内存空间-Manager123456789101112131415161718192021from multiprocessing import Process, Managerimport osdef work(l, d): l.append(os.getpid()) d[os.getpid()] = os.getpid()if __name__ == &apos;__main__&apos;: m = Manager() # 由manager创建的列表和字典对象可以被所有进程操作 l = m.list([&apos;init&apos;]) d = m.dict(&#123;&apos;name&apos;: &apos;egon&apos;&#125;) p_l = [] for i in range(5): p = Process(target=work, args=(l, d)) p_l.append(p) p.start() for p in p_l: p.join() print(d, l) 队列-Queue q=Queue(3) 定义队列及其大小 q.put() 向队列放置元素 q.full() 队列是否已满 q.empty() 队列是否为空 q.put_nowait() 不能放置元素直接报异常 q.put(‘4’, block=False) 不能放则报异常【默认block为True】 q.put(‘4’, timeout=2) 放置时最多等待2s，超时则报异常 队列-JoinableQueue 和Queue方法类似，但是JoinableQueue消费者消费完时必须向生产者发送信号，生产者必须等待消费者消费完成时发送的信号 JoinableQueue.task_done()：向生产者发送已消费的信号 JoinableQueue.join()：等待消费者发送已消费的信号 123456789101112131415161718192021222324252627282930313233343536373839404142434445from multiprocessing import Process, Queue, Pool, Manager, JoinableQueueimport os, time, randomdef write(seq, q): print(&apos;Process to write: %s&apos; % os.getpid()) for value in seq: time.sleep(random.randint(1, 3)) print(&apos;put %s to queue...&apos; % value) q.put(value) # (JoinableQueue下）等待消费者发送已消费的信号 q.join()def read(q): print(&apos;Process to read: %s&apos; % os.getpid()) while True: time.sleep(random.randint(1, 3)) value = q.get(True) # （JoinableQueue下）向生产者发送已消费的信号 q.task_done() print(&apos;get %s from queue&apos; % value)# 进程模式下队列使用【使用原生的queue】if __name__ == &apos;__main__&apos;: #q = Queue() q = JoinableQueue() data = list(range(5)) pw = Process(target=write, args=(data, q)) pr = Process(target=read, args=(q,)) # 当主进程结束时子进程也跟着结束，子进程的daemon属性必须先于start设置 pr.daemon = True pw.start() pr.start() pw.join() # pr.join()# 进程池模式下队列使用【使用Manager的queue】#if __name__ == &apos;__main__&apos;:# manager = Manager()# q = manager.Queue()# p = Pool()# p.apply_async(write, args=(q,))# p.apply_async(read, args=(q,))# p.close()# p.join()]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>IPC</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python常用模块]]></title>
    <url>%2F2018%2F02%2F28%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%2Fpython%E5%BC%80%E5%8F%91%2Fpython%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[包和模块简介 在python中，一个py文件就是一个模块 使用模块还可以避免函数名和变量名冲突，相同的函数和变量完全可以分别存在不同的模块中；我们自己在编写模块时，不必考虑名字与其他模块冲突，但是尽量不要和内置函数名冲突。 为了避免模块名冲突，python又引入了按目录来组织模块的方法，称之为包。 每一个包目录下都会有__init__.py文件，在python2下这个文件是必须存在的【python3中可以不存在】，否则python就会把这个目录当成普通目录,而不是一个包；__init__.py可以是空文件，也可以有python代码；因为__init__.py本身就是一个模块，而它的模块名就是目录名。 模块与脚本 当python文件当做脚本直接运行时，__name__ = &#39;__main__&#39;; 当python文件作为模块导入时，__name__=&#39;文件名&#39;; 因此可以在if __name__ == &#39;__main__&#39;:下定义一些只作为脚本使用时的操作，而作为模块不执行。 导入方式 import a as b：导入模块a并设置为别名b，实际为导入该包下的init.py文件 from A.C import B：B为具体的模块名或函数名 包内导入： 绝对导入【最上层使用 包名】：from A.C import B 相对导入【使用逗号表示目录层级】：from ..C import B 搜索路径 sys.path显示模块搜索路径（使用列表的append方法可以修改） 当前目录 PYTHONPATH定义路径 python默认安装路径 subprocess作用 开启一个子进程，在其中执行系统命令 直接和进程通信获取执行结果，或者获取他们的返回码【成功或失败】 替代一些旧的模块，比如os.system、os.spawn* call方法 执行命令，并返回执行状态 其中shell参数为False时，命令需要通过列表的方式传入，当shell为True时，可直接传入命令 1234import subprocessprint('$ nslookup')r = subprocess.call(['nslookup', 'www.python.org']) #开启子进程，传入命令行参数，捕获返回码print('Exite code:', r) Popen方法执行命令，获取命令的执行结果 参数 args：shell命令，可以是字符串，或者序列类型，如list,tuple。 stdin,stdout,stderr：分别表示程序的标准输入，标准输出及标准错误 shell：与上面方法中用法相同 cwd：用于设置子进程的当前目录 env：用于指定子进程的环境变量。如果env=None，则默认从父进程继承环境变量 universal_newlines：不同系统的的换行符不同，当该参数设定为true时，则表示使用\n作为换行符 read/write直接和管道通信，进行读写操作 12345678obj = subprocess.Popen(["python"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)obj.stdin.write(b"print('test')")obj.stdin.close()cmd_out = obj.stdout.read()obj.stdout.close()cmd_error = obj.stderr.read()obj.stderr.close()print(cmd_out.decode()) communicate和管道通信，获取结果 1234567import subprocess#打开一个管道对象，并把命令行执行结果保存到管道中df = subprocess.Popen(["df", "-P", "-k"], stdout=subprocess.PIPE) #和管道通信，获取数据output = df.communicate()[0] #将获取的管道数据读到内存中【解码过程】print(output.decode("utf-8")) 进程间通信将一个子进程的输出，作为另一个子进程的输入 1234child1 = subprocess.Popen('cat /etc/passwd', shell=True, stdout=subprocess.PIPE)child2 = subprocess.Popen('grep "0:0"', shell=True, stdin=child1.stdout, stdout=subprocess.PIPE)out = child2.communicate()print(out[0].decode()) 其他进程方法123456import subprocesschild = subprocess.Popen('sleep 60',shell=True,stdout=subprocess.PIPE)child.poll() #检查子进程状态child.kill() #终止子进程child.send_signal() #向子进程发送信号child.terminate() #终止子进程 logging 记录日志的模块 参数 日志级别：critical&gt;error&gt;warning&gt;info&gt;debug&gt;noset 参数 含义 level 大于某等级的日志 %(asctime)s 创建时间 %(filename)s 当前执行的文件 %(lineno)d 当前行号 %(levelname)s 当前日志级别名称 %(message)s 当前日志信息 datefmt 时间格式 filename 记录的文件名 filemode 文件打开模式（’w’：写 ‘a’：追加） 范例123456789import logginglogging.basicConfig(level=logging.INFO, format='%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s', datefmt='%a, %d %b %Y %H:%M:%S', filename='/tmp/apiserver.log', filemode='w')logging.debug('this is debug message')logging.info('this is info message')logging.warning('this is warn message') 系统管理os os.path.isfile(__file__)：判断文件是否存在 os.environ：获取系统环境变量 os.path.abspath(__file__):当前文件的绝对路径 os.mkdir(‘ceshi’):创建目录 os.rmdir(‘ceshi’)：删除空目录 os.remove(‘./ceshi/1.py’)：删除文件 shutil shutil.rmtree(‘ceshi’)：删除目录 shutil.copy(‘module.py’, ‘ceshi.txt’)：复制文件 shutil.copytree(‘11’, ‘ww’)：复制目录 shutil.copytree(‘11’, ‘ww’, ignore=shutil.ignore_patterns(‘12’))：排除指定的文件 shutil.make_archive(‘22’, ‘gztar’, root_dir=’11’)：打包文件或目录 sys sys.argv：命令行参数【列表形式】 sys.stdout：进度条实现 123456789for i in range(30): # 向终端输出字符 sys.stdout.write('%s' % '#'*i) # 刷新缓存立即显示 sys.stdout.flush() time.sleep(0.5) # \r光标回到行首 sys.stdout.write('\r')sys.stdout.write('\n') argparse命令行选项与参数解析 123456789101112131415161718import argparseimport osdef nslookup(url): print(os.system('nslookup %s' % url))if __name__ == '__main__': parser = argparse.ArgumentParser() # 设置需要解析的选项参数 parser.add_argument('--hostname', '-n', help="url info") # 从命令行获取选项参数，并将其转换为字典 args = vars(parser.parse_args()) if args['hostname']: nslookup(args['hostname']) else: # 打印帮助信息 print(parser.print_help()) time12345678910111213import time# 获取当前系统时间time1 = time.localtime()# 获取当前系统时间的子项print(time1.tm_year)# 获取格式化时间print(time.strftime('%Y-%m-%d %H:%M:%S'))print(time.strftime('%X'))# 格式化时间time2 = time.strptime('2018-05-12 10:04:55', '%Y-%m-%d %H:%M:%S')print(time2)# 暂停3stime.sleep(3) datetime语法123from datetime import datetime, timedelta# 获取当前系统时间now = datetime.now() timestamp我们把1970年1月1日 00:00:00 UTC+00:00时区的时刻称为epoch time，记为0；timestamp的值与时区毫无关系，因为timestamp一旦确定，其UTC时间就确定了；转换到任意时区的时间也是完全确定的，这就是为什么计算机存储的当前时间是以timestamp表示的，因为全球各地的计算机在任意时刻的timestamp都是完全相同的 datetime.timestamp(now) 时间格式 函数 含义 范例 timestamp() datetime转换为timestamp fromtimestamp() timestamp转换为本地datetime strptime() str转换为datetime datetime.strptime(‘2015-12-20 11:11:11’, ‘%Y-%m-%d %H:%M:%S’) strftime() datetime转换为str datetime.now().strftime(‘%y-%d-%m’) 123456789# timestamptm = datetime.timestamp(now)print(datetime.fromtimestamp(tm))# strfprint(now.strftime('%Y-%m-%d'))# strptime = '1988-04-26 00:00'time1 = datetime.strptime(time, '%Y-%m-%d %H:%S')print(type(time1)) 时间计算123# timedeltaTom = now + timedelta(hours=1)print(Tom) random返回随机数 方法123456789101112131415# 0~1之间的随机小数a = random.random()# 1~5之间的随机整数a = random.randint(1, 5)# 1~5之间的随机整数【不包含结束】a = random.randrange(1, 5)# 从列表中随机选择一个数字a = random.choice(range(1, 10))# 从列表中国随机选择2个数字组成新的结果a = random.sample(range(1, 10), 2)# 1~3之间的随机小数a = random.uniform(1, 3)# 乱序重排a = [1, 3, 8, 2, 4]random.shuffle(a) 范例 生成由数字和大写字母组成的n位字符串 12345678910def v_code(n): res = "" for i in range(n): # chr 数字转字母 str1 = chr(random.randint(65, 90)) int1 = str(random.randint(0, 9)) res1 = random.choice([str1, int1]) res += res1 return resprint(v_code(4)) hashlib 摘要算法又称哈希算法、散列算法。它通过一个函数，把任意长度的数据转换为一个长度固定的数据串（通常用16进制的字符串表示） 摘要算法不是加密算法，不能用于加密（因为无法通过摘要反推明文），只能用于防篡改；但是它的单向计算特性决定了可以在不存储明文口令的情况下验证用户口令 通过在原始口令中“加盐”并配合用户名，可以实现不同用户名相同口令但是在数据库中以不同的摘要存储 1234567891011import hashlibmd5 = hashlib.md5()md5.update("how to use python".encode("utf-8"))print(md5.hexdigest())user = 'hejingqi'password = '123456'salt = '123eedcdwsx'sha1 = hashlib.sha1()sha1.update((user + password + salt).encode('utf-8'))print(sha1.hexdigest()) urllibget请求12345678910from urllib import requestreq = request.Request('http://www.douban.com/')req.add_header('User-Agent', 'Mozilla/6.0 (iPhone; CPU iPhone OS 8_0 like Mac OS X) \ AppleWebKit/536.26 (KHTML, like Gecko) Version/8.0 Mobile/10A5376e Safari/8536.25')with request.urlopen(req) as f: print('status: %s %s' % (f.status, f.reason)) for k, v in f.getheaders(): print('%s: %s' % (k, v)) print('Data: %s' % f.read().decode('utf-8')) 下载request.urlretrieve(&#39;http://www.521609.com/uploads/allimg/140717/1-140GF92J7.jpg&#39;, &#39;a.jpg&#39;)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>subprocess</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yaml语法学习]]></title>
    <url>%2F2018%2F02%2F27%2F%E9%80%9A%E7%94%A8%E6%8A%80%E8%83%BD%2Fyaml%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[语法 大小写敏感 使用缩进表示层级关系 缩进时只允许使用空格，不允许使用tab 缩进时的空格数量不重要，重要的是同一层级的元素左侧对齐 #表示注释 yaml文件应当以’—‘【三横杠】开头，以’…’【三点】结尾 字典语法：以key: value形式表示字典（冒号后必须跟着一个空格） 行内式dict: {a: &#39;test1&#39;, b: &#39;test2&#39;} 复合式123dict: a: &apos;test3&apos; b: &apos;test4&apos; 列表语法：列表的所有成员都是从同一缩进级别开始的行，以“ - ”开头（短划线和空格） 行内式list: [&#39;one&#39;, &#39;two&#39;, &#39;three&#39;] 复合式1234list: - one - two - three 纯量注意 字符串有多行内容时，使用|或&gt;表示 字符串内容默认可以直接表示，不用添加引号 当字符串内容以[] {} &gt; | * &amp; ! % # \ @ ,`开头时，应当对字符串整体使用双引号 字符串中包含单引号、双引号、反斜线，应当对字符串整体使用双引号，同时也要使用转义字符进行转义 由于”: “【冒号后接空格】表示一个映射【字典、列表】，“ #”【空格后接井号】表示注释，因此字符串中包含这些时需要整体使用引号 单引号和双引号的区别就是，双引号可以使用转义字符【比如\n】 内容 数字 字符串 12345678str: | line 1 line 2 line 3str: &gt; line 1 line 2 line 3 布尔值 引用 &amp;定义锚点，&lt;&lt;表示合并到当前数据，*引用锚点 范例1-字典 1234567891011# 数据结构dict1: &amp;defaults &#123;a: &apos;test1&apos;, b: &apos;test2&apos;&#125;dict2: c: &apos;test3&apos; d: &apos;test4&apos; &lt;&lt;: *defaults# 输出print(dict1, dict2)&#123;&apos;a&apos;: &apos;test1&apos;, &apos;b&apos;: &apos;test2&apos;&#125; &#123;&apos;c&apos;: &apos;test3&apos;, &apos;a&apos;: &apos;test1&apos;, &apos;d&apos;: &apos;test4&apos;, &apos;b&apos;: &apos;test2&apos;&#125; 范例2-列表 123456ceshi: - &amp;var a - b - c - d - *var]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>yaml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[版本库命令-git]]></title>
    <url>%2F2018%2F02%2F26%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E8%BE%85%E5%8A%A9%E5%BC%80%E5%8F%91%2F%E7%89%88%E6%9C%AC%E5%BA%93%E5%91%BD%E4%BB%A4-git%2F</url>
    <content type="text"><![CDATA[状态迁移版本库=》工作区=》暂存区=》版本库 clean 从工作区中清理未追踪的文件或目录 参数 -d 清除未追踪的目录 -f 强制删除未追踪的文件或目录 -x 删除为追踪的文件，使目录保持干净的原始状态应用清除未追踪的文件或目录：git clean -xdf reset指定路径或文件的回退 还原暂存区内容，即撤销 git add操作 git reset HEAD 【file】 版本库整体回退 在git中用HEAD表示当前版本,上个版本HEAD^,往上100个版本HEAD~100 回退到上个版本：git reset –hard HEAD^ 回退到特定版本：git reset –hard 2ff6b08 checkout 切换分支或恢复工作区为版本库文件【撤销工作区变更】 分支切换 切换：git checkout 【branch_name】 创建+切换：git checkout -b 【branch_name】 【start_point】 从某一分支创建新分支，不写默认为当前分支 tag git tag：查看标签列表 git show tag_name：查看标签变更 git tag tag_name：使用当前commit打标签 git tag -d tag_name：删除本地标签 -m：tag注释 git tag tag_name commit_id：针对某个commit打标签 add/rm add：提交工作区变更到暂存区 rm：删除版本库文件 config 设置或获取版本库或全局配置 全局设置 –global 有此参数对此电脑下的所有仓库有效，形成的参数文件在用户主目录的.gitconfig文件中 无此参数，只对某个仓库有效，形成的参数文件在仓库.git/config文件中配置别名 git config –global alias.st status git config –global alias.last ‘log -1’设置用户及邮件 git config –global user.name “何静奇” git config –global user.email “hejingqi@quxiu8.com“ push/pull push：推送本地版本库对象到远程 tag： 推送指定标签：git push origin 1.4 推送所有标签：git push origin –tags 删除远程标签：git push origin –delete tag branch： 推送分支：git push &lt;远程主机名&gt; &lt;本地分支名&gt; &lt;远程分支名&gt; 如果远程分支被省略，如上则表示将本地分支推送到与之存在追踪关系的远程分支 删除远程分支：git push origin –delete 【branchName】 范例： git push origin master：origin为主机名，在配置文件中设置 git push -u origin master：如果当前分支与多个主机存在追踪关系，则可以使用 -u 参数指定一个默认主机，这样后面就可以不加任何参数使用git push pull：拉取远程版本库对象到本地 other diff：对比工作区和版本库中某个文件的差异 commit：提交暂存区至版本库 status：版本库状态查看 reflog：查看命令操作历史 clone：克隆分支 将远程库克隆至本地【默认克隆master分支】：git clone git@github.com:simple0426/Spoon-Knife.git -b dev 克隆dev分支 log：历史变更查看 –pretty=oneline branch：分支管理 git branch 查看分支 git branch -r 查看远程分支 git branch 【name】 创建分支 git branch -d 【name】 删除分支 git branch –set-upstream dev origin/dev 关联本地分支和远程分支 merge：分支合并 合并某分支到当前分支 git merge dev init：将普通目录初始化为版本库 .gitignore 配置.gitignore文件忽略部分文件或目录的变更 FAQgit中文数字类型乱码git config –global core.quotepath false 强制放弃本地修改和增加的文件 此时，本地修改“多于”远程库 git checkout . 放弃修改 git clean -xdf 删除未追踪文件 强制本地与远程版本库保持一致 此时本地与远程库的均有修改 git fetch –all 取回远程端所有【分支】修改，但不和本地合并 git reset –hard origin/master 将版本强制设置到origin/master【远程master】这个分支的最新代码 放弃本地所有修改等操作，保持与远程代码库的一致 git pull 与远程分支保持同步 remote 变更本地关联的远程库：git remote set-url origin URL 故障收集 git bash乱码：git config –global core.quotepath false 清除污点提交或大文件前言 git库提交内容有时候会包含大文件或密码这样的隐私信息，当使用正常的git提交等措施删除文件或密码信息后，仍然可以从历史提交记录中找到这些内容。对于删除的大文件而言，它会占用仓库存储空间；对于密码等隐私内容来说，隐私内容依然存在。 git自带的工具git-filter-branch可以清除历史提交信息，但是操作比较复杂 可以使用第三方工具BFG Repo-Cleaner方便的处理文件和密码的历史提交信息 工具介绍 bfg是一个jar文件，下载地址 以下命令bfg就是【java -jar bfg.jar】的别名 操作步骤 克隆仓库元数据：git clone –mirror git@github.com:my-account/my-repo.git 移除文件【可以是下列任意一个操作】： 删除所有文件id_rsa或id_dsa：bfg –delete-files id_{dsa,rsa} my-repo.git 删除目录.git：bfg –delete-folders .git –delete-files .git –no-blob-protection my-repo.git 删除大于1M的文件：bfg –strip-blobs-bigger-than 1M my-repo.git 删除密码等文本：bfg –replace-text banned.txt my-repo.git 在指定的文件【比如：banned.txt】中一行定义一个要删除的密码等隐私信息，执行删除后，密码信息会被【REMOVED】关键词替换 比如在banned.txt中包含原来密码信息【426hx118】，则在执行操作时会将历史记录中=的【426hx118】替换为REMOVED 将本地修改推送到远程 cd my-repo.git git reflog expire –expire=now –all &amp;&amp; git gc –prune=now –aggressive git push 将远程元数据信息同步到本地 cd my-repo git pull]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件共享samba]]></title>
    <url>%2F2018%2F02%2F26%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E8%BE%85%E5%8A%A9%E5%BC%80%E5%8F%91%2F%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%ABsamba%2F</url>
    <content type="text"><![CDATA[安装samba软件用户设置创建系统用户组groupadd marketop 创建系统用户 useradd -g marketop -s /usr/sbin/nologin -M ceshi1 useradd -g marketop -s /usr/sbin/nologin -M marketop 将系统用户转为samba用户 同时设置密码 smbpasswd -a marketop smbpasswd -a ceshi1 目录设置创建目录mkdir market_operation 变更目录所有者chown ceshi1.marketop market_operation/ 目录设置粘滞位 当一个目录被设置为”粘着位”(用chmod a+t),则该目录下的文件只能由一、超级管理员删除二、该目录的所有者删除三、该文件的所有者删除也就是说,即便该目录是任何人都可以写,但也只有文件的属主才可以删除文件。 chmod a+t market_operation/ 配置文件设置可用参数 [public] 共享文件夹名称 path 共享路径 public 公共文件夹，不许凭证可访问（访问权限在本地设置） writable 可对文件夹写操作 Valid users 有访问文件夹权限的用户【@为组 】 browseable 该文件夹是否可见 read only =yes （默认） write list= @shichang，cw1 可写权限列表（当前面为readonly=yes 时可写用户列表） directory mask= 0744 （文件夹建立后的默认权限） create mask = 0600（文件建立后的默认权限） 范例1234567891011121314151617181920212223242526[global] workgroup = WORKGROUP server string = %h server (Samba, Ubuntu) dns proxy = no security = user log file = /var/log/samba/log.%m max log size = 1000 syslog = 0 panic action = /usr/share/samba/panic-action %d server role = standalone server passdb backend = tdbsam obey pam restrictions = yes unix password sync = yes passwd program = /usr/bin/passwd %u passwd chat = *Enter\snew\s*\spassword:* %n\n *Retype\snew\s*\spassword:* %n\n *password\supdated\ssuccessfully* . pam password change = yes map to guest = bad user usershare allow guests = yes# 自定义选项[市场部] path = /home/dell/market_operation readonly = yes write list = zhangwanting valid users = @marketop directory mask = 0755 create mask = 0640 测试windows 连接：win + R =》 \\10.10.10.244 切换用户测试： 删除网络连接：net use **** /d macfinder =》 连接服务器 =》 smb://10.10.10.244 linuxmount -t cifs –o username=sc1,passwordd=sc1 //10.10.10.1/Market /mnt]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件同步rsync]]></title>
    <url>%2F2018%2F02%2F26%2F%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%2F%E6%96%87%E4%BB%B6%E5%90%8C%E6%AD%A5rsync%2F</url>
    <content type="text"><![CDATA[简介 远程同步：remote synchronization 是一个快速的、全能的远程或本地的文件复制工具 只支持本地、本地与远程之间的文件拷贝，不支持俩个远程主机之间的文件拷贝 当只有源没有目标指定时，命令类似于【ls -l】 使用方式本地模式rsync [OPTION…] SRC… [DEST] 远程shell模式 Pull: rsync [OPTION…] [USER@]HOST:SRC… [DEST] Push: rsync [OPTION…] SRC… [USER@]HOST:DEST 远程daemon模式 Pull rsync [OPTION…] [USER@]HOST::SRC… [DEST] rsync [OPTION…] rsync://[USER@]HOST[:PORT]/SRC… [DEST] Push rsync [OPTION…] SRC… [USER@]HOST::DEST rsync [OPTION…] SRC… rsync://[USER@]HOST[:PORT]/DEST 主要功能 支持拷贝链接、设备、属主、属组、权限 类似于tar命令一样的排除选项 类似于版本控制系统一样的排除模式 可以使用任何的远程管道方式传输，包括ssh、rsh等 不需要超级用户权限 最小花费的管道传输 支持匿名和认证的rsync进程模式 命令选项 目录末尾加斜线，则只拷贝目录内的内容；与此相反，没有斜线时，会拷贝目录本身以及目录下的内容。 -e 指定远程shell选项，如：-e ‘ssh -p 50121’ –password-file 指定连接rsync daemon的密码文件 -C –cvs-exclude 和版本控制系统一样忽略文件 -v ,–verbose 显示传输详情 -z , - -compress 压缩传输 -a ,- -archive 归档模式，表示以递归方式传输文件，并保持文件属性不变 -P ,- -progress 显示传输进度 –delete 保持源和目标文件的一致性，如果目标的文件在源没有则删除 –delete-before 在传输前删除相关文件 include与exclude参数 –exclude=PATTERN exclude files matching PATTERN –exclude-from=FILE read exclude patterns from FILE –include=PATTERN don’t exclude files matching PATTERN –include-from=FILE read include patterns from FILE 特别注意 当要排除特定内容时，可以只使用exclude选项以排除指定的文件或目录 但要只包含特定内容时，必须先使用include包含特定内容，再使用exclude排除其余部分 .当使用include-from或exclude-from包含文件时，一行一个匹配规则， include选项引用时，规则行首使用“+” exclude选项引用时，规则行首使用“-” 匹配规则以“/”开始时，则传输根路径上的文件和目录都匹配 匹配规则以“/”结束，则只匹配目录 范例include 只同步部分目录及其下的目录和文件 include：rsync -azvP –include “pre/“ –include “keyfile/“ –exclude “/*” files/ test include-from：rsync -azvP –include-from include_file.list –exclude “/*” python_scripts/ test11/ 123include_file.list文件+ test1 + test2 exclude 排除部分不需要同步的目录 exclude：rsync -azvP –exclude “prod/“ files/ test exclude-from：rsync -azvP –exclude-from exclude_file.list python_scripts/ test11/ 1234exclude_file.list文件- aa- socket_tcp.py- test1/test234 daemon模式配置文件 rsyncd.conf 12345678910111213141516171819202122# rsyncd.confuid = rsyncgid = rsyncuse chroot = nomax connections = 2000timeout = 600pid file = /var/run/rsyncd.pidlock file = /var/run/rsync.locklog file = /var/log/rsyncd.logignore errorsread only = falselist = falsehosts allow = 172.16.1.0/24hosts deny = 0.0.0.0/32auth users = tridge, susansecrets file = /etc/rsync.password[backup]comment = backuppath = /backup[share]comment = sharepath = /share rsync.password 文件属主：chown rsync.rsync rsync.password 文件权限：chmod 0600 rsync.password 12tridge:mypasssusan:herpass 服务启动 默认配置 默认使用873端口 默认配置文件/etc/rsyncd.conf 启动 rsync –daemon –config=config_file daemon错误集锦 服务端有防火墙阻挡 123[root@client-2 log]# rsync -avzP messages_2014-03-30.tar.gz susan@192.168.100.1::oldboy --password-file=/etc/rsyncd.secretsrsync: failed to connect to 192.168.100.1: No route to host (113)rsync error: error in socket IO (code 10) at clientserver.c(124) [sender=3.0.6] 服务端log显示secrets file权限有问题，此文件不能被其他人读取 12345678# client[root@client-3 mnt]# rsync -avzP /mnt rsync1@192.168.100.2::oldboyPassword: @ERROR: auth failed on module oldboyrsync error: error starting client-server protocol (code 5) at main.c(1503) [sender=3.0.6]# server2014/04/11 16:22:26 [1768] secrets file must not be other-accessible (see strict modes option) 客户端提示secrets file权限有问题，此文件不能被其他人读取 123[root@client-3 mnt]# rsync -avzP /mnt rsync1@192.168.100.2::oldboy --password-file=/etc/rsyncd.secrets password file must not be other-accessiblecontinuing without password file ssh使用系统账号登陆 123[root@client-2 oldboy]# rsync -avzP -e &quot;ssh -p 22&quot; /etc/hosts susan@192.168.100.1::oldboy --password-file=/etc/rsyncd.secretssusan@192.168.100.1&apos;s password: rsync error: received SIGINT, SIGTERM, or SIGHUP (code 20) at rsync.c(544) [sender=3.0.6]]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>rsync</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitbook简单使用]]></title>
    <url>%2F2018%2F02%2F26%2F%E9%80%9A%E7%94%A8%E6%8A%80%E8%83%BD%2Fgitbook%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[介绍 范例参考 可以将markdown书写的文章转换为html文档直接在网页上浏览 可以将markdown书写的文章导出为电子书 可以搭配github做文章版本管理 安装 安装nodejs 使用nmp安装gitbook-clinpm install gitbook-cli -g 目录设置 创建电子书目录[同时也是github库] 创建SUMMARY.md文件,此文件主要描述电子书的目录结构 创建book.json文件，此文件主要用于描述gitbook提供web服务时使用的插件及配置 1234567891011121314151617&#123; "plugins": [ "-lunr", "-search", "-livereload", "expandable-chapters-small", "anchors", "anchor-navigation-ex", "edit-link" ], "pluginsConfig": &#123; "edit-link": &#123; "base": "https://github.com/simple0426/blog/edit/master", "label": "修改本文" &#125; &#125;&#125; 命令使用 gitbook help 使用帮助 gitbook install 根据book.json中的设置安装相应插件 gitbook build 根据SUMMARY.md的设置在当前目录的_book目录下生产用于提供web服务的html文件 gitbook serve –port 80 在80端口提供浏览电子书的web服务 默认4000端口 此命令同时也会执行build的功能 导出电子书 需要安装calibre【使用其中的ebook-convert这个插件】 导出命令gitbook pdf . my.pdf 插件使用 官网地址 中文参考]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>gitbook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客应用hexo]]></title>
    <url>%2F2018%2F02%2F26%2F%E9%80%9A%E7%94%A8%E6%8A%80%E8%83%BD%2F%E5%8D%9A%E5%AE%A2%E5%BA%94%E7%94%A8hexo%2F</url>
    <content type="text"><![CDATA[安装参考 安装前提 Node.js Git 安装命令npm install -g hexo-cli 建站hexo建站 hexo init blog cd blog npm install 使用git版本控制 目录切换：cd blog 初始化：git init 关联远程：git remote add origin git@github.com:simple0426/blog.git 保持同步：git pull origin master 目录介绍 scaffolds：模版文件夹。Hexo的模板是指在新建的markdown文件中默认填充的内容。 source：资源文件夹是存放用户资源的地方。 除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。 Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。 themes：主题 文件夹。Hexo 会根据主题来生成静态页面。 标签插件相当于在markdown文件中使用非markdown语法，它是的hexo私有语法，不能被markdown解析，但可以被hexo解析 引入其他文章语法：{% post_link path/to/file [title] %}范例：{% post_link 系统管理/系统基础/shell编程 shell %}注意：post_link使用的路径为相对于source/posts的路径 引入代码语法：{% include [title] [lang:language] path/to/file %}范例：{% include_code python登录 lang:python login.py %}目录设置： 代码目录【code_dir】在主站config.yml中设置 【code_dir：code】表示路径为source/code 上述login.py表示的实际路径为source/code/login.py Next主题下载 cd blog git clone https://github.com/iissnan/hexo-theme-next themes/next 配置站点配置 theme: next【主题】 language: zh-Hans【语言】 order_by: -updated【以文章修改时间排序】 主题配置 scheme: Mist【主题风格】 文章缩略显示 12auto_excerpt: enable: true 菜单配置【主题配置】 12345menu: home: / || home tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive 分类与标签 创建categories和tags目录 分类页 标签页 搜索安装npm install hexo-generator-searchdb 配置 主题配置 12345678search: path: search.xml field: post format: html limit: 10000# Local searchlocal_search: enable: true hexo命令 hexo init：新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。 hexo new 文章标题：新建一篇文章 hexo new draft 文章标题：新建一篇草稿【或私密文章】 在source/_drafts目录下建立相应文件 hexo generate|g：生成静态文件。 hexo server|s -p, –port 重设端口【默认4000】 -s, –static 只使用静态文件 -l, –log 启动日记记录，使用覆盖记录格式 –drafts 将草稿也显示【默认不显示草稿】 hexo deploy|d：部署网站。 -g, –generate 部署之前预先生成静态文件 hexo clean：清除缓存文件 (db.json) 和已生成的静态文件 (public)。 hexo publish 文章标题：将草稿发布为文章 FAQ文章插入图片 主站配置：post_asset_folder:这个选项设置为true 安装插件：npm install hexo-asset-image 使用： 运行hexo n “xxxx”来生成md博文时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹 把图片复制进入文件夹内 markdown文章内引入![](xxxx目录/图片) github-pages配置 使用gh-pages分支方式部署 安装插件npm install hexo-deployer-git 主站配置123456url: http://blog.unlazy.cn/root: /deploy:- type: git repository: git@github.com:simple0426/blog.git branch: gh-pages 自定义域名 在source文件夹下建立CNAME文件 CNAME文件内容：blog.unlazy.cn 部署githubhexo d -g public的压缩bug 现象：将windows下的public文件夹使用zip压缩后，传输至linux系统，文章标题为中文的的文件或目录名乱码 原因：这是zip格式的缺陷，所以目前并没有很完美的解决办法。参考 解决：使用tar方式传输public文件夹 特殊字符处理 特别注意的是小括号 ( ) 大括号 { } ,如果不小心写了,你执行hexo s –debug可能报一些莫名其妙的错误! 12345678910111213141516171819202122! &amp;#33; — 惊叹号Exclamation mark ” &amp;#34; &amp;quot; 双引号Quotation mark # &amp;#35; — 数字标志Number sign $ &amp;#36; — 美元标志Dollar sign % &amp;#37; — 百分号Percent sign &amp; &amp;#38; &amp;amp; Ampersand ‘ &amp;#39; — 单引号Apostrophe ( &amp;#40; — 小括号左边部分Left parenthesis ) &amp;#41; — 小括号右边部分Right parenthesis * &amp;#42; — 星号Asterisk + &amp;#43; — 加号Plus sign &lt; &amp;#60; &amp;lt; 小于号Less than = &amp;#61; — 等于符号Equals sign &gt; &amp;#62; &amp;gt; 大于号Greater than ? &amp;#63; — 问号Question mark @ &amp;#64; — Commercial at [ &amp;#91; --- 中括号左边部分Left square bracket \ &amp;#92; --- 反斜杠Reverse solidus (backslash) ] &amp;#93; — 中括号右边部分Right square bracket &#123; &amp;#123; — 大括号左边部分Left curly brace | &amp;#124; — 竖线Vertical bar &#125; &amp;#125; — 大括号右边部分Right curly brace]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown学习]]></title>
    <url>%2F2018%2F02%2F26%2F%E9%80%9A%E7%94%A8%E6%8A%80%E8%83%BD%2Fmarkdown%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[段落段落是由一个或多个的文本行组成，段落前后必须包含一个或多个空行段落内的换行方式：两个空格+回车 标题1234# 级别一## 级别二###### 级别六末尾可以加#，但只起美观作用，且#的数量可以任意 区块引用在段落的开始使用任意数量的&gt;符号划分缩进层级 列表无序列表展示 使用*或+或-，然后跟一个空格或制表符，最多三个空格 列表必须是一个单独的段落[列表前必须是标题或空行] 1234* apple * banana * orange * coconut 有序列表显示: 使用数字+英文句点 1233. Bird 1. McHale 8. Parish 多级列表使用缩进实现123* aa * bb * cc 代码代码区块 在原始代码的每一行前添加4个空格或一个制表符 或者使用```代码``` 为了使语法高亮，应当提示代码类型如下所示：```pythonprint(‘hello’)``` 文本中的代码标记[反引号]小段代码标记：1python代码:`print(&apos;hello world&apos;)` 链接行内式12&gt;链接到[django](https://www.djangoproject.com/)站点 链接到[admin](/admin)站点 参考式1234&gt;链接到[百度][]站点 链接到[腾讯][qq]站点[百度]: http://www.baidu.com[qq]: http://www.qq.com 原始链接 使用方括号包围网址或邮箱地址 12&lt;http://www.163.com&gt; &lt;hejingqi@quxiu8.com&gt; 引入图片123美女图片: ![beauty][][beauty]: http://file.youxiniao.com/uploads/allimg/160615/63-160615144538.jpg 页面内跳转12[点击跳转](#jump) #使用Markdown跳转&lt;span id=&quot;jump&quot;&gt;跳转到这&lt;/span&gt; #设置跳转的锚点[id] 标记 使用*或下划线来强调,单个为斜体，2个为加粗12*斜体* __加粗__ 反斜杠[在文本中使用*-等字符的原始含义] 删除线 显示：删除 源码：~~删除~~ 分割线可以使用连续3个以上星号或减号做分割线【星号或减号之间可以有空格】，但是行内不能有其他字符]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
</search>
