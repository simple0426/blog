# redis.conf必须作为第一个参数，如下
# ./redis-server /path/to/redis.conf

# redis涉及内存时的计量单位
# 1k => 1000 bytes
# 1kb => 1024 bytes
# 1m => 1000000 bytes
# 1mb => 1024*1024 bytes
# 1g => 1000000000 bytes
# 1gb => 1024*1024*1024 bytes

################################## INCLUDES ###################################

# include包含的文件不能被<config rewrite>命令改写
# 因为redis指令总是使用配置的最后一个值，所以需要注意include指令是在此文件的首行还是尾行
# include /path/to/local.conf
# include /path/to/other.conf

################################## MODULES #####################################

# 加载自定义模块
# loadmodule /path/to/my_module.so
# loadmodule /path/to/other_module.so

################################## NETWORK #####################################

# 如果没有指定bind参数，redis运行在所有网络接口上
# redis可以指定运行在一个或多个网络接口
# bind 192.168.1.100 10.0.0.1
# bind 127.0.0.1 ::1
bind 127.0.0.1

# 公网保护模式，默认开启；
# 如果没有配置bind指令，或配置密码认证信息，则只能从127.0.0.1等回环接口访问
protected-mode yes

# 监听端口，默认6379
# 如果设置为0，则不在tcp上监听
port 6379

# 定义tcp队列长度，在linux环境下，linux内核会自动将其值变更为
# /proc/sys/net/core/somaxconn的值，以确保同时提高somaxconn
# 和tcp_max_syn_backlog的值达到期望的结果
tcp-backlog 511

# 设置unix socket文件，默认不产生socket文件
# unixsocket /tmp/redis.sock
# unixsocketperm 700

# 客户端连接超时时间
timeout 0

# tcp连接心跳检测，从3.2.1之后，默认值为300s
tcp-keepalive 300

################################# GENERAL #####################################

# 是否开启后台运行模式【默认no】
# 如果设置为后台模式，则会产生一个pid文件
daemonize no

# 如果使用其他控制程序(如upstart、systemd)控制redis启停，相关设置
#   supervised no      - no supervision interaction
#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode
#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET
#   supervised auto    - detect upstart or systemd method based on
#                        UPSTART_JOB or NOTIFY_SOCKET environment variables
# Note: these supervision methods only signal "process is ready."
#       They do not enable continuous liveness pings back to your supervisor.
supervised no

# 指定后台运行模式时的pid文件位置，如果没有指定，默认写入/var/run/redis.pid
pidfile /var/run/redis_6379.pid

# 日志级别
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably)
# warning (only very important / critical messages are logged)
loglevel notice

# 日志文件位置
logfile ""

# 是否使用系统的syslog方式写日志
# syslog-enabled no

# Specify the syslog identity.
# syslog-ident redis

# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.
# syslog-facility local0

# 设置数据库数量，每个库都有独立的命名空间
databases 16

# 交互模式下，是否显示redis log信息
always-show-logo yes

################################ SNAPSHOTTING  ################################

# 设置保存数据到rdb文件的频率：save <seconds> <changes>
# 以下设置的含义：
# 900秒后至少有1个key发生变更
# 300秒后至少有10个key发生变更
# 60秒后至少有10000个key发生变更
# 
# 取消所有保存频率的设置
#   save ""
save 900 1
save 300 10
save 60 10000

# 开启rdb写入时，如果后台持久化存储失败则停止客户端写操作
stop-writes-on-bgsave-error yes

# rdb文件压缩存储
rdbcompression yes

# rdb校验【增加可用性，但会增加存储或加载开销】
rdbchecksum yes

# rdb文件名
dbfilename dump.rdb

# 指定rdb和aof文件的存储目录
dir ./

################################# REPLICATION #################################

# redis复制是异步的，但是可以配置停止写操作，当指定数量的从机没有连接
# redis复制会自动重连，不需要特别关注；但可以根据需要，配置复制队列大小(repl-backlog-size)
# slaveof <masterip> <masterport>

# 如果主机配置requirepass参数，则从机也需要配置认证信息
# masterauth <master-password>

# 主从复制中断时，从机的处理：
# slave-serve-stale-data设置为（默认）yes，则从机可以使用过期的数据为客户端提供服务
# slave-serve-stale-data设置为no，则从机会对除了INFO和SLAVEOF的其他命令返回错误信息：
# 	"SYNC with master in progress"
slave-serve-stale-data yes

# 从机只读设置
slave-read-only yes

# rdb文件传输方式（复制同步策略）：
# 有盘方式：主开启写进程在本地写rdb文件，在rdb文件阶段性写完后，
#	就可以和（多个）从机通信，然后由父进程传输文件到从机
# 无盘方式（网络）：主开启写进程直接将rdb文件写入从机网络socket，
#	当阶段性写操作完成后，主和另一个从机通信进行复制操作
#
# 复制同步其他要点：
# 1.无盘模式当前是实验性功能
# 2.新建一个从机或从机重连时会执行一个全量同步
# 3.使用无盘方式，会配置一个等待时间，以便所有从机可达以并行方式传输
# 4.磁盘容量小或磁盘io小，同时网络带宽大的情况更适合使用无盘方式
repl-diskless-sync no

# 无盘方式工作时，一旦同步开始，新的从机并不会被主接纳；
#	所以需要配置一个等待时间，以确认所有从机可达
# 默认5秒，0则进行等待直接开始复制操作
repl-diskless-sync-delay 5

# 从机检测主机可达的时间间隔
# repl-ping-slave-period 10

# 复制超时时间
# 它包含，主机视角的ping响应超时，从机角度的ping和数据传输超时
# 它必须比repl-ping-slave-period时间长
# repl-timeout 60

# 设置为yes时，会传输更小的数据包并使用更小的带宽，但延迟会增加【linux内核限制，最多40ms】
# 设置为no，延迟会更低，但是需要更大的带宽
# 默认为no，此时复制延迟更低；但是主从之间的网络繁忙时，设置为yes则更合适 
repl-disable-tcp-nodelay no

# 主从复制时允许从机断开，重连时可以继续同步的缓冲区大小【避免全量同步】
# repl-backlog-size 1mb

# 超时则主释放同步缓冲区，0则永不释放
# repl-backlog-ttl 3600

# 从机优先级，主要是redis sentinel使用，当master出现异常时提升从机为master
# 数字小的从机优先被提升为主机，优先级为0的从机永远不会成为主机，默认100
slave-priority 100

# 最大限度的减少主机宕机造成的数据丢失影响，其中1个参数设置为0则关闭此项功能
# 范例：至少3个从机的延迟小于10，否则master停止写入操作
# min-slaves-to-write 3
# min-slaves-max-lag 10

# 主从复制时，主查看从机ip的方式：INFO replication 和 ROLE
# 当在端口转发和nat网络情况下，上述命令获取的信息会有误
# 通过在从机声明如下变量，可以告诉主机自己真实的ip和port【可选设置】
# slave-announce-ip 5.5.5.5
# slave-announce-port 1234

################################## SECURITY ###################################

# 客户端密码认证【也是主从复制的密码】，由于redis没有防爆破的手段，所以需要设置一个强密码
# requirepass foobared

# 重命名命令：
# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
# 也可通过空字符串“删除”命令
# rename-command CONFIG ""
# 【注意】重命名命令在写入aof或传输到从机时会出问题

################################### CLIENTS ####################################

# 设置客户端最大连接数，默认10000
# 如果redis不能设置最大文件描述符数量，
#	则maxclients被设置为当前最大文件描述符数量减32【redis保留部分描述符供内部使用】
# maxclients 10000

############################## MEMORY MANAGEMENT ################################

# 最大可用内存【超过后根据驱逐策略删除key】
# 如果设置驱逐策略为noeviction，则对于写命令则返回错误，读命令则正常返回
# 当redis作为LRU或LFU缓存时，或在对于一个使用noeviction驱逐策略的实例设置硬限制时，都非常有用
# 这个最大限制不包含主从复制的输出缓冲区大小（repl-backlog-size）
# maxmemory <bytes>

# 内存使用达到最大限制时的key删除策略【默认noeviction】：
# volatile-lru -> 使用LRU策略驱逐具有过期设置的key
# allkeys-lru -> 使用LRU策略驱逐任意的key
# volatile-lfu -> 使用LFU策略驱逐具有过期设置的key
# allkeys-lfu -> 使用LFU策略驱逐任意的key
# volatile-random -> 从具有过期设置的key中随机删除一个
# allkeys-random -> 从所有key中随机删除一个
# volatile-ttl -> 删除最接近过期的key
# noeviction -> 不驱逐任何key，向写操作返回错误
#
# LRU：Least Recently Used【最近最少使用】
# LFU：Least Frequently Used【经常最少使用】
# LRU, LFU 和 volatile-ttl都使用了近似的随机算法
#
# 即使使用上述策略，如果没有合适的key被删除，依然会对写操作返回错误，包含的写操作如下：
# set setnx setex append
# incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd
# sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby
# zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby
# getset mset msetnx exec sort
#
# maxmemory-policy noeviction

# 启动内存回收时，单次取样数量；3个速度最快，但是策略执行不精确；5个足够；10个最精确，但是更消耗cpu
# maxmemory-samples 5

############################# LAZY FREEING ####################################

# redis有两种删除key的模式，默认的del命令是一种（同步）阻塞式删除
# 在进行删除操作的同时停止处理新命令，阻塞时间的长短根据删除对象的大小而定
#
# redis（4.0.0之上版本）也提供非阻塞式删除命令，比如unlink（非阻塞del）、flushdb|flushall的async选项
# 这些命令会在限定时间内执行完，但是会在后台开启一个新线程持续释放内存空间
#
# 在下列情景中，默认情况下，redis会以阻塞方式删除key或清空库【独立于用户操作命令】
# 1.根据最大内存和驱逐策略删除key
# 2.由于key的过期设置（EXPIRE）
# 3.对一个已存在的key进行操作，如RENAME
# 4.在复制操作时，从机执行全量复制时，会清空从机rdb
# 
# 可以单独设置以上情况以非阻塞方式释放内存，具体命令如下：
lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
slave-lazy-flush no

############################## APPEND ONLY MODE ###############################

# 默认情况下，redis异步导出数据集到磁盘；基于rdb的不同刷新策略（save）可能会有部分数据丢失
# aof和rdb可以同时开启；当aof开启时，redis启动时会将加载aof文件
appendonly no

# aof文件名
appendfilename "appendonly.aof"

# fsync为数据写入磁盘的策略
# no: 让操作系统处理什么时候刷新数据到磁盘，此时速度最快
# always: 每次都等待数据写入aof文件，速度最慢，安全性最好
# everysec: 每秒刷新数据到磁盘，折中选择【默认选项】
appendfsync everysec

# 在后台执行BGSAVE或BGREWRITEAOF命令时，是否阻止主进程进行磁盘刷新操作
# 这个选项是为了减轻磁盘写压力，但会造成数据丢失【默认不开启】
no-appendfsync-on-rewrite no

# 自动重写aof文件时，增长的大小所占的百分比
auto-aof-rewrite-percentage 100
# 自动重写aof文件时，要求最小增加的文件大小
auto-aof-rewrite-min-size 64mb

# 是否允许加载不完整（被截断）的aof文件；如果设置为no，必须使用redis-check-aof修复aof文件
aof-load-truncated yes

# 使用aof和rdb混合方式持久化数据【可以更快的执行重写和恢复操作，默认关闭】
aof-use-rdb-preamble no

################################ LUA SCRIPTING  ###############################

# lua脚本执行超时时间（毫秒），0或负值则不限制时间 
# 超过时间，redis会记录脚本依然在执行，并对查询信息返回错误
# 【SCRIPT KILL】命令会停止一个不含写操作的脚本
# 【SHUTDOWN NOSAVE】可以停止包含写操作的脚本
lua-time-limit 5000

################################ REDIS CLUSTER  ###############################

# 是否开启redis集群功能
# redis单实例模式和集群模式不能相互转换，只能在一开始就确定使用的方式
# cluster-enabled yes

# redis集群节点的配置文件，每个节点都有一个配置文件
# 这个配置文件由集群节点自动创建和更新，一般不用手动编辑
# cluster-config-file nodes-6379.conf

# 节点断开超时时间（毫秒），超过这个时间，节点被认为是失败状态
# 其他内部限制时间都是这个值的倍数
# cluster-node-timeout 15000

# 如果出故障的主机的从机数据太旧，则应该避免此从机执行故障切换
# 通过下面两种方式判断数据的新旧情况：
# 1.当有多个从机时，会根据他们从主上接收数据的多少（offset）选择谁执行故障切换提升为主
# 2.单个从机计算，则根据距离上次接收ping响应、接收命令的时间（连接状态下）
# 	或距离与主断开的时间
# 
# 第2点可以由用户控制，超过【(node-timeout * slave-validity-factor) + repl-ping-slave-period】
# 	的从机不能提升为主
# slave-validity-factor是从机选举为主的因子：
# 1）非常大的值允许有非常旧数据的从机执行故障切换
# 2）值太小则无法在众多从机中选出提升为主的从机
# 3）为了最大可用性，允许从机立即提升为主，但是依然会根据从主机接收数据的多少选择提升为主的从机
#	默认为0，超时即选为主，其他数据n，则超过（n*timeout+ping）后选举为主，此段时间内，集群不可用除非原来的主恢复
#
# cluster-slave-validity-factor 10

# 在保证主机至少有如下数量从机的情况下，此主机的剩余从机可以自动迁移到孤立的主机（没有从机）
# cluster-migration-barrier 1

# 是否要求所有数据槽都可用时集群才可用
# 设置为no时允许集群数据不完整时依然可以对外提供查询服务
# cluster-require-full-coverage yes

# 当主故障时，禁止从机执行故障切换；此时会手动处理主机故障切换操作
# 在有多个数据中心时非常有用，此时会期望只有这个数据中心的节点出现全部故障时才执行切换
# cluster-slave-no-failover no

########################## CLUSTER DOCKER/NAT support  ########################

# 当遇到ip nat或端口转发时【如docker等容器环境】集群节点地址发现会失败，所以
# 每个集群节点都需要知道一个公共地址，即为如下配置
# * cluster-announce-ip
# * cluster-announce-port
# * cluster-announce-bus-port
#
# Example:
#
# cluster-announce-ip 10.1.1.5
# cluster-announce-port 6379
# cluster-announce-bus-port 6380

################################## SLOW LOG ###################################

# redis慢日志记录超过一定执行时间的查询命令
# 这个时间不包含io操作，比如：和客户端通信、发送响应
# 仅包含：命令的实际执行时间，此时线程被阻塞不能服务于其他请求

# 执行时间阈值（微秒），超过则记录在内存中
# 负值则关闭slowlog功能，0则记录每一个命令
slowlog-log-slower-than 10000

# 由于慢日志记录在内存中，所以需要设置最多存多少条慢记录，超过则超过最旧的记录
# 【SLOWLOG RESET】强制回收内存
slowlog-max-len 128

################################ LATENCY MONITOR ##############################

# 超过阈值的延迟因素会被记录，默认为0，关闭功能 
# 可以在交互式界面设置此参数："CONFIG SET latency-monitor-threshold <milliseconds>"
latency-monitor-threshold 0

############################# EVENT NOTIFICATION ##############################

# redis可以通知发布/订阅的客户端发生在键空间的事件，
# 相关文档：http://redis.io/topics/notifications
#
# redis可以选择要通知的事件，每个类型的事件都可以通过单字符定义
#  K     Keyspace events, published with __keyspace@<db>__ prefix.
#  E     Keyevent events, published with __keyevent@<db>__ prefix.
#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...
#  $     String commands
#  l     List commands
#  s     Set commands
#  h     Hash commands
#  z     Sorted set commands
#  x     Expired events (events generated every time a key expires)
#  e     Evicted events (events generated when a key is evicted for maxmemory)
#  A     Alias for g$lshzxe, so that the "AKE" string means all the events.
# 
# notify-keyspace-events使用0或多个字符构成的字符串串作为参数，
# 0个字符串表示关闭事件通知功能（默认）
# 至少需要指定K或E，否则会没有事件通知
#
# 范例1：开启列表和通用事件，从事件名称的角度，使用如下
#  notify-keyspace-events Elg
#
# 范例2：获取提交给频道【__keyevent@0__:expired】的过期key流
#  notify-keyspace-events Ex
notify-keyspace-events ""

############################### ADVANCED CONFIG ###############################

# 数据类型为hash，在条目数量小、最大条目值小于给定阈值时，使用内存高效的存储结构存储数据
# 超过阈值时，使用原生的数据结构存储数据；这个设定主要是节约存储空间
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

# 数据类型是list，在没有超过下列阈值时，也会被编码，以节省存储空间
# 定义为正值时，表示单个列表最大元素数量
# 定义为负值时【-5到-1】表示单个列表的最大存储空间
# -5: max size: 64 Kb  <-- not recommended for normal workloads
# -4: max size: 32 Kb  <-- not recommended
# -3: max size: 16 Kb  <-- probably not recommended
# -2: max size: 8 Kb   <-- good
# -1: max size: 4 Kb   <-- good
list-max-ziplist-size -2

# 数据类型是list，也可以被压缩
# 压缩深度定义如下
# 0：关闭列表所有节点的压缩
# 1：列表的首尾节点不压缩，其他节点都压缩
# 2：列表的首及相邻节点、尾及相邻节点不压缩，其他节点都压缩
# n：以此类推，首尾的n个节点不压缩，中间节点压缩
list-compress-depth 0

# 数据类型为set，且仅由恰好是基数为10的整数（64为有符号整数）组成的字符串
# 当set类型的大小小于阈值时，可以使用这种节省内存的编码
set-max-intset-entries 512

# 数据类型sorted sets（zset），也可以使用节省内存的方式存储数据
# 仅当sorted sets的长度或条目数小于阈值
zset-max-ziplist-entries 128
zset-max-ziplist-value 64

# HyperLogLog sparse representation bytes limit. The limit includes the
# 16 bytes header. When an HyperLogLog using the sparse representation crosses
# this limit, it is converted into the dense representation.
#
# A value greater than 16000 is totally useless, since at that point the
# dense representation is more memory efficient.
#
# The suggested value is ~ 3000 in order to have the benefits of
# the space efficient encoding without slowing down too much PFADD,
# which is O(N) with the sparse encoding. The value can be raised to
# ~ 10000 when CPU is not a concern, but space is, and the data set is
# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.
hll-sparse-max-bytes 3000

# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in
# order to help rehashing the main Redis hash table (the one mapping top-level
# keys to values). The hash table implementation Redis uses (see dict.c)
# performs a lazy rehashing: the more operation you run into a hash table
# that is rehashing, the more rehashing "steps" are performed, so if the
# server is idle the rehashing is never complete and some more memory is used
# by the hash table.
#
# The default is to use this millisecond 10 times every second in order to
# actively rehash the main dictionaries, freeing memory when possible.
#
# If unsure:
# use "activerehashing no" if you have hard latency requirements and it is
# not a good thing in your environment that Redis can reply from time to time
# to queries with 2 milliseconds delay.
#
# use "activerehashing yes" if you don't have such hard requirements but
# want to free memory asap when possible.
activerehashing yes

# The client output buffer limits can be used to force disconnection of clients
# that are not reading data from the server fast enough for some reason (a
# common reason is that a Pub/Sub client can't consume messages as fast as the
# publisher can produce them).
#
# The limit can be set differently for the three different classes of clients:
#
# normal -> normal clients including MONITOR clients
# slave  -> slave clients
# pubsub -> clients subscribed to at least one pubsub channel or pattern
#
# The syntax of every client-output-buffer-limit directive is the following:
#
# client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>
#
# A client is immediately disconnected once the hard limit is reached, or if
# the soft limit is reached and remains reached for the specified number of
# seconds (continuously).
# So for instance if the hard limit is 32 megabytes and the soft limit is
# 16 megabytes / 10 seconds, the client will get disconnected immediately
# if the size of the output buffers reach 32 megabytes, but will also get
# disconnected if the client reaches 16 megabytes and continuously overcomes
# the limit for 10 seconds.
#
# By default normal clients are not limited because they don't receive data
# without asking (in a push way), but just after a request, so only
# asynchronous clients may create a scenario where data is requested faster
# than it can read.
#
# Instead there is a default limit for pubsub and slave clients, since
# subscribers and slaves receive data in a push fashion.
#
# Both the hard or the soft limit can be disabled by setting them to zero.
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit slave 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60

# Client query buffers accumulate new commands. They are limited to a fixed
# amount by default in order to avoid that a protocol desynchronization (for
# instance due to a bug in the client) will lead to unbound memory usage in
# the query buffer. However you can configure it here if you have very special
# needs, such us huge multi/exec requests or alike.
#
# client-query-buffer-limit 1gb

# In the Redis protocol, bulk requests, that are, elements representing single
# strings, are normally limited ot 512 mb. However you can change this limit
# here.
#
# proto-max-bulk-len 512mb

# Redis calls an internal function to perform many background tasks, like
# closing connections of clients in timeout, purging expired keys that are
# never requested, and so forth.
#
# Not all tasks are performed with the same frequency, but Redis checks for
# tasks to perform according to the specified "hz" value.
#
# By default "hz" is set to 10. Raising the value will use more CPU when
# Redis is idle, but at the same time will make Redis more responsive when
# there are many keys expiring at the same time, and timeouts may be
# handled with more precision.
#
# The range is between 1 and 500, however a value over 100 is usually not
# a good idea. Most users should use the default of 10 and raise this up to
# 100 only in environments where very low latency is required.
hz 10

# When a child rewrites the AOF file, if the following option is enabled
# the file will be fsync-ed every 32 MB of data generated. This is useful
# in order to commit the file to the disk more incrementally and avoid
# big latency spikes.
aof-rewrite-incremental-fsync yes

# Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good
# idea to start with the default settings and only change them after investigating
# how to improve the performances and how the keys LFU change over time, which
# is possible to inspect via the OBJECT FREQ command.
#
# There are two tunable parameters in the Redis LFU implementation: the
# counter logarithm factor and the counter decay time. It is important to
# understand what the two parameters mean before changing them.
#
# The LFU counter is just 8 bits per key, it's maximum value is 255, so Redis
# uses a probabilistic increment with logarithmic behavior. Given the value
# of the old counter, when a key is accessed, the counter is incremented in
# this way:
#
# 1. A random number R between 0 and 1 is extracted.
# 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).
# 3. The counter is incremented only if R < P.
#
# The default lfu-log-factor is 10. This is a table of how the frequency
# counter changes with a different number of accesses with different
# logarithmic factors:
#
# +--------+------------+------------+------------+------------+------------+
# | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |
# +--------+------------+------------+------------+------------+------------+
# | 0      | 104        | 255        | 255        | 255        | 255        |
# +--------+------------+------------+------------+------------+------------+
# | 1      | 18         | 49         | 255        | 255        | 255        |
# +--------+------------+------------+------------+------------+------------+
# | 10     | 10         | 18         | 142        | 255        | 255        |
# +--------+------------+------------+------------+------------+------------+
# | 100    | 8          | 11         | 49         | 143        | 255        |
# +--------+------------+------------+------------+------------+------------+
#
# NOTE: The above table was obtained by running the following commands:
#
#   redis-benchmark -n 1000000 incr foo
#   redis-cli object freq foo
#
# NOTE 2: The counter initial value is 5 in order to give new objects a chance
# to accumulate hits.
#
# The counter decay time is the time, in minutes, that must elapse in order
# for the key counter to be divided by two (or decremented if it has a value
# less <= 10).
#
# The default value for the lfu-decay-time is 1. A Special value of 0 means to
# decay the counter every time it happens to be scanned.
#
# lfu-log-factor 10
# lfu-decay-time 1

########################### ACTIVE DEFRAGMENTATION #######################
#
# WARNING THIS FEATURE IS EXPERIMENTAL. However it was stress tested
# even in production and manually tested by multiple engineers for some
# time.
#
# What is active defragmentation?
# -------------------------------
#
# Active (online) defragmentation allows a Redis server to compact the
# spaces left between small allocations and deallocations of data in memory,
# thus allowing to reclaim back memory.
#
# Fragmentation is a natural process that happens with every allocator (but
# less so with Jemalloc, fortunately) and certain workloads. Normally a server
# restart is needed in order to lower the fragmentation, or at least to flush
# away all the data and create it again. However thanks to this feature
# implemented by Oran Agra for Redis 4.0 this process can happen at runtime
# in an "hot" way, while the server is running.
#
# Basically when the fragmentation is over a certain level (see the
# configuration options below) Redis will start to create new copies of the
# values in contiguous memory regions by exploiting certain specific Jemalloc
# features (in order to understand if an allocation is causing fragmentation
# and to allocate it in a better place), and at the same time, will release the
# old copies of the data. This process, repeated incrementally for all the keys
# will cause the fragmentation to drop back to normal values.
#
# Important things to understand:
#
# 1. This feature is disabled by default, and only works if you compiled Redis
#    to use the copy of Jemalloc we ship with the source code of Redis.
#    This is the default with Linux builds.
#
# 2. You never need to enable this feature if you don't have fragmentation
#    issues.
#
# 3. Once you experience fragmentation, you can enable this feature when
#    needed with the command "CONFIG SET activedefrag yes".
#
# The configuration parameters are able to fine tune the behavior of the
# defragmentation process. If you are not sure about what they mean it is
# a good idea to leave the defaults untouched.

# Enabled active defragmentation
# activedefrag yes

# Minimum amount of fragmentation waste to start active defrag
# active-defrag-ignore-bytes 100mb

# Minimum percentage of fragmentation to start active defrag
# active-defrag-threshold-lower 10

# Maximum percentage of fragmentation at which we use maximum effort
# active-defrag-threshold-upper 100

# Minimal effort for defrag in CPU percentage
# active-defrag-cycle-min 25

# Maximal effort for defrag in CPU percentage
# active-defrag-cycle-max 75

